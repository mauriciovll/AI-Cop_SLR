{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0ef248",
   "metadata": {},
   "source": [
    "## Generate the initial keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a21236b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar arquivo xml\n",
    "tree = ET.parse('../../data/raw/seed-articles.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Definir lista vazia para armazenamento de dados\n",
    "seed_articles_list = []\n",
    "\n",
    "# Iterate sobre os <record> elementos e extrair as informações\n",
    "for record in root.findall('records/record'):\n",
    "    \n",
    "    # Extrair dados de cada campo\n",
    "    database = record.find('database').text if record.find('database') is not None else None\n",
    "    ref_type = record.find('ref-type').get('name') if record.find('ref-type') is not None else None\n",
    "    authors = \", \".join([author.text for author in record.findall('contributors/authors/author')]) if record.findall('contributors/authors/author') is not None else None\n",
    "    title = record.find('titles/title').text if record.find('titles/title') is not None else None\n",
    "    secondary_title = record.find('titles/secondary-title').text if record.find('titles/secondary-title') is not None else None\n",
    "    periodical = record.find('periodical/full-title').text if record.find('periodical/full-title') is not None else None\n",
    "    pages = record.find('pages').text if record.find('pages') is not None else None\n",
    "    volume = record.find('volume').text if record.find('volume') is not None else None\n",
    "    issue = record.find('issue').text if record.find('issue') is not None else None\n",
    "    keywords = \", \".join([keyword.text for keyword in record.findall('keywords/keyword')]) if record.findall('keywords/keyword') is not None else None\n",
    "    year = record.find('dates/year').text if record.find('dates/year') is not None else None\n",
    "    pdf_url = record.find('urls/pdf-urls/url').text if record.find('urls/pdf-urls/url') is not None else None\n",
    "    web_url = record.find('urls/web-urls/url').text if record.find('urls/web-urls/url') is not None else None\n",
    "    abstract = record.find('abstract').text if record.find('abstract') is not None else None\n",
    "    \n",
    "    # Adicionar os dados à lista\n",
    "    seed_articles_list.append([database, ref_type, authors, title, secondary_title, periodical, pages, volume, issue, keywords, year, pdf_url, web_url, abstract])\n",
    "\n",
    "# Criar o dataframe\n",
    "seed_articles_df = pd.DataFrame(seed_articles_list, columns=['database', 'ref-type', 'authors', 'title', 'secondary-title', 'periodical', 'pages', 'volume', 'issue', 'keywords', 'year', 'pdf_url', 'web_url', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69d7849-dd2f-4083-9e23-c557fa5cc0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>ref-type</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>secondary-title</th>\n",
       "      <th>periodical</th>\n",
       "      <th>pages</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>web_url</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emerging-techs-articles.enl</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Sivarajah, Uthayasankar, Kamal, Muhammad Musta...</td>\n",
       "      <td>Critical analysis of Big Data challenges and a...</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>263-286</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>Big Data, Big Data Analytics, Challenges, Meth...</td>\n",
       "      <td>2017</td>\n",
       "      <td>internal-pdf://2017 - Sivarajah et al. - Journ...</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.jbusres.2016.08.001</td>\n",
       "      <td>Big Data (BD), with their potential to ascerta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emerging-techs-articles.enl</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Peppard, Joe, Edwards, Chris, Lambert, Rob</td>\n",
       "      <td>Exploiting Big Data from mobile device sensor ...</td>\n",
       "      <td>MIS Quarterly</td>\n",
       "      <td>MIS Quarterly</td>\n",
       "      <td>115-117</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2011</td>\n",
       "      <td>internal-pdf://2011 - Peppard, Edwards, Lamber...</td>\n",
       "      <td>None</td>\n",
       "      <td>The role of chief information officer (CIO) is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emerging-techs-articles.enl</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Tambe, Prasanna, Hitt, Lorin, Rock, Daniel, Br...</td>\n",
       "      <td>NBER WORKING PAPER SERIES DIGITAL CAPITAL AND ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>2020</td>\n",
       "      <td>internal-pdf://2020 - Tambe et al. - Unknown.pdf</td>\n",
       "      <td>http://www.nber.org/papers/w28285</td>\n",
       "      <td>General purpose technologies like information ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      database         ref-type  \\\n",
       "0  Emerging-techs-articles.enl  Journal Article   \n",
       "1  Emerging-techs-articles.enl  Journal Article   \n",
       "2  Emerging-techs-articles.enl  Journal Article   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Sivarajah, Uthayasankar, Kamal, Muhammad Musta...   \n",
       "1         Peppard, Joe, Edwards, Chris, Lambert, Rob   \n",
       "2  Tambe, Prasanna, Hitt, Lorin, Rock, Daniel, Br...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Critical analysis of Big Data challenges and a...   \n",
       "1  Exploiting Big Data from mobile device sensor ...   \n",
       "2  NBER WORKING PAPER SERIES DIGITAL CAPITAL AND ...   \n",
       "\n",
       "                secondary-title                    periodical    pages volume  \\\n",
       "0  Journal of Business Research  Journal of Business Research  263-286     70   \n",
       "1                 MIS Quarterly                 MIS Quarterly  115-117     10   \n",
       "2                          None                          None     None   None   \n",
       "\n",
       "  issue                                           keywords  year  \\\n",
       "0  None  Big Data, Big Data Analytics, Challenges, Meth...  2017   \n",
       "1     2                                                     2011   \n",
       "2  None                                                     2020   \n",
       "\n",
       "                                             pdf_url  \\\n",
       "0  internal-pdf://2017 - Sivarajah et al. - Journ...   \n",
       "1  internal-pdf://2011 - Peppard, Edwards, Lamber...   \n",
       "2   internal-pdf://2020 - Tambe et al. - Unknown.pdf   \n",
       "\n",
       "                                           web_url  \\\n",
       "0  http://dx.doi.org/10.1016/j.jbusres.2016.08.001   \n",
       "1                                             None   \n",
       "2                http://www.nber.org/papers/w28285   \n",
       "\n",
       "                                            abstract  \n",
       "0  Big Data (BD), with their potential to ascerta...  \n",
       "1  The role of chief information officer (CIO) is...  \n",
       "2  General purpose technologies like information ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando o resultado\n",
    "seed_articles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b18257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_kw_list\n",
      "social media                 13\n",
      "big data                     11\n",
      "                              7\n",
      "twitter                       5\n",
      "market efficiency             4\n",
      "                             ..\n",
      "greenwashing                  1\n",
      "customers                     1\n",
      "earnings persistence          1\n",
      "revenues                      1\n",
      "analyst earnings forecast     1\n",
      "Name: count, Length: 210, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Colocar palavas-chave em minúsculas\n",
    "seed_articles_df['keywords'] = seed_articles_df['keywords'].str.lower()\n",
    "\n",
    "# Dividir as palavras-chave em listas\n",
    "seed_articles_df['initial_kw_list'] = seed_articles_df['keywords'].str.split(',')\n",
    "\n",
    "# Explodir a lista em uma série plana, para que cada palavra-chave esteja em uma linha\n",
    "initial_kw_list = seed_articles_df['initial_kw_list'].explode().str.strip()\n",
    "\n",
    "from collections import Counter\n",
    "# Contar as palavras-chave\n",
    "initial_kw_list_counts = initial_kw_list.value_counts()\n",
    "print(initial_kw_list_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c1a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar arquivo excel\n",
    "initial_kw_list_counts.to_excel('../../data/processed/_1_initial-kw-list.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1e1d7",
   "metadata": {},
   "source": [
    "A figura 2 apresenta a etapa de geração da lista final de palavras-chave. Conforme apresentado na figura, com base na lista inicial foi feita busca em Web of Science do resultado da busca os artigos foram organizados por número de citações e a lista com os 50 mais citados foi importada para o gerenciador de referências."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287fc25",
   "metadata": {},
   "source": [
    "![image-2.png](static/images/_01-02-Final-KW-definition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14eaf6",
   "metadata": {},
   "source": [
    "Em seguida essa lista de 50 artigos foi exportada em formato .xml para tratamento dos dados e geração de uma lista final de palavras-cahve, conforme scripts a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbdeb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the XML file\n",
    "tree = ET.parse('data/top-50-review.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define a empty list to store the data\n",
    "top_50_list = []\n",
    "\n",
    "# Iterate over the <record> elements and extract the information\n",
    "for record in root.findall('records/record'):\n",
    "    \n",
    "    # Extract data from each field\n",
    "    database = record.find('database').text if record.find('database') is not None else None\n",
    "    ref_type = record.find('ref-type').get('name') if record.find('ref-type') is not None else None\n",
    "    authors = \", \".join([author.text for author in record.findall('contributors/authors/author')]) if record.findall('contributors/authors/author') is not None else None\n",
    "    title = record.find('titles/title').text if record.find('titles/title') is not None else None\n",
    "    secondary_title = record.find('titles/secondary-title').text if record.find('titles/secondary-title') is not None else None\n",
    "    periodical = record.find('periodical/full-title').text if record.find('periodical/full-title') is not None else None\n",
    "    pages = record.find('pages').text if record.find('pages') is not None else None\n",
    "    volume = record.find('volume').text if record.find('volume') is not None else None\n",
    "    issue = record.find('issue').text if record.find('issue') is not None else None\n",
    "    keywords = \", \".join([keyword.text for keyword in record.findall('keywords/keyword')]) if record.findall('keywords/keyword') is not None else None\n",
    "    year = record.find('dates/year').text if record.find('dates/year') is not None else None\n",
    "    pdf_url = record.find('urls/pdf-urls/url').text if record.find('urls/pdf-urls/url') is not None else None\n",
    "    web_url = record.find('urls/web-urls/url').text if record.find('urls/web-urls/url') is not None else None\n",
    "    abstract = record.find('abstract').text if record.find('abstract') is not None else None\n",
    "    \n",
    "    # Add the extracted data to the list\n",
    "    top_50_list.append([database, ref_type, authors, title, secondary_title, periodical, pages, volume, issue, keywords, year, pdf_url, web_url, abstract])\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "top_50_df = pd.DataFrame(top_50_list, columns=['database', 'ref-type', 'authors', 'title', 'secondary-title', 'periodical', 'pages', 'volume', 'issue', 'keywords', 'year', 'pdf_url', 'web_url', 'abstract'])\n",
    "\n",
    "# Check the result\n",
    "top_50_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar palavas-chave em minúsculas\n",
    "top_50_df['keywords'] = top_50_df['keywords'].str.lower()\n",
    "\n",
    "# Dividir as palavras-chave em listas\n",
    "top_50_df['final_kw_list'] = top_50_df['keywords'].str.split(';')\n",
    "\n",
    "# Explodir a lista em uma série plana, para que cada palavra-chave esteja em uma linha\n",
    "final_kw_list = top_50_df['final_kw_list'].explode().str.strip()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Contar as palavras-chave\n",
    "final_kw_list_counts = final_kw_list.value_counts()\n",
    "print(final_kw_list_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3430047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar arquivo excel\n",
    "final_kw_list_counts.to_excel('data/final-kw-list.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
