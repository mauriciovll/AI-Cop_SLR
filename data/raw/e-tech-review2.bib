@article{Wang2020,
abstract = {The issuance and implementation of intellectual property policies have promoted the rapid development of intellectual property intermediary services in China, bringing new opportunities and challenges for public sectors of the government. With their continuous development, Internet of Things (IoT) technology and big data have become the analytical tools widely applied in many technical fields. Through the analysis of IoT data, the optimal resource configuration could be obtained, which would guide both governments and enterprise managers to make scientific decisions in terms of future development. {\textcopyright} 2020 Informa UK Limited, trading as Taylor & Francis Group.},
annote = {Cited by: 9},
author = {Wang, Wenjing},
doi = {10.1080/17517575.2020.1712744},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Wang - Enterprise Information Systems.pdf:pdf},
issn = {1751-7575},
journal = {Enterprise Information Systems},
keywords = {Internet of Things,data analysis,data mining,intellectual property policy},
language = {English},
month = {nov},
number = {9-10},
pages = {1475--1493},
title = {{Data analysis of intellectual property policy system based on Internet of Things}},
url = {https://www.tandfonline.com/doi/full/10.1080/17517575.2020.1712744},
volume = {14},
year = {2020}
}
@article{Schug2020,
abstract = {This case study examines the experience of the interdisciplinary Measuring the Effects of Catch Shares (MECS) project, a five-year demonstration project designed to explore the opportunities and constraints for third-party acquisition, organization, and communication of government fisheries statistics in order to track the ecological, economic, social, and governance outcomes of catch share programs. Catch share programs, whereby fishery managers allocate to private entities percentages of the total amount of fish that can be caught in a year, have been used to manage some US fisheries since the 1990s. Given the high financial stakes of commercial fisheries and the wide-ranging impacts ascribed to these programs, they are among the most controversial and contentious tools of contemporary fisheries management. The goal of the MECS project was to create an interactive, web-based platform for conveying a set of neutral, scientific indicators based on the best available fisheries data that could be used by fishing industry participants, fishery managers, and other interested parties to supplement and inform their own understanding of catch share program effects. The MECS project focused on the effects of two US catch share programs: the Northeast Multispecies Sector Program implemented in 2010 in the Northeast groundfish fishery and the Shorebased IFQ Program implemented in 2011 in the West Coast groundfish trawl fishery. The MECS project encountered data access challenges but ultimately succeeded in developing a website that has been received by members of the private and public sector alike as a useful tool that brings together and communicates disparate information that is not otherwise readily accessible. {\textcopyright} 2020 Elsevier Ltd},
annote = {Cited by: 2},
author = {Schug, Donald M. and Taylor, Peter H. and Iudicello, Suzanne and Swasey, Jill H.},
doi = {10.1016/j.marpol.2020.104272},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Schug et al. - Marine Policy.pdf:pdf},
issn = {0308597X},
journal = {Marine Policy},
keywords = {Catch shares,Data confidentiality,Data visualization,Fisheries management,Performance indicators,Stakeholder engagement},
language = {English},
month = {dec},
pages = {104272},
title = {{Using online data visualization and analysis to facilitate public involvement in management of catch share programs}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0308597X20309180},
volume = {122},
year = {2020}
}
@article{Desouza2020,
abstract = {Artificial intelligence applications in cognitive computing systems can be found in organizations across every market, including chatbots that help customers navigate websites, predictive analytics systems used for fraud detection, and augmented decision-support systems for knowledge workers. In this article, we share reflections and insights from our experience with AI projects in the public sector that can add value to any organization. We organized our findings into four thematic domains—(1) data, (2) technology, (3) organizational, and (4) environmental—and examine them relative to the phases of AI. We conclude with best practices for capturing value with cognitive computing systems. {\textcopyright} 2019 Kelley School of Business, Indiana University},
annote = {Cited by: 143},
author = {Desouza, Kevin C. and Dawson, Gregory S. and Chenok, Daniel},
doi = {10.1016/j.bushor.2019.11.004},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Desouza, Dawson, Chenok - Business Horizons.pdf:pdf},
issn = {00076813},
journal = {Business Horizons},
keywords = {Artificial intelligence applications,Cognitive computing systems,Innovation management,Technology adoption},
language = {English},
month = {mar},
number = {2},
pages = {205--213},
title = {{Designing, developing, and deploying artificial intelligence systems: Lessons from and for the public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0007681319301582},
volume = {63},
year = {2020}
}
@article{Mattei2020,
abstract = {Digital healthcare promises to achieve cost-efficiency gains, improve clinical effectiveness, support better public sector governance by enhancing transparency and accountability, and increase confidence in medical diagnoses, especially in the field of oncology. This article aims to discuss the benefits offered by digital technologies in tax-based European healthcare systems against the backdrop of structural bureaucratic rigidities and a slow pace of implementation. Artificial intelligence (AI) will transform the existing delivery of healthcare services, inducing a redesign of public accountability systems and the traditional relationships between professionals and patients. Despite legitimate ethical and accountability concerns, which call for clearer guidance and regulation, digital governance of healthcare is a powerful means of empowering patients and improving their medical treatment in terms of quality and effectiveness. On the path to better health, the use of digital technologies has moved beyond the back office of administrative processes and procedures, and is now being applied to clinical activities and direct patient engagement. {\textcopyright} 2020 The Author(s).},
annote = {Cited by: 3},
author = {Mattei, Paola},
doi = {10.1186/s13584-020-0361-1},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Mattei - Israel Journal of Health Policy Research.pdf:pdf},
issn = {20454015},
journal = {Israel Journal of Health Policy Research},
keywords = {Accountability,Artificial intelligence,Digital health,Health care organizations,Patients' engagement,Tax-funded health care systems},
language = {English},
number = {1},
title = {{Digital governance in tax-funded European healthcare systems: From the Back office to patient empowerment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078000204&doi=10.1186%2Fs13584-020-0361-1&partnerID=40&md5=9b3f60175ef8fd242ecebc3b8934cad4},
volume = {9},
year = {2020}
}
@article{Al-Ruithe2020,
abstract = {Businesses have grown more sophisticated in their use of data, which drives new demands that require different ways to handle this data. Data management solutions on their own are becoming very expensive and unable to cope with the reality of everlasting data complexity. Forward-thinking organisations believe that the only way to solve the data problem will be the implementation of effective data governance. Attempts to govern data failed before, as they were driven by information technology (IT), and affected by rigid processes and fragmented activities carried out on a system-by-system basis. Until very recently, governance remained mostly informal, with very ambiguous and generic regulations in silos around specific enterprise repositories, lacking structure and the wider support of the organisation. Despite its highly recognised importance, the area of data governance is still underdeveloped and under-researched. In the cloud computing context, the cloud brings new issues of data governance, where the loss of governance is one of the top risks of cloud computing. Thus, before adopting the cloud, the organisations should develop a cloud data governance programme. It is important, therefore, to understand the enabling factors for successful implementation of cloud data governance in organisations. However, as every organisation has its own constraints and requirements, the phrase ‘no one size fits all' applies in this case. This study focuses on the case of the public sector in the Kingdom of Saudi Arabia. Therefore, the aim of this research is to identify the enabling factors in adopting and implementing cloud data governance in the Saudi public sector. The study's sample covered the largest and most important Saudi public sector organisations, with questionnaires distributed to relevant employees. The results of the study were based on 206 respondents, and structural equation modelling (SEM) was used to evaluate these results. {\textcopyright} 2018 Elsevier B.V.},
annote = {Cited by: 11},
author = {Al-Ruithe, Majid and Benkhelifa, Elhadj},
doi = {10.1016/j.future.2017.12.057},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Al-Ruithe, Benkhelifa - Future Generation Computer Systems.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud computing,Cloud data governance,Data governance,Data science,Saudi Arabia,Saudi vision 2030,Structural Equation Modelling (SEM)},
language = {English},
month = {jun},
pages = {1061--1076},
title = {{Determining the enabling factors for implementing cloud data governance in the Saudi public sector by structural equation modelling}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X17321489},
volume = {107},
year = {2020}
}
@article{Rocca2020,
abstract = {Purpose: Because of the expansion of the internet and Web 2.0 phenomenon, new challenges are emerging in the disclosure practises adopted by organisations in the public-sector. This study aims to examine local governments' (LGOs) use of social media (SM) in disclosing environmental actions/plans/information as a new way to improve accountability to citizens to obtain organisational legitimacy and the related sentiment of citizens' judgements. Design/methodology/approach: This paper analyses the content of 39 Italian LGOs' public pages on Facebook. After the distinction between five classes of environmental issues (air, water, energy, waste and territory), an initial study is performed to detect possible sub-topics applying latent Dirichlet allocation. Having a list of posts related to specific environmental themes, the researchers computed the sentiment of citizens' comments. To measure sentiment, two different approaches were implemented: one based on a lexicon dictionary and the other based on convolutional neural networks. Findings: Facebook is used by LGOs to disclose environmental issues, focussing on their main interest in obtaining organisational legitimacy, and the analysis shows an increasing impact of Web 2.0 in the direct interaction of LGOs with citizens. On the other hand, there is a clear divergence of interest on environmental topics between LGOs and citizens in a dialogic accountability framework. Practical implications: Sentiment analysis (SA) could be used by politicians, but also by managers/entrepreneurs in the business sector, to analyse stakeholders' judgements of their communications/actions and plans on corporate social responsibility. This tool gives a result on time (i.e. not months or years after, as for the reporting system). It is cheaper than a survey and allows a first “photograph” of stakeholders' sentiment. It can also be a useful tool for supporting, developing and improving environmental reporting. Originality/value: To the best of the authors' knowledge, this paper is one of the first to apply SA to environmental disclosure via SM in the public sphere. The study links modern techniques in natural language processing and machine learning with the important aspects of environmental communication between LGOs and citizens. {\textcopyright} 2020, Laura Rocca, Davide Giacomini and Paola Zola.},
annote = {Cited by: 18},
author = {Rocca, Laura and Giacomini, Davide and Zola, Paola},
doi = {10.1108/MEDAR-09-2019-0563},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Rocca, Giacomini, Zola - Meditari Accountancy Research.pdf:pdf},
issn = {2049372X},
journal = {Meditari Accountancy Research},
keywords = {Dialogical accountability,Environment,Facebook,Local governments,Natural language processing,Organisational legitimacy,Sentiment analysis},
language = {English},
number = {3},
pages = {617 -- 646},
title = {{Environmental disclosure and sentiment analysis: state of the art and opportunities for public-sector organisations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089603646&doi=10.1108%2FMEDAR-09-2019-0563&partnerID=40&md5=2893337cbc86223283a88a0ddac02f9d},
volume = {29},
year = {2020}
}
@article{Uras2020,
abstract = {A UN report states that in 2050, about 70% of the total world population will live in cities. This increases the complexity of the services that the local public administrations have to provide the citizens with to keep an acceptable level of quality of life. For an appropriate design, deployment and management of these services, there is the need for tools to extract data on how the people move, which activities they conduct out and their behaviour (in an anonymous way). This need has justified extensive efforts towards the design of effective solutions for extracting this information. In this work, we present the People Mobility Analytics (PmA) solution, which collects probe requests generated by Wi-Fi devices when scanning the radio channels to detect Access Points. The PmA system processes the collected data to extract key insights on the people mobility, such as: crowd density per area of interest, people flows, time of permanence, time of return, heat maps, origin-destination matrices and estimation of people positions. The major novelty with respect to the state of the art is related to new powerful indicators that are needed for some key city services, such as security management and people transport services, and the experimental activities carried out in real scenarios. {\textcopyright} 2020 Elsevier Ltd},
annote = {Cited by: 18},
author = {Uras, Marco and Cossu, Raimondo and Ferrara, Enrico and Liotta, Antonio and Atzori, Luigi},
doi = {10.1016/j.jclepro.2020.122084},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Uras et al. - Journal of Cleaner Production.pdf:pdf},
issn = {09596526},
journal = {Journal of Cleaner Production},
keywords = {Crowd density,Crowdsensed data,Mobility patterns,Passive Wi-Fi sniffer,Pedestrian flow,Trajectory mining},
language = {English},
month = {oct},
pages = {122084},
title = {{PmA: A real-world system for people mobility monitoring and analysis based on Wi-Fi probes}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652620321314},
volume = {270},
year = {2020}
}
@article{Fatima2020,
abstract = {Nations have recognized the transformational potential of artificial intelligence (AI). Advances in AI will impact all facets of society. A spate of recently released national strategic AI plans provides valuable insights into how nations are considering their future trajectories. These strategic plans offer a rich source of evidence to understand national-level strategic actions, both proactive and reactive, in the face of rapid technological innovation. Based on a comprehensive content analysis of thirty-four national strategic plans, this article reports on (1) opportunities for AI to modernize the public sector and enhance industry competitiveness, (2) the role of the public sector in ensuring that the two most critical elements of AI systems, data and algorithms, are managed responsibly, (3) the role of the public sector in the governance of AI systems, and (4) how nations plan to invest in capacity development initiatives to strengthen their AI capabilities. {\textcopyright} 2020 Economic Society of Australia, Queensland},
annote = {Cited by: 77},
author = {Fatima, Samar and Desouza, Kevin C. and Dawson, Gregory S.},
doi = {10.1016/j.eap.2020.07.008},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Fatima, Desouza, Dawson - Economic Analysis and Policy.pdf:pdf},
issn = {03135926},
journal = {Economic Analysis and Policy},
keywords = {Artificial intelligence,Autonomous systems,Intelligent systems,Public agencies,Science and technology policy,Strategic plans,Technological innovation},
language = {English},
month = {sep},
pages = {178--194},
title = {{National strategic artificial intelligence plans: A multi-dimensional analysis}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0313592620304021},
volume = {67},
year = {2020}
}
@article{Fertier2020,
abstract = {An effective crisis response requires up-to-date information. The crisis cell must reach for new, external, data sources. However, new data lead to new issues: their volume, veracity, variety or velocity cannot be managed by humans only, especially under high stress and time pressure. This paper proposes (i) a framework to enhance situation awareness while managing the 5Vs of Big Data, (ii) general principles to be followed and (iii) a new architecture implementing the proposed framework. The latter merges event-driven and model-driven architectures. It has been tested on a realistic flood scenario set up by official French services. {\textcopyright} 2019, {\textcopyright} 2019 Informa UK Limited, trading as Taylor & Francis Group.},
annote = {Cited by: 10},
author = {Fertier, Audrey and Montarnal, Aur{\'{e}}lie and Barthe-Delano{\"{e}}, Anne-Marie and Truptil, S{\'{e}}bastien and B{\'{e}}naben, Fr{\'{e}}d{\'{e}}rick},
doi = {10.1080/17517575.2019.1691268},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Fertier et al. - Enterprise Information Systems.pdf:pdf},
issn = {1751-7575},
journal = {Enterprise Information Systems},
keywords = {EIS for public sector,Situation awareness,complex event processing,crisis management,event-driven architecture,model-driven architecture},
language = {English},
month = {jul},
number = {6},
pages = {769--796},
title = {{Real-time data exploitation supported by model- and event-driven architecture to enhance situation awareness, application to crisis management}},
url = {https://www.tandfonline.com/doi/full/10.1080/17517575.2019.1691268},
volume = {14},
year = {2020}
}
@article{Cobbe2020,
abstract = {In this paper we introduce the concept of `reviewability' as an alternative approach to im-proving the accountability of automated decision-making that involves machine learning systems. In doing so, we draw on an understanding of automated decision-making as a socio-technical process, involving both human (organisational) and technical components, beginning before a decision is made and extending beyond the decision itself. Although explanations for automated decisions may be useful in some contexts, they focus more narrowly on the model and therefore do not provide the information about that process as a whole that is necessary for many aspects of accountability, regulatory oversight, and assessments for legal compliance. Drawing on previous work on the application of administrative law and judicial review mechanisms to automated decision-making in the public sector, we argue that breaking down the automated decision-making process into its technical and organisational components allows us to consider how appropriate record-keeping and logging mechanisms implemented at each stage of that process would allow for the process as a whole to be reviewed. Although significant research is needed to explore how it can be implemented, we argue that a reviewability framework potentially offers for a more useful and more holistic form of accountability for automated decision-making than approaches focused more narrowly on explanations. (C) 2020 Jennifer Cobbe and Jatinder Singh. Published by Elsevier Ltd. All rights reserved.},
author = {Cobbe, Jennifer and Singh, Jatinder},
doi = {10.1016/j.clsr.2020.105475},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Cobbe, Singh - Computer Law & Security Review.pdf:pdf},
issn = {02673649},
journal = {Computer Law & Security Review},
keywords = {accountable systems,automated decision-making,reviewability},
language = {English},
month = {nov},
pages = {105475},
title = {{Reviewable Automated Decision-Making}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364920300807},
volume = {39},
year = {2020}
}
@article{Kowalski2020,
abstract = {<p>Research on user satisfaction has increased substantially in recent years. To date, most studies have tested the significance of predefined factors thought to influence user satisfaction, with no scalable means of verifying the validity of their assumptions. Digital technology has created new methods of collecting user feedback where service users post comments. As topic models can analyse large volumes of feedback, they have been proposed as a feasible approach to aggregating user opinions. This novel approach has been applied to process reviews of primary care practices in England. Findings from an analysis of more than 200,000 reviews show that the quality of interactions with staff and bureaucratic exigencies are the key drivers of user satisfaction. In addition, patient satisfaction is strongly influenced by factors that are not measured by state‐of‐the‐art patient surveys. These results highlight the potential benefits of text mining and machine learning for public administration.</p>},
author = {Kowalski, Radoslaw and Esteve, Marc and {Jankin Mikhaylov}, Slava},
doi = {10.1111/padm.12656},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Kowalski, Esteve, Jankin Mikhaylov - Public Administration.pdf:pdf},
issn = {0033-3298},
journal = {Public Administration},
language = {English},
month = {dec},
number = {4},
pages = {1011--1026},
title = {{Improving public services by mining citizen feedback: An application of natural language processing}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/padm.12656},
volume = {98},
year = {2020}
}
@article{Guenduez2020,
abstract = {Being among the largest creators and gatherers of data in many countries, public administrations are looking for ways to harness big data technology. However, the de facto uses of big data in the public sector remain very limited. Despite numerous studies aiming to clarify the term big data, for many public managers, it remains unclear what this technology does and does not offer public administration. Using the concept of technological frames, we explore the assumptions, expectations, and understandings that public managers possess in order to interpret and make sense of big data. We identify nine big data frames, ranging from inward-oriented technoenthusiasts to outward-oriented techno-skeptics, each of which characterizes public managers' specific viewpoints relating to the introduction of big data in public administrations. Our findings highlight inconsistencies between different perceptions and reveal widespread skepticism among public managers, helping better understand why the de facto uses of big data in the public sector remain very limited.},
author = {Guenduez, Ali A. and Mettler, Tobias and Schedler, Kuno},
doi = {10.1016/j.giq.2019.101406},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Guenduez, Mettler, Schedler - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Big data,Public administration,Public manager,Q methodology,Technological frame},
language = {English},
month = {jan},
number = {1},
pages = {101406},
title = {{Technological frames in public administration: What do public managers think of big data?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X18305173},
volume = {37},
year = {2020}
}
@article{Vogl2020,
abstract = {In recent years, local authorities in the UK have begun to adopt a
variety of ``smart'' technological changes to enhance service
delivery. These changes are having profound impacts on the structure of
public administration. Focusing on the particular case of artificial
intelligence, specifically autonomous agents and predictive analytics, a
combination of desk research, a survey questionnaire, and interviews
were used to better understand the extent and nature of these changes in
local government. Findings suggest that local authorities are beginning
to adopt smart technologies and that these technologies are having an
unanticipated impact on how public administrators and computational
algorithms become imbricated in the delivery of public services. This
imbrication is described as algorithmic bureaucracy, and it provides a
framework within which to explore how these technologies transform both
the socio-technical relationship between workers and their tools, as
well as the ways that work is organized in the public sector.},
author = {Vogl, Thomas M. and Seidelin, Cathrine and Ganesh, Bharath and Bright, Jonathan},
doi = {10.1111/puar.13286},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Vogl et al. - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {nov},
number = {6},
pages = {946--961},
title = {{Smart Technology and the Emergence of Algorithmic Bureaucracy: Artificial Intelligence in UK Local Authorities}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13286},
volume = {80},
year = {2020}
}
@article{Aoki2020,
abstract = {This study investigates the public's initial trust in so-called ``artificial intelligence'' (AI) chatbots about to be introduced into use in the public sector. While the societal impacts of AI are widely speculated about, empirical testing remains rare. To narrow this gap, this study builds on theories of operators' trust in machines in industrial settings and proposes that initial public trust in chatbot responses depends on (i) the area of enquiry, since expectations about a chatbot's performance vary with the topic, and (ii) the purposes that governments communicate to the public for introducing the use of chatbots. Analyses based on an experimental online survey in Japan generated results indicating that, if a government were to announce its intention to use ``AI'' chatbots to answer public enquiries, the public's initial trust in their responses would be lower in the area of parental support than in the area of waste separation, with a moderate effect size. Communicating purposes that would directly benefit citizens, such as achieving uniformity in response quality and timeliness in responding, would enhance public trust in chatbots. Although the effect sizes are small, communicating these purposes might be still worthwhile, as it would be an inexpensive measure for a government to take.},
author = {Aoki, Naomi},
doi = {10.1016/j.giq.2020.101490},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Aoki - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Administrative discretion,Artificial intelligence,Chatbot,Human-machine relationship,Public service,Public trust,Street-level bureaucracy},
language = {English},
month = {oct},
number = {4},
pages = {101490},
title = {{An experimental study of public trust in AI chatbots in the public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X1930406X},
volume = {37},
year = {2020}
}
@article{Kuziemski2020,
abstract = {The rush to understand new socio-economic contexts created by the wide adoption of AI is justified by its far-ranging consequences, spanning almost every walk of life. Yet, the public sector's predicament is a tragic double bind: its obligations to protect citizens from potential algorithmic harms are at odds with the temptation to increase its own efficiency - or in other words - to govern algorithms, while governing by algorithms. Whether such dual role is even possible, has been a matter of debate, the challenge stemming from algorithms' intrinsic properties, that make them distinct from other digital solutions, long embraced by the governments, create externalities that rule-based programming lacks. As the pressures to deploy automated decision making systems in the public sector become prevalent, this paper aims to examine how the use of AI in the public sector in relation to existing data governance regimes and national regulatory practices can be intensifying existing power asymmetries. To this end, investigating the legal and policy instruments associated with the use of AI for strenghtening the immigration process control system in Canada; ``optimising'' the employment services'' in Poland, and personalising the digital service experience in Finland, the paper advocates for the need of a common framework to evaluate the potential impact of the use of AI in the public sector. In this regard, it discusses the specific effects of automated decision support systems on public services and the growing expectations for governments to play a more prevalent role in the digital society and to ensure that the potential of technology is harnessed, while negative effects are controlled and possibly avoided. This is of particular importance in light of the current COVID-19 emergency crisis where AI and the underpinning regulatory framework of data ecosystems, have become crucial policy issues as more and more innovations are based on large scale data collections from digital devices, and the real-time accessibility of information and services, contact and relationships between institutions and citizens could strengthen - or undermine - trust in governance systems and democracy.},
author = {Kuziemski, Maciej and Misuraca, Gianluca},
doi = {10.1016/j.telpol.2020.101976},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Kuziemski, Misuraca - Telecommunications Policy.pdf:pdf},
issn = {03085961},
journal = {Telecommunications Policy},
keywords = {Algorithmic accountability,Artificial intelligence,Automated decision making,Public sector innovation},
language = {English},
month = {jul},
number = {6},
pages = {101976},
title = {{AI governance in the public sector: Three tales from the frontiers of automated decision-making in democratic settings}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0308596120300689},
volume = {44},
year = {2020}
}
@article{Lee2019,
abstract = {The Internet of Things (IoT) has the potential to transform the way we live, work, do business, and meet the needs of the public. While IoT's potential benefits for economic growth and social welfare appear to be indisputable, IoT faces several technological, social, legal, and regulatory policy challenges, ranging from interoperability and spectrum availability to cybersecurity and privacy. These challenges can and should be addressed by the joint efforts of a wide range of stakeholders from the public and private sector. The advancement of IoT depends in part on how policymakers respond to the opportunities and challenges associated with it. This research aims to identify the potential roles for the government in fostering the advancement of IoT innovation and adoption. To this end, we analyze data collected from 177 documents of public comments submitted to the U.S. National Telecommunications and Information Administration and from a focus group discussion with senior managers. Our content data analysis results in a set of recommendations for the government in terms of general policy principles, specific policy prescriptions, and governance and process approach that facilitate policy development. {\textcopyright} 2018 Elsevier Ltd},
annote = {Cited by: 24},
author = {Lee, Gwanhoo},
doi = {10.1016/j.telpol.2018.12.002},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Lee - Telecommunications Policy.pdf:pdf},
issn = {03085961},
journal = {Telecommunications Policy},
keywords = {Content analysis,Governance,Internet of things,Policy,Process,Public comments,Qualitative research,Regulation,Role of government},
language = {English},
month = {jun},
number = {5},
pages = {434--444},
title = {{What roles should the government play in fostering the advancement of the internet of things?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0308596118303951},
volume = {43},
year = {2019}
}
@article{Androutsopoulou2019,
abstract = {Driven by ‘success stories' reported by private sector firms, government agencies have also started adopting various Artificial Intelligence (AI) technologies in diverse domains (e.g. health, taxation, and education); however, extensive research is required in order to exploit the full potential of AI in the public sector, and leverage various AI technologies to address important problems/needs. This paper makes a contribution in this direction: it presents a novel approach, as well as the architecture of an ICT platform supporting it, for the advanced exploitation of a specific AI technology, namely chatbots, in the public sector in order to address a crucial issue: the improvement of communication between government and citizens (which has for long time been problematic). The proposed approach builds on natural language processing, machine learning and data mining technologies, and leverages existing data of various forms (such as documents containing legislation and directives, structured data from government agencies' operational systems, social media data, etc.), in order to develop a new digital channel of communication between citizens and government. Making use of appropriately structured and semantically annotated data, this channel enables ‘richer' and more expressive interaction of citizens with government in everyday language, facilitating and advancing both information seeking and conducting of transactions. Compared to existing digital channels, the proposed approach is appropriate for a wider range of citizens' interactions, with higher levels of complexity, ambiguity and uncertainty. In close co-operation with three Greek government agencies (the Ministry of Finance, a social security organization, and a big local government organization), this approach has been validated through a series of application scenarios. {\textcopyright} 2018 Elsevier Inc.},
annote = {Cited by: 300},
author = {Androutsopoulou, Aggeliki and Karacapilidis, Nikos and Loukis, Euripidis and Charalabidis, Yannis},
doi = {10.1016/j.giq.2018.10.001},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley//2019 - Androutsopoulou et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
language = {English},
number = {2},
pages = {358 -- 367},
title = {{Transforming the communication between citizens and government through AI-guided chatbots}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054685951&doi=10.1016%2Fj.giq.2018.10.001&partnerID=40&md5=ce8ec8ad15c56a4fce6c0f4d8eaa89ec},
volume = {36},
year = {2019}
}
@article{Anejionu2019,
abstract = {The Spatial Urban Data System (SUDS) is a spatial big data infrastructure to support UK-wide analytics of the social and economic aspects of cities and city-regions. It utilises data generated from traditional as well as new and emerging sources of urban data. The SUDS deploys geospatial technology, synthetic small area urban metrics, and cloud computing to enable urban analytics, and geovisualization with the goal of deriving actionable knowledge for better urban management and data-driven urban decision making. At the core of the system is a programme of urban indicators generated by using novel forms of data and urban modelling and simulation programme. SUDS differs from other similar systems by its emphasis on the generation and use of regularly updated spatially-activated urban area metrics from real or near-real time data sources, to enhance understanding of intra-city interactions and dynamics. By deploying public transport, labour market accessibility and housing advertisement data in the system, we were able to identify spatial variations of key urban services at intra-city levels as well as social and economically-marginalised output areas in major cities across the UK. This paper discusses the design and implementation of SUDS, the challenges and limitations encountered, and considerations made during its development. The innovative approach adopted in the design of SUDS will enable it to support research and analysis of urban areas, policy and city administration, business decision-making, private sector innovation, and public engagement. Having been tested with housing, transport and employment metrics, efforts are ongoing to integrate information from other sources such as IoT, and User Generated Content into the system to enable urban predictive analytics. {\textcopyright} 2019},
annote = {Cited by: 42},
author = {Anejionu, Obinna C.D. and Thakuriah, Piyushimita (Vonu) and McHugh, Andrew and Sun, Yeran and McArthur, David and Mason, Phil and Walpole, Rod},
doi = {10.1016/j.future.2019.03.052},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Anejionu et al. - Future Generation Computer Systems.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Small area assessment,Spatial big data,Spatial urban indicators,Urban analytics,Urban big data infrastructure},
language = {English},
month = {sep},
pages = {456--473},
title = {{Spatial urban data system: A cloud-enabled big data infrastructure for social and economic urban analytics}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X18319046},
volume = {98},
year = {2019}
}
@article{Huang2019,
abstract = {Most recent discussion of the adaptive reuse of school land has focused almost exclusively on repurposing or redeploying vacant school space rather than comprehensively re-planning and constructing the entire school land for the overall needs of society and urban development. The relevant government agencies for school land reuse in Taiwan, such as the Ministry of Education and municipal governments, mostly provide subjective regulations or revitalization provisions for the sustainable development of school resources; however, no specific scientific assessment or a planning procedure has been proposed to revitalize school land. Therefore, constructing a scientific, quantitative, and objective planning framework and procedure is necessary for the adaptive reuse of school land based on the needs of overall society and urban development in order to replace the existing and outdated planning philosophy and to correct prominent shortcomings of past planning operations that were solely in accordance with the qualitative judgment and decision making of official agencies. In this study, we mainly adopted the analytic network process (ANP) and big data, including demographics, facility usage, and social welfare indicators, to assist the Taipei City government to construct or reform land reuse strategies for junior high and elementary schools facing immediate or future closure, consolidation, or downsizing. To take a more realistic approach to improve final decision making, the investigation of expert questionnaires through the ANP was based on the consideration of future trends that were objectively evaluated by big datasets. The novel planning philosophy and concise decision framework for reuse strategies we designed are expected to improve public decision-making transparency, adaptive reuse effectiveness, and quality of urban life. Ultimately, our proposed strategies and suggestions can not only assist local public sectors to promote the policy of adaptive reuse of surplus school lands but also serve as an appropriate blueprint of urban sustainability for the central government in the near future. {\textcopyright} 2018, Springer Nature B.V.},
annote = {Cited by: 16},
author = {Huang, Jhong-You and Wey, Wann-Ming},
doi = {10.1007/s11205-018-1951-y},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Huang, Wey - Social Indicators Research.pdf:pdf},
issn = {0303-8300},
journal = {Social Indicators Research},
keywords = {Reuse of school land {\textperiodcentered} Analytic network process {\textperiodcentered}},
language = {English},
month = {apr},
number = {3},
pages = {1075--1102},
title = {{Application of Big Data and Analytic Network Process for the Adaptive Reuse Strategies of School Land}},
url = {http://link.springer.com/10.1007/s11205-018-1951-y},
volume = {142},
year = {2019}
}
@article{Mohabeer2019,
abstract = {This study examines how big data analytics could optimize the use of public funds while ensuring delivery of quality service by public organizations to the citizens of Mauritius. Political Economic Social Technological (PEST) analysis has been carried out to scan the environment to identify at least two major policies and initiatives corresponding to big data that will be impacting the Mauritian Economy in the next 10 years. Subsequently, causal layered analysis (CLA) has been applied for the two signals to create transformative spaces for the creation of alternative futures. Indeed, the findings have demonstrated that open data initiative and the implementation of e-health project in Mauritius would certainly contribute positively to the government of Mauritius. However, this study has revealed through a matrix diagram for probable futures that the Mauritian government should bring amendments to existing conventional laws through reforms and regulations to fully take advantage of big data analytics applications. This is also one of the recommendations of the Mauritius e-Government 2013–2017–Formulation and Implementation of Data Sharing Policy. Considering only the recent emergence of big data analytics in governments, still there is certain aspect of it that needs careful consideration before the full potential of big data could be realized. This research also highlights the factors that need to be addressed for the successful use of Big Data in this particular context. {\textcopyright} 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
annote = {Cited by: 2},
author = {Mohabeer, Preethivirajsingh and Santally, Mohammad Issack and Sungkur, Roopesh Kevin},
doi = {10.1007/s13132-018-0524-2},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Mohabeer, Santally, Sungkur - Journal of the Knowledge Economy.pdf:pdf},
issn = {1868-7865},
journal = {Journal of the Knowledge Economy},
keywords = {Big data,Causal layer,Mauritius,Public sector},
language = {English},
month = {sep},
number = {3},
pages = {1230--1247},
title = {{An Investigation of the Potential Benefits of Big Data in the Public Sector of Mauritius}},
url = {http://link.springer.com/10.1007/s13132-018-0524-2},
volume = {10},
year = {2019}
}
@article{Dunleavy2019,
abstract = {Within long-lived public sector bureaucracies, the organizational cultures developed by administrative elites have strong filtering and focusing effects on the kinds of technological changes adopted, especially in the modern era. Normally seen as very slow-moving and hard to alter, senior officials' attitudes towards digital changes have recently begun to alter in more substantial ways in Australia. We review first a considerable reappraisal of the priority given to digital changes by top public service managers. This cultural shift has followed on from tech-lead disruptive societal changes affecting most areas of government now, and from the rise of global-scaled ICT corporations to become key management exemplars for officials. Second, we look at the chequered history of political leaders' interventions to speed up digital change, showing that in the period 2015-19 Australia witnessed both the initial power and later limits of such involvement. Finally, we consider Australia's recent experience with big data/ artificial intelligence (BDAI), a key area of technological change for public service officials, but one that in a liberal democracy can also easily spark public resistance to their plans.},
author = {Dunleavy, Patrick and Evans, Mark},
doi = {10.1080/23812346.2019.1596544},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Dunleavy, Evans - Journal of Chinese Governance.pdf:pdf},
issn = {2381-2346},
journal = {Journal of Chinese Governance},
keywords = {Bureaucracy,In,artificial intelligence,digital,public service officials,service reform},
language = {English},
month = {apr},
number = {2},
pages = {181--200},
title = {{Australian administrative elites and the challenges of digital-era change}},
url = {https://www.tandfonline.com/doi/full/10.1080/23812346.2019.1596544},
volume = {4},
year = {2019}
}
@article{Ingrams2019a,
abstract = {<p>Big data applications have been acclaimed as potentially transformative for the public sector. But, despite this acclaim, most theory of big data is narrowly focused around technocratic goals. The conceptual frameworks that situate big data within democratic governance systems recognizing the role of citizens are still missing. This paper explores the democratic governance impacts of big data in three policy areas using Robert Dahl's dimensions of control and autonomy. Key impacts and potential tensions are highlighted. There is evidence of impacts on both dimensions, but the dimensions conflict as well as align in notable ways and focused policy efforts will be needed to find a balance.</p>},
author = {Ingrams, Alex},
doi = {10.1111/ropr.12331},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Ingrams - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {Internet; e-governance; governance; ICTs; Media},
language = {English},
month = {may},
number = {3},
pages = {357--377},
title = {{Big Data and Dahl's Challenge of Democratic Governance}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12331},
volume = {36},
year = {2019}
}
@article{Schuelke-Leech2019,
abstract = {Self‐driving cars (also known as driverless cars, autonomous vehicles, and highly automated vehicles [HAVs]) will change the regulatory, political, and ethical frameworks surrounding motor vehicles. At the highest levels of automation, HAVs are operated by independent machine agents, making decisions without the direct intervention of humans. The current transportation system assumes human intervention though, including legal and moral responsibilities of human operators. Has the development of these artificial intelligence (AI) and autonomous system (AS) technologies outpaced the ethical and political conversations? This paper examines discussions of HAVs, driver responsibility, and technology failure to highlight the differences between how the policy‐making institutions in the United States (Congress and the Public Administration) and technology and transportation experts are or are not speaking about responsibility in the context of autonomous systems technologies. We report findings from a big data analysis of corpus‐level documents to find that enthusiasm for HAVs has outpaced other discussions of the technology.},
author = {Schuelke‐Leech, Beth‐Anne and Jordan, Sara R. and Barry, Betsy},
doi = {10.1111/ropr.12332},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Schuelke‐Leech, Jordan, Barry - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {autonomous vehicles,big data analysis,driverless cars,highly automated vehicles,policy making,responsibility},
language = {English},
month = {jul},
number = {4},
pages = {547--579},
title = {{Regulating Autonomy: An Assessment of Policy Language for Highly Automated Vehicles}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12332},
volume = {36},
year = {2019}
}
@article{Ingrams2019,
abstract = {Public administration scholars have so far largely viewed big data as a kind of technocratictransformation. However, through citizens' digital records, use of service apps, social media, digitalsensors, and other digital footprints, big data also gives policymakers insights into citizen choicesand is therefore potentially supportive of public values such as participation and openness. Focusingon two underexplored countries, Germany and the Netherlands, this article develops a public valuesframework for big data that considers citizen values alongside technocratic ones. It takes theparticular case of public information agencies such as ombudsmen and courts of audit, examiningthe functions they play and whether they have the capacity to address tensions arising betweentechnocratic and citizen values. The study ﬁnds that, while capacity does exist, it is heavily tiltedtoward technocratic values, with no capacity to address participative values. Finally, ﬁvepropositions are advanced, which describe where the tensions lie and therefore where the attention ofpublic information agencies should best be focused},
author = {Ingrams, Alex},
doi = {10.1002/poi3.193},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Ingrams - Policy & Internet.pdf:pdf},
issn = {1944-2866},
journal = {Policy & Internet},
keywords = {big data,democracy,public information,public policy,public values,technocracy},
language = {English},
month = {jun},
number = {2},
pages = {128--148},
title = {{Public Values in the Age of Big Data: A Public Information Perspective}},
url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.193},
volume = {11},
year = {2019}
}
@article{Anastasopoulos2019,
abstract = {Machine learning (ML) methods have gained a great deal of popularity in
recent years among public administration scholars and practitioners.
These techniques open the door to the analysis of text, image and other
types of data that allow us to test foundational theories of public
administration and to develop new theories. Despite the excitement
surrounding ML methods, clarity regarding their proper use and potential
pitfalls is lacking. This article attempts to fill this gap in the
literature through providing an ML ``guide to practice'' for public
administration scholars and practitioners. Here, we take a foundational
view of ML and describe how these methods can enrich public
administration research and practice through their ability develop new
measures, tap into new sources of data and conduct statistical inference
and causal inference in a principled manner. We then turn our attention
to the pitfalls of using these methods such as unvalidated measures and
lack of interpretability. Finally, we demonstrate how ML techniques can
help us learn about organizational reputation in federal agencies
through an illustrated example using tweets from 13 executive federal
agencies. All R code, analyses, and data described in this article can
be found in the Supplementary Appendix.},
author = {Anastasopoulos, L Jason and Whitford, Andrew B},
doi = {10.1093/jopart/muy060},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Anastasopoulos, Whitford - Journal of Public Administration Research and Theory.pdf:pdf},
issn = {1053-1858},
journal = {Journal of Public Administration Research and Theory},
language = {English},
month = {jun},
number = {3},
pages = {491--510},
title = {{Machine Learning for Public Administration Research, With Application to Organizational Reputation}},
url = {https://academic.oup.com/jpart/article/29/3/491/5161227},
volume = {29},
year = {2019}
}
@article{VanderVoort2019,
abstract = {Big data promises to transform public decision-making for the better by
making it more responsive to actual needs and policy effects. However,
much recent work on big data in public decision-making assumes a
rational view of decision-making, which has been much criticized in the
public administration debate. In this paper, we apply this view, and a
more political one, to the context of big data and offer a qualitative
study. We question the impact of big data on decision-making, realizing
that big data including its new methods and functions must inevitably
encounter existing political and managerial institutions. By studying
two illustrative cases of big data use processes, we explore how these
two worlds meet. Specifically, we look at the interaction between data
analysts and decision makers. In this we distinguish between a rational
view and a political view, and between an information logic and a
decision logic. We find that big data provides ample opportunities for
both analysts and decision makers to do a better job, but this doesn't
necessarily imply better decision-making, because big data also provides
opportunities for actors to pursue their own interests. Big data enables
both data analysts and decision makers to act as autonomous agents
rather than as links in a functional chain. Therefore, big data's impact
cannot be interpreted only in terms of its functional promise; it must
also be acknowledged as a phenomenon set to impact our policymaking
institutions, including their legitimacy.},
author = {van der Voort, H.G. and Klievink, A.J. and Arnaboldi, M. and Meijer, A.J.},
doi = {10.1016/j.giq.2018.10.011},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - van der Voort et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
language = {English},
month = {jan},
number = {1},
pages = {27--38},
title = {{Rationality and politics of algorithms. Will the promise of big data survive the dynamics of public decision making?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X17304951},
volume = {36},
year = {2019}
}
@article{Wirtz2019,
abstract = {Artificial intelligence (AI) extends the limits of current performance in data processing and analysis many times over. Since this states a great improvement in managing public data, this conceptual study discusses the use of AI in public management structures in connection with their risks and side effects. The exercise of state power and public influence through intelligent machines make ethical and political guidelines essential for their operation, constituting the cornerstones of the AI framework model developed here. The organizational structure and technical specification are additional aspects of the AI that determine design and functionality of the framework model in practical application.},
author = {Wirtz, Bernd W. and M{\"{u}}ller, Wilhelm M.},
doi = {10.1080/14719037.2018.1549268},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Wirtz, M{\"{u}}ller - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {Artificial intelligence,conceptual study,framework,public administration,public business model},
language = {English},
month = {jul},
number = {7},
pages = {1076--1100},
title = {{An integrated artificial intelligence framework for public management}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2018.1549268},
volume = {21},
year = {2019}
}
@article{Andrews2019,
abstract = {<p>Public administration scholarship has to a significant degree neglected technological change. The age of the algorithm and ‘big data' is throwing up new challenges for public leadership, which are already being confronted by public leaders in different jurisdictions. Algorithms may be perceived as presenting new kinds of ‘wicked problems' for public authorities. The article offers a tentative overview of the kind of algorithmic challenges facing public leaders in an environment where the discursive context is shaped by corporate technology companies. Public value theory is assessed as an analytical framework to examine how public leaders are seeking to address the ethical and public value issues affecting governance and regulation, drawing on recent UK experience in particular. The article suggests that this is a fruitful area for future research.</p>},
author = {Andrews, Leighton},
doi = {10.1111/padm.12534},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Andrews - Public Administration.pdf:pdf},
issn = {0033-3298},
journal = {Public Administration},
language = {English},
month = {jun},
number = {2},
pages = {296--310},
title = {{Public administration, public leadership and the construction of public value in the age of the algorithm and ‘big data'}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/padm.12534},
volume = {97},
year = {2019}
}
@article{Sun2019,
abstract = {The nascent adoption of Artificial Intelligence (AI) in the public sector is being assessed in contradictory ways. But while there is increasing speculation about both its dangers and its benefits, there is very little empirical research to substantiate them. This study aims at mapping the challenges in the adoption of AI in the public sector as perceived by key stakeholders. Drawing on the theoretical lens of framing, we analyse a case of adoption of the AI system IBM Watson in public healthcare in China, to map how three groups of stakeholders (government policy-makers, hospital managers/doctors, and Information Technology (IT) firm managers) perceive the challenges of AI adoption in the public sector. Findings show that different stakeholders have diverse, and sometimes contradictory, framings of the challenges. We contribute to research by providing an empirical basis to claims of AI challenges in the public sector, and to practice by providing four sets of guidelines for the governance of AI adoption in the public sector.},
author = {Sun, Tara Qian and Medaglia, Rony},
doi = {10.1016/j.giq.2018.09.008},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Sun, Medaglia - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial Intelligence,Challenges,China,Framing,Healthcare,Public sector},
language = {English},
month = {apr},
number = {2},
pages = {368--383},
title = {{Mapping the challenges of Artificial Intelligence in the public sector: Evidence from public healthcare}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X17304781},
volume = {36},
year = {2019}
}
@article{Madsen2018,
abstract = {This paper presents an analysis of interviews, focus groups and workshops with employees in the technical administration in the municipality of Copenhagen in the year after it won a prestigious Smart City award. The administration is interpreted as a ‘most likely' to succeed in translating the idealised version of the smart city into a workable bureaucratic practice. Drawing on the work of Orlikowski and Gash, the empirical analysis identifies and describes two incongruent ‘technological frames' that illustrates different ways of making sense of data and the smart city within this single organisational unit. One is called the experimentalist's credo and it is characterised by inspiration from the development of an Internet of Things as well as a readiness to learn from the open source community in software development. The other is called the data-owners vocation and it is characterised by a more situated approach that interprets data as strategic and political. It is argued that the existence of these frames provides two insights relevant for the literature on smart cities. First, they illustrate that one should be careful not to reify the smart city as a phenomenon that can be criticised in generic terms. Second, they suggest that even if there exists a transition toward the implementation of a technocratic smart city paradigm across public administrations, this paradigm is not unique in its focus on markets and evidence in governance.},
annote = {Cited by: 25},
author = {Madsen, Anders Koed},
doi = {10.1177/2053951718802321},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Madsen - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Big Data,Smart city,This,sense-making,technological frames},
language = {English},
month = {jul},
number = {2},
pages = {205395171880232},
title = {{Data in the smart city: How incongruent frames challenge the transition from ideal to practice}},
url = {http://journals.sagepub.com/doi/10.1177/2053951718802321},
volume = {5},
year = {2018}
}
@article{Oswald2018,
abstract = {As is common across the public sector, the UK police service is under pressure to do more with less, to target resources more efficiently and take steps to identify threats proactively; for example under riskassessment schemes such as ‘Clare's Law' and ‘Sarah's Law'. Algorithmic tools promise to improve a police force's decisionmaking and prediction abilities by making better use of data (including intelligence), both from inside and outside the force. This article uses Durham Constabulary's Harm Assessment Risk Tool (HART) as a case-study. HART is one of the first algorithmic models to be deployed by a UK police force in an operational capacity. Our article comments upon the potential benefits of such tools, explains the concept and method of HART and considers the results of the first validation of the model's use and accuracy. The article then critiques the use of algorithmic tools within policing from a societal and legal perspective, focusing in particular upon substantive common law grounds for judicial review. It considers a concept of ‘experimental' proportionality to permit the use of unproven algorithms in the public sector in a controlled and time-limited way, and as part of a combination of approaches to combat algorithmic opacity, proposes ‘ALGO-CARE', a guidance framework of some of the key legal and practical concerns that should be considered in relation to the use of algorithmic risk assessment tools by the police. The article concludes that for the use of algorithmic tools in a policing context to result in a ‘better' outcome, that is to say, a more efficient use of police resources in a landscape of more consistent, evidence-based decision-making, then an ‘experimental' proportionality approach should be developed to ensure that new solutions from ‘big data' can be found for criminal justice problems traditionally arising from clouded, non-augmented decision-making. Finally, this article notes that there is a sub-set of decisions around which there is too great an impact upon society and upon the welfare of individuals for them to be influenced by an emerging technology; to an extent, in fact, that they should be removed from the influence of algorithmic decision-making altogether. {\textcopyright} 2018 The Author(s).},
annote = {Cited by: 105},
author = {Oswald, Marion and Grace, Jamie and Urwin, Sheena and Barnes, Geoffrey C.},
doi = {10.1080/13600834.2018.1458455},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Oswald et al. - Information & Communications Technology Law.pdf:pdf},
issn = {1360-0834},
journal = {Information & Communications Technology Law},
keywords = {Keywords Algorithms,criminal justice,law,predictions,proportionality,risk assessment},
language = {English},
month = {may},
number = {2},
pages = {223--250},
title = {{Algorithmic risk assessment policing models: lessons from the Durham HART model and ‘Experimental' proportionality}},
url = {https://www.tandfonline.com/doi/full/10.1080/13600834.2018.1458455},
volume = {27},
year = {2018}
}
@article{Agarwal2018,
abstract = {<p> <italic>Technology‐driven disruption is taking place at a pace and scale not witnessed before in history. Waves of technology, such as the internet of things, big data, machine learning, and artificial intelligence, are reshaping our personal and professional lives in profound ways. A new world is emerging in which many of the current job classes will disappear, while new ones, requiring entirely different sets of skills, are emerging. Public administrators are unprepared for the challenges they must face in order to cope with this nonincremental and exponential change. Many of the existing government structures and processes that have evolved over the last few centuries will likely become irrelevant in the near future. There is a compelling need to lay the groundwork for governments to rethink how they will be able to best serve their constituents</italic> . </p>},
annote = {Cited by: 107},
author = {Agarwal, P. K.},
doi = {10.1111/puar.12979},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Agarwal - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {nov},
number = {6},
pages = {917--921},
title = {{Public Administration Challenges in the World of AI and Bots}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.12979},
volume = {78},
year = {2018}
}
@article{Choi2018,
abstract = {The prevalence of big data is starting to spread across the public and private sectors however, an impediment to its widespread adoption orientates around a lack of appropriate big data analytics (BDA) and resulting skills to exploit the full potential of big data availability. In this paper, we propose a novel BDA to contribute towards this void, using a fuzzy cognitive map (FCM) approach that will enhance decision-making thus prioritising IT service procurement in the public sector. This is achieved through the development of decision models that capture the strengths of both data analytics and the established intuitive qualitative approach. By taking advantages of both data analytics and FCM, the proposed approach captures the strength of data-driven decision-making and intuitive model-driven decision modelling. This approach is then validated through a decision-making case regarding IT service procurement in public sector, which is the fundamental step of IT infrastructure supply for publics in a regional government in the Russia federation. The analysis result for the given decision-making problem is then evaluated by decision makers and e-government expertise to confirm the applicability of the proposed BDA. In doing so, demonstrating the value of this approach in contributing towards robust public decision-making regarding IT service procurement. {\textcopyright} 2016, The Author(s).},
annote = {Cited by: 54},
author = {Choi, Youngseok and Lee, Habin and Irani, Zahir},
doi = {10.1007/s10479-016-2281-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Choi, Lee, Irani - Annals of Operations Research.pdf:pdf},
issn = {02545330},
journal = {Annals of Operations Research},
keywords = {Big data analytics,Decision modeling,Fuzzy cognitive map,IT service procurement,simulation},
language = {English},
number = {1-2},
pages = {75 -- 104},
title = {{Big data-driven fuzzy cognitive map for prioritising IT service procurement in the public sector}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982292325&doi=10.1007%2Fs10479-016-2281-6&partnerID=40&md5=1677c94bef289f0e0a4a40409a88a2c5},
volume = {270},
year = {2018}
}
@article{Schmid2017,
abstract = {The @ is the link between the name of the recipient and its address. The e-mail has revolutionized the communication behavior. It represents a new era of information and data exchange. The speed of information exchange and the possibility of non-physical data transport have fundamentally changed human communication. Big Data has become the synonym for a new technological age. Generally Big Data collects data and delivers valuable and useful information (Baron, 2013, 1). A general definition of the term has not yet taken place in science and practice. The work of the public sector is based on the collection, identification and use of data in many areas. Public organizations are often data monopolists and the only provider of public goods. The acquisition of new information in the sense of Big Data requires a connection between existing data and the use of new information. This gives the public administration a whole new potential. The organizational function "Controlling" supports decision-makers in the context of management and control (Horv{\'{a}}th, 2011, 16). The proximity of Big Data and Controlling is obvious. This article describes the potentials resulting from the use of Big Data and its effects on Public Controlling. Big Data will revolutionize Public Controlling and thus the public administration as a whole.},
annote = {Cited by: 3},
author = {Schmid, Andreas},
doi = {10.13165/VPA-17-16-2-11},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Schmid - Public Policy and Administration.pdf:pdf},
issn = {16482603},
journal = {Public Policy and Administration},
keywords = {Big Data,Public Controlling,effectiveness,efficiency,public sector},
language = {English},
number = {2},
pages = {325 -- 334},
title = {{BigData-PublicControlling Fundamental changes in Public Management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028679650&doi=10.13165%2FVPA-17-16-2-11&partnerID=40&md5=b7dced8ec6f98b5dfa3d94de9c0b1bd4},
volume = {16},
year = {2017}
}
@article{Intezari2017,
abstract = {Purpose: The purpose of this paper is to provide a theoretical framework of how knowledge management (KM) systems can facilitate the incorporation of big data into strategic decisions. Advanced analytics are becoming increasingly critical in making strategic decisions in any organization from the private to public sectors and from for-profit companies to not-for-profit organizations. Despite the growing importance of capturing, sharing and implementing people's knowledge in organizations, it is still unclear how big data and the need for advanced analytics can inform and, if necessary, reform the design and implementation of KM systems. Design/methodology/approach: To address this gap, a combined approach has been applied. The KM and data analysis systems implemented by companies were analyzed, and the analysis was complemented by a review of the extant literature. Findings: Four types of data-based decisions and a set of ground rules are identified toward enabling KM systems to handle big data and advanced analytics. Practical implications: The paper proposes a practical framework that takes into account the diverse combinations of data-based decisions. Suggestions are provided about how KM systems can be reformed to facilitate the incorporation of big data and advanced analytics into organizations' strategic decision-making. Originality/value: This is the first typology of data-based decision-making considering advanced analytics. {\textcopyright} 2017, {\textcopyright} Emerald Publishing Limited.},
annote = {Cited by: 104},
author = {Intezari, Ali and Gressel, Simone},
doi = {10.1108/JKM-07-2015-0293},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Intezari, Gressel - Journal of Knowledge Management.pdf:pdf},
issn = {1367-3270},
journal = {Journal of Knowledge Management},
keywords = {Advanced analytics,Big data,Data-based decisions,Knowledge management systems,Strategic decision-making},
language = {English},
month = {feb},
number = {1},
pages = {71--91},
title = {{Information and reformation in KM systems: big data and strategic decision-making}},
url = {https://www.emerald.com/insight/content/doi/10.1108/JKM-07-2015-0293/full/html},
volume = {21},
year = {2017}
}
@article{Giest2017,
abstract = {The buzz surrounding big data has taken shape in various theoretical and practical forms when it comes to policymaking. The paper combines current research streams with long-standing discussions on government and technology in public policy and public administration, such as e-government and evidence-based policymaking. The goal is to answer the question whether big data is a fleeting trend or has long-lasting effects on policymaking. Three larger themes in the literature are identified: First, the role that institutional capacity has within government to utilize big data analytics; second, government use of big data analytics in the context of digital public services; and finally, the way that big data information enters the policy cycle, focusing on substantive and procedural policy instruments. Examples from the education, crisis management, environmental and healthcare domain highlight the opportunities and challenges for each of these themes. Exploring the various aspects of big data and policymaking shows that big data is here to stay, but that its utilization by government will take time due to institutional barriers and capacity bottlenecks. {\textcopyright} 2017, The Author(s).},
annote = {Cited by: 132},
author = {Giest, Sarah},
doi = {10.1007/s11077-017-9293-1},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Giest - Policy Sciences.pdf:pdf},
issn = {00322687},
journal = {Policy Sciences},
keywords = {Big data,Data readiness,Digital-era governance,Evidence-based policymaking,Policy design,Policy instruments},
language = {English},
number = {3},
pages = {367 -- 382},
title = {{Big data for policymaking: fad or fasttrack?}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027009690&doi=10.1007%2Fs11077-017-9293-1&partnerID=40&md5=95d8382918059aad38fe07b4e430fa08},
volume = {50},
year = {2017}
}
@article{Klievink2017,
abstract = {Big data is being implemented with success in the private sector and science. Yet the public sector seems to be falling behind, despite the potential value of big data for government. Government organizations do recognize the opportunities of big data but seem uncertain about whether they are ready for the introduction of big data, and if they are adequately equipped to use big data. This paper addresses those uncertainties. It presents an assessment framework for evaluating public organizations' big data readiness. Doing so demystifies the concept of big data, as it is expressed in terms of specific and measureable organizational characteristics. The framework was tested by applying it to organizations in the Dutch public sector. The results suggest that organizations may be technically capable of using big data, but they will not significantly gain from these activities if the applications do not fit their organizations and main statutory tasks. The framework proved helpful in pointing out areas where public sector organizations could improve, providing guidance on how government can become more big data ready in the future. {\textcopyright} 2016, The Author(s).},
annote = {Cited by: 157},
author = {Klievink, Bram and Romijn, Bart-Jan and Cunningham, Scott and de Bruijn, Hans},
doi = {10.1007/s10796-016-9686-2},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Klievink et al. - Information Systems Frontiers.pdf:pdf},
issn = {13873326},
journal = {Information Systems Frontiers},
keywords = {Assessment,Big data,Bold Readiness,E-government,Use},
language = {English},
number = {2},
pages = {267 -- 283},
title = {{Big data in the public sector: Uncertainties and readiness}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982126226&doi=10.1007%2Fs10796-016-9686-2&partnerID=40&md5=84822de6a52d6dd0aeaa989cce50369e},
volume = {19},
year = {2017}
}
@article{Desouza2017,
abstract = {In this essay, we consider the role of Big Data in the public sector. Motivating our work is the recognition that Big Data is still in its infancy and many important questions regarding the true value of Big Data remain unanswered. The question we consider is as follows: What are the limits, or potential, of Big Data in the public sector? By reviewing the literature and summarizing insights from a series of interviews from public sector Chief Information Officers (CIOs), we offer a scholarly foundation for both practitioners and researchers interested in understanding Big Data in the public sector.},
annote = {Cited by: 121},
author = {Desouza, Kevin C. and Jacob, Benoy},
doi = {10.1177/0095399714555751},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Desouza, Jacob - Administration & Society.pdf:pdf},
issn = {0095-3997},
journal = {Administration & Society},
keywords = {big data,policy analysis,public management,public organizations},
language = {English},
month = {aug},
number = {7},
pages = {1043--1064},
title = {{Big Data in the Public Sector: Lessons for Practitioners and Scholars}},
url = {http://journals.sagepub.com/doi/10.1177/0095399714555751},
volume = {49},
year = {2017}
}
@article{Shah2017,
abstract = {This research highlights a contextual application for big data within a HR case study setting. This is achieved through the development of a normative conceptual model that seeks to envelop employee behaviors and attitudes in the context of organizational change readiness. This empirical application considers a data sample from a large public sector organization and through applying Structural Equation Modelling (SEM) identifies salary, job promotion, organizational loyalty and organizational identity influences on employee job satisfaction (suggesting and mediating employee readiness for organizational change). However in considering this specific context, the authors highlight how, where and why such a normative approach to employee factors may be limited and thus, proposes through a framework which brings together big data principles, implementation approaches and management commitment requirements can be applied and harnessed more effectively in order to assess employee attitudes and behaviors as part of wider HR predictive analytics (HRPA) approaches. The researchers conclude with a discussion on these research elements and a set of practical, conceptual and management implications of the findings along with recommendations for future research in the area. {\textcopyright} 2016 Elsevier Inc.},
annote = {Cited by: 149},
author = {Shah, Naimatullah and Irani, Zahir and Sharif, Amir M.},
doi = {10.1016/j.jbusres.2016.08.010},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Shah, Irani, Sharif - Journal of Business Research.pdf:pdf},
issn = {01482963},
journal = {Journal of Business Research},
keywords = {Big data,Employee readiness,Extrinsic and intrinsic satisfaction,HR predictive analytics,Job satisfaction,Organizational change},
language = {English},
month = {jan},
pages = {366--378},
title = {{Big data in an HR context: Exploring organizational change readiness, employee attitudes and behaviors}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0148296316304970},
volume = {70},
year = {2017}
}
@article{Baur2017,
abstract = {Transparency, participation, and collaboration are the core pillars of open government. For the systematic integration of citizens and other stakeholders into the policy and public value creation process, their opinions, wishes, and complaints first need to be received. In the future, including user-generated content from social media will become a main channel for the enrichment of this information base for public administrative bodies and commercial firms. However, the sheer speed of growth of this constantly updated data pool makes manual work infeasible. The automated gathering, combination, analysis, and visualization of user-generated content from various sources and multiple languages is therefore imperative. In this study, we present a design science research approach to develop a general framework (‘MarketMiner') to handle large amounts of foreign-language user-generated content. As a first empirical application, we implement the framework in the automotive industry by analyzing Chinese automotive forums for the benefit of English-speaking users. At the same time, the ideas, methods, and insights are transferred to the public sector context, especially in light of the current challenges of a high number of political refugees from Arabic countries entering into the European Union. The results are promising in that MarketMiner can dramatically improve the utilization of multi-language, multi-source social media content. The modular set-up of the artifact allows an easy transfer to additional areas of application. {\textcopyright} 2016, Springer Science+Business Media New York.},
annote = {Cited by: 42},
author = {Baur, Aaron W.},
doi = {10.1007/s10796-016-9681-7},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Baur - Information Systems Frontiers.pdf:pdf},
issn = {1387-3326},
journal = {Information Systems Frontiers},
keywords = {Open government . Open data . Participation . Publ},
language = {English},
month = {apr},
number = {2},
pages = {231--251},
title = {{Harnessing the social web to enhance insights into people's opinions in business, government and public administration}},
url = {http://link.springer.com/10.1007/s10796-016-9681-7},
volume = {19},
year = {2017}
}
@article{Malomo2017,
abstract = {The concept of Big Data has become very popular over the last decade, with large technology companies successfully building their business models around its exploitation. The public sector in the United Kingdom has tried to follow suit and local governments in particular have tried to introduce new models of service delivery based on the routine extraction of information from their own Big Data. These attempts have been hailed as the beginning of a new era for the public sector where service delivery and commissioning are shaped by data intelligence on local needs and by evidence on the outcomes. In this article we assess this claim and the extent to which it captures the way local governments in the United Kingdom use intelligence from Big Data in light of the structural barriers they face when trying to exploit their data. We also present a case study on the development and deployment of an integrated data model for children services in a large county council in the South-East of England. {\textcopyright} 2016 Policy Studies Organization},
annote = {Cited by: 61},
author = {Malomo, Fola and Sena, Vania},
doi = {10.1002/poi3.141},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Malomo, Sena - Policy & Internet.pdf:pdf},
issn = {1944-2866},
journal = {Policy & Internet},
keywords = {Big Data,Introduction,data ecosystem,integrated data model,local government,public sector,service delivery},
language = {English},
month = {mar},
number = {1},
pages = {7--27},
title = {{Data Intelligence for Local Government? Assessing the Benefits and Barriers to Use of Big Data in the Public Sector}},
url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.141},
volume = {9},
year = {2017}
}
@article{Beccali2017,
abstract = {The public buildings sector represents one of the most intensive items of EU energy consumption; the application of retrofit solutions in existing buildings is a crucial way to reduce its impact. To facilitate the knowledge of the energy performance of existing non-residential buildings and the choice of the more adequate actions, Public Administrations (PA) should have the availability of proper tools. Within the Italian project “POI 2007-13”, a database and a decision support tool, for easy use, even to a non-technical user, have been developed. A large set of data, obtained from the energy audits of 151 existing public buildings located in four regions of South Italy have been analysed, elaborated, and organised in a database. This was used to identify the best architectures of two ANNs and to train them. The first ANN provides the actual energy performance of any building; the second ANN assesses key economic indicators. A decision support tool, based on the use of these ANNs is conceived for a fast prediction of the energy performance of buildings and for a first selection of energy retrofit actions that can be applied. {\textcopyright} 2017 Elsevier Ltd},
annote = {Cited by: 78},
author = {Beccali, Marco and Ciulla, Giuseppina and {Lo Brano}, Valerio and Galatioto, Alessandra and Bonomolo, Marina},
doi = {10.1016/j.energy.2017.05.200},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Beccali et al. - Energy.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {ANN,Decision support tool,Energy audit,Energy efficiency,Non-residential building,Retrofit action},
language = {English},
month = {oct},
pages = {1201--1218},
title = {{Artificial neural network decision support tool for assessment of the energy performance and the refurbishment actions for the non-residential building stock in Southern Italy}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360544217310186},
volume = {137},
year = {2017}
}
