<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schmid, Andreas</author></authors></contributors><titles><title>BigData-PublicControlling Fundamental changes in Public Management</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>325 - 334</pages><volume>16</volume><issue>2</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.13165/VPA-17-16-2-11</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028679650&amp;doi=10.13165%2FVPA-17-16-2-11&amp;partnerID=40&amp;md5=b7dced8ec6f98b5dfa3d94de9c0b1bd4</url></web-urls></urls><abstract>The @ is the link between the name of the recipient and its address. The e-mail has revolutionized the communication behavior. It represents a new era of information and data exchange. The speed of information exchange and the possibility of non-physical data transport have fundamentally changed human communication. Big Data has become the synonym for a new technological age. Generally Big Data collects data and delivers valuable and useful information (Baron, 2013, 1). A general definition of the term has not yet taken place in science and practice. The work of the public sector is based on the collection, identification and use of data in many areas. Public organizations are often data monopolists and the only provider of public goods. The acquisition of new information in the sense of Big Data requires a connection between existing data and the use of new information. This gives the public administration a whole new potential. The organizational function &quot;Controlling&quot; supports decision-makers in the context of management and control (Horváth, 2011, 16). The proximity of Big Data and Controlling is obvious. This article describes the potentials resulting from the use of Big Data and its effects on Public Controlling. Big Data will revolutionize Public Controlling and thus the public administration as a whole.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rogge, Nicky</author><author>Agasisti, Tommaso</author><author>De Witte, Kristof</author></authors></contributors><titles><title>Big data and the measurement of public organizations’ performance and efficiency: The state-of-the-art</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>263 - 281</pages><volume>32</volume><issue>4</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1177/0952076716687355</electronic-resource-num><notes>Cited by: 75</notes><research-notes>Cited by: 75</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030151796&amp;doi=10.1177%2F0952076716687355&amp;partnerID=40&amp;md5=69687fa620d2fe4b68d500e49d436674</url></web-urls></urls><abstract>The increasing availability of statistical data raises opportunities for ‘big’ data and learning analytics. Here, we review the academic literature and research relating to the use of big data analytics in the public sector, and its contribution to public organizations’ performance and efficiency. We outline the advantages as well as the limitations of using big data in public sector organizations and identify research gaps in recent studies and interesting areas for future research. © 2017, © The Author(s) 2017.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Intezari, Ali</author><author>Gressel, Simone</author></authors></contributors><titles><title>Information and reformation in KM systems: big data and strategic decision-making</title><secondary-title>Journal of Knowledge Management</secondary-title></titles><periodical><full-title>Journal of Knowledge Management</full-title></periodical><pages>71 - 91</pages><volume>21</volume><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1108/JKM-07-2015-0293</electronic-resource-num><notes>Cited by: 104</notes><research-notes>Cited by: 104</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014758737&amp;doi=10.1108%2FJKM-07-2015-0293&amp;partnerID=40&amp;md5=9376ebd8aa0b4ea702a11c0d9f2d33d9</url></web-urls></urls><abstract>Purpose: The purpose of this paper is to provide a theoretical framework of how knowledge management (KM) systems can facilitate the incorporation of big data into strategic decisions. Advanced analytics are becoming increasingly critical in making strategic decisions in any organization from the private to public sectors and from for-profit companies to not-for-profit organizations. Despite the growing importance of capturing, sharing and implementing people’s knowledge in organizations, it is still unclear how big data and the need for advanced analytics can inform and, if necessary, reform the design and implementation of KM systems. Design/methodology/approach: To address this gap, a combined approach has been applied. The KM and data analysis systems implemented by companies were analyzed, and the analysis was complemented by a review of the extant literature. Findings: Four types of data-based decisions and a set of ground rules are identified toward enabling KM systems to handle big data and advanced analytics. Practical implications: The paper proposes a practical framework that takes into account the diverse combinations of data-based decisions. Suggestions are provided about how KM systems can be reformed to facilitate the incorporation of big data and advanced analytics into organizations’ strategic decision-making. Originality/value: This is the first typology of data-based decision-making considering advanced analytics. © 2017, © Emerald Publishing Limited.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Madsen, Anders Koed</author></authors></contributors><titles><title>Data in the smart city: How incongruent frames challenge the transition from ideal to practice</title><secondary-title>Big Data and Society</secondary-title></titles><periodical><full-title>Big Data and Society</full-title></periodical><volume>5</volume><issue>2</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1177/2053951718802321</electronic-resource-num><notes>Cited by: 25</notes><research-notes>Cited by: 25</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069871184&amp;doi=10.1177%2F2053951718802321&amp;partnerID=40&amp;md5=216c8dc841b816a6805201705d644638</url></web-urls></urls><abstract>This paper presents an analysis of interviews, focus groups and workshops with employees in the technical administration in the municipality of Copenhagen in the year after it won a prestigious Smart City award. The administration is interpreted as a ‘most likely’ to succeed in translating the idealised version of the smart city into a workable bureaucratic practice. Drawing on the work of Orlikowski and Gash, the empirical analysis identifies and describes two incongruent ‘technological frames’ that illustrates different ways of making sense of data and the smart city within this single organisational unit. One is called the experimentalist’s credo and it is characterised by inspiration from the development of an Internet of Things as well as a readiness to learn from the open source community in software development. The other is called the data-owners vocation and it is characterised by a more situated approach that interprets data as strategic and political. It is argued that the existence of these frames provides two insights relevant for the literature on smart cities. First, they illustrate that one should be careful not to reify the smart city as a phenomenon that can be criticised in generic terms. Second, they suggest that even if there exists a transition toward the implementation of a technocratic smart city paradigm across public administrations, this paradigm is not unique in its focus on markets and evidence in governance. © The Author(s) 2018.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Oswald, Marion</author><author>Grace, Jamie</author><author>Urwin, Sheena</author><author>Barnes, Geoffrey C</author></authors></contributors><titles><title>Algorithmic risk assessment policing models: Lessons from the Durham HART model and ‘experimental’ proportionality</title><secondary-title>Information and Communications Technology Law</secondary-title></titles><periodical><full-title>Information and Communications Technology Law</full-title></periodical><pages>223 - 250</pages><volume>27</volume><issue>2</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1080/13600834.2018.1458455</electronic-resource-num><notes>Cited by: 105</notes><research-notes>Cited by: 105</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044749514&amp;doi=10.1080%2F13600834.2018.1458455&amp;partnerID=40&amp;md5=c6df75361f92320c53dd43d9b6e0bafe</url></web-urls></urls><abstract>As is common across the public sector, the UK police service is under pressure to do more with less, to target resources more efficiently and take steps to identify threats proactively; for example under riskassessment schemes such as ‘Clare’s Law’ and ‘Sarah’s Law’. Algorithmic tools promise to improve a police force’s decisionmaking and prediction abilities by making better use of data (including intelligence), both from inside and outside the force. This article uses Durham Constabulary’s Harm Assessment Risk Tool (HART) as a case-study. HART is one of the first algorithmic models to be deployed by a UK police force in an operational capacity. Our article comments upon the potential benefits of such tools, explains the concept and method of HART and considers the results of the first validation of the model’s use and accuracy. The article then critiques the use of algorithmic tools within policing from a societal and legal perspective, focusing in particular upon substantive common law grounds for judicial review. It considers a concept of ‘experimental’ proportionality to permit the use of unproven algorithms in the public sector in a controlled and time-limited way, and as part of a combination of approaches to combat algorithmic opacity, proposes ‘ALGO-CARE’, a guidance framework of some of the key legal and practical concerns that should be considered in relation to the use of algorithmic risk assessment tools by the police. The article concludes that for the use of algorithmic tools in a policing context to result in a ‘better’ outcome, that is to say, a more efficient use of police resources in a landscape of more consistent, evidence-based decision-making, then an ‘experimental’ proportionality approach should be developed to ensure that new solutions from ‘big data’ can be found for criminal justice problems traditionally arising from clouded, non-augmented decision-making. Finally, this article notes that there is a sub-set of decisions around which there is too great an impact upon society and upon the welfare of individuals for them to be influenced by an emerging technology; to an extent, in fact, that they should be removed from the influence of algorithmic decision-making altogether. © 2018 The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Beccali, Marco</author><author>Ciulla, Giuseppina</author><author>Lo Brano, Valerio</author><author>Galatioto, Alessandra</author><author>Bonomolo, Marina</author></authors></contributors><titles><title>Artificial neural network decision support tool for assessment of the energy performance and the refurbishment actions for the non-residential building stock in Southern Italy</title><secondary-title>Energy</secondary-title></titles><periodical><full-title>Energy</full-title></periodical><pages>1201 - 1218</pages><volume>137</volume><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1016/j.energy.2017.05.200</electronic-resource-num><notes>Cited by: 78</notes><research-notes>Cited by: 78</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020622964&amp;doi=10.1016%2Fj.energy.2017.05.200&amp;partnerID=40&amp;md5=e564d4b49f6e31721ba652253de94206</url></web-urls></urls><abstract>The public buildings sector represents one of the most intensive items of EU energy consumption; the application of retrofit solutions in existing buildings is a crucial way to reduce its impact. To facilitate the knowledge of the energy performance of existing non-residential buildings and the choice of the more adequate actions, Public Administrations (PA) should have the availability of proper tools. Within the Italian project “POI 2007-13”, a database and a decision support tool, for easy use, even to a non-technical user, have been developed. A large set of data, obtained from the energy audits of 151 existing public buildings located in four regions of South Italy have been analysed, elaborated, and organised in a database. This was used to identify the best architectures of two ANNs and to train them. The first ANN provides the actual energy performance of any building; the second ANN assesses key economic indicators. A decision support tool, based on the use of these ANNs is conceived for a fast prediction of the energy performance of buildings and for a first selection of energy retrofit actions that can be applied. © 2017 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Klievink, Bram</author><author>Romijn, Bart-Jan</author><author>Cunningham, Scott</author><author>de Bruijn, Hans</author></authors></contributors><titles><title>Big data in the public sector: Uncertainties and readiness</title><secondary-title>Information Systems Frontiers</secondary-title></titles><periodical><full-title>Information Systems Frontiers</full-title></periodical><pages>267 - 283</pages><volume>19</volume><issue>2</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1007/s10796-016-9686-2</electronic-resource-num><notes>Cited by: 157</notes><research-notes>Cited by: 157</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982126226&amp;doi=10.1007%2Fs10796-016-9686-2&amp;partnerID=40&amp;md5=84822de6a52d6dd0aeaa989cce50369e</url></web-urls></urls><abstract>Big data is being implemented with success in the private sector and science. Yet the public sector seems to be falling behind, despite the potential value of big data for government. Government organizations do recognize the opportunities of big data but seem uncertain about whether they are ready for the introduction of big data, and if they are adequately equipped to use big data. This paper addresses those uncertainties. It presents an assessment framework for evaluating public organizations’ big data readiness. Doing so demystifies the concept of big data, as it is expressed in terms of specific and measureable organizational characteristics. The framework was tested by applying it to organizations in the Dutch public sector. The results suggest that organizations may be technically capable of using big data, but they will not significantly gain from these activities if the applications do not fit their organizations and main statutory tasks. The framework proved helpful in pointing out areas where public sector organizations could improve, providing guidance on how government can become more big data ready in the future. © 2016, The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Desouza, Kevin C</author><author>Jacob, Benoy</author></authors></contributors><titles><title>Big Data in the Public Sector: Lessons for Practitioners and Scholars</title><secondary-title>Administration and Society</secondary-title></titles><periodical><full-title>Administration and Society</full-title></periodical><pages>1043 - 1064</pages><volume>49</volume><issue>7</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1177/0095399714555751</electronic-resource-num><notes>Cited by: 121</notes><research-notes>Cited by: 121</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022022132&amp;doi=10.1177%2F0095399714555751&amp;partnerID=40&amp;md5=212306507a9b50076c14acabdcbc3f6a</url></web-urls></urls><abstract>In this essay, we consider the role of Big Data in the public sector. Motivating our work is the recognition that Big Data is still in its infancy and many important questions regarding the true value of Big Data remain unanswered. The question we consider is as follows: What are the limits, or potential, of Big Data in the public sector? By reviewing the literature and summarizing insights from a series of interviews from public sector Chief Information Officers (CIOs), we offer a scholarly foundation for both practitioners and researchers interested in understanding Big Data in the public sector. © 2014, © The Author(s) 2014.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Shah, Naimatullah</author><author>Irani, Zahir</author><author>Sharif, Amir M</author></authors></contributors><titles><title>Big data in an HR context: Exploring organizational change readiness, employee attitudes and behaviors</title><secondary-title>Journal of Business Research</secondary-title></titles><periodical><full-title>Journal of Business Research</full-title></periodical><pages>366 - 378</pages><volume>70</volume><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1016/j.jbusres.2016.08.010</electronic-resource-num><notes>Cited by: 149</notes><research-notes>Cited by: 149</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504360&amp;doi=10.1016%2Fj.jbusres.2016.08.010&amp;partnerID=40&amp;md5=dc42efedbb49dcfed21f5826778fa7f6</url></web-urls></urls><abstract>This research highlights a contextual application for big data within a HR case study setting. This is achieved through the development of a normative conceptual model that seeks to envelop employee behaviors and attitudes in the context of organizational change readiness. This empirical application considers a data sample from a large public sector organization and through applying Structural Equation Modelling (SEM) identifies salary, job promotion, organizational loyalty and organizational identity influences on employee job satisfaction (suggesting and mediating employee readiness for organizational change). However in considering this specific context, the authors highlight how, where and why such a normative approach to employee factors may be limited and thus, proposes through a framework which brings together big data principles, implementation approaches and management commitment requirements can be applied and harnessed more effectively in order to assess employee attitudes and behaviors as part of wider HR predictive analytics (HRPA) approaches. The researchers conclude with a discussion on these research elements and a set of practical, conceptual and management implications of the findings along with recommendations for future research in the area. © 2016 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Baur, Aaron W</author></authors></contributors><titles><title>Harnessing the social web to enhance insights into people’s opinions in business, government and public administration</title><secondary-title>Information Systems Frontiers</secondary-title></titles><periodical><full-title>Information Systems Frontiers</full-title></periodical><pages>231 - 251</pages><volume>19</volume><issue>2</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1007/s10796-016-9681-7</electronic-resource-num><notes>Cited by: 42</notes><research-notes>Cited by: 42</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979692073&amp;doi=10.1007%2Fs10796-016-9681-7&amp;partnerID=40&amp;md5=2828e55730f793b2b6e35bef8411253a</url></web-urls></urls><abstract>Transparency, participation, and collaboration are the core pillars of open government. For the systematic integration of citizens and other stakeholders into the policy and public value creation process, their opinions, wishes, and complaints first need to be received. In the future, including user-generated content from social media will become a main channel for the enrichment of this information base for public administrative bodies and commercial firms. However, the sheer speed of growth of this constantly updated data pool makes manual work infeasible. The automated gathering, combination, analysis, and visualization of user-generated content from various sources and multiple languages is therefore imperative. In this study, we present a design science research approach to develop a general framework (‘MarketMiner’) to handle large amounts of foreign-language user-generated content. As a first empirical application, we implement the framework in the automotive industry by analyzing Chinese automotive forums for the benefit of English-speaking users. At the same time, the ideas, methods, and insights are transferred to the public sector context, especially in light of the current challenges of a high number of political refugees from Arabic countries entering into the European Union. The results are promising in that MarketMiner can dramatically improve the utilization of multi-language, multi-source social media content. The modular set-up of the artifact allows an easy transfer to additional areas of application. © 2016, Springer Science+Business Media New York.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Malomo, Fola</author><author>Sena, Vania</author></authors></contributors><titles><title>Data Intelligence for Local Government? Assessing the Benefits and Barriers to Use of Big Data in the Public Sector</title><secondary-title>Policy and Internet</secondary-title></titles><periodical><full-title>Policy and Internet</full-title></periodical><pages>7 - 27</pages><volume>9</volume><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1002/poi3.141</electronic-resource-num><notes>Cited by: 61</notes><research-notes>Cited by: 61</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006761764&amp;doi=10.1002%2Fpoi3.141&amp;partnerID=40&amp;md5=49fb93eee68dec97f0075e3bdff31997</url></web-urls></urls><abstract>The concept of Big Data has become very popular over the last decade, with large technology companies successfully building their business models around its exploitation. The public sector in the United Kingdom has tried to follow suit and local governments in particular have tried to introduce new models of service delivery based on the routine extraction of information from their own Big Data. These attempts have been hailed as the beginning of a new era for the public sector where service delivery and commissioning are shaped by data intelligence on local needs and by evidence on the outcomes. In this article we assess this claim and the extent to which it captures the way local governments in the United Kingdom use intelligence from Big Data in light of the structural barriers they face when trying to exploit their data. We also present a case study on the development and deployment of an integrated data model for children services in a large county council in the South-East of England. © 2016 Policy Studies Organization</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Lee, Gwanhoo</author></authors></contributors><titles><title>What roles should the government play in fostering the advancement of the internet of things?</title><secondary-title>Telecommunications Policy</secondary-title></titles><periodical><full-title>Telecommunications Policy</full-title></periodical><pages>434 - 444</pages><volume>43</volume><issue>5</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.telpol.2018.12.002</electronic-resource-num><notes>Cited by: 24</notes><research-notes>Cited by: 24</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057725886&amp;doi=10.1016%2Fj.telpol.2018.12.002&amp;partnerID=40&amp;md5=2a09962e7f0fb1f3c2689f0639cf9e69</url></web-urls></urls><abstract>The Internet of Things (IoT) has the potential to transform the way we live, work, do business, and meet the needs of the public. While IoT's potential benefits for economic growth and social welfare appear to be indisputable, IoT faces several technological, social, legal, and regulatory policy challenges, ranging from interoperability and spectrum availability to cybersecurity and privacy. These challenges can and should be addressed by the joint efforts of a wide range of stakeholders from the public and private sector. The advancement of IoT depends in part on how policymakers respond to the opportunities and challenges associated with it. This research aims to identify the potential roles for the government in fostering the advancement of IoT innovation and adoption. To this end, we analyze data collected from 177 documents of public comments submitted to the U.S. National Telecommunications and Information Administration and from a focus group discussion with senior managers. Our content data analysis results in a set of recommendations for the government in terms of general policy principles, specific policy prescriptions, and governance and process approach that facilitate policy development. © 2018 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Wenjing</author></authors></contributors><titles><title>Data analysis of intellectual property policy system based on Internet of Things</title><secondary-title>Enterprise Information Systems</secondary-title></titles><periodical><full-title>Enterprise Information Systems</full-title></periodical><pages>1475 - 1493</pages><volume>14</volume><issue>9-10</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1080/17517575.2020.1712744</electronic-resource-num><notes>Cited by: 9</notes><research-notes>Cited by: 9</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077840756&amp;doi=10.1080%2F17517575.2020.1712744&amp;partnerID=40&amp;md5=3237cbd6c3b68afff981bae2b95412ca</url></web-urls></urls><abstract>The issuance and implementation of intellectual property policies have promoted the rapid development of intellectual property intermediary services in China, bringing new opportunities and challenges for public sectors of the government. With their continuous development, Internet of Things (IoT) technology and big data have become the analytical tools widely applied in many technical fields. Through the analysis of IoT data, the optimal resource configuration could be obtained, which would guide both governments and enterprise managers to make scientific decisions in terms of future development. © 2020 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Androutsopoulou, Aggeliki</author><author>Karacapilidis, Nikos</author><author>Loukis, Euripidis</author><author>Charalabidis, Yannis</author></authors></contributors><titles><title>Transforming the communication between citizens and government through AI-guided chatbots</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><pages>358 - 367</pages><volume>36</volume><issue>2</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.10.001</electronic-resource-num><notes>Cited by: 300</notes><research-notes>Cited by: 300</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2019 - Androutsopoulou et al. - Government Information Quarterly.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054685951&amp;doi=10.1016%2Fj.giq.2018.10.001&amp;partnerID=40&amp;md5=ce8ec8ad15c56a4fce6c0f4d8eaa89ec</url></web-urls></urls><abstract>Driven by ‘success stories’ reported by private sector firms, government agencies have also started adopting various Artificial Intelligence (AI) technologies in diverse domains (e.g. health, taxation, and education); however, extensive research is required in order to exploit the full potential of AI in the public sector, and leverage various AI technologies to address important problems/needs. This paper makes a contribution in this direction: it presents a novel approach, as well as the architecture of an ICT platform supporting it, for the advanced exploitation of a specific AI technology, namely chatbots, in the public sector in order to address a crucial issue: the improvement of communication between government and citizens (which has for long time been problematic). The proposed approach builds on natural language processing, machine learning and data mining technologies, and leverages existing data of various forms (such as documents containing legislation and directives, structured data from government agencies’ operational systems, social media data, etc.), in order to develop a new digital channel of communication between citizens and government. Making use of appropriately structured and semantically annotated data, this channel enables ‘richer’ and more expressive interaction of citizens with government in everyday language, facilitating and advancing both information seeking and conducting of transactions. Compared to existing digital channels, the proposed approach is appropriate for a wider range of citizens’ interactions, with higher levels of complexity, ambiguity and uncertainty. In close co-operation with three Greek government agencies (the Ministry of Finance, a social security organization, and a big local government organization), this approach has been validated through a series of application scenarios. © 2018 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Anejionu, Obinna C D</author><author>Thakuriah, Piyushimita (Vonu)</author><author>McHugh, Andrew</author><author>Sun, Yeran</author><author>McArthur, David</author><author>Mason, Phil</author><author>Walpole, Rod</author></authors></contributors><titles><title>Spatial urban data system: A cloud-enabled big data infrastructure for social and economic urban analytics</title><secondary-title>Future Generation Computer Systems</secondary-title></titles><periodical><full-title>Future Generation Computer Systems</full-title></periodical><pages>456 - 473</pages><volume>98</volume><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.future.2019.03.052</electronic-resource-num><notes>Cited by: 42</notes><research-notes>Cited by: 42</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063759990&amp;doi=10.1016%2Fj.future.2019.03.052&amp;partnerID=40&amp;md5=670cf612ee5f79f8d8fb2bf23ecbbf60</url></web-urls></urls><abstract>The Spatial Urban Data System (SUDS) is a spatial big data infrastructure to support UK-wide analytics of the social and economic aspects of cities and city-regions. It utilises data generated from traditional as well as new and emerging sources of urban data. The SUDS deploys geospatial technology, synthetic small area urban metrics, and cloud computing to enable urban analytics, and geovisualization with the goal of deriving actionable knowledge for better urban management and data-driven urban decision making. At the core of the system is a programme of urban indicators generated by using novel forms of data and urban modelling and simulation programme. SUDS differs from other similar systems by its emphasis on the generation and use of regularly updated spatially-activated urban area metrics from real or near-real time data sources, to enhance understanding of intra-city interactions and dynamics. By deploying public transport, labour market accessibility and housing advertisement data in the system, we were able to identify spatial variations of key urban services at intra-city levels as well as social and economically-marginalised output areas in major cities across the UK. This paper discusses the design and implementation of SUDS, the challenges and limitations encountered, and considerations made during its development. The innovative approach adopted in the design of SUDS will enable it to support research and analysis of urban areas, policy and city administration, business decision-making, private sector innovation, and public engagement. Having been tested with housing, transport and employment metrics, efforts are ongoing to integrate information from other sources such as IoT, and User Generated Content into the system to enable urban predictive analytics. © 2019</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Huang, Jhong-You</author><author>Wey, Wann-Ming</author></authors></contributors><titles><title>Application of Big Data and Analytic Network Process for the Adaptive Reuse Strategies of School Land</title><secondary-title>Social Indicators Research</secondary-title></titles><periodical><full-title>Social Indicators Research</full-title></periodical><pages>1075 - 1102</pages><volume>142</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s11205-018-1951-y</electronic-resource-num><notes>Cited by: 16</notes><research-notes>Cited by: 16</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049589635&amp;doi=10.1007%2Fs11205-018-1951-y&amp;partnerID=40&amp;md5=d48d40eb7e47aa86b0438cba898dc6b8</url></web-urls></urls><abstract>Most recent discussion of the adaptive reuse of school land has focused almost exclusively on repurposing or redeploying vacant school space rather than comprehensively re-planning and constructing the entire school land for the overall needs of society and urban development. The relevant government agencies for school land reuse in Taiwan, such as the Ministry of Education and municipal governments, mostly provide subjective regulations or revitalization provisions for the sustainable development of school resources; however, no specific scientific assessment or a planning procedure has been proposed to revitalize school land. Therefore, constructing a scientific, quantitative, and objective planning framework and procedure is necessary for the adaptive reuse of school land based on the needs of overall society and urban development in order to replace the existing and outdated planning philosophy and to correct prominent shortcomings of past planning operations that were solely in accordance with the qualitative judgment and decision making of official agencies. In this study, we mainly adopted the analytic network process (ANP) and big data, including demographics, facility usage, and social welfare indicators, to assist the Taipei City government to construct or reform land reuse strategies for junior high and elementary schools facing immediate or future closure, consolidation, or downsizing. To take a more realistic approach to improve final decision making, the investigation of expert questionnaires through the ANP was based on the consideration of future trends that were objectively evaluated by big datasets. The novel planning philosophy and concise decision framework for reuse strategies we designed are expected to improve public decision-making transparency, adaptive reuse effectiveness, and quality of urban life. Ultimately, our proposed strategies and suggestions can not only assist local public sectors to promote the policy of adaptive reuse of surplus school lands but also serve as an appropriate blueprint of urban sustainability for the central government in the near future. © 2018, Springer Nature B.V.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Agarwal, P K</author></authors></contributors><titles><title>Public Administration Challenges in the World of AI and Bots</title><secondary-title>Public Administration Review</secondary-title></titles><periodical><full-title>Public Administration Review</full-title></periodical><pages>917 - 921</pages><volume>78</volume><issue>6</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1111/puar.12979</electronic-resource-num><notes>Cited by: 107</notes><research-notes>Cited by: 107</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053198340&amp;doi=10.1111%2Fpuar.12979&amp;partnerID=40&amp;md5=b9e4bea4646dabfc342c7e5654c7f723</url></web-urls></urls><abstract>Technology-driven disruption is taking place at a pace and scale not witnessed before in history. Waves of technology, such as the internet of things, big data, machine learning, and artificial intelligence, are reshaping our personal and professional lives in profound ways. A new world is emerging in which many of the current job classes will disappear, while new ones, requiring entirely different sets of skills, are emerging. Public administrators are unprepared for the challenges they must face in order to cope with this nonincremental and exponential change. Many of the existing government structures and processes that have evolved over the last few centuries will likely become irrelevant in the near future. There is a compelling need to lay the groundwork for governments to rethink how they will be able to best serve their constituents. © 2018 by The American Society for Public Administration</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mohabeer, Preethivirajsingh</author><author>Santally, Mohammad Issack</author><author>Sungkur, Roopesh Kevin</author></authors></contributors><titles><title>An Investigation of the Potential Benefits of Big Data in the Public Sector of Mauritius</title><secondary-title>Journal of the Knowledge Economy</secondary-title></titles><periodical><full-title>Journal of the Knowledge Economy</full-title></periodical><pages>1230 - 1247</pages><volume>10</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s13132-018-0524-2</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070240786&amp;doi=10.1007%2Fs13132-018-0524-2&amp;partnerID=40&amp;md5=5ff3be2b36f511901b7eb908f1a94330</url></web-urls></urls><abstract>This study examines how big data analytics could optimize the use of public funds while ensuring delivery of quality service by public organizations to the citizens of Mauritius. Political Economic Social Technological (PEST) analysis has been carried out to scan the environment to identify at least two major policies and initiatives corresponding to big data that will be impacting the Mauritian Economy in the next 10 years. Subsequently, causal layered analysis (CLA) has been applied for the two signals to create transformative spaces for the creation of alternative futures. Indeed, the findings have demonstrated that open data initiative and the implementation of e-health project in Mauritius would certainly contribute positively to the government of Mauritius. However, this study has revealed through a matrix diagram for probable futures that the Mauritian government should bring amendments to existing conventional laws through reforms and regulations to fully take advantage of big data analytics applications. This is also one of the recommendations of the Mauritius e-Government 2013–2017–Formulation and Implementation of Data Sharing Policy. Considering only the recent emergence of big data analytics in governments, still there is certain aspect of it that needs careful consideration before the full potential of big data could be realized. This research also highlights the factors that need to be addressed for the successful use of Big Data in this particular context. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schug, Donald M</author><author>Taylor, Peter H</author><author>Iudicello, Suzanne</author><author>Swasey, Jill H</author></authors></contributors><titles><title>Using online data visualization and analysis to facilitate public involvement in management of catch share programs</title><secondary-title>Marine Policy</secondary-title></titles><periodical><full-title>Marine Policy</full-title></periodical><volume>122</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.marpol.2020.104272</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093701142&amp;doi=10.1016%2Fj.marpol.2020.104272&amp;partnerID=40&amp;md5=8b22b3ecaa58ecfdc45bf0ab74440b40</url></web-urls></urls><abstract>This case study examines the experience of the interdisciplinary Measuring the Effects of Catch Shares (MECS) project, a five-year demonstration project designed to explore the opportunities and constraints for third-party acquisition, organization, and communication of government fisheries statistics in order to track the ecological, economic, social, and governance outcomes of catch share programs. Catch share programs, whereby fishery managers allocate to private entities percentages of the total amount of fish that can be caught in a year, have been used to manage some US fisheries since the 1990s. Given the high financial stakes of commercial fisheries and the wide-ranging impacts ascribed to these programs, they are among the most controversial and contentious tools of contemporary fisheries management. The goal of the MECS project was to create an interactive, web-based platform for conveying a set of neutral, scientific indicators based on the best available fisheries data that could be used by fishing industry participants, fishery managers, and other interested parties to supplement and inform their own understanding of catch share program effects. The MECS project focused on the effects of two US catch share programs: the Northeast Multispecies Sector Program implemented in 2010 in the Northeast groundfish fishery and the Shorebased IFQ Program implemented in 2011 in the West Coast groundfish trawl fishery. The MECS project encountered data access challenges but ultimately succeeded in developing a website that has been received by members of the private and public sector alike as a useful tool that brings together and communicates disparate information that is not otherwise readily accessible. © 2020 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Desouza, Kevin C</author><author>Dawson, Gregory S</author><author>Chenok, Daniel</author></authors></contributors><titles><title>Designing, developing, and deploying artificial intelligence systems: Lessons from and for the public sector</title><secondary-title>Business Horizons</secondary-title></titles><periodical><full-title>Business Horizons</full-title></periodical><pages>205 - 213</pages><volume>63</volume><issue>2</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.bushor.2019.11.004</electronic-resource-num><notes>Cited by: 143</notes><research-notes>Cited by: 143</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076865373&amp;doi=10.1016%2Fj.bushor.2019.11.004&amp;partnerID=40&amp;md5=fc35479cd1a61daae78aa0c13e609810</url></web-urls></urls><abstract>Artificial intelligence applications in cognitive computing systems can be found in organizations across every market, including chatbots that help customers navigate websites, predictive analytics systems used for fraud detection, and augmented decision-support systems for knowledge workers. In this article, we share reflections and insights from our experience with AI projects in the public sector that can add value to any organization. We organized our findings into four thematic domains—(1) data, (2) technology, (3) organizational, and (4) environmental—and examine them relative to the phases of AI. We conclude with best practices for capturing value with cognitive computing systems. © 2019 Kelley School of Business, Indiana University</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Al-Ruithe, Majid</author><author>Benkhelifa, Elhadj</author></authors></contributors><titles><title>Determining the enabling factors for implementing cloud data governance in the Saudi public sector by structural equation modelling</title><secondary-title>Future Generation Computer Systems</secondary-title></titles><periodical><full-title>Future Generation Computer Systems</full-title></periodical><pages>1061 - 1076</pages><volume>107</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.future.2017.12.057</electronic-resource-num><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040984891&amp;doi=10.1016%2Fj.future.2017.12.057&amp;partnerID=40&amp;md5=4605d7f9ba5bdaab23dd40e69c3d96f3</url></web-urls></urls><abstract>Businesses have grown more sophisticated in their use of data, which drives new demands that require different ways to handle this data. Data management solutions on their own are becoming very expensive and unable to cope with the reality of everlasting data complexity. Forward-thinking organisations believe that the only way to solve the data problem will be the implementation of effective data governance. Attempts to govern data failed before, as they were driven by information technology (IT), and affected by rigid processes and fragmented activities carried out on a system-by-system basis. Until very recently, governance remained mostly informal, with very ambiguous and generic regulations in silos around specific enterprise repositories, lacking structure and the wider support of the organisation. Despite its highly recognised importance, the area of data governance is still underdeveloped and under-researched. In the cloud computing context, the cloud brings new issues of data governance, where the loss of governance is one of the top risks of cloud computing. Thus, before adopting the cloud, the organisations should develop a cloud data governance programme. It is important, therefore, to understand the enabling factors for successful implementation of cloud data governance in organisations. However, as every organisation has its own constraints and requirements, the phrase ‘no one size fits all’ applies in this case. This study focuses on the case of the public sector in the Kingdom of Saudi Arabia. Therefore, the aim of this research is to identify the enabling factors in adopting and implementing cloud data governance in the Saudi public sector. The study's sample covered the largest and most important Saudi public sector organisations, with questionnaires distributed to relevant employees. The results of the study were based on 206 respondents, and structural equation modelling (SEM) was used to evaluate these results. © 2018 Elsevier B.V.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Uras, Marco</author><author>Cossu, Raimondo</author><author>Ferrara, Enrico</author><author>Liotta, Antonio</author><author>Atzori, Luigi</author></authors></contributors><titles><title>PmA: A real-world system for people mobility monitoring and analysis based on Wi-Fi probes</title><secondary-title>Journal of Cleaner Production</secondary-title></titles><periodical><full-title>Journal of Cleaner Production</full-title></periodical><volume>270</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.jclepro.2020.122084</electronic-resource-num><notes>Cited by: 18</notes><research-notes>Cited by: 18</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088903935&amp;doi=10.1016%2Fj.jclepro.2020.122084&amp;partnerID=40&amp;md5=205a310bce14a5b029ee720d8bf82eb9</url></web-urls></urls><abstract>A UN report states that in 2050, about 70% of the total world population will live in cities. This increases the complexity of the services that the local public administrations have to provide the citizens with to keep an acceptable level of quality of life. For an appropriate design, deployment and management of these services, there is the need for tools to extract data on how the people move, which activities they conduct out and their behaviour (in an anonymous way). This need has justified extensive efforts towards the design of effective solutions for extracting this information. In this work, we present the People Mobility Analytics (PmA) solution, which collects probe requests generated by Wi-Fi devices when scanning the radio channels to detect Access Points. The PmA system processes the collected data to extract key insights on the people mobility, such as: crowd density per area of interest, people flows, time of permanence, time of return, heat maps, origin-destination matrices and estimation of people positions. The major novelty with respect to the state of the art is related to new powerful indicators that are needed for some key city services, such as security management and people transport services, and the experimental activities carried out in real scenarios. © 2020 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fatima, Samar</author><author>Desouza, Kevin C</author><author>Dawson, Gregory S</author></authors></contributors><titles><title>National strategic artificial intelligence plans: A multi-dimensional analysis</title><secondary-title>Economic Analysis and Policy</secondary-title></titles><periodical><full-title>Economic Analysis and Policy</full-title></periodical><pages>178 - 194</pages><volume>67</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.eap.2020.07.008</electronic-resource-num><notes>Cited by: 77</notes><research-notes>Cited by: 77</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088951674&amp;doi=10.1016%2Fj.eap.2020.07.008&amp;partnerID=40&amp;md5=ac89bbeb30219b35234f7a809685c74b</url></web-urls></urls><abstract>Nations have recognized the transformational potential of artificial intelligence (AI). Advances in AI will impact all facets of society. A spate of recently released national strategic AI plans provides valuable insights into how nations are considering their future trajectories. These strategic plans offer a rich source of evidence to understand national-level strategic actions, both proactive and reactive, in the face of rapid technological innovation. Based on a comprehensive content analysis of thirty-four national strategic plans, this article reports on (1) opportunities for AI to modernize the public sector and enhance industry competitiveness, (2) the role of the public sector in ensuring that the two most critical elements of AI systems, data and algorithms, are managed responsibly, (3) the role of the public sector in the governance of AI systems, and (4) how nations plan to invest in capacity development initiatives to strengthen their AI capabilities. © 2020 Economic Society of Australia, Queensland</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fertier, Audrey</author><author>Montarnal, Aurélie</author><author>Barthe-Delanoë, Anne-Marie</author><author>Truptil, Sébastien</author><author>Bénaben, Frédérick</author></authors></contributors><titles><title>Real-time data exploitation supported by model- and event-driven architecture to enhance situation awareness, application to crisis management</title><secondary-title>Enterprise Information Systems</secondary-title></titles><periodical><full-title>Enterprise Information Systems</full-title></periodical><pages>769 - 796</pages><volume>14</volume><issue>6</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1080/17517575.2019.1691268</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075751430&amp;doi=10.1080%2F17517575.2019.1691268&amp;partnerID=40&amp;md5=e228c8ac55142603a797ddbe5d73d375</url></web-urls></urls><abstract>An effective crisis response requires up-to-date information. The crisis cell must reach for new, external, data sources. However, new data lead to new issues: their volume, veracity, variety or velocity cannot be managed by humans only, especially under high stress and time pressure. This paper proposes (i) a framework to enhance situation awareness while managing the 5Vs of Big Data, (ii) general principles to be followed and (iii) a new architecture implementing the proposed framework. The latter merges event-driven and model-driven architectures. It has been tested on a realistic flood scenario set up by official French services. © 2019, © 2019 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Conejero, Jose María</author><author>Preciado, Juan Carlos</author><author>Fernández-García, Antonio Jesús</author><author>Prieto, Alvaro E</author><author>Rodríguez-Echeverría, Roberto</author></authors></contributors><titles><title>Towards the use of Data Engineering, Advanced Visualization techniques and Association Rules to support knowledge discovery for public policies</title><secondary-title>Expert Systems with Applications</secondary-title></titles><periodical><full-title>Expert Systems with Applications</full-title></periodical><volume>170</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.eswa.2020.114509</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099203384&amp;doi=10.1016%2Fj.eswa.2020.114509&amp;partnerID=40&amp;md5=4128dc687f091e1ea31b108141d34243</url></web-urls></urls><abstract>Education and employment are key aspects of a country's well-being. Governments expend valuable resources on designing education plans and employment programs. These two aspects are usually analysed separately, although, as they are closely related, considering them together might improve their efficacy. The problem lies, at least in part, in the fact that different public entities manage their own data with their own isolated systems, and do not develop joint educational and employment policies. In order to facilitate working towards this goal, in this manuscript, we make use of Data Engineering, Data Visualization, and Intelligent Data Analytics methods to create a decision support system for the Government of Extremadura. Extremadura is a European Union Objective 1 region in Spain with high rates of unemployment and secondary school drop-out. Data Engineering is used to create a Data Warehouse that unifies the different data sources into a central repository for quick access and control. This allows dealing with the challenge of transforming, processing, storing and accessing the data. Data Visualization techniques are applied to create an interactive dashboard that assists users in analysing and interpreting the data in the Data Warehouse repository. Thus, charts, diagrams, and maps are created specifically to help technical or political decision-makers. Finally, Intelligent Data Analytics techniques are used to incorporate Association Rules into the visualization dashboard. Its goal is to identify associations, relationships, and patterns in data that, at least in plain sight, are not readable or interpretable by humans. It does this by inferring knowledge that humans cannot pick out by themselves. As a result, a complete system was defined and implemented to support public administrations in their decision-making and definition of precise evidence-based policies in the areas of education and employment. In particular, it allows the definition of unified strategies to reduce the unemployment rate. © 2020 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Merhi, Mohammad I</author></authors></contributors><titles><title>Evaluating the critical success factors of data intelligence implementation in the public sector using analytical hierarchy process</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>173</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.techfore.2021.121180</electronic-resource-num><notes>Cited by: 21</notes><research-notes>Cited by: 21</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114125763&amp;doi=10.1016%2Fj.techfore.2021.121180&amp;partnerID=40&amp;md5=0789d492ad5068a120a6a2b024e925df</url></web-urls></urls><abstract>This study aims to fill a gap in the literature by identifying, defining, and evaluating the critical success factors that impact the implementation of data intelligence in the public sector. Fourteen factors were identified, and then divided into three categories: organization, process, and technology. We used the analytical hierarchy process, a quantitative method of decision-making, to evaluate the importance of the factors presented in the study using data collected from nine experts. The results showed that technology, as a category, is the most important. The analysis also indicated that project management, information systems &amp; data, and data quality are the most important factors among all fourteen critical success factors. We discuss the implications of the analysis for practitioners and researchers in the paper. © 2021</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Mengji</author><author>Xu, Shan</author><author>Husain, Lewis</author><author>Galea, Gauden</author></authors></contributors><titles><title>Digital health interventions for COVID-19 in China: a retrospective analysis</title><secondary-title>Intelligent Medicine</secondary-title></titles><periodical><full-title>Intelligent Medicine</full-title></periodical><pages>29 - 36</pages><volume>1</volume><issue>1</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.imed.2021.03.001</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127092627&amp;doi=10.1016%2Fj.imed.2021.03.001&amp;partnerID=40&amp;md5=a7cb429f52fba17270bfed2276b4e656</url></web-urls></urls><abstract>Background: The use of digital health technologies was an integral part to China's early response to coronavirus disease 2019 (COVID-19). Existing literatures have analyzed and discussed implemented digital health innovations from the perspective of technologies, whereas how policy mechanisms contributed to the formulation of the digital health landscape for COVID-19 was overlooked. This study aimed to examine the contexts and key mechanisms in China's rapid mobilization of digital health interventions in response to COVID-19, and to document and share lessons learned. Methods: Policy documents were identified and retrieved from government portals and recognized media outlets. Data on digital health interventions were collected through three consecutive surveys administered between 23 January 2020 and 31 March 2020 by China Academy of Information and Communication Technology (CAICT) affiliated to the Ministry of Industry and Information Technology (MIIT). Participants were member companies of the Internet Health alliance established by MIIT and the National Health Commission (NHC) in June 2016. Self-report digital interventions focusing on social and economic recovery were excluded. Two hundred and sixty-six unique digital health interventions meeting our criteria were extracted from 175 narratives on digital health interventions submitted by 116 participating companies. Thematic analysis was conducted to describe the scope and priority of policies advocating for the use of digital health technologies and the implementation pattern of digital health interventions. Data limitations precluded an evaluation of the impact of digital health interventions over a longer time frame. Results: Between January and March 2020, national policy directives promoting the use of digital technologies for the containment of COVID-19 collectively advocated for use cases in emergency planning and preparedness, public health response, and clinical services. Interventions to strengthen clinical services were mentioned more than the other two themes (n = 15, 62.5% (15/24)). Using digital technologies for public health response was mentioned much less than clinical services (n = 5, 20.8% (5/24)). Emergency planning and preparedness was least mentioned (n = 4, 16.7% (4/24)). Interventions in support of clinical services disproportionately favored healthcare facilities in less resource-constraint settings. Digital health interventions shared the same pattern of distribution. More digital health technologies were implemented in clinical services (n = 103, 38.7% (103/266)) than that in public health response (n = 91, 34.2% (91/266)). Emergency planning and preparedness had the least self-reported digital health interventions (n = 72, 27.1% (72/266)). We further identified case studies under each theme in which the wide use of digital health technologies highlighted contextual factors and key enabling mechanisms. Conclusions: The contextual factors and key enabling mechanisms through the use of policy instruments to promote digital health interventions for COVID-19 in China include pathway of policy directives influencing the private sector using a decentralized system, the booming digital health landscape before COVID-19, agility of the public sector in introducing regulatory flexibilities and incentives to mobilize the private sector. © 2021</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Shah, Syed Iftikhar Hussain</author><author>Peristeras, Vassilios</author><author>Magnisalis, Ioannis</author></authors></contributors><titles><title>DaLiF: a data lifecycle framework for data-driven governments</title><secondary-title>Journal of Big Data</secondary-title></titles><periodical><full-title>Journal of Big Data</full-title></periodical><volume>8</volume><issue>1</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1186/s40537-021-00481-3</electronic-resource-num><notes>Cited by: 21</notes><research-notes>Cited by: 21</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2021 - Shah, Peristeras, Magnisalis - Journal of Big Data.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107949250&amp;doi=10.1186%2Fs40537-021-00481-3&amp;partnerID=40&amp;md5=7e2b6c38f966b0ec182fc8db046b6f01</url></web-urls></urls><abstract>The public sector, private firms, business community, and civil society are generating data that is high in volume, veracity, velocity and comes from a diversity of sources. This kind of data is known as big data. Public Administrations (PAs) pursue big data as “new oil” and implement data-centric policies to transform data into knowledge, to promote good governance, transparency, innovative digital services, and citizens’ engagement in public policy. From the above, the Government Big Data Ecosystem (GBDE) emerges. Managing big data throughout its lifecycle becomes a challenging task for governmental organizations. Despite the vast interest in this ecosystem, appropriate big data management is still a challenge. This study intends to fill the above-mentioned gap by proposing a data lifecycle framework for data-driven governments. Through a Systematic Literature Review, we identified and analysed 76 data lifecycles models to propose a data lifecycle framework for data-driven governments (DaliF). In this way, we contribute to the ongoing discussion around big data management, which attracts researchers’ and practitioners’ interest. © 2021, The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aerts, Ann</author><author>Bogdan-Martin, Doreen</author></authors></contributors><titles><title>Leveraging data and AI to deliver on the promise of digital health</title><secondary-title>International Journal of Medical Informatics</secondary-title></titles><periodical><full-title>International Journal of Medical Informatics</full-title></periodical><volume>150</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijmedinf.2021.104456</electronic-resource-num><notes>Cited by: 24</notes><research-notes>Cited by: 24</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104593451&amp;doi=10.1016%2Fj.ijmedinf.2021.104456&amp;partnerID=40&amp;md5=5f038d694972617af3b3d92f70ca9ad9</url></web-urls></urls><abstract>Rising rates of NCDs threaten fragile healthcare systems in low- and middle-income countries. Fortunately, new digital technology provides tools to more effectively address the growing dual burden of disease. Two-thirds of the world's population subscribed to mobile services by the end of 2018, while the falling price of connectivity and the 5G networks rollout promise to accelerate the use of digital technology. Properly leveraged, we can employ digital solutions and applications to transform health systems from reactive to proactive and even preventive, helping people stay healthy. With artificial intelligence (AI), health systems can be made more predictive by detecting risk factors and helping health professionals respond faster to prevent disease. Yet this rapid pace of growth has also complicated the digital health landscape. Myriad digital health apps compete and overlap in the public and private sectors, and significant gaps in the collection and analysis of digital data threaten to leave some behind. Established in 2010, the Broadband Commission for Sustainable Development is led by ITU and UNESCO and advocates for the transformational impact of broadband technologies for development. Its working group on digital and AI in health, co-chaired by the Novartis Foundation and at different times Nokia, Intel and Microsoft, identifies best practices for countries to realize the potential of digital technology in health and care. Interviewing more than 100 key stakeholders and reviewing over 200 documents, the Working Group set out to identify common challenges that countries face in implementing digital health solutions, and to develop a framework that countries can use to build systems for supporting digital health solutions. Common challenges include a lack of coordination leading to fragmented digital health solutions; lack of systems and workforce capacity to manage data and digital technology, and inadequate financing to support digital health. The working group proposes six building blocks for digital health systems: formulate and execute a national digital health strategy; create policy and regulatory frameworks that support innovation while protecting security and privacy; ensure access to digital infrastructure; ensure interoperability of digital health system components; establish effective partnerships; and sustain adequate financing. © 2021</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rosecký, Martin</author><author>Šomplák, Radovan</author><author>Slavík, Jan</author><author>Kalina, Jiří</author><author>Bulková, Gabriela</author><author>Bednář, Josef</author></authors></contributors><titles><title>Predictive modelling as a tool for effective municipal waste management policy at different territorial levels</title><secondary-title>Journal of Environmental Management</secondary-title></titles><periodical><full-title>Journal of Environmental Management</full-title></periodical><volume>291</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.jenvman.2021.112584</electronic-resource-num><notes>Cited by: 39</notes><research-notes>Cited by: 39</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2021 - Rosecký et al. - Journal of Environmental Management.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105836019&amp;doi=10.1016%2Fj.jenvman.2021.112584&amp;partnerID=40&amp;md5=c8d07d817d38ecd149aca24836cb81d4</url></web-urls></urls><abstract>Nowadays, the European municipal waste management policy based on the circular economy paradigm demands the closing of material and financial loops at all territorial levels of public administration. The effective planning of treatment capacities (especially sorting plants, recycling, and energy recovery facilities) and municipal waste management policy requires an accurate prognosis of municipal waste generation, and therefore, the knowledge of behavioral, socio-economic, and demographic factors influencing the waste management (and recycling) behavior of households, and other municipal waste producers. To enable public bodies at different territorial levels to undertake an effective action resulting in circular economy we evaluated various factors influencing the generation of municipal waste fractions at regional, micro-regional and municipal level in the Czech Republic. Principal components were used as input for traditional models (multivariable linear regression, generalized linear model) as well as tree-based machine learning models (regression trees, random forest, gradient boosted regression trees). Study results suggest that the linear regression model usually offers a good trade-off between model accuracy and interpretability. When the most important goal of the prediction is supposed to be accuracy, the random forest is generally the best choice. The quality of developed models depends mostly on the chosen territorial level and municipal waste fraction. The performance of these models deteriorates significantly for lower territorial levels because of worse data quality and bigger variability. Only the age structure seems to be important across territorial levels and municipal waste fractions. Nevertheless, also other factors are of high significance in explaining the generation of municipal waste fractions at different territorial levels (e.g. number of economic subjects, expenditures, population density and the level of education). Therefore, there is not one single effective public policy dealing with circular economy strategy that fits all territorial levels. Public representatives should focus on policies effective at specific territorial level. However, performance of the models is poor for lower territorial levels (municipality and micro-regions). Thus, results for municipalities and micro-regions are weak and should be treated as such. © 2021 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Tao</author><author>Guo, Wenshan</author><author>Gao, Xian</author><author>Liang, Zhehao</author></authors></contributors><titles><title>AI-based self-service technology in public service delivery: User experience and influencing factors</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>38</volume><issue>4</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.giq.2020.101520</electronic-resource-num><notes>Cited by: 92</notes><research-notes>Cited by: 92</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089828048&amp;doi=10.1016%2Fj.giq.2020.101520&amp;partnerID=40&amp;md5=28cacbd12928c430ac12983255acca06</url></web-urls></urls><abstract>Public sectors are utilizing AI-based self-service technology (SST) at an accelerating rate, given its potential for improving work efficiency and user experience, reducing service costs, and relieving human workloads. However, there is a limited understanding of the factors influencing citizens' user experience when services supported by AI-based SST are provided. Thus, with insights from the Consumer Value Theory, this paper aims to explore the factors that are important to AI-based SST user experience and the conditional role of trust in government. The on-site survey of 379 citizens in a public service center in China indicates that user experience positively relates to personalization and aesthetics and negatively associates with perceived time spent on the AI-based self-service machines. In addition, the results suggest that citizens with more trust in government are more likely to have a pleasant experience coming from AI-based SST's personalization and aesthetics. Public managers should ensure that the AI-based SST is aesthetically appealing and should be able to personalize the delivery of the right contents to the right person at the right time. Furthermore, they should always prioritize cultivating more trust from citizens to achieve a more positive user experience. © 2020 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gupta, Agrayan K</author><author>Grannis, Shaun J</author><author>Kasthurirathne, Suranga N</author></authors></contributors><titles><title>Evaluation of a parsimonious COVID-19 outbreak prediction model: Heuristic modeling approach using publicly available data sets</title><secondary-title>Journal of Medical Internet Research</secondary-title></titles><periodical><full-title>Journal of Medical Internet Research</full-title></periodical><volume>23</volume><issue>7</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.2196/28812</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111662029&amp;doi=10.2196%2F28812&amp;partnerID=40&amp;md5=91e9b6c0330c87a0a41079b625b4537c</url></web-urls></urls><abstract>Background: The COVID-19 pandemic has changed public health policies and human and community behaviors through lockdowns and mandates. Governments are rapidly evolving policies to increase hospital capacity and supply personal protective equipment and other equipment to mitigate disease spread in affected regions. Current models that predict COVID-19 case counts and spread are complex by nature and offer limited explainability and generalizability. This has highlighted the need for accurate and robust outbreak prediction models that balance model parsimony and performance. Objective: We sought to leverage readily accessible data sets extracted from multiple states to train and evaluate a parsimonious predictive model capable of identifying county-level risk of COVID-19 outbreaks on a day-to-day basis. Methods: Our modeling approach leveraged the following data inputs: COVID-19 case counts per county per day and county populations. We developed an outbreak gold standard across California, Indiana, and Iowa. The model utilized a per capita running 7-day sum of the case counts per county per day and the mean cumulative case count to develop baseline values. The model was trained with data recorded between March 1 and August 31, 2020, and tested on data recorded between September 1 and October 31, 2020. Results: The model reported sensitivities of 81%, 92%, and 90% for California, Indiana, and Iowa, respectively. The precision in each state was above 85% while specificity and accuracy scores were generally &gt;95%. Conclusions: Our parsimonious model provides a generalizable and simple alternative approach to outbreak prediction. This methodology can be applied to diverse regions to help state officials and hospitals with resource allocation and to guide risk management, community education, and mitigation strategies. © Agrayan K Gupta, Shaun J Grannis, Suranga N Kasthurirathne. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 26.07.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ortiz, Guadalupe</author><author>Zouai, Meftah</author><author>Kazar, Okba</author><author>Garcia-de-Prado, Alfonso</author><author>Boubeta-Puig, Juan</author></authors></contributors><titles><title>Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing</title><secondary-title>Computer Standards and Interfaces</secondary-title></titles><periodical><full-title>Computer Standards and Interfaces</full-title></periodical><volume>79</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.csi.2021.103550</electronic-resource-num><notes>Cited by: 34</notes><research-notes>Cited by: 34</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109793830&amp;doi=10.1016%2Fj.csi.2021.103550&amp;partnerID=40&amp;md5=ca74fbfbf75ea930971d1ca51b06af7b</url></web-urls></urls><abstract>The Internet of Things (IoT) has grown significantly in popularity, accompanied by increased capacity and lower cost of communications, and overwhelming development of technologies. At the same time, big data and real-time data analysis have taken on great importance and have been accompanied by unprecedented interest in sharing data among citizens, public administrations and other organisms, giving rise to what is known as the Collaborative Internet of Things. This growth in data and infrastructure must be accompanied by a software architecture that allows its exploitation. Although there are various proposals focused on the exploitation of the IoT at edge, fog and/or cloud levels, it is not easy to find a software solution that exploits the three tiers together, taking maximum advantage not only of the analysis of contextual and situational data at each tier, but also of two-way communications between adjacent ones. In this paper, we propose an architecture that solves these deficiencies by proposing novel technologies which are appropriate for managing the resources of each tier: edge, fog and cloud. In addition, the fact that two-way communications along the three tiers of the architecture is allowed considerably enriches the contextual and situational information in each layer, and substantially assists decision making in real time. The paper illustrates the proposed software architecture through a case study of respiratory disease surveillance in hospitals. As a result, the proposed architecture permits efficient communications between the different tiers responding to the needs of these types of IoT scenarios. © 2021 The Author(s)</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zuiderwijk, Anneke</author><author>Chen, Yu-Che</author><author>Salem, Fadi</author></authors></contributors><titles><title>Implications of the use of artificial intelligence in public governance: A systematic literature review and a research agenda</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>38</volume><issue>3</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.giq.2021.101577</electronic-resource-num><notes>Cited by: 237</notes><research-notes>Cited by: 237</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103086959&amp;doi=10.1016%2Fj.giq.2021.101577&amp;partnerID=40&amp;md5=9d9059392cac8088c36742758978ae30</url></web-urls></urls><abstract>To lay the foundation for the special issue that this research article introduces, we present 1) a systematic review of existing literature on the implications of the use of Artificial Intelligence (AI) in public governance and 2) develop a research agenda. First, an assessment based on 26 articles on this topic reveals much exploratory, conceptual, qualitative, and practice-driven research in studies reflecting the increasing complexities of using AI in government – and the resulting implications, opportunities, and risks thereof for public governance. Second, based on both the literature review and the analysis of articles included in this special issue, we propose a research agenda comprising eight process-related recommendations and seven content-related recommendations. Process-wise, future research on the implications of the use of AI for public governance should move towards more public sector-focused, empirical, multidisciplinary, and explanatory research while focusing more on specific forms of AI rather than AI in general. Content-wise, our research agenda calls for the development of solid, multidisciplinary, theoretical foundations for the use of AI for public governance, as well as investigations of effective implementation, engagement, and communication plans for government strategies on AI use in the public sector. Finally, the research agenda calls for research into managing the risks of AI use in the public sector, governance modes possible for AI use in the public sector, performance and impact measurement of AI use in government, and impact evaluation of scaling-up AI usage in the public sector. © 2021 The Author(s)</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Scannapieco, Monica</author><author>Virgillito, Antonino</author></authors></contributors><titles><title>How to be responsible in all the steps of a data science pipeline: The case of the Italian public sector</title><secondary-title>Patterns</secondary-title></titles><periodical><full-title>Patterns</full-title></periodical><volume>2</volume><issue>12</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.patter.2021.100393</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123699030&amp;doi=10.1016%2Fj.patter.2021.100393&amp;partnerID=40&amp;md5=59508b82ca85b4bd4c7c7900835c15bc</url></web-urls></urls><abstract>The paper highlights how each step of a data science pipeline can be performed in a “responsible” way, taking into account privacy, ethics, and quality issues. Several examples from the Italian public sector contribute to clarifying how data collections and data analyses can be carried out under a responsible view. © 2021 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wirtz, Bernd W</author><author>Weyerer, Jan C</author><author>Kehl, Ines</author></authors></contributors><titles><title>Governance of artificial intelligence: A risk and guideline-based integrative framework</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>39</volume><issue>4</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101685</electronic-resource-num><notes>Cited by: 38</notes><research-notes>Cited by: 38</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Wirtz, Weyerer, Kehl - Government Information Quarterly.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126090396&amp;doi=10.1016%2Fj.giq.2022.101685&amp;partnerID=40&amp;md5=ba7bab1e031c65b0fd444ce43f61599f</url></web-urls></urls><abstract>This study addresses the growing challenge of governing artificial intelligence (AI) arising from the risks that it increasingly poses to the public sector and society. Based on an in-depth literature analysis, we first identify AI risks and guidelines and classify them into six categories, including technological, data, and analytical risks and guidelines, informational and communicational risks and guidelines, economic risks and guidelines, social risks and guidelines, ethical risks and guidelines, as well as legal and regulatory risks and guidelines. These risks and guidelines are then elaborated and transferred into a four-layered conceptual framework for AI governance. The framework interrelates AI risks and AI guidelines by means of a risk management and guidance process, resulting in an AI governance layer depicting the process for implementation of customised risk mitigation guidelines. The framework constitutes a comprehensive reference point for developing and implementing AI governance strategies and measures in the public sector. © 2022 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ahn, Michael J</author><author>Chen, Yu-Che</author></authors></contributors><titles><title>Digital transformation toward AI-augmented public administration: The perception of government employees and the willingness to use AI in government</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>39</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2021.101664</electronic-resource-num><notes>Cited by: 73</notes><research-notes>Cited by: 73</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122144137&amp;doi=10.1016%2Fj.giq.2021.101664&amp;partnerID=40&amp;md5=c68caf4d5ae4568a5c61bd0824524bf8</url></web-urls></urls><abstract>Government employees play a critical role in adopting and using new technologies in government, and their attitude and willingness to use them matter in creating a sustainable and meaningful digital transformation. This study explores how the perception of government employees shapes the willingness to support the use of AI technologies in government. Based on a survey data on current government employees in the U.S., our analysis reveals that the willingness to implement and use AI technologies in government was contingent upon a series of positive and negative perceptions about the new technologies, long-term outlook on the role of AI technologies in society, and the familiarity and experience in using some form of AI applications in the past. In particular, the perception of AI enhancing the efficiency and effectiveness of the work and a positive and longer-term outlook on AI's future about human labor (as an assistant or a competitor), the perception of the technology's ultimate harm or benefit (does it harm or benefit humanity), its ability to eventually make ethical and moral judgments influenced the willingness to support AI technologies in government. A substantial proportion of the government employees in the survey sample responded that they had experienced using some form of AI applications in their work and this familiarity had a strong positive influence on their support for AI. Our findings point to the importance of training the government employees in AI technologies to improve their understanding and perception about the new technologies as well as their potentials in government that will foster a culture of innovation toward sustainable and impactful digital transformation. © 2021 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chaudhary, Megha</author><author>Bansal, Divya</author></authors></contributors><titles><title>Open source intelligence extraction for terrorism-related information: A review</title><secondary-title>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</secondary-title></titles><periodical><full-title>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</full-title></periodical><volume>12</volume><issue>5</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1002/widm.1473</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133547962&amp;doi=10.1002%2Fwidm.1473&amp;partnerID=40&amp;md5=56381c931174ffdc73145c4045cbb53e</url></web-urls></urls><abstract>In this contemporary era, where a large part of the world population is deluged by extensive use of the internet and social media, terrorists have found it a potential opportunity to execute their vicious plans. They have got a befitting medium to reach out to their targets to spread propaganda, disseminate training content, operate virtually, and further their goals. To restrain such activities, information over the internet in context of terrorism needs to be analyzed to channel it to appropriate measures in combating terrorism. Open Source Intelligence (OSINT) accounts for a felicitous solution to this problem, which is an emerging discipline of leveraging publicly accessible sources of information over the internet by effectively utilizing it to extract intelligence. The process of OSINT extraction is broadly observed to be in three phases (i) Data Acquisition, (ii) Data Enrichment, and (iii) Knowledge Inference. In the context of terrorism, researchers have given noticeable contributions in compliance with these three phases. However, a comprehensive review that delineates these research contributions into an integrated workflow of intelligence extraction has not been found. The paper presents the most current review in OSINT, reflecting how the various state-of-the-art tools and techniques can be applied in extracting terrorism-related textual information from publicly accessible sources. Various data mining and text analysis-based techniques, that is, natural language processing, machine learning, and deep learning have been reviewed to extract and evaluate textual data. Additionally, towards the end of the paper, we discuss challenges and gaps observed in different phases of OSINT extraction. This article is categorized under: Application Areas &gt; Government and Public Sector Commercial, Legal, and Ethical Issues &gt; Social Considerations Fundamental Concepts of Data and Knowledge &gt; Motivation and Emergence of Data Mining. © 2022 Wiley Periodicals LLC.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bodó, Balázs</author><author>Janssen, Heleen</author></authors></contributors><titles><title>Maintaining trust in a technologized public sector</title><secondary-title>Policy and Society</secondary-title></titles><periodical><full-title>Policy and Society</full-title></periodical><pages>414 - 429</pages><volume>41</volume><issue>3</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1093/polsoc/puac019</electronic-resource-num><notes>Cited by: 13</notes><research-notes>Cited by: 13</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Bodó, Janssen - Policy and Society.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144051812&amp;doi=10.1093%2Fpolsoc%2Fpuac019&amp;partnerID=40&amp;md5=1c490966292cbf967095b39e612e5524</url></web-urls></urls><abstract>Emerging technologies permeate and potentially disrupt a wide spectrum of our social, economic, and political relations. Various state institutions, including education, law enforcement, and healthcare, increasingly rely on technical components, such as automated decision-making systems, e-government systems, and other digital tools to provide cheap, efficient public services, and supposedly fair, transparent, disinterested, and accountable public administration. The increased interest in various blockchain-based solutions from central bank digital currencies, via tokenized educational credentials, and distributed ledger-based land registries to self-sovereign identities is the latest, still mostly unwritten chapter in a long history of standardized, objectified, automated, technocratic, and technologized public administration. The rapid, (often) unplanned, and uncontrolled technologization of public services (as happened in the hasty adoption of distance-learning and teleconferencing systems during Corona Virus Disease (COVID) lockdowns) raises complex questions about the use of novel technological components, which may or may not be ultimately adequate for the task for which they are used. The question whether we can trust the technical infrastructures the public sector uses when providing public services is a central concern in an age where trust in government is declining: If the government’s artificial intelligence system that detects welfare fraud fails, the public’s confidence in the government is ultimately hit. In this paper, we provide a critical assessment of how the use of potentially untrustworthy (private) technological systems including blockchain-based systems in the public sector may affect trust in government. We then propose several policy options to protect the trust in government even if some of their technological components prove fundamentally untrustworthy. © The Author(s) 2022. Published by Oxford University Press.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Criado, J Ignacio</author><author>O.de Zarate-Alcarazo, Lucia</author></authors></contributors><titles><title>Technological frames, CIOs, and Artificial Intelligence in public administration: A socio-cognitive exploratory study in Spanish local governments</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>39</volume><issue>3</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101688</electronic-resource-num><notes>Cited by: 24</notes><research-notes>Cited by: 24</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Criado, O.de Zarate-Alcarazo - Government Information Quarterly.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126864088&amp;doi=10.1016%2Fj.giq.2022.101688&amp;partnerID=40&amp;md5=a69857fd60b8092c99df31f6439403b3</url></web-urls></urls><abstract>Artificial Intelligence (AI) policies and strategies have been designed and adopted in the public sector during the last few years, with Chief Information Officers (CIOs) playing a key role. Using socio-cognitive and institutional approaches on Information Technologies (ITs) in (public) organizations, we consider that the assumptions, expectations, and knowledge (technological frames) of those in charge (CIOs) of designing AI strategies are guiding the future of these emerging systems in the public sector. In this study, we focus on the technological frames of CIOs in the largest Spanish local governments. Based on a survey administered to CIOs leading IT departments, this article presents original data about their technological frames on AI. Our results: (1) provide insights about how CIOs tend to focus on the technological features of AI implementation while often overlook some of the social, political, and ethical challenges in the public sector; (2) expand the theory on AI by enabling the construction of propositions and testable hypotheses for future research in the field. Therefore, the comparative study of technological frames will be key to successfully design and implement AI policies and strategies in the public sector and to tackle future challenges and opportunities. © 2022 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hong, Sounman</author><author>Kim, Sun Hyoung</author><author>Kwon, Myungjung</author></authors></contributors><titles><title>Determinants of digital innovation in the public sector</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>39</volume><issue>4</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101723</electronic-resource-num><notes>Cited by: 25</notes><research-notes>Cited by: 25</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Hong, Kim, Kwon - Government Information Quarterly.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133403917&amp;doi=10.1016%2Fj.giq.2022.101723&amp;partnerID=40&amp;md5=f4f02fdfa1824d074697e0abbbbf63a5</url></web-urls></urls><abstract>This study explores the determinants of digital innovation in the public sector. Focusing specifically on new digital technologies, such as big data, artificial intelligence, Internet of things, and augmented reality, we explained the wide variation in how Korean local governments used these technologies to transform their services. We found support for four theoretical mechanisms. First, our findings support the existence of demand-pull innovation in the public sector: public organizations respond to citizen demands or needs for innovation. Second, we also find support for an electoral incentive hypothesis, which posits that local governments' motivation for digital innovation is influenced by local politicians' electoral incentives. Third, our results show the existence of isomorphic pressure as a driver for public sector innovation: public organizations emulate their neighbors in adopting innovative practices. Fourth, the results support the upper echelons theory, as younger policymakers are more active innovators. © 2022 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Yesmagambetov, Daulet</author><author>Kussainova, Larisa</author><author>Junusbekova, Gulsara</author></authors></contributors><titles><title>DIGITAL TOOLS FOR IMPROVING THE EFFICIENCY OF PUBLIC PROCUREMENT OF WORKS IN THE REPUBLIC OF KAZAKHSTAN; [SKAITMENINES PRIEMONES VIEŠUJU PIRKIMU EFEKTYVUMUI GERINTI KAZACHSTANO RESPUBLIKOJE]</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>395 - 406</pages><volume>21</volume><issue>4</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.13165/VPA-22-21-4-04</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149005773&amp;doi=10.13165%2FVPA-22-21-4-04&amp;partnerID=40&amp;md5=02e8baaf6bb3bc4c8802d8a5dd21c78f</url></web-urls></urls><abstract>The issue of public procurement effectiveness is becoming increasingly relevant in the context of the observed budget deficit in Kazakhstan. In this article, business processes related to ensuring the best combination of low price and quality in public procurement as the main indicators of procurement efficiency are studied and described in more depth. Considering the problems of public procurement efficiency, many researchers analyze the supplier identification stage. However, in the procurement of works, the execution phase is equally, if not more, important for efficiency. Analysis of the work execution process in Kazakhstan revealed problems related to quality control of the work performed and the construction materials used, as well as limited competition in their procurement. The high degree of the human factor's presence in the quality assurance process and the low availability of information about the demand for goods creates the risk of purchasing poor-quality goods at a high price. While the effectiveness of using big data in the decision-making process is universally proven, information in the public procurement system is not accumulated properly. In this regard, to ensure the best combination of price and quality of work, the authors propose a model of public procurement of works using digital tools. © 2022 Uspekhi Khimii, ZIOC RAS, Russian Academy of Sciences.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chien, Herlin</author><author>Hori, Keiko</author><author>Saito, Osamu</author></authors></contributors><titles><title>Urban commons in the techno-economic paradigm shift: An information and communication technology-enabled climate-resilient solutions review</title><secondary-title>Environment and Planning B: Urban Analytics and City Science</secondary-title></titles><periodical><full-title>Environment and Planning B: Urban Analytics and City Science</full-title></periodical><pages>1389 - 1405</pages><volume>49</volume><issue>5</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1177/23998083211066324</electronic-resource-num><notes>Cited by: 7</notes><research-notes>Cited by: 7</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124579307&amp;doi=10.1177%2F23998083211066324&amp;partnerID=40&amp;md5=47b013d9c479ee22a17e4891fa46feeb</url></web-urls></urls><abstract>The commons concept has evolved in multiple ways after the publication of Ostrom’s seminal work in 1990, which emphasized the evolution of resource management institutions and the usefulness of self-governance. As we move into the 21st century, one of the institutional transformations is catalyzed by the emergence of Information and Communication Technology (ICT) as a techno-economic paradigm shift and the epochal creation of a new online social structure. However, there is a lack of understanding about the impact of ICT on common resource management, particularly in urban settings, that is urban commons. This study presents a systematic literature review of ICT-enabled urban commons with particular attention to its application to climate-related issues such as climate mitigation/adaptation in order to improve our collective ability to leverage ICT for building a more sustainable and resilient city. A total of 66 pieces of literature were included in our qualitative synthesis. We analyzed the geographical, categorical, and climate relevance. Subsequently, we used the coupled infrastructure system framework as a system thinking approach to dissect distinct usefulness of ICT-enabled commons in the building of relationships between resource system, resource user, infrastructure, and infrastructure provider to tackle climate-related issues. Our findings identified three key contributions of ICT to innovate climate-resilient solutions: 1) to redefine role of resource user as co-producer, co-designer, and co-monitor; 2) to enable real-time data-driven urban planning; 3) to improve resource efficiency and effectiveness. In other words, in a time of insufficient and limited public resources, the public sector can leverage the power of technology to harness public support and engage non-traditional stakeholders to make cities more sustainable and resilient while allowing policy-making to be big data-driven to tackle new urban problems that cannot be otherwise uncovered without the aid of ICT. The results provide directions to rethink the city based on collective action to diversity modes to govern common resources. © The Author(s) 2022.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gupta, Meenu</author><author>Chaudhary, Gopal</author><author>Bansal, Dhruvi</author><author>Pandey, Shashwat</author></authors></contributors><titles><title>DTLMV2—A real-time deep transfer learning mask classifier for overcrowded spaces</title><secondary-title>Applied Soft Computing</secondary-title></titles><periodical><full-title>Applied Soft Computing</full-title></periodical><volume>127</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.asoc.2022.109313</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134886926&amp;doi=10.1016%2Fj.asoc.2022.109313&amp;partnerID=40&amp;md5=9f3d84027554d2d95b6c0037f607c01a</url></web-urls></urls><abstract>Through the commencement of the COVID-19 pandemic, the whole globe is in disarray and debating on unique approaches to stop this viral transmission. Masks are being worn by people all around the world as one of the preventative measures to avoid contracting this sickness. Although some people are following and adopting this precaution, others are not, despite official recommendations from the administration and public health organisations has been announced. In this paper DTLMV2 (Deep Transfer Learning MobileNetV2 for the objective of classification) is proposed - A face mask identification model that can reliably determine whether an individual is wearing a mask or not is suggested and implemented in this work. The model architecture employs the peruse of MobileNetV2, a lightweight Convolutional Neural Network (CNN) that requires less computing power and can be readily integrated into computer vision and mobile systems. The computer vision with MobileNet is required to formulate a low-cost mask detection system for a group of people in open spaces that can assist in determining whether a person is wearing a mask or not, as well as function as a surveillance system since it is effective on both real-time pictures and videos. The face recognition model obtained 97.01% accuracy on validation data, 98% accuracy on training data and 97.45% accuracy on testing data. © 2022 Elsevier B.V.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Newman, Joshua</author><author>Mintrom, Michael</author><author>O'Neill, Deirdre</author></authors></contributors><titles><title>Digital technologies, artificial intelligence, and bureaucratic transformation</title><secondary-title>Futures</secondary-title></titles><periodical><full-title>Futures</full-title></periodical><volume>136</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.futures.2021.102886</electronic-resource-num><notes>Cited by: 31</notes><research-notes>Cited by: 31</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121440551&amp;doi=10.1016%2Fj.futures.2021.102886&amp;partnerID=40&amp;md5=809a6c70d03aea995a20150e6db9a690</url></web-urls></urls><abstract>Bureaucracies are often criticized for their inflexibility, budget-maximizing wastefulness, and excessive rules and procedures. Rapid advances in technology, including the expansion of digital government, the use of artificial intelligence, and the ability to collect and analyze big data, promise to make public sector organizations leaner, more efficient, and more responsive to citizens' needs. While these technological changes have prompted some observers to forecast the end of bureaucracy, data from many countries show that bureaucratic public organizations are not disappearing. In this article, we argue that this paradox can be explained by revisiting some of the foundational work of sociologist Max Weber, who envisioned public administration itself as a bureaucratic machine. Advanced computing technologies, like artificial intelligence, are reinforcing bureaucratic tendencies in the public sector, not eliminating them. While advances in technology may transform the way public sector organizations operate, they can also serve to strengthen bureaucracy's core purpose. © 2021 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wong, Wilson</author><author>C. Hinnant, Charles</author></authors></contributors><titles><title>Competing perspectives on the Big Data revolution: a typology of applications in public policy</title><secondary-title>Journal of Economic Policy Reform</secondary-title></titles><periodical><full-title>Journal of Economic Policy Reform</full-title></periodical><pages>268 - 282</pages><volume>26</volume><issue>3</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/17487870.2022.2103701</electronic-resource-num><notes>Cited by: 8</notes><research-notes>Cited by: 8</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135491304&amp;doi=10.1080%2F17487870.2022.2103701&amp;partnerID=40&amp;md5=3677f3fc10384b4e67d26849b76562a0</url></web-urls></urls><abstract>While the Big Data revolution is transforming public policy, some debates and competing perspectives on the impact of the disruptive technology of Big Data analytics remain. Although trade-offs among objectives are inevitable in Big Data applications, its ultimate impact would depend on the moderating factors, which vary across contexts such as policy areas and national systems. Integrating the literature from multiple disciplines, this article identifies some of the critical moderating factors accounting for the differentials of Big Data impacts and develops a typology of its applications in public policy as a heuristic to understand and reconcile competing perspectives. © 2022 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bolton, Mitzi</author><author>Mintrom, Michael</author></authors></contributors><titles><title>RegTech and creating public value: opportunities and challenges</title><secondary-title>Policy Design and Practice</secondary-title></titles><periodical><full-title>Policy Design and Practice</full-title></periodical><pages>266 - 282</pages><volume>6</volume><issue>3</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/25741292.2023.2213059</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159315954&amp;doi=10.1080%2F25741292.2023.2213059&amp;partnerID=40&amp;md5=f4dcee5821e068d8c6016e567963641f</url></web-urls></urls><abstract>Regulatory technology (RegTech) has its origins in private sector applications of information technology in pursuit of more efficient compliance with government regulations. Initially, the term “RegTech” referred to either the technical solutions intended to aid financial service providers in managing regulatory issues or to the companies and organizations that develop and deliver such solutions. Increasingly, regulatory experts are stretching the term’s coverage to include efforts by governments to harness technical solutions in pursuit of more efficient targeting and conduct of regulatory monitoring and enforcement. Whether deployed within the private or public sectors, RegTech holds significant potential to improve regulatory compliance, reduce compliance costs, and improve the speed and accuracy with which known harms can be addressed and emerging risks can be identified. Here, we focus on the potential for RegTech to support the creation of public value. We suggest public value is most likely to be realized when governments (1) keep focused on regulatory purpose and effective design and (2) build effective collaboration with RegTech providers and regulated entities. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Carlsson, Vanja</author><author>Rönnblom, Malin</author></authors></contributors><titles><title>From politics to ethics: Transformations in EU policies on digital technology</title><secondary-title>Technology in Society</secondary-title></titles><periodical><full-title>Technology in Society</full-title></periodical><volume>71</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.techsoc.2022.102145</electronic-resource-num><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140457654&amp;doi=10.1016%2Fj.techsoc.2022.102145&amp;partnerID=40&amp;md5=de529937679ffb0988cce5e4c0983060</url></web-urls></urls><abstract>Artificial intelligence (AI) and digitalisation have become an integral part of public governance. While digital technology is expected to enhance neutrality and accuracy in decision-making, it raises concerns about the status of public values and democratic principles. Guided by the theoretical concepts of input, throughput and output democracy, this article analyses how democratic principles have been interpreted and defended in EU policy formulations relating to digital technology over the last decade. The emergence of AI policy has changed the conditions for democratic input and throughput legitimacy, which is an expression of a shift in power and influence between public and private sectors. Democratic input values in AI production are promoted by ethical guidelines directed towards the industry, while democratic throughput, e.g., accountability and transparency, receive less attention in EU AI policy. This indicates future political implications for the ability of citizens to influence technological change and pass judgement on accountable actors. © 2022 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jato-Espino, Daniel</author><author>Mayor-Vitoria, Fernando</author></authors></contributors><titles><title>A statistical and machine learning methodology to model rural depopulation risk and explore its attenuation through agricultural land use management</title><secondary-title>Applied Geography</secondary-title></titles><periodical><full-title>Applied Geography</full-title></periodical><volume>152</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.apgeog.2023.102870</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146319426&amp;doi=10.1016%2Fj.apgeog.2023.102870&amp;partnerID=40&amp;md5=03fde80be25cd4b61a23d036c4c7694f</url></web-urls></urls><abstract>The abandonment of rural areas has become a major demographical challenge in recent years, especially in Spain and, more specifically, in the Valencian Community. A classification released by the government of this region revealed that almost a third of its municipalities are at depopulation risk. This classification is based on demographic variables, which are valid for identifying the phenomenon but insufficient to provide insight into how to counteract it. Instead, this study developed a methodology to model rural depopulation risk from land use and socioeconomic variables. Correlation analysis and principal component analysis enabled identifying which variables were meaningful for rural depopulation. Then, support vector classification was used to fit the demography-based depopulation classification used by the regional government. The mean accuracy reached was above 80%, which validated the proposed model and variables. Since crop areas was found to be one of the most influential variables in such model, the potential of agroeconomic measures to counter depopulation was examined. The results achieved suggested that depopulation might be reduced by 25% if exploiting 25% of the areas suitable for agriculture. In view of these outputs, public administrations may promote the implementation of land use spatial strategies based on sustainable agriculture. © 2023 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Banabilah, Syreen</author><author>Aloqaily, Moayad</author><author>Alsayed, Eitaa</author><author>Malik, Nida</author><author>Jararweh, Yaser</author></authors></contributors><titles><title>Federated learning review: Fundamentals, enabling technologies, and future applications</title><secondary-title>Information Processing and Management</secondary-title></titles><periodical><full-title>Information Processing and Management</full-title></periodical><volume>59</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.ipm.2022.103061</electronic-resource-num><notes>Cited by: 195</notes><research-notes>Cited by: 195</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136606514&amp;doi=10.1016%2Fj.ipm.2022.103061&amp;partnerID=40&amp;md5=5244fdba096f23260dda11f14cb60009</url></web-urls></urls><abstract>Federated Learning (FL) has been foundational in improving the performance of a wide range of applications since it was first introduced by Google. Some of the most prominent and commonly used FL-powered applications are Android's Gboard for predictive text and Google Assistant. FL can be defined as a setting that makes on-device, collaborative Machine Learning possible. A wide range of literature has studied FL technical considerations, frameworks, and limitations with several works presenting a survey of the prominent literature on FL. However, prior surveys have focused on technical considerations and challenges of FL, and there has been a limitation in more recent work that presents a comprehensive overview of the status and future trends of FL in applications and markets. In this survey, we introduce the basic fundamentals of FL, describing its underlying technologies, architectures, system challenges, and privacy-preserving methods. More importantly, the contribution of this work is in scoping a wide variety of FL current applications and future trends in technology and markets today. We present a classification and clustering of literature progress in FL in application to technologies including Artificial Intelligence, Internet of Things, blockchain, Natural Language Processing, autonomous vehicles, and resource allocation, as well as in application to market use cases in domains of Data Science, healthcare, education, and industry. We discuss future open directions and challenges in FL within recommendation engines, autonomous vehicles, IoT, battery management, privacy, fairness, personalization, and the role of FL for governments and public sectors. By presenting a comprehensive review of the status and prospects of FL, this work serves as a reference point for researchers and practitioners to explore FL applications under a wide range of domains. © 2022 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Wei</author><author>Zhang, Mingyang</author><author>Yuan, Ling</author><author>Fan, Fengchun</author></authors></contributors><titles><title>Social network analysis and public policy: what’s new?</title><secondary-title>Journal of Asian Public Policy</secondary-title></titles><periodical><full-title>Journal of Asian Public Policy</full-title></periodical><pages>115 - 145</pages><volume>16</volume><issue>2</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/17516234.2021.1996869</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118342448&amp;doi=10.1080%2F17516234.2021.1996869&amp;partnerID=40&amp;md5=4d43c70f26c41a2f60f79b7d6b59c5d7</url></web-urls></urls><abstract>As a mature paradigm of network analysis, social network analysis (SNA) is suitable for exploring complicated and interactive relationships in policy research and is of great significance to the innovation and development of public policy research. In this paper, 45 typical articles published in high-ranking journals in the field of public administration were analysed using co-word analysis and qualitative analysis. The application of SNA in public policy studies, including research methods, analytic tools, and basic concepts of network analysis, were systematically reviewed. UCINET software was used to visualize the knowledge network of research topics. The main research topics were classified into five categories: agenda setting, policy network, advocacy coalition, policy learning and diffusion, policy implementation. Finally, this article suggests that network analysis in public administration should be thoroughly re-examined; in particular, scholars should consider the benefits of SNA for public policy research. In the application of SNA to public policy research, it is necessary to broaden the study perspective and scope, further strengthen interdisciplinary theoretical interaction and theoretical innovation, and take advantage of big data and other new technological tools that can develop giant network analysis for public policy. © 2021 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jiang, Peng</author><author>Hu, Yi-Chung</author></authors></contributors><titles><title>Constructing interval models using neural networks with non-additive combinations of grey prediction models in tourism demand</title><secondary-title>Grey Systems</secondary-title></titles><periodical><full-title>Grey Systems</full-title></periodical><pages>58 - 77</pages><volume>13</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1108/GS-11-2021-0180</electronic-resource-num><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133543602&amp;doi=10.1108%2FGS-11-2021-0180&amp;partnerID=40&amp;md5=f94f22c6216064a849aa1c87bf8ac126</url></web-urls></urls><abstract>Purpose: In contrast to point forecasts, interval forecasts provide information on future variability. This research thus aimed to develop interval prediction models by addressing two significant issues: (1) a simple average with an additive property is commonly used to derive combined forecasts, but this unreasonably ignores the interaction among sequences used as sources of information, and (2) the time series often does not conform to any statistical assumptions. Design/methodology/approach: To develop an interval prediction model, the fuzzy integral was applied to nonlinearly combine forecasts generated by a set of grey prediction models, and a sequence including the combined forecasts was then used to construct a neural network. All required parameters relevant to the construction of an interval model were optimally determined by the genetic algorithm. Findings: The empirical results for tourism demand showed that the proposed non-additive interval model outperformed the other interval prediction models considered. Practical implications: The private and public sectors in economies with high tourism dependency can benefit from the proposed model by using the forecasts to help them formulate tourism strategies. Originality/value: In light of the usefulness of combined point forecasts and interval model forecasting, this research contributed to the development of non-additive interval prediction models on the basis of combined forecasts generated by grey prediction models. © 2022, Emerald Publishing Limited.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wilson, Christopher</author><author>Broomfield, Heather</author></authors></contributors><titles><title>Learning how to do AI: managing organizational boundaries in an intergovernmental learning forum</title><secondary-title>Public Management Review</secondary-title></titles><periodical><full-title>Public Management Review</full-title></periodical><pages>1938 - 1957</pages><volume>25</volume><issue>10</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/14719037.2022.2055119</electronic-resource-num><notes>Cited by: 7</notes><research-notes>Cited by: 7</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128713952&amp;doi=10.1080%2F14719037.2022.2055119&amp;partnerID=40&amp;md5=5517e797b2ab66a9a31a06f2ac637ce7</url></web-urls></urls><abstract>This analysis applies boundary theory to public manager efforts to overcome AI capacity gaps through a public sector collaborative learning forum. Administrative and interview data identify the types of knowledge managers are able to access, the types of organizational differences that influence learning, and the strategies public managers use to overcome them. Analysis suggests that unstructured learning fora are better suited to the transfer of tacit procedural knowledge than declarative knowledge about AI, and emphasizes the importance of social trust and network structure to overcome knowledge gaps through peer learning. © 2022 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Smith, Catherine</author><author>Vajdic, Claire M</author><author>Stephenson, Niamh</author></authors></contributors><titles><title>Techno-legal expertise and the datafication of the state: Big data, accountability and the value of a social license with institutional roots</title><secondary-title>Futures</secondary-title></titles><periodical><full-title>Futures</full-title></periodical><volume>154</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.futures.2023.103263</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174354062&amp;doi=10.1016%2Fj.futures.2023.103263&amp;partnerID=40&amp;md5=8fa384c6c2cea48a44b7d9e36b18027d</url></web-urls></urls><abstract>As governments around the world become increasingly datafied, debates are emerging about the best ways to attend to the complex socio-political implications of big data and the datafication of the state. Drawing on semi-structured interviews with senior executives and data experts within Australian government agencies, high-level privacy experts, and other experts in public sector data integration, this article examines how a sociotechnical imaginary about data-driven, democratic government acts within and alongside routinely bureaucratised forms of techno-legal risk management to inform the work of Australia's data integration experts. Notably, these techno-legal experts recognised the limitations of techno-legal data management, and mobilised notions of the social license when seeking to (re)orient the trajectories of data integration towards the democratic, data-driven government they envisage. Contributing to debates about the datafication of the state, we argue that while a social license will not be a panacea to all the complexities of datafication, a social license with institutional roots is essential to deepen accountability towards publics, and to help ensure that datafication can be co-produced by, and reflective of, the sociotechnical futures envisaged by a broader range of publics. © 2023 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Laux, Johann</author><author>Wachter, Sandra</author><author>Mittelstadt, Brent</author></authors></contributors><titles><title>Trustworthy artificial intelligence and the European Union AI act: On the conflation of trustworthiness and acceptability of risk</title><secondary-title>Regulation and Governance</secondary-title></titles><periodical><full-title>Regulation and Governance</full-title></periodical><pages>3 - 32</pages><volume>18</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1111/rego.12512</electronic-resource-num><notes>Cited by: 35</notes><research-notes>Cited by: 35</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147512970&amp;doi=10.1111%2Frego.12512&amp;partnerID=40&amp;md5=e27b299e9fa111f48f13c78bbc6b8045</url></web-urls></urls><abstract>In its AI Act, the European Union chose to understand trustworthiness of AI in terms of the acceptability of its risks. Based on a narrative systematic literature review on institutional trust and AI in the public sector, this article argues that the EU adopted a simplistic conceptualization of trust and is overselling its regulatory ambition. The paper begins by reconstructing the conflation of “trustworthiness” with “acceptability” in the AI Act. It continues by developing a prescriptive set of variables for reviewing trust research in the context of AI. The paper then uses those variables for a narrative review of prior research on trust and trustworthiness in AI in the public sector. Finally, it relates the findings of the review to the EU's AI policy. Its prospects to successfully engineer citizen's trust are uncertain. There remains a threat of misalignment between levels of actual trust and the trustworthiness of applied AI. © 2023 The Authors. Regulation &amp; Governance published by John Wiley &amp; Sons Australia, Ltd.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Li, Chaoran</author><author>Han, Xianjie</author><author>Zhang, Qiang</author><author>Li, Menghan</author><author>Rao, Zhonghao</author><author>Liao, Wei</author><author>Liu, Xiaori</author><author>Liu, Xinjian</author><author>Li, Gang</author></authors></contributors><titles><title>State-of-health and remaining-useful-life estimations of lithium-ion battery based on temporal convolutional network-long short-term memory</title><secondary-title>Journal of Energy Storage</secondary-title></titles><periodical><full-title>Journal of Energy Storage</full-title></periodical><volume>74</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.est.2023.109498</electronic-resource-num><notes>Cited by: 12</notes><research-notes>Cited by: 12</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175293019&amp;doi=10.1016%2Fj.est.2023.109498&amp;partnerID=40&amp;md5=40076172fc24f5d07aa4227559568cf5</url></web-urls></urls><abstract>Accurate estimations in state of health (SOH) and remaining useful life (RUL) are significant for safe and efficient operation of batteries. With the development of big data and deep learning technology, the neural network method has been widely used for SOH and RUL estimations because of its excellent nonlinear mapping performance, adaptive performance and self-learning performance. In this paper, a novel hybrid model based on temporal convolutional network-long short-term memory (TCN-LSTM) for SOH and RUL estimations is proposed. The hyperparameters of each layer in the model are optimized using Bayesian optimization algorithm. Three different models, including convolutional neural network-long short-term memory (CNN-LSTM) model, temporal convolutional network (TCN) model and long short-term memory (LSTM) model, are adopted as comparisons to evaluate the performance of the proposed model. All the models are tested using two public battery datasets from National Aeronautics and Space Administration (NASA dataset) and Oxford University (OX dataset). In SOH task, the TCN-LSTM model achieves an accuracy improvement of &gt;16 % and 14 % in NASA and OX datasets, respectively. In RUL task, the accuracies of the TCN-LSTM model and the CNN-LSTM model are superior to other models in NASA dataset; while the LSTM model and the CNN-LSTM model have better performance in OX dataset. © 2023 Elsevier Ltd</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aggarwal, Ajay</author><author>Court, Laurence Edward</author><author>Hoskin, Peter</author><author>Jacques, Isabella</author><author>Kroiss, Mariana</author><author>Laskar, Sarbani</author><author>Lievens, Yolande</author><author>Mallick, Indranil</author><author>Abdul Malik, Rozita</author><author>Miles, Elizabeth</author><author>Mohamad, Issa</author><author>Murphy, Claire</author><author>Nankivell, Matthew</author><author>Parkes, Jeannette</author><author>Parmar, Mahesh</author><author>Roach, Carol</author><author>Simonds, Hannah</author><author>Torode, Julie</author><author>Vanderstraeten, Barbara</author><author>Langley, Ruth</author></authors></contributors><titles><title>ARCHERY: a prospective observational study of artificial intelligence-based radiotherapy treatment planning for cervical, head and neck and prostate cancer - study protocol</title><secondary-title>BMJ Open</secondary-title></titles><periodical><full-title>BMJ Open</full-title></periodical><volume>13</volume><issue>12</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1136/bmjopen-2023-077253</electronic-resource-num><notes>Cited by: 4</notes><research-notes>Cited by: 4</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Aggarwal et al. - BMJ Open.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179808654&amp;doi=10.1136%2Fbmjopen-2023-077253&amp;partnerID=40&amp;md5=6afd1c0c8fc4ce9db271e81fc66fdb41</url></web-urls></urls><abstract>Introduction Fifty per cent of patients with cancer require radiotherapy during their disease course, however, only 10%-40% of patients in low-income and middle-income countries (LMICs) have access to it. A shortfall in specialised workforce has been identified as the most significant barrier to expanding radiotherapy capacity. Artificial intelligence (AI)-based software has been developed to automate both the delineation of anatomical target structures and the definition of the position, size and shape of the radiation beams. Proposed advantages include improved treatment accuracy, as well as a reduction in the time (from weeks to minutes) and human resources needed to deliver radiotherapy. Methods ARCHERY is a non-randomised prospective study to evaluate the quality and economic impact of AI-based automated radiotherapy treatment planning for cervical, head and neck, and prostate cancers, which are endemic in LMICs, and for which radiotherapy is the primary curative treatment modality. The sample size of 990 patients (330 for each cancer type) has been calculated based on an estimated 95% treatment plan acceptability rate. Time and cost savings will be analysed as secondary outcome measures using the time-driven activity-based costing model. The 48-month study will take place in six public sector cancer hospitals in India (n=2), Jordan (n=1), Malaysia (n=1) and South Africa (n=2) to support implementation of the software in LMICs. Ethics and dissemination The study has received ethical approval from University College London (UCL) and each of the six study sites. If the study objectives are met, the AI-based software will be offered as a not-for-profit web service to public sector state hospitals in LMICs to support expansion of high quality radiotherapy capacity, improving access to and affordability of this key modality of cancer cure and control. Public and policy engagement plans will involve patients as key partners.  © 2023 BMJ. All rights reserved.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nai, Roberto</author><author>Meo, Rosa</author><author>Morina, Gabriele</author><author>Pasteris, Paolo</author></authors></contributors><titles><title>Public tenders, complaints, machine learning and recommender systems: a case study in public administration</title><secondary-title>Computer Law and Security Review</secondary-title></titles><periodical><full-title>Computer Law and Security Review</full-title></periodical><volume>51</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.clsr.2023.105887</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Nai et al. - Computer Law and Security Review.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172335320&amp;doi=10.1016%2Fj.clsr.2023.105887&amp;partnerID=40&amp;md5=969b7f74f777baf28adc3394c565fc8d</url></web-urls></urls><abstract>With the proliferation of e-procurement systems in the public sector, valuable and open information sources can be jointly accessed. Our research aims to explore different legal Open Data; in particular, we explored the data set of the National Anti-Corruption Authority in Italy on public procurement and the judges’ sentences related to public procurement, published on the website of the Italian Administrative Justice from 2007 to 2022. Our first goal was to train machine learning models capable of automatically recognizing which procurement has led to disputes and consequently complaints to the Administrative Justice, identifying the relevant features of procurement that correspond to certain anomalies. Our second goal was to develop a recommender system on procurement to return similar procurement to a given one and find companies for bidders, depending on the procurement requirements. © 2023 Roberto Nai, Rosa Meo, Gabriele Morina, Paolo Pasteris</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Henriksen, Anne</author><author>Blond, Lasse</author></authors></contributors><titles><title>Executive-centered AI? Designing predictive systems for the public sector</title><secondary-title>Social Studies of Science</secondary-title></titles><periodical><full-title>Social Studies of Science</full-title></periodical><pages>738 - 760</pages><volume>53</volume><issue>5</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1177/03063127231163756</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159071461&amp;doi=10.1177%2F03063127231163756&amp;partnerID=40&amp;md5=b6aef03032ac59ee1e771b681f33769d</url></web-urls></urls><abstract>Recent policies and research articles call for turning AI into a form of IA (‘intelligence augmentation’), by envisioning systems that center on and enhance humans. Based on a field study at an AI company, this article studies how AI is performed as developers enact two predictive systems along with stakeholders in public sector accounting and public sector healthcare. Inspired by STS theories about values in design, we analyze our empirical data focusing especially on how objectives, structured performances, and divisions of labor are built into the two systems and at whose expense. Our findings reveal that the development of the two AI systems is informed by politically motivated managerial interests in cost-efficiency. This results in AI systems that are (1) designed as managerial tools meant to enable efficiency improvements and cost reductions, and (2) enforced on professionals on the ‘shop floor’ in a top-down manner. Based on our findings and a discussion drawing on literature on the original visions of human-centered systems design from the 1960s, we argue that turning AI into IA seems dubious, and ask what human-centered AI really means and whether it remains an ideal not easily realizable in practice. More work should be done to rethink human-machine relationships in the age of big data and AI, in this way making the call for ethical and responsible AI more genuine and trustworthy. © The Author(s) 2023.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rönnblom, Malin</author><author>Carlsson, Vanja</author><author>Öjehag-Pettersson, Andreas</author></authors></contributors><titles><title>Gender equality in Swedish AI policies. What's the problem represented to be?</title><secondary-title>Review of Policy Research</secondary-title></titles><periodical><full-title>Review of Policy Research</full-title></periodical><pages>688 - 704</pages><volume>40</volume><issue>5</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1111/ropr.12547</electronic-resource-num><notes>Cited by: 9</notes><research-notes>Cited by: 9</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150754418&amp;doi=10.1111%2Fropr.12547&amp;partnerID=40&amp;md5=4bcda433d37402970e19e3b8ee52b0f6</url></web-urls></urls><abstract>Over the past few decades, Sweden has established itself as a “world leader” in gender equality. Alongside this development, Swedish politicians have also initiated ambitious plans that aim to establish the country as “world class” in terms of digitalization. International research shows that women and racialized groups are in a minority in the design processes, that AI facial recognition systems are built with white male faces as the norm, and that digital tools replicate racial injustices. In this paper, we are interested in if, and if so how, gender equality is articulated and thus filled with meaning in national policies on AI and digitalization. The overall aim is to discuss the potential of gender (equality) mainstreaming to challenge systems of privilege in the implementation of AI systems in the public sector. The paper analyses how gender equality is filled with meaning in national policy documents on AI and gender equality. The main findings show that gender equality is turned into a question of lack of knowledge and information, which in turn blocks out an understanding of gender equality as something that is related to gendered power relations. © 2023 The Authors. Review of Policy Research published by Wiley Periodicals LLC on behalf of Policy Studies Organization.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kussl, Sebastian</author><author>Omberg, Kristian S</author><author>Lekang, Odd-Ivar</author></authors></contributors><titles><title>Advancing Vehicle Classification: A Novel Framework for Type, Model, and Fuel Identification Using Nonvisual Sensor Systems for Seamless Data Sharing</title><secondary-title>IEEE Sensors Journal</secondary-title></titles><periodical><full-title>IEEE Sensors Journal</full-title></periodical><pages>19390 - 19397</pages><volume>23</volume><issue>17</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1109/JSEN.2023.3289230</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163722393&amp;doi=10.1109%2FJSEN.2023.3289230&amp;partnerID=40&amp;md5=c5372e5070e661275457f168be3891a3</url></web-urls></urls><abstract>Vehicle classification (VC) down to type and model is exclusively visual-/image-based and struggles with restricted data availability and latency in data-sharing toward an increasing market of public and private mobility service providers. This article presents a framework architecture for VC down to type and model using a microelectromechanical systems (MEMS) intrusive magnetic sensor system combined with advanced machine learning (ML). The framework follows the principles of 'privacy-by-design' (PbD) and adds fuel identification as a new attribute. The framework was validated in an experiment on nine predefined passenger car models, confirming the capability of nonvisual sensors to classify vehicle type, model, and fuel. This innovative approach has the potential to significantly impact how transport and infrastructure agencies collect, process, and share intelligent traffic monitoring systems (ITMS) data in the future, providing more accurate and detailed information for improving roadway utilization efficiency, predicting transportation needs, enhancing transportation safety, and reducing environmental impact. The work proposes a system framework, experimental design, and evaluation against automatic number plate recognition. The evaluation involved collaboration among various partners, including academia, public road administration, and private companies, with diverse interests that need to be preserved due to significant development progress.  © 2001-2012 IEEE.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hashim, Hasan</author></authors></contributors><titles><title>E-government impact on developing smart cities initiative in Saudi Arabia: Opportunities &amp; challenges</title><secondary-title>Alexandria Engineering Journal</secondary-title></titles><periodical><full-title>Alexandria Engineering Journal</full-title></periodical><pages>124 - 131</pages><volume>96</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.aej.2024.04.008</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189864367&amp;doi=10.1016%2Fj.aej.2024.04.008&amp;partnerID=40&amp;md5=4036c8fdcbc9a2df07dc18026332daa8</url></web-urls></urls><abstract>Information and communication technologies (ICT) have a recent impact on governance and public administration. Electronic government (e-government) services were created to streamline administrative processes and enhance citizen engagement on the one hand, and to build new governance models that would empower individuals, involve them in the decision-making process, and increase transparency on the other. Many individuals are doubtful about smart city projects because of the security issues that arise in such environments. In essence, internet of things gadgets are security flaws. Concerns about the proliferation of IoT sensors and the tighter coupling of infrastructure silos in cities are well-founded. The major objective of the study is to identify the influencing factors of smart cities on e-government in Saudi Arabia. Additionally, this research explores the definition of e-government, and its supporting technologies like smart cities, IoT, big data, cloud computing and other digital government platforms. After exploring the detailed definitions, the study identifies the challenging scenarios of e-government in Saudi Arabia, and discusses the different opportunities. This study also concentrates on the good practices to be followed to overcome the challenges. Furthermore, this study can be used in future research for solving real time challenges of e-government. © 2024 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aranha, Meera Laetitia B</author><author>Mahapatra, Mrutyunjay</author><author>Jacob, Remya Tressa</author></authors></contributors><titles><title>Mergers of public sector banks: Best partner selection using a data-driven approach</title><secondary-title>Finance Research Letters</secondary-title></titles><periodical><full-title>Finance Research Letters</full-title></periodical><volume>63</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.frl.2024.105297</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189370457&amp;doi=10.1016%2Fj.frl.2024.105297&amp;partnerID=40&amp;md5=c5484a9a08c460af9807f54448747c15</url></web-urls></urls><abstract>This study investigates the selection of the best partners while merging the public sector banks in India. It is set in the context of the announcement of the mega-merger of multiple Indian public sector banks on 30th August 2019. Using the clustering technique (a machine learning approach) and Data Envelopment Analysis (DEA), we identify ideal merger combinations with better efficiency. The findings highlight the possibility of identifying ideal merger combinations using objective techniques. © 2024 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jain, Shrey</author><author>Jauhar, Sunil Kumar</author><author>Piyush</author></authors></contributors><titles><title>A machine-learning-based framework for contractor selection and order allocation in public construction projects considering sustainability, risk, and safety</title><secondary-title>Annals of Operations Research</secondary-title></titles><periodical><full-title>Annals of Operations Research</full-title></periodical><pages>225 - 267</pages><volume>338</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1007/s10479-024-05898-6</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186946153&amp;doi=10.1007%2Fs10479-024-05898-6&amp;partnerID=40&amp;md5=0bdc4eca8c34bdb5e8580b2647f680f5</url></web-urls></urls><abstract>Effective contractor selection is crucial for successful execution of construction projects. In contrast to the conventional lowest-bid approach prevalent in the public sector, this study focuses on developing a framework that minimizes time and cost overruns by considering diverse criteria for contractor selection. A variety of machine learning models, including multi-linear regression, random forest, Support Vector Machine, and Artificial Neural Network, have been employed, with multi-linear regression proving to be the most effective, achieving the lowest Mean Squared Error of 0.00003366. To determine the final order allocation, a multi-objective mathematical model was utilized to optimize conflicting criteria, such as time and cost overruns, sustainability, risk, and safety aspects related to shortlisted contractors. The findings highlight the significance of specific selection criteria, such as turnover, experience in similar projects, qualification of staff, technology utilization, client satisfaction, accident records, available bid capacity, and socioeconomic factors. This study emphasizes a three-phase decision-making framework for contractor selection and order allocation, particularly in public construction projects, with a focus on sustainability. By adopting this approach, government agencies can enhance infrastructure projects and minimize overruns through optimization and analytical tools, which aligns with the Gati-Shakti scheme of the Indian government. It is recommended that clients embrace a holistic approach to contractor selection, considering both technical and non-technical factors, to ensure successful project outcomes. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kurmangali, Medeu</author><author>Yeraliyeva, Yana</author><author>Beimisheva, Aigul</author></authors></contributors><titles><title>DIGITALIZATION AND ARTIFICIAL INTELLIGENCE IN CENTRAL ASIA: GOVERNMENTAL RESPONSES AND FURTHER IMPLICATIONS; [SKAITMENINIMAS IR DIRBTINIS INTELEKTAS VIDURINĖJE AZIJOJE: IŠŠŪKIAI IR POVEIKIS VYRIAUSYBĖMS]</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>146 - 159</pages><volume>23</volume><issue>2</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.13165/VPA-24-23-2-03</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197797777&amp;doi=10.13165%2FVPA-24-23-2-03&amp;partnerID=40&amp;md5=2b06d077e517bf0d2fc22746ab3ea89e</url></web-urls></urls><abstract>Digitalization and new technologies are now firmly on the agendas of governments worldwide. New technological trends have not only become catalysts for economic development, but are also reshaping how the public sector works and implements its policies. Amid technological transformations, the countries of Central Asia are searching for new ways to adapt to these changes. This paper aims to assess these attempts by exploring the digitalization policies of the five Central Asian countries. By using qualitative methods and expert interviews, the article identifies key limitations and potential areas of development for the Central Asian states regarding digitalization and artificial intelligence. By providing valuable insights, the article contributes to a deeper understanding of the digitalization challenges faced by developing countries. Through the analysis of local expert opinions, the article seeks to contribute valuable insights to the distinct approaches adopted by these countries, thus enriching the understanding of the region’s trajectory in the digital era. © 2024 Mykolo Romerio Universitetas. All rights reserved.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Berman, Alexander</author><author>de Fine Licht, Karl</author><author>Carlsson, Vanja</author></authors></contributors><titles><title>Trustworthy AI in the public sector: An empirical analysis of a Swedish labor market decision-support system</title><secondary-title>Technology in Society</secondary-title></titles><periodical><full-title>Technology in Society</full-title></periodical><volume>76</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techsoc.2024.102471</electronic-resource-num><notes>Cited by: 6</notes><research-notes>Cited by: 6</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Berman, de Fine Licht, Carlsson - Technology in Society.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184027069&amp;doi=10.1016%2Fj.techsoc.2024.102471&amp;partnerID=40&amp;md5=a99c3caeb3fcce4eb7e14c5134647d3d</url></web-urls></urls><abstract>This paper investigates the deployment of Artificial Intelligence (AI) in the Swedish Public Employment Service (PES), focusing on the concept of trustworthy AI in public decision-making. Despite Sweden's advanced digitalization efforts and the widespread application of AI in the public sector, our study reveals significant gaps between theoretical ambitions and practical outcomes, particularly in the context of AI's trustworthiness. We employ a robust theoretical framework comprising Institutional Theory, the Resource-Based View (RBV), and Ambidexterity Theory, to analyze the challenges and discrepancies in AI implementation within PES. Our analysis shows that while AI promises enhanced decision-making efficiency, the reality is marred by issues of transparency, interpretability, and stakeholder engagement. The opacity of the neural network used by the agency to assess jobseekers’ need for support and the lack of comprehensive technical understanding among PES management contribute to the challenges in achieving transparent and interpretable AI systems. Economic pressures for efficiency often overshadow the need for ethical considerations and stakeholder involvement, leading to decisions that may not be in the best interest of jobseekers. We propose recommendations for enhancing AI's trustworthiness in public services, emphasizing the importance of stakeholder engagement, particularly involving jobseekers in the decision-making process. Our study advocates for a more nuanced balance between the use of advanced AI technologies and the leveraging of internal resources such as skilled personnel and organizational knowledge. We also highlight the need for improved AI literacy among both management and personnel to effectively navigate AI's integration into public decision-making processes. Our findings contribute to the ongoing debate on trustworthy AI, offering a detailed case study that bridges the gap between theoretical exploration and practical application. By scrutinizing the AI implementation in the Swedish PES, we provide valuable insights and guidelines for other public sector organizations grappling with the integration of AI into their decision-making processes. © 2024 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Misra, Shalini</author><author>Katz, Benjamin</author><author>Roberts, Patrick</author><author>Carney, Mackenzie</author><author>Valdivia, Isabel</author></authors></contributors><titles><title>Toward a person-environment fit framework for artificial intelligence implementation in the public sector</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>41</volume><issue>3</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101962</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199797451&amp;doi=10.1016%2Fj.giq.2024.101962&amp;partnerID=40&amp;md5=19aa9ece174b9508de5bd152088d9a61</url></web-urls></urls><abstract>Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI. © 2024 Elsevier Inc.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cazzola, Walter</author><author>Favalli, Luca</author></authors></contributors><titles><title>Software modernization powered by dynamic language product lines</title><secondary-title>Journal of Systems and Software</secondary-title></titles><periodical><full-title>Journal of Systems and Software</full-title></periodical><volume>218</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.jss.2024.112188</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203019716&amp;doi=10.1016%2Fj.jss.2024.112188&amp;partnerID=40&amp;md5=c80e8bf2b0bf97dd6ef001ca3cd7263c</url></web-urls></urls><abstract>Legacy software poses a critical challenge for organizations due to the costs of maintaining and modernizing outdated systems, as well as the scarcity of experts in aging programming languages. The issue extends beyond commercial applications, affecting public administration, as exemplified by the urgent need for COBOL programmers during the COVID-19 pandemic. In response, this work introduces a modernization approach based on dynamic language product lines, a subset of dynamic software product lines. This approach leverages open language implementations and dynamically generated micro-languages for the incremental migration of legacy systems to modern technologies. The language can be reconfigured at runtime to adapt to the execution of either legacy or modern code, and to generate a compatibility layer between the data types handled by the two languages. Through this process, the costs of modernizing legacy systems can be spread across several iterations, as developers can replace legacy code incrementally, with legacy and modern code coexisting until a complete refactoring is possible. By moving the overhead of making legacy and modern features work together in a hybrid system from the system implementation to the language implementation, the quality of the system itself does not degrade due to the introduction of glue code. To demonstrate the practical applicability of this approach, we present a case study on a COBOL system migration to Java. Using the Neverlang language workbench to create modular and reconfigurable language implementations, both the COBOL interpreter and the application evolve to spread the development effort across several iterations. Through this study, this work presents a viable solution for organizations dealing with the complexity of modernizing legacy software to contemporary technologies. The contributions of this work are (i) a language-oriented, incremental refactoring process for legacy systems, (ii) a concrete application of open language implementations, and (iii) a general template for the implementation of interoperability between languages in hybrid systems. © 2024 The Author(s)</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hülter, Svenja M</author><author>Ertel, Christian</author><author>Heidemann, Ansgar</author></authors></contributors><titles><title>Exploring the individual adoption of human resource analytics: Behavioural beliefs and the role of machine learning characteristics</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>208</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techfore.2024.123709</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202345905&amp;doi=10.1016%2Fj.techfore.2024.123709&amp;partnerID=40&amp;md5=6f310f5c943d1a055f4977dcd0d0815e</url></web-urls></urls><abstract>The technological capabilities of Human Resource Analytics (HRA), enhanced by recent innovations in Machine Learning (ML), offer exciting opportunities. However, organisations often fail to realise these potentials because of a limited understanding of why individuals choose to adopt or disregard respective tools. Prior research on innovation adoption offers preliminary insights but fails to aggregate the determinants of individual adoption into actionable suggestions for decisions in the ML adoption process. Our study applies focused interviews to examine non-ML experts' reasoning for using a specific tool tailored to a public sector organisation, which corresponds to the usual end-user perspective of ML-based HRA adoption. By drawing from the HRA adoption framework, provided by Vargas et al. (2018), we contribute to the literature by identifying relevant beliefs and experiences influencing one's intention to adopt ML-based HRA and by qualitatively linking these beliefs to ML characteristics such as transparency, automation and fairness. For practitioners, we provide actionable guidance emphasising the need to ensure fairness proactively, as interviewees do not consider this aspect when deciding to adopt ML-based HRA. © 2024 The Authors</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Delfos, J</author><author>Zuiderwijk, A M G</author><author>van Cranenburgh, S</author><author>Chorus, C G</author><author>Dobbe, R I J</author></authors></contributors><titles><title>Integral system safety for machine learning in the public sector: An empirical account</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>41</volume><issue>3</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101963</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201764597&amp;doi=10.1016%2Fj.giq.2024.101963&amp;partnerID=40&amp;md5=f307761584c81878e8fe6049c7717033</url></web-urls></urls><abstract>This paper introduces systems theory and system safety concepts to ongoing academic debates about the safety of Machine Learning (ML) systems in the public sector. In particular, we analyze the risk factors of ML systems and their respective institutional context, which impact the ability to control such systems. We use interview data to abductively show what risk factors of such systems are present in public professionals' perceptions and what factors are expected based on systems theory but are missing. Based on the hypothesis that ML systems are best addressed with a systems theory lens, we argue that the missing factors deserve greater attention in ongoing efforts to address ML systems safety. These factors include the explication of safety goals and constraints, the inclusion of systemic factors in system design, the development of safety control structures, and the tendency of ML systems to migrate towards higher risk. Our observations support the hypothesis that ML systems can be best regarded through a systems theory lens. Therefore, we conclude that system safety concepts can be useful aids for policymakers who aim to improve ML system safety. © 2024</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ballestar, María Teresa</author><author>Mir, Miguel Cuerdo</author><author>Pedrera, Luis Miguel Doncel</author><author>Sainz, Jorge</author></authors></contributors><titles><title>Effectiveness of tutoring at school: A machine learning evaluation</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>199</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techfore.2023.123043</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178346572&amp;doi=10.1016%2Fj.techfore.2023.123043&amp;partnerID=40&amp;md5=cf855fa8b9d87d804828ebb9893b3df6</url></web-urls></urls><abstract>Tutoring programs are effective in reducing school failures among at-risk students. However, there is still room for improvement in maximising the social returns they provide on investments. Many factors and components can affect student engagement in a program and academic success. This complexity presents a challenge for Public Administrations to use their budgets as efficiently as possible. Our research focuses on providing public administration with advanced decision-making tools. First, we analyse a database with information on 2066 students of the Programa para la Mejora de Éxito Educativo (Programme for the Improvement of Academic Success) of the Junta de Comunidades de Castilla y Léon in Spain, in 2018–2019, the academic year previous to the pandemic. This program is designed to help schools with students at risk of failure in Spanish, literature, mathematics, and English. We developed a machine learning model (ML) based on Kohonen self-organising maps (SOMs), which are a type of unsupervised (ANN), to group students based on their characteristics, the type of tutoring program in which they were enrolled, and their results in both the completion of the program and the 4th year of Compulsory Secondary Education (ESO). Second, we evaluated the results of tutoring programs and identified and explained how different factors and components affect student engagement and academic success. Our findings provide Public Administrations with better decision-making tools to evaluate and measure the results of tutoring programs in terms of social return on investment, improve the design of these programs, and choose the students to enrol. © 2023 The Author(s)</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zaidi, Syed Mohammad Asad</author><author>Mahfooz, Amna</author><author>Latif, Abdullah</author><author>Nawaz, Nainan</author><author>Fatima, Razia</author><author>Rehman, Fazal Ur</author><author>Reza, Tahira Ezra</author><author>Emmanuel, Faran</author></authors></contributors><titles><title>Geographical targeting of active case finding for tuberculosis in Pakistan using hotspots identified by artificial intelligence software (SPOT-TB): Study protocol for a pragmatic stepped wedge cluster randomised control trial</title><secondary-title>BMJ Open Respiratory Research</secondary-title></titles><periodical><full-title>BMJ Open Respiratory Research</full-title></periodical><volume>11</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1136/bmjresp-2023-002079</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198594547&amp;doi=10.1136%2Fbmjresp-2023-002079&amp;partnerID=40&amp;md5=82c9056d570e3a948b6c2a38666c07c2</url></web-urls></urls><abstract>Introduction Pakistan has significantly strengthened its capacity for active case finding (ACF) for tuberculosis (TB) that is being implemented at scale in the country. However, yields of ACF have been lower than expected, raising concerns on its effectiveness in the programmatic setting. Distribution of TB in communities is likely to be spatially heterogeneous and targeting of ACF in areas with higher TB prevalence may help improve yields. The primary aim of SPOT-TB is to investigate whether a policy change to use a geographically targeted approach towards ACF supported by an artificial intelligence (AI) software, MATCH-AI, can improve yields in Pakistan. Methods and analysis SPOT-TB will use a pragmatic, stepped wedge cluster randomised design. A total of 30 mobile X-ray units and their field teams will be randomised to receive the intervention. Site selection for ACF in the intervention areas will be guided primarily through the use of MATCH-AI software that models subdistrict TB prevalence and identifies potential disease hotspots. Control areas will use existing approaches towards site selection that are based on staff knowledge, experience and analysis of historical data. The primary outcome measure is the difference in bacteriologically confirmed incident TB detected in the intervention relative to control areas. All remaining ACF-related procedures and algorithms will remain unaffected by this trial. Ethics and dissemination Ethical approval has been obtained from the Health Services Academy, Islamabad, Pakistan (7-82/IERC-HSA/2022-52) and from the Common Management Unit for TB, HIV and Malaria, Ministry of Health Services, Regulation and Coordination, Islamabad, Pakistan (26-IRB-CMU-2023). Findings from this study will be disseminated through publications in peer-reviewed journals and stakeholder meetings in Pakistan with the implementing partners and public-sector officials. Findings will also be presented at local and international medical and public health conferences.  © Author(s) (or their employer(s)) 2024.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Abubakar, Muhammad</author><author>Che, Yanbo</author><author>Faheem, Muhammad</author><author>Bhutta, Muhammad Shoaib</author><author>Mudasar, Abdul Qadeer</author></authors></contributors><titles><title>Intelligent Modeling and Optimization of Solar Plant Production Integration in the Smart Grid Using Machine Learning Models</title><secondary-title>Advanced Energy and Sustainability Research</secondary-title></titles><periodical><full-title>Advanced Energy and Sustainability Research</full-title></periodical><volume>5</volume><issue>4</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1002/aesr.202300160</electronic-resource-num><notes>Cited by: 5</notes><research-notes>Cited by: 5</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182808271&amp;doi=10.1002%2Faesr.202300160&amp;partnerID=40&amp;md5=b355c04ec90d1f822c2043962d051941</url></web-urls></urls><abstract>To address the rising energy demands in industrial and public sectors, integrating zero-carbon emission energy sources into the power grid is crucial. Smart grids, equipped with advanced sensing, computing, and communication technologies, offer an efficient way to incorporate renewable energy resources and manage power systems effectively. However, improving solar energy efficiency, which currently contributes around 3.6% to global electricity, is a challenge in smart grid infrastructures. This research tackles this issue by deploying machine learning models, specifically recurrent neural network (RNN), long short-term memory (LSTM), and gate recurrent unit (GRU), to predict measurements that could enhance solar power generation in smart grids. The objective is to boost both performance and accuracy of solar power generation in the smart grid. The study conducts experimental analyses and performance evaluations of these models in smart grid environments, considering factors like power output, irradiance, and performance ratio. The results, presented through graphical visualizations, show notable improvements, particularly with the LSTM model, which achieves a 97% accuracy, outperforming the RNN and GRU models. This outcome highlights the LSTM model's effectiveness in accurately predicting measurements, thereby advancing solar power generation efficiency in the smart grid framework. © 2024 The Authors. Advanced Energy and Sustainability Research published by Wiley-VCH GmbH.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Krepl, Vladimir</author><author>Fandi, Ghaeth</author><author>Rehabi, Mohammad</author><author>Ghanem, Safwan</author><author>Jrad, Fayez</author><author>Mueller, Zdenek</author><author>Smutka, Lubos</author><author>Kyncl, Jan</author><author>Urbanus, Melkior</author><author>Fandie, Soliman</author><author>Cabelkova, Inna</author><author>Tlusty, Josef</author></authors></contributors><titles><title>Effective criteria in the public-private partnership in developing
countries to apply the sustainable development goals: GAN-based decision
support system for the renewable electrical system, case study Syria</title><secondary-title>HELIYON</secondary-title></titles><periodical><full-title>HELIYON</full-title></periodical><volume>9</volume><issue>11</issue><keywords><keyword>Effective criteria; Private-public partnership; El</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.heliyon.2023.e21422</electronic-resource-num><language>English</language><urls/><abstract>The cost of generating electricity in developing countries surpasses the
government's ability to sustain it, necessitating the involvement of the
private sector in this service provision through public-private
partnerships (PPPs) contracts. In Syria, the electricity system has been
highly susceptible to damage as a result of the ongoing crisis, leading
to frequent and prolonged blackouts. This research focuses on addressing
the need for a comprehensive system that aids decision-making for PPPs
contracts in the country. By employing a combination of studies,
reports, and interviews with domain experts, significant general and
exclusive factors that guide decision-makers in PPPs contracts are
identified and organized into questionnaires. These questionnaires are
then filled out by professionals engaged in PPPs contracts. The
collected data is analyzed and validated using SPSS software. However,
due to insufficient data collected, generative adversarial neural
networks (GAN) are utilized to enhance the research data. Additionally,
Expert Choice and the analytic hierarchy process are employed to
calculate weights for each factor. Remarkably, the calculated weights
for both general and exclusive factors align with real-life strategies.
General factors primarily address the financial and commercial
considerations associated with PPPs, while exclusive factors primarily
focus on the operational aspects of the electrical power system. These
factors are arranged in descending order of effectiveness, enabling
stakeholders to determine whether the private sector should be engaged
in the project or if it should remain within the public sector's
purview. The proposed system has demonstrated its reliability and can
serve as a promising starting point for PPPs contracts.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Madan, Rohit</author><author>Ashok, Mona</author></authors></contributors><titles><title>Making Sense of AI Benefits: A Mixed-method Study in Canadian Public
Administration</title><secondary-title>INFORMATION SYSTEMS FRONTIERS</secondary-title></titles><periodical><full-title>INFORMATION SYSTEMS FRONTIERS</full-title></periodical><keywords><keyword>Artificial Intelligence; Public administration; Se</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1007/s10796-024-10475-0</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Madan, Ashok - INFORMATION SYSTEMS FRONTIERS.pdf</url></pdf-urls></urls><abstract>Public administrators receive conflicting signals on the transformative
benefits of Artificial Intelligence (AI) and the counternarratives of
AI's ethical impacts on society and democracy. Against this backdrop,
this paper explores the factors that affect the sensemaking of AI
benefits in Canadian public administration. A mixed-method research
design using PLS-SEM (n = 272) and interviews (n = 38) tests and
explains the effect of institutional and consultant pressures on the
perceived benefits of AI use. The quantitative study shows only service
coercive pressures have a significant effect on perceived benefits of AI
use and consultant pressures are significant in generating all
institutional pressures. The qualitative study explains the results and
highlights the underlying mechanisms. The key conclusion is that in the
earlier stages of AI adoption, demand pull is the main driver rather
than technology push. A processual sensemaking model is developed
extending the theory on institutions and sensemaking. And several
managerial implications are discussed.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Dongkun</author><author>Peng, Jieyang</author><author>Tao, Xiaoming</author><author>Duan, Yiping</author></authors></contributors><titles><title>Boosting urban prediction tasks with domain-sharing knowledge via
meta-learning</title><secondary-title>INFORMATION FUSION</secondary-title></titles><periodical><full-title>INFORMATION FUSION</full-title></periodical><volume>107</volume><keywords><keyword>Data mining; Traffic prediction; Meta learning; Gr</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.inffus.2024.102324</electronic-resource-num><language>English</language><urls/><abstract>Urban prediction tasks refer to predicting urban indicators ( e.g. ,
traffic, temperature, etc.) using urban big data, which is crucial for
understanding the urban patterns, and further benefits the urban public
administration. An empirical study indicates that there are correlated
patterns among urban prediction tasks from various domains, which
suggests the existence of domain -sharing knowledge. Aggregating such
domain -sharing knowledge would significantly benefit urban prediction
tasks. However, as a widely used learning paradigm for knowledge
aggregation, existing meta -learning methods, especially gradient -based
methods, can only work for singledomain tasks. To solve the problem, we
propose Cross -Domain Meta -Learning (CDML), a flexible framework for
aggregating domain -sharing knowledge from cross -domain urban
prediction tasks. Specifically, the core architecture of CDML is the
model fusion block that includes (1) meta -model, shared by cross
-domain tasks for capturing domain -sharing knowledge; (2) domain
-specific model, shared only by the same -domain tasks for preserving
domain -specific knowledge; and (3) knowledge fusion unit, for combining
both the domainsharing/specific knowledge for good generalization.
Moreover, we develop asynchronous meta -training and adaption strategy
strategies to further guarantee cross -domain generalization. The
extensive experimental results validate the effectiveness of the
proposed framework with the superior ability of boosting existing urban
prediction models, quick adaption, and the potential for simplifying
models.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mokander, Jakob</author><author>Schroeder, Ralph</author></authors></contributors><titles><title>Artificial Intelligence, Rationalization, and the Limits of Control in
the Public Sector: The Case of Tax Policy Optimization</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><keywords><keyword>artificial intelligence; automated decision-making</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1177/08944393241235175</electronic-resource-num><language>English</language><urls/><abstract>In this paper, we first frame the use of artificial intelligence (AI)
systems in the public sector as a continuation and intensification of
long-standing rationalization and bureaucratization processes. Drawing
on Weber, we understand the core of these processes to be the
replacement of traditions with instrumental rationality, that is, the
most calculable and efficient way of achieving any given policy
objective. Second, we demonstrate how much of the criticisms, both among
the public and in scholarship, directed towards AI systems spring from
well-known tensions at the heart of Weberian rationalization. To
illustrate this point, we introduce a thought experiment whereby AI
systems are used to optimize tax policy to advance a specific normative
end: reducing economic inequality. Our analysis shows that building a
machine-like tax system that promotes social and economic equality is
possible. However, our analysis also highlights that AI-driven policy
optimization (i) comes at the exclusion of other competing political
values, (ii) overrides citizens' sense of their (non-instrumental)
obligations to each other, and (iii) undermines the notion of humans as
self-determining beings. Third, we observe that contemporary scholarship
and advocacy directed towards ensuring that AI systems are legal,
ethical, and safe build on and reinforce central assumptions that
underpin the process of rationalization, including the modern idea that
science can sweep away oppressive systems and replace them with a rule
of reason that would rescue humans from moral injustices. That is overly
optimistic: science can only provide the means - it cannot dictate the
ends. Nonetheless, the use of AI in the public sector can also benefit
the institutions and processes of liberal democracies. Most importantly,
AI-driven policy optimization demands that normative ends are made
explicit and formalized, thereby subjecting them to public scrutiny,
deliberation, and debate.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Tao</author><author>Li, Siqi</author><author>Zeng, Zhongping</author><author>Liang, Zhehao</author><author>Chen, Yuxi</author><author>Guo, Wenshan</author></authors></contributors><titles><title>An empirical investigation of users' switching intention to public
service robots: From the perspective of PPM framework</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>2</issue><keywords><keyword>Public service robot; Artificial intelligence; Pus</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101933</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Chen et al. - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>In recent years, the application of artificial intelligence (AI)
technology has become increasingly common in the public sector. Users
have been switching their experiences in handling businesses from
interactions with human staff to those with robots. Prior studies have
focused on investigating the key factors that influence users' adoption
of public service robots; however, only a few have considered users'
switching behaviors from traditional human services to robotic ones.
This study employs a push-pull-mooring (PPM) framework derived from the
human migration field to understand the factors that affect users'
switching intentions in the context of public service robot
applications. The research model was tested with 419 valid responses
among users who had experienced both human services and public service
robots in Chinese government service halls. The structural equation
modeling (SEM) method was applied to quantitatively analyze the data.
This study sheds new light on the key determinants of users' switching
intentions toward public service robots from the perspectives of push,
pull, and mooring effects. The results can help practitioners and
managers understand users' intentions for such switches and make
scientific decisions to encourage citizens' positive responses to
service robots.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Enqvist, Lena</author></authors></contributors><titles><title>Rule-based versus AI-driven benefits allocation: GDPR and AIA legal
implications and challenges for automation in public social security
administration</title><secondary-title>INFORMATION &amp; COMMUNICATIONS TECHNOLOGY LAW</secondary-title></titles><periodical><full-title>INFORMATION &amp; COMMUNICATIONS TECHNOLOGY LAW</full-title></periodical><pages>222-246</pages><volume>33</volume><issue>2</issue><keywords><keyword>Automated decision-making; GDPR; Artificial Intell</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/13600834.2024.2349835</electronic-resource-num><language>English</language><urls/><abstract>This article focuses on the legal implications of the growing reliance
on automated systems in public administrations, using the example of
social security benefits administration. It specifically addresses the
deployment of automated systems for decisions on benefits eligibility
within the frameworks of the General Data Protection Regulation (GDPR)
and the Artificial Intelligence Act (AIA). It compares how these two
legal frameworks, each targeting different regulatory objects (personal
data versus AI systems) and employing different protective measures,
apply for two common system types: rule-based systems utilised for
making fully automated decisions on eligibility, and machine learning AI
systems utilised for assisting case administrators in their
decision-making. It concludes on the combined impact that the GDPR and
the AIA will have on each of these types of systems, as well as on
differences in how these instruments determines the basic legality of
utilising such systems within social security administration.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fattah, Ikhsan A</author></authors></contributors><titles><title>Decision making performance of business analytics capabilities: the role
of big data literacy and analytics competency</title><secondary-title>BUSINESS PROCESS MANAGEMENT JOURNAL</secondary-title></titles><periodical><full-title>BUSINESS PROCESS MANAGEMENT JOURNAL</full-title></periodical><keywords><keyword>Decision making performance; Business analytics ca</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1108/BPMJ-11-2023-0894</electronic-resource-num><language>English</language><urls/><abstract>PurposeThis study investigates the relationships between data governance
(DG), business analytics capabilities (BAC), and decision-making
performance (DMP), with a focus on the mediating effects of big data
literacy (BDL) and data analytics competency
(DAC).Design/methodology/approachThe study was conducted with 178
experienced managers in public service organizations, using a
quantitative approach. Structural equation modeling (SEM) and mediation
tests were employed to analyze the data.FindingsThe findings reveal that
DG and BDL are critical antecedents for developing analytical
capabilities. Big data literacy mediates the relationship between DG and
BAC, while BAC mediates the relationship between DG and DMP.
Furthermore, DAC mediates the relationship between BA capabilities and
DMP, explaining most of the effect of BAC on DMP.Practical
implicationsThese results highlight the importance of DG in fostering
BDL and analytical skills for improved decision-making in
organizations.Originality/valueBy prioritizing DG practices that promote
BDL and analytical capabilities, organizations can leverage business
analytics to enhance decision-making.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sundberg, Leif</author><author>Holmstrom, Jonny</author></authors></contributors><titles><title>Fusing domain knowledge with machine learning: A public sector
perspective</title><secondary-title>JOURNAL OF STRATEGIC INFORMATION SYSTEMS</secondary-title></titles><periodical><full-title>JOURNAL OF STRATEGIC INFORMATION SYSTEMS</full-title></periodical><volume>33</volume><issue>3</issue><keywords><keyword>Knowledge production; Artificial Intelligence; Mac</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.jsis.2024.101848</electronic-resource-num><language>English</language><urls/><abstract>Machine learning (ML) offers widely-recognized, but complex,
opportunities for both public and private sector organizations to
generate value from data. A key requirement is that organizations must
find ways to develop new knowledge by merging crucial `domain knowledge
` of experts in relevant fields with `machine knowledge `, i.e., data
that can be used to inform predictive models. In this paper, we argue
that understanding the process of generating such knowledge is essential
to strategically develop ML. In efforts to contribute to such
understanding, we examine the generation of new knowledge from domain
knowledge through ML via an exploratory study of two cases in the
Swedish public sector. The findings reveal the roles of three mechanisms
- dubbed consolidation, algorithmic mediation, and naturalization - in
tying domain knowledge to machine knowledge. The study contributes a
theory of knowledge production related to organizational use of ML, with
important implications for its strategic governance, particularly in the
public sector.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Botta, Federico</author><author>Lovelace, Robin</author><author>Gilbert, Laura</author><author>Turrell, Arthur</author></authors></contributors><titles><title>Packaging code and data for reproducible research: A case study of
journey time statistics</title><secondary-title>ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE</secondary-title></titles><periodical><full-title>ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE</full-title></periodical><keywords><keyword>Data science for public good; government data; ope</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1177/23998083241267331</electronic-resource-num><language>English</language><urls/><abstract>The effective and ethical use of data to inform decision-making offers
huge value to the public sector, especially when delivered by
transparent, reproducible, and robust data processing workflows. One way
that governments are unlocking this value is through making their data
publicly available, allowing more people and organisations to derive
insights. However, open data is not enough in many cases: publicly
available datasets need to be accessible in an analysis-ready form from
popular data science tools, such as R and Python, for them to realise
their full potential. This paper explores ways to maximise the impact of
open data with reference to a case study of packaging code to facilitate
reproducible analysis. We present the jtstats project, which consists of
a main Python package, and a smaller R version, for importing,
processing, and visualising large and complex datasets representing
journey times, for many transport modes and trip purposes at multiple
geographic levels, released by the UK Department for Transport (DfT).
jtstats shows how domain specific packages can enable reproducible
research within the public sector and beyond, saving duplicated effort
and reducing the risks of errors from repeated analyses. We hope that
the jtstats project inspires others, particularly those in the public
sector, to add value to their data sets by making them more accessible.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Frost, Neli</author></authors></contributors><titles><title>The Impoverished Publicness of Algorithmic Decision Making</title><secondary-title>OXFORD JOURNAL OF LEGAL STUDIES</secondary-title></titles><periodical><full-title>OXFORD JOURNAL OF LEGAL STUDIES</full-title></periodical><keywords><keyword>public decision making; artificial intelligence; m</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1093/ojls/gqae027</electronic-resource-num><language>English</language><urls/><abstract>The increasing use of machine learning (ML) in public administration
requires that we think carefully about the political and legal
constraints imposed on public decision making. These developments
confront us with the following interrelated questions: can algorithmic
public decisions be truly `public'? And, to what extent does the use of
ML models compromise the `publicness' of such decisions? This article is
part of a broader inquiry into the myriad ways in which digital and AI
technologies transform the fabric of our democratic existence by
mutating the `public'. Focusing on the site of public administration,
the article develops a conception of publicness that is grounded in a
view of public administrations as communities of practice. These
communities operate through dialogical, critical and synergetic
interactions that allow them to track-as faithfully as possible-the
public's heterogeneous view of its interests, and reify these interests
in decision making. Building on this theorisation, the article suggests
that the use of ML models in public decision making inevitably generates
an impoverished publicness, and thus undermines the potential of public
administrations to operate as a locus of democratic construction. The
article thus advocates for a reconsideration of the ways in which
administrative law problematises and addresses the harms of algorithmic
decision making.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Criado, J Ignacio</author><author>Sandoval-Almazan, Rodrigo</author><author>Gil-Garcia, J.
Ramon</author></authors></contributors><titles><title>Artificial intelligence and public administration: Understanding actors,
governance, and policy from micro, meso, and macro perspectives</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>;
analytical framework</keyword><keyword>Artificial intelligence; public administration; pu</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1177/09520767241272921</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has become one of the most prominent topics
in public policy and administration studies over the last years. Despite
the attention to AI in this field isn't entirely new, the universality
of these group of technologies has radically increased the attention of
scholars around the globe. This expansion of AI in the public sector
entails the exploration of renovated foundations of analysis, not only
to understand the novelty of these technologies, but also to connect
these processes of adoption and implementation with other debates in
public policy and administration. To do so, in this article we debate
the need of an analytical framework of AI in the public sector based on
the three levels of public administration: macro, meso, and micro. Also,
we review the state-of-the-art in the field using the articles presented
in the special issue on Artificial Intelligence and Public
Administration: Actors, Governance, and Policy. Form here, we propose
studying AI using a combination of macro, meso, and micro levels of
public administration. We assume this will help to broadly apprehend how
and why people, policies, and institutions interrelate with AI in public
sector settings, and which effects can be expected from these processes
in public administration.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bignami, Francesca</author></authors></contributors><titles><title>Artificial Intelligence Accountability of Public
Administration&lt;SUP&gt;†&lt;/SUP&gt;</title><secondary-title>AMERICAN JOURNAL OF COMPARATIVE LAW</secondary-title></titles><periodical><full-title>AMERICAN JOURNAL OF COMPARATIVE LAW</full-title></periodical><pages>i312-i346</pages><volume>70</volume><issue>SUPP 1, 1, SI</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1093/ajcl/avac012</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Bignami - AMERICAN JOURNAL OF COMPARATIVE LAW.pdf</url></pdf-urls></urls></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wanckel, Camilla</author></authors></contributors><titles><title>An ounce of prevention is worth a pound of cure - Building capacities
for the use of big data algorithm systems (BDAS) in early crisis
detection</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>4</issue><keywords><keyword>Big data algorithm system (BDAS); Artificial intel</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101705</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Wanckel - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>Public sector organizations at all levels of government increasingly
rely on Big Data Algorithmic Systems (BDAS) to support decision-making
along the entire policy cycle. But while our knowledge on the use of big
data continues to grow for government agencies implementing and
delivering public services, empirical research on applications for
anticipatory policy design is still in its infancy. Based on the concept
of policy analytical capacity (PAC), this case study examines the
application of BDAS for early crisis detection within the German Federal
Government-that is, the German Federal Foreign Office (FFO) and the
Federal Ministry of Defence (FMoD). It uses the nested model of PAC to
reflect on systemic, organizational, and individual capacity-building
from a neoinstitutional perspective and allow for the consideration of
embedded institutional contexts. Results from semi-structured interviews
indicate that governments seeking to exploit BDAS in policymaking depend
on their institutional environment (e.g., through research and data
governance infrastructure). However, specific capacity-building
strategies may differ according to the departments' institutional
framework, with the FMoD relying heavily on subordinate agencies and the
FFO creating network-like structures with external researchers.
Government capacity-building at the individual and organizational level
is similarly affected by long-established institutional structures,
roles, and practices within the organization and beyond, making it
important to analyze these three levels simultaneously instead of
separately.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jeong, Jonggu</author></authors></contributors><titles><title>Introduction of the First AI Impact Assessment and Future Tasks: South
Korea Discussion</title><secondary-title>LAWS</secondary-title></titles><periodical><full-title>LAWS</full-title></periodical><volume>11</volume><issue>5</issue><keywords><keyword>AI; AI impact assessment; intelligent information</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.3390/laws11050073</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Jeong - LAWS.pdf</url></pdf-urls></urls><abstract>South Korea introduced the artificial intelligence impact assessment and
was the first case of introducing the artificial intelligence impact
assessment as national-level legislation. Artificial intelligence impact
assessments will be helpful in deciding whether to introduce artificial
intelligence by comparing costs and benefits. However, South Korea's
approach had limitations. First, an impact assessment was introduced
only in the public sector. Second, artificial intelligence impact
assessments were voluntary. Third, the subject of artificial
intelligence impact assessments was limited to society. Fourth, it is
necessary to establish a relationship with other impact assessments.
Fifth, specific details were incomplete.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Costa, Goncal</author><author>Arroyo, Oriol</author><author>Rueda, Pablo</author><author>Briones, Alan</author></authors></contributors><titles><title>A ventilation early warning system (VEWS) for diaphanous workspaces
considering COVID-19 and future pandemics scenarios</title><secondary-title>HELIYON</secondary-title></titles><periodical><full-title>HELIYON</full-title></periodical><volume>9</volume><issue>3</issue><keywords><keyword>Smart building; Building digital twin; COVID-19; I</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.heliyon.2023.e14640</electronic-resource-num><language>English</language><urls/><abstract>The COVID-19 pandemic has generated new needs due to the associated
health risks and, more specifically, its rapid infection rate.
Prevention measures to avoid contagions in indoor spaces, especially in
office and public buildings (e.g., hospitals, public administration,
educational cen-tres, etc.), have led to the need for adequate
ventilation to dilute the possible concentration of the virus. This
article presents our contribution to this new challenge, namely the
Ventilation Early Warning System (VEWS) which has aims to adapt the
operation of the current Heating, Venti-lating and Air Conditioning
(HVAC) systems to the ventilation needs of diaphanous workspaces, based
on a Smart Campus Digital Twin (SCDT) framework approach, while
maintaining sus-tainability. Different technologies such as the Internet
of Things (IoT), Building Information Modelling (BIM) and Artificial
Intelligence (AI) algorithms are combined to collect and integrate
monitoring data (historical records, real-time information, and
location-related patterns) to carry out forecasting simulations in this
digital twin. The generated outputs serve to assist facility managers in
their building governance, considering the appropriate application of
health mea-sures to reduce the risk of coronavirus contagion in
combination with sustainability criteria. The article also provides the
results of the implementation of the VEWS in a university workspace as a
case study. Its application has made it possible to detect and warn of
inadequate ventilation situations for the daily flow of people in the
different controlled zones.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ruvalcaba-Gomez, Edgar A</author></authors></contributors><titles><title>Systematic and axiological capacities in artificial intelligence applied
in the public sector</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>Artificial intelligence; public sector; explorator</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231170321</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) as a technological development is being
implemented in the public sector with the intention of improving service
delivery, as well as to help solve complex problems. However, there is a
wide range of capabilities that AI can perform and that public officials
perceive and implement in different ways. This paper aims to describe
and analyze some categories into which AI capabilities in the public
sector are divided. Using an Exploratory Factor Analysis (EFA), our
results show that the capabilities of AI from the perspective of public
officials can be classified into two aspects: systematic factors and
axiological factors. Systematic factors are related to the analysis and
behavior of data, including monitoring, analyzing, interacting,
remembering, and anticipation. Axiological factors refer to the impacts
of values, ethics, and decisions, including acting, feeling, moralizing,
creating, and deciding capacities. This categorization of AI
capabilities in the public sector sheds light on the perception of
public officials about the implementation of this technological
development.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zahid, Reeba</author><author>Altaf, Ayesha</author><author>Ahmad, Tauqir</author><author>Iqbal, Faiza</author><author>Vera, Yini Airet Miro</author><author>Flores, Miguel Angel Lopez</author><author>Ashraf, Imran</author></authors></contributors><titles><title>Secure Data Management Life Cycle for Government Big-Data Ecosystem:
Design and Development Perspective</title><secondary-title>SYSTEMS</secondary-title></titles><periodical><full-title>SYSTEMS</full-title></periodical><volume>11</volume><issue>8</issue><keywords><keyword>big data; data life cycle; GBDE; secure data life</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.3390/systems11080380</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Zahid et al. - SYSTEMS.pdf</url></pdf-urls></urls><abstract>The rapid generation of data from various sources by the public sector,
private corporations, business associations, and local communities is
referred to as big data. This large and complex dataset is often
regarded as the `new oil' by public administrations (PAs), and
data-driven approaches are employed to transform it into valuable
insights that can improve governance, transparency, digital services,
and public engagement. The government's big-data ecosystem (GBDE) is a
result of this initiative. Effective data management is the first step
towards large-scale data analysis, which yields insights that benefit
your work and your customers. However, managing big data throughout its
life cycle is a daunting challenge for public agencies. Despite its
widespread use, big data management is still a significant obstacle. To
address this issue, this study proposes a hybrid approach to secure the
data management life cycle for GBDE. Specifically, we use a combination
of the ECC algorithm with AES 128 BITS encryption to ensure that the
data remain confidential and secure. We identified and analyzed various
data life cycle models through a systematic literature review to create
a data management life cycle for data-driven governments. This approach
enhances the security and privacy of data management and addresses the
challenges faced by public agencies.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Abbas, Syed Wasim</author><author>Hamid, Muhammad</author><author>Alkanhel, Reem</author><author>Abdallah, Hanaa A</author></authors></contributors><titles><title>Official Statistics and Big Data Processing with Artificial
Intelligence: Capacity Indicators for Public Sector Organizations</title><secondary-title>SYSTEMS</secondary-title></titles><periodical><full-title>SYSTEMS</full-title></periodical><volume>11</volume><issue>8</issue><keywords><keyword>artificial intelligence; big data; convex logistic</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.3390/systems11080424</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Abbas et al. - SYSTEMS.pdf</url></pdf-urls></urls><abstract>Efficient monitoring and achievement of the Sustainable Development
Goals (SDGs) has increased the need for a variety of data and
statistics. The massive increase in data gathering through social
networks, traditional business systems, and Internet of Things
(IoT)-based sensor devices raises real questions regarding the capacity
of national statistical systems (NSS) for utilizing big data sources.
Further, in this current era, big data is captured through sensor-based
systems in public sector organizations. To gauge the capacity of public
sector institutions in this regard, this work provides an indicator to
monitor the processing capacity of the public sector organizations
within the country (Pakistan). Some of the indicators related to
measuring the capacity of the NSS were captured through a census-based
survey. At the same time, convex logistic principal component analysis
was used to develop scores and relative capacity indicators. The
findings show that most organizations hesitate to disseminate data due
to concerns about data privacy and that public sector organizations' IT
personnel are unable to deal with big data sources to generate official
statistics. Artificial intelligence (AI) techniques can be used to
overcome these challenges, such as automating data processing, improving
data privacy and security, and enhancing the capabilities of IT human
resources. This research helps to design capacity-building initiatives
for public sector organizations in weak dimensions, focusing on
leveraging AI to enhance the production of quality and reliable
statistics.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pautz, Hartwig</author></authors></contributors><titles><title>Policy making and artificial intelligence in Scotland</title><secondary-title>CONTEMPORARY SOCIAL SCIENCE</secondary-title></titles><periodical><full-title>CONTEMPORARY SOCIAL SCIENCE</full-title></periodical><pages>618-636</pages><volume>18</volume><issue>5</issue><keywords><keyword>Artificial intelligence; policy making; Scotland;</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/21582041.2023.2293822</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Pautz - CONTEMPORARY SOCIAL SCIENCE.pdf</url></pdf-urls></urls><abstract>The article presents an exploratory qualitative single case study about
whether and how artificial intelligence (AI) is used by the Scottish
Government, about the key concerns relating to its usage, and about
obstacles to, and drivers of AI usage. Besides the academic literature
and published reports, the analysis rests on 12 semi-structured
interviews. Interviewees include Scottish Government employees, experts
from academia and representatives of commercial and non-commercial AI
and Big Data organisations. The article finds that the Scottish
Government has, so far, made little use of AI. Currently, AI is used in
very limited ways in process automation and for gaining `cognitive
insights' with the human in control. There are no `strategic' AI
applications where advanced reasoning and `decision-making by algorithm'
play a role. Data-driven e-policy making is not currently on the cards.
The reasons are the Scottish Government's wariness of AI, a lack of
`digital maturity' (concerning Big Data and digital infrastructure, but
also expertise) in the public sector, and ethical concerns around the
use of AI. Governments need to conduct a debate about the extent of AI
usage to avoid `AI creep' in their institutions and to assure that AI
does not have negative consequences for democracy.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Marty, Robert</author><author>Duhaut, Alice</author></authors></contributors><titles><title>Global poverty estimation using private and public sector big data
sources</title><secondary-title>SCIENTIFIC REPORTS</secondary-title></titles><periodical><full-title>SCIENTIFIC REPORTS</full-title></periodical><volume>14</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1038/s41598-023-49564-6</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Marty, Duhaut - SCIENTIFIC REPORTS.pdf</url></pdf-urls></urls><abstract>Household surveys give a precise estimate of poverty; however, surveys
are costly and are fielded infrequently. We demonstrate the importance
of jointly using multiple public and private sector data sources to
estimate levels and changes in wealth for a large set of countries. We
train models using 63,854 survey cluster locations across 59 countries,
relying on data from satellites, Facebook Marketing information, and
OpenStreetMaps. The model generalizes previous approaches to a wide set
of countries. On average, across countries, the model explains 55% (min
= 14%; max = 85%) of the variation in levels of wealth at the survey
cluster level and 59% (min = 0%; max = 93%) of the variation at the
district level, and the model explains 4% (min = 0%; max = 17%) and
6% (min = 0%; max = 26%) of the variation of changes in wealth at the
cluster and district levels. Models perform best in lower-income
countries and in countries with higher variance in wealth. Features from
nighttime lights, OpenStreetMaps, and land cover data are most important
in explaining levels of wealth, and features from nighttime lights are
most important in explaining changes in wealth.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hjaltalin, Illugi Torfason</author><author>Sigurdarson, Hallur Thor</author></authors></contributors><titles><title>The strategic use of AI in the public sector: A public values analysis
of national AI strategies</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Artificial intelligence; Public value; E -governme</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101914</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Hjaltalin, Sigurdarson - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>Governments worldwide are strategically investing in artificial
intelligence (AI) to improve public services and streamline internal
operations. In this context, national AI strategies play a pivotal role.
This study uses combined qualitative research methods analyzing 28
national AI strategies (i.e., the texts). Our aim is to delve into how
governments define and position AI applications within the public
sector. Specifically, the study explores how the texts convey AI's
application in this context employing a public value(s) perspective. Its
discursive analytical approach coupled with a comprehensive take on
public value theory (Moore, 1995) engenders novel insights into national
discourses on AI in the public sector. Against this background we draw
on public administration and policy research in our analysis of three
dominant discourses that we identify in the texts, i.e. empowerment
through information, enhanced administrative practices, and improved
service delivery. We find that the discourses involve different
positions in relation to governments' use of AI and depend on particular
actors and types of public service. Commonly, they concern government
objectives to tackle critical societal issues through AI, such as in the
areas of health and social care and employment. In particular, the
discourse of enhanced administrative practices commonly positioned AI as
a tool to optimize internal processes, resource allocation, and
organizational management. On the other hand, the discourse of improved
service delivery similarly placed public services front and center,
while the discourse of empowerment through information framed AI as
being able to enhance citizens' service experiences. Interestingly,
discourses emphasizing the policymaking function, i.e., AI applied to
the development of public policy,-receives limited attention. Our
findings underscore strategic prioritizations. While efficiency and
service delivery dominate the discourse, citizen engagement remains
underemphasized. We argue that policymakers must strike a balance,
ensuring AI aligns with broader societal outcomes while addressing
democratic imperatives.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kaushal, Akshay</author><author>Acharjee, Animesh</author><author>Mandal, Anandadeep</author></authors></contributors><titles><title>Machine learning based attribution mapping of climate related
discussions on social media</title><secondary-title>SCIENTIFIC REPORTS</secondary-title></titles><periodical><full-title>SCIENTIFIC REPORTS</full-title></periodical><volume>12</volume><issue>1</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1038/s41598-022-22034-1</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Kaushal, Acharjee, Mandal - SCIENTIFIC REPORTS.pdf</url></pdf-urls></urls><abstract>A united front from all the stakeholders including public,
administration and academia alike is required to counter the growing
threat of climate change. The recent rise of social media as the new
public address system, makes it an ideal source of information to assess
public discussions and responses in real time. We mine c.1.7 m posts
from 55 climate related subreddits on social media platform Reddit since
its inception. Using USE, a state-of-the-art sentence encoder, and
K-means clustering algorithm, we develop a machine learning based
approach to identify, store, process and classify the posts
automatically, and at a scale. In the broad and multifaceted theme of
climate change, our approach narrows down the focus to 10 critical
underlying themes comprising the public discussions on social media over
time. Furthermore, we employ a full order partial correlation analysis
to assess the relationship between the different identified themes. We
show that in line with Paris Agreement, while the climate science
community has been successful in influencing the discussions on both the
causes and effects of climate change, the public administration has
failed to appropriately communicate the causes of climate change and has
been able to influence only the discussions on the effects of it. Hence,
our study shows a clear gap in the public communication by the
administration, wherein counter-intuitively less emphasis has been given
on the drivers of climate change. This information can be particularly
beneficial to policymakers and climate activists in decision making as
they try to close the gap between public and academia.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cho, Ji Yeon</author><author>Lee, Bong Gyou</author></authors></contributors><titles><title>Creating value using public big data: comparison of driving factors from
the provider's perspective</title><secondary-title>INFORMATION TECHNOLOGY &amp; PEOPLE</secondary-title></titles><periodical><full-title>INFORMATION TECHNOLOGY &amp; PEOPLE</full-title></periodical><pages>467-493</pages><volume>35</volume><issue>2</issue><keywords><keyword>Big data; Open government data; Data value; Public</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1108/ITP-04-2019-0169</electronic-resource-num><language>English</language><urls/><abstract>Purpose The revitalization of big data has gained attention in the
public sector. However, such open government data (OGD) is facing major
challenges with respect to data quality and limited use. To solve this
problem, this study analyzes the factors driving the use of OGD from the
perspective of data providers in the public sector.
Design/methodology/approach Using the analytic hierarchy process and
analytic network process methodologies, the importance of the factors
driving the use of big data in the public sector was ranked. In
addition, the different characteristics of tasks among the departments
in a public agency were compared based on expert interviews. Findings
The factors driving OGD use are not only political environment or the
technological environment. The importance of the institutional culture
within the organization increases with the motivation of the data
provider. The priorities of the OGD factors also depend on the
objectives of the department involved. Originality/value This study
provides implications for improving the publication of open data by
analyzing the priorities of the factors driving its use from the
perspective of big data providers. It focuses on different perceptions
of the factors valued by public officials in charge of data in
institutions. The results suggest the need to explore officials'
perceptions of value creation in big data fields.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Buttow, Clarissa Valli</author><author>Weerts, Sophie</author></authors></contributors><titles><title>Public sector information in the European Union policy: The misbalance
between economy and individuals</title><secondary-title>BIG DATA &amp; SOCIETY</secondary-title></titles><periodical><full-title>BIG DATA &amp; SOCIETY</full-title></periodical><volume>9</volume><issue>2</issue><keywords><keyword>Public sector information; open government data; d</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/20539517221124587</electronic-resource-num><language>English</language><urls/><abstract>Algorithmic technologies and artificial intelligence are centred on data
and generate new business models, known as the data-driven economy. In
the European Union context, the development of such new business is
accompanied by a regulatory and political framework. An important aspect
of this regulatory framework regards the legal conditions that enable
the data collection, availability, sharing, use and reuse. Within the
larger context, this article analyses the development of the European
Union regulatory framework governing the availability, sharing and reuse
of public sector data, also referred to as Public Sector Information
policy. Anchored in the analytical tools provided by Discursive
Institutionalism and Critical Data Studies and after studying the
evolution of this policy over 25 years, this article argues that
economic considerations have been overwhelmingly decisive in the
European Union Public Sector Information policy and much less attention
has been paid to fundamental rights and democracy issues. It also shows
how European Union Public Sector Information policy contributes to the
data infrastructure, enabling a thriving data-driven economy. In doing
so, this article argues that the possible problematic effects of this
new data-driven economy are not only affordances of the technology
itself but are also the result of political and regulatory choices. More
globally, the article stresses the need for policymakers to inscribe
each of the policies and regulations affecting the digital
transformation in the framework of fundamental rights and democracy.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Engstrom, David Freeman</author><author>Haim, Amit</author></authors></contributors><titles><title>Regulating Government AI and the Challenge of Sociotechnical Design</title><secondary-title>ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE</secondary-title></titles><periodical><full-title>ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE</full-title></periodical><pages>277-298</pages><volume>19</volume><keywords><keyword>artificial intelligence; government; public admini</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1146/annurev-lawsocsci-120522-091626</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Engstrom, Haim - ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE.pdf</url></pdf-urls></urls><abstract>Artificial intelligence (AI) is transforming how governments work, from
distribution of public benefits, to identifying enforcement targets, to
meting out sanctions. But given AI's twin capacity to cause and cure
error, bias, and inequity, there is little consensus about how to
regulate its use. This review advances debate by lifting up research at
the intersection of computer science, organizational behavior, and law.
First, pushing past the usual catalogs of algorithmic harms and
benefits, we argue that what makes government AI most concerning is its
steady advance into discretion-laden policy spaces where we have long
tolerated less-than-full legal accountability. The challenge is how, but
also whether, to fortify existing public law paradigms without
hamstringing government or stymieing useful innovation. Second, we argue
that sound regulation must connect emerging knowledge about internal
agency practices in designing and implementing AI systems to
longer-standing lessons about the limits of external legal constraints
in inducing organizations to adopt desired practices. Meaningful
accountability requires a more robust understanding of organizational
behavior and law as AI permeates bureaucratic routines.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Haesevoets, Tessa</author><author>Verschuere, Bram</author><author>Van Severen, Ruben</author><author>Roets, Arne</author></authors></contributors><titles><title>How do citizens perceive the use of Artificial Intelligence in public
sector decisions?</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Artificial Intelligence (AI); Public sector decisi</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2023.101906</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Haesevoets et al. - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>Artificial Intelligence (AI) has become increasingly prevalent in almost
every aspect of our lives. At the same time, a debate about its
applications, safety, and privacy is raging. In three studies, we
explored how UK respondents perceive the usage of AI in various public
sector decisions. Our results are fourfold. First, we found that people
prefer AI to have considerably less decisional weight than various human
decision-makers; those being: politicians, citizens, and (human)
experts. Secondly, our findings revealed that people prefer AI to
provide input and advice to these human decision-makers, rather than
letting AI make decisions by itself. Thirdly, although AI is seen as
contributing less to perceived legitimacy than these human
decision-makers, similar to (human) experts, its contribution is seen
more in terms of output legitimacy than in terms of input and throughput
legitimacy. Finally, our results suggest that the involvement of AI is
perceived more suitable for decisions that are low (instead of high)
ideologically-charged. Overall, our findings thus show that people are
rather skeptical towards using AI in the public domain, but this does
not imply that they want to exclude AI entirely from the decision-making
process.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dunleavy, Patrick</author><author>Evans, Mark</author></authors></contributors><titles><title>Australian administrative elites and the challenges of digital-era
change</title><secondary-title>JOURNAL OF CHINESE GOVERNANCE</secondary-title></titles><periodical><full-title>JOURNAL OF CHINESE GOVERNANCE</full-title></periodical><pages>181-200</pages><volume>4</volume><issue>2, SI</issue><keywords><keyword>Bureaucracy; public service officials; digital; ar</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1080/23812346.2019.1596544</electronic-resource-num><language>English</language><urls/><abstract>Within long-lived public sector bureaucracies, the organizational
cultures developed by administrative elites have strong filtering and
focusing effects on the kinds of technological changes adopted,
especially in the modern era. Normally seen as very slow-moving and hard
to alter, senior officials' attitudes towards digital changes have
recently begun to alter in more substantial ways in Australia. We review
first a considerable reappraisal of the priority given to digital
changes by top public service managers. This cultural shift has followed
on from tech-lead disruptive societal changes affecting most areas of
government now, and from the rise of global-scaled ICT corporations to
become key management exemplars for officials. Second, we look at the
chequered history of political leaders' interventions to speed up
digital change, showing that in the period 2015-19 Australia witnessed
both the initial power and later limits of such involvement. Finally, we
consider Australia's recent experience with big data/ artificial
intelligence (BDAI), a key area of technological change for public
service officials, but one that in a liberal democracy can also easily
spark public resistance to their plans.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cerrillo-Martinez, Agusti</author><author>Casadesus-de-Mingo, Anahi</author></authors></contributors><titles><title>Data governance for public transparency</title><secondary-title>PROFESIONAL DE LA INFORMACION</secondary-title></titles><periodical><full-title>PROFESIONAL DE LA INFORMACION</full-title></periodical><volume>30</volume><issue>4</issue><keywords><keyword>Data; Data governance; Transparency; Public admini</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.3145/epi.2021.jul.02</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2021 - Cerrillo-Martinez, Casadesus-de-Mingo - PROFESIONAL DE LA INFORMACION.pdf</url></pdf-urls></urls><abstract>Public transparency is becoming increasingly complex due to the volume
of data generated by government, the plurality of uses given to public
data, their dispersal over different organizations, bodies and units and
the diversity of mechanisms through which they are channelled. All this
requires government agencies not only to improve data management but
also to adopt procedures and structures that facilitate decision-making
regarding data's use and quality. In this context, this study defines
data governance as the set of principles, values and standards that
guide interaction in decision-making among stakeholders who create,
manage and use data. This study uses the analysis of three data
governance cases to identify the defining characteristics of data
governance (data governance's design, the institutional position on data
governance in the organizational structure, the stakeholders involved in
data governance, the interaction channels provided and the functions
attributed to them). Based on these elements, three models of data
governance promoted by government agencies are observed. In the light of
the data governance models analysed, the final reflection identifies how
data governance can contribute to improve public transparency.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sovrano, Francesco</author><author>Palmirani, Monica</author><author>Vitali, Fabio</author></authors></contributors><titles><title>Combining shallow and deep learning approaches against data scarcity in
legal domains</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Data scarcity; Deep learning; TF-IDF; Syntagmatic</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101715</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Sovrano, Palmirani, Vitali - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>We are recently witnessing a radical shift towards digitisation in many
aspects of our daily life, including law, public administration and
governance. This has sometimes been done with the aim of reducing costs
and human errors by improving data analysis and management, but not
without raising major technological challenges. One of these challenges
is certainly the need to cope with relatively small amounts of data,
without sacrificing performance. Indeed, cutting-edge approaches to
(natural) language processing and understanding are often data-hungry,
especially those based on deep learning. With this paper we seek to
address the problem of data scarcity in automatic Legalese (or legal
English) processing and understanding. What we propose is an ensemble of
shallow and deep learning techniques called SyntagmTuner, designed to
combine the accuracy of deep learning with the ability of shallow
learning to work with little data. Our contribution is based on the
assumption that Legalese differs from its spoken language in the way the
meaning is encoded by the structure of the text and the co-occurrence of
words. As result, we show with SyntagmTuner how we can perform important
tasks for e-governance, as multi-label classification of the United
Nations General Assembly (UNGA) Resolutions or legal question answering,
with data-sets of roughly 100 samples or even less.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jorgensen, Andreas Moller</author><author>Nissen, Maria Appel</author></authors></contributors><titles><title>Making sense of decision support systems: Rationales, translations and
potentials for critical reflections on the reality of child protection</title><secondary-title>BIG DATA &amp; SOCIETY</secondary-title></titles><periodical><full-title>BIG DATA &amp; SOCIETY</full-title></periodical><volume>9</volume><issue>2</issue><keywords><keyword>Algorithms; big data; artificial intelligence; chi</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/20539517221125163</electronic-resource-num><language>English</language><urls/><abstract>Decision support systems, which incorporate artificial intelligence and
big data, are receiving significant attention in the public sector.
Decision support systems are sociocultural artefacts that are subject to
a mix of technical and political choices, and critical investigation of
these choices and the rationales they reflect are paramount since they
are inscribed into and may cause harm, violate fundamental rights and
reproduce negative social patterns. Applying and merging the concepts of
sense-making and translation, this article investigates the rationales,
translations and critical reflections that shape the development of a
decision support system to support social workers assessing referrals
concerning child neglect. It presents findings from a qualitative case
study conducted in 2019-2020 at the Citizen Centre Children and Young
People, Copenhagen Municipality, Denmark. The analysis shows how key
actors through processes of translation construct, negotiate and
readjust problem definitions, roles, interests, responsibilities and
ideas of ambiguity and accountability. Although technological
solutionism is present in these processes, it is not the only rationale
invested. Rather, technological and data-driven rationales are adjusted
to and merged with rationales of efficiency, return on investment and
child welfare. Through continuous renegotiation of roles,
responsibilities and problems according to these rationales, the key
actors attempt to orchestrate ways of managing the complexity facing
child welfare services by projecting images of future potentials of the
decision support system that are yet to be realised.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Papyshev, Gleb</author><author>Yarime, Masaru</author></authors></contributors><titles><title>The state's role in governing artificial intelligence: development,
control, and promotion through national strategies</title><secondary-title>POLICY DESIGN AND PRACTICE</secondary-title></titles><periodical><full-title>POLICY DESIGN AND PRACTICE</full-title></periodical><pages>79-102</pages><volume>6</volume><issue>1, SI</issue><keywords><keyword>Artificial intelligence; national AI strategy; sta</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/25741292.2022.2162252</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Papyshev, Yarime - POLICY DESIGN AND PRACTICE.pdf</url></pdf-urls></urls><abstract>Numerous governments worldwide have issued national artificial
intelligence (AI) strategies in the last five years to deal with the
opportunities and challenges posed by this technology. However, a
systematic understanding of the roles and functions that the governments
are taking is lacking in the academic literature. Therefore, this
research uses qualitative content analysis and Latent Dirichlet
Allocation (LDA) topic modeling methodologies to investigate the texts
of 31 strategies from across the globe. The findings of the qualitative
content analysis highlight thirteen functions of the state, which
include human capital, ethics, R&amp;D, regulation, data, private sector
support, public sector applications, diffusion and awareness, digital
infrastructure, national security, national challenges, international
cooperation, and financial support. We combine these functions into
three general themes, representing the state's role: development,
control, and promotion. LDA topic modeling results are also reflective
of these themes. Each general theme is present in every national
strategy's text, but the proportion they occupy in the text is
different. The combined typology based on two methods reveals that the
countries from the post-soviet bloc and East Asia prioritize the theme
``development,'' highlighting the high level of the state's
involvement in AI innovation. The countries from the EU focus on
``control,'' which reflects the union's hard stance on AI regulation,
whereas countries like the UK, the US, and Ireland emphasize a more
hands-off governance arrangement with the leading role of the private
sector by prioritizing ``promotion.''</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Yi-Fan</author><author>Chen, Yu-Che</author><author>Chien, Shih-Yi</author></authors></contributors><titles><title>Citizens' intention to follow recommendations from a
government-supported AI-enabled system</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>artificial intelligence; transparency; privacy; te</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231176126</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) applications in public services are an
emerging and crucial issue in the modern world. Many countries utilize
AI-enabled systems to serve citizens and deliver public services.
Although AI can bring more efficiency and responsiveness, this
technology raises privacy and social inequality concerns. From the
perspective of behavioral public administration (BPA), citizens' use of
AI-enabled systems depends on their perception of this technology. This
study proposes a conceptual framework connecting citizens' perceptions,
trust, and intention to follow instructions from the
government-supported AI-enabled recommendation system in the pandemic.
Our study launches an online-based experimental survey and analyzes the
data with the partial least square structural equation model (PLS-SEM).
The research findings suggest that algorithmic transparency increases
trust in the recommendations, but privacy concerns decrease the trust
when the system asks for sensitive information. Additionally, citizens
familiar with technologies are more likely to trust the recommendations
in the feature-based communication strategy. Finally, trust in the
recommendations can mediate the impacts of citizens' perceptions of the
AI system. This study clarifies the effects of perceptions, identifies
the role of trust, and explores the communication strategies in
citizens' intention to follow the AI-enabled system recommendations. The
results can deepen AI research in public administration and provide
policy suggestions for the public sector to develop strategies to
increase policy compliance with system recommendations.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Robles, Pedro</author><author>Mallinson, Daniel J</author></authors></contributors><titles><title>Artificial intelligence technology, public trust, and effective
governance</title><secondary-title>REVIEW OF POLICY RESEARCH</secondary-title></titles><periodical><full-title>REVIEW OF POLICY RESEARCH</full-title></periodical><keywords><keyword>AI governance; AI policy; artificial intelligence</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1111/ropr.12555</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Robles, Mallinson - REVIEW OF POLICY RESEARCH.pdf</url></pdf-urls></urls><abstract>Advancement in information technology continues to evolve especially in
the field of artificial intelligence (AI). Research studies have been
conducted to evaluate the perceptions of Americans on the development
and utilization of AI technology and if it is appropriate to use AI in
public administrative duties. The research revealed that society is
fragmented regarding the acceptance of AI, and whether AI decisions
could have long-term effects on the labor industry, legal system, and
national security. The 2018 AI Public Opinion Survey revealed
significant concerns among the American public regarding AI, yet also a
recognition of its promise. The goal of this article is to further
develop a governance framework for AI that considers the importance of
public trust in AI policy. First, it discusses the necessity of public
trust for the effective governance of emergent technology. Then, it
evaluates public opinion on AI technology that specifically pertains to
governance. The article concludes with a discussion of why public trust
is central to good AI governance.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Straub, Vincent J</author><author>Morgan, Deborah</author><author>Bright, Jonathan</author><author>Margetts, Helen</author></authors></contributors><titles><title>Artificial intelligence in government: Concepts, standards, and a
unified framework</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>40</volume><issue>4</issue><keywords><keyword>Government; Public administration; Artificial inte</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.giq.2023.101881</electronic-resource-num><language>English</language><urls/><abstract>Recent advances in artificial intelligence (AI), especially in
generative language modelling, hold the promise of transforming
government. Given the advanced capabilities of new AI systems, it is
critical that these are embedded using standard operational procedures,
clear epistemic criteria, and behave in alignment with the normative
expectations of society. Scholars in multiple domains have subsequently
begun to conceptualize the different forms that AI applications may
take, highlighting both their potential benefits and pitfalls. However,
the literature remains fragmented, with researchers in social science
disciplines like public administration and political science, and the
fast-moving fields of AI, ML, and robotics, all developing concepts in
relative isolation. Although there are calls to formalize the emerging
study of AI in government, a balanced account that captures the full
depth of theoretical perspectives needed to understand the consequences
of embedding AI into a public sector context is lacking. Here, we unify
efforts across social and technical disciplines by first conducting an
integrative literature review to identify and cluster 69 key terms that
frequently co-occur in the multidisciplinary study of AI. We then build
on the results of this bibliometric analysis to propose three new
multifaceted concepts for understanding and analysing AI-based systems
for government (AI-GOV) in a more unified way: (1) operational fitness,
(2) epistemic alignment, and (3) normative divergence. Finally, we put
these concepts to work by using them as dimensions in a conceptual
typology of AI-GOV and connecting each with emerging AI technical
measurement standards to encourage operationalization, foster
cross-disciplinary dialogue, and stimulate debate among those aiming to
rethink government with AI.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fest, Isabelle</author><author>Wieringa, Maranke</author><author>Wagner, Ben</author></authors></contributors><titles><title>Paper vs. practice: How legal and ethical frameworks influence public
sector data professionals in the Netherlands</title><secondary-title>PATTERNS</secondary-title></titles><periodical><full-title>PATTERNS</full-title></periodical><volume>3</volume><issue>10</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.patter.2022.100604</electronic-resource-num><language>English</language><urls/><abstract>Recent years have seen a massive growth in ethical and legal frameworks
to govern data science practices. Yet one of the core questions
associated with ethical and legal frameworks is the extent to which they
are implemented in practice. A particularly interesting case in this
context comes to public officials, for whom higher standards typically
exist. We are thus trying to understand how ethical and legal frameworks
influence the everyday practices on data and algorithms of public sector
data professionals. The following paper looks at two cases: public
sector data professionals (1) at municipalities in the Netherlands and
(2) at the Netherlands Police. We compare these two cases based on an
analytical research framework we develop in this article to help
understanding of everyday professional practices. We conclude that there
is a wide gap between legal and ethical governance rules and the
everyday practices.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Johnson, Brad A M</author><author>Coggburn, Jerrell D</author><author>Llorens, Jared J</author></authors></contributors><titles><title>Artificial Intelligence and Public Human Resource Management: Questions
for Research and Practice</title><secondary-title>PUBLIC PERSONNEL MANAGEMENT</secondary-title></titles><periodical><full-title>PUBLIC PERSONNEL MANAGEMENT</full-title></periodical><pages>538-562</pages><volume>51</volume><issue>4</issue><keywords><keyword>artificial intelligence (AI); public human resourc</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/00910260221126498</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Johnson, Coggburn, Llorens - PUBLIC PERSONNEL MANAGEMENT.pdf</url></pdf-urls></urls><abstract>Advances in big data and artificial intelligence (AI), including machine
learning (ML) and other cognitive computing technologies (CCT), have
facilitated the development of human resource management (HRM)
applications promising greater efficiency, economy, and effectiveness
for public administration (Maciejewski, 2017) and better alignment with
the modern, constantly evolving employment landscape. It is not
surprising then that these advanced technologies are featured in
proposals to elevate the government's human capital. This article
discusses current and emerging AI applications that stand to impact most
(if not all) HRM functions and their prospects for elevating public
human capital. In particular, this article (a) reviews the current state
of the field with regards to AI and HRM, (b) discusses AI's current and
potential impact upon the core functional areas of HRM, (c) identifies
the main challenges AI poses to such concerns as public values, equity,
and traditional merit system principles, and (d) concludes by
identifying research needs for public HRM scholarship and practice that
highlight the growing role and influence of AI applications in the
workplace.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Keppeler, Florian</author></authors></contributors><titles><title>No Thanks, Dear AI! Understanding the Effects of Disclosure and
Deployment of Artificial Intelligence in Public Sector Recruitment</title><secondary-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</full-title></periodical><pages>39-52</pages><volume>34</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1093/jopart/muad009</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Keppeler - JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY.pdf</url></pdf-urls></urls><abstract>Applications based on artificial intelligence (AI) play an increasing
role in the public sector and invoke political discussions. Research
gaps exist regarding the disclosure effects-reactions to disclosure of
the use of AI applications-and the deployment effect-efficiency gains in
data savvy tasks. This study analyzes disclosure effects and explores
the deployment of an AI application in a preregistered field experiment
(n = 2,000) co-designed with a public organization in the context of
employer-driven recruitment. The linear regression results show that
disclosing the use of the AI application leads to significantly less
interest in an offer among job candidates. The explorative analysis of
the deployment of the AI application indicates that the person-job fit
determined by the leaders can be predicted by the AI application. Based
on the literature on algorithm aversion and digital discretion, this
study provides a theoretical and empirical disentanglement of the
disclosure effect and the deployment effect to inform future evaluations
of AI applications in the public sector. It contributes to the
understanding of how AI applications can shape public policy and
management decisions, and discusses the potential benefits and downsides
of disclosing and deploying AI applications in the public sector and in
employer-driven recruitment.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Exmeyer, Patrick C</author><author>Hall, Jeremy L</author></authors></contributors><titles><title>High time for a higher-level look at high-technology: Plotting a course
for managing government information in an age of governance</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>429-434</pages><volume>83</volume><issue>2</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1111/puar.13513</electronic-resource-num><language>English</language><urls/><abstract>For years, scholarly interest in the intersection of government and
technology has overwhelmingly focused on the end-product of technology
capabilities. Recent advancements in computational power have
facilitated breathtaking growth of data analytics, artificial
intelligence (AI), and process automation, sparking considerable
attention by scholars and practitioners alike. However, insight
concerning the technology hardware assets powering emergent applications
in the public sector remains glaringly absent amidst this rapidly
expanding area of research. We position that gaining a greater
understanding of the scope of technology utility in governance requires
exploration of not only the applications or interfaces produced by
technology hardware, but rather the aim of promoting both modernity and
processing capacity of the hardware driving technology in government.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Newman, Joshua</author><author>Mintrom, Michael</author></authors></contributors><titles><title>Mapping the discourse on evidence-based policy, artificial intelligence,
and the ethical practice of policy analysis</title><secondary-title>JOURNAL OF EUROPEAN PUBLIC POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF EUROPEAN PUBLIC POLICY</full-title></periodical><pages>1839-1859</pages><volume>30</volume><issue>9</issue><keywords><keyword>Policy analysis; evidence-based policy; artificial</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/13501763.2023.2193223</electronic-resource-num><language>English</language><urls/><abstract>Scholarship on evidence-based policy, a subset of the policy analysis
literature, largely assumes information is produced and consumed by
humans. However, due to the expansion of artificial intelligence in the
public sector, debates no longer capture the full range concerns. Here,
we derive a typology of arguments on evidence-based policy that performs
two functions: taken separately, the categories serve as directions in
which debates may proceed, in light of advances in technology; taken
together, the categories act as a set of frames through which the use of
evidence in policy making might be understood. Using a case of welfare
fraud detection in the Netherlands, we show how the acknowledgement of
divergent frames can enable a holistic analysis of evidence use in
policy making that considers the ethical issues inherent in automated
data processing. We argue that such an analysis will enhance the
real-world relevance of the evidence-based policy paradigm.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Li, Yiran</author><author>Fan, Yingying</author><author>Nie, Lin</author></authors></contributors><titles><title>Making governance agile: Exploring the role of artificial intelligence
in China's local governance</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>Artificial intelligence; agile governance; governm</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231188229</electronic-resource-num><language>English</language><urls/><abstract>As the key to digital transformation, artificial intelligence is
believed to help achieve the goal of government as a platform and the
agile development of digital services. Yet we know little about its
potential role in local governance, especially the advances that
AI-supported services for the public sector in local governance have
ventured and the public value they have created. Combining the digital
transformation concepts and public value theory, we fill the gap by
examining artificial intelligence (AI) deployment in the public sector
of a pilot city of digital transformation in China. Using a mixed-method
approach, we show how AI configurations facilitate public value creation
in the digital era and identify four dimensions of AI deployment in the
public sector: data integration, policy innovation, smart application,
and collaboration. Our case analysis on these four dimensions
demonstrates two roles that AI technology plays in local
governance-''AI cage'' and ``AI colleague.'' The former builds the
technology infrastructure and platform in each stage of service
delivery, regulating the behaviors of frontline workers, while the
latter helps frontline workers make decisions, thus improving the
agility of public service provision.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Maragno, Giulia</author><author>Tangi, Luca</author><author>Gastaldi, Luca</author><author>Benedetti, Michele</author></authors></contributors><titles><title>Exploring the factors, affordances and constraints outlining the
implementation of Artificial Intelligence in public sector organizations</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>73</volume><keywords><keyword>Artificial Intelligence; Public Sector Organizatio</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2023.102686</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) is viewed as having great potential for the
public sector to improve the management of internal activities and the
delivery of public services. However, realizing its potential depends on
the proper implementation of the technology, which is characterized by
unique factors, that afford or constrain its use. What these factors are
and how they affect AI implementation is still poorly understood, and
scholars call for studies to add empirical evidence to the existing
knowledge. This study relies on a case study methodology and, by
adopting an abductive approach, applies a double theoretical
perspective: the Technology-OrganizationEnvironment (TOE) framework and
the Technology Affordances and Constraints Theory (TACT). Drawing on
these combined lenses, we develop a conceptual framework that extends
previous studies by showing how AI implementation is the result of a
combination of contextual factors that are deeply interrelated and,
specifically, how AI-related factors bring new affordances and
constraints to the application domain.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van Noordt, Colin</author><author>Tangi, Luca</author></authors></contributors><titles><title>The dynamics of AI capability and its influence on public value creation
of AI within public administration</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>40</volume><issue>4</issue><keywords><keyword>Artificial intelligence; AI-capability; Digital go</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.giq.2023.101860</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) technologies in public administration are
gaining increasing attention due to the potential benefits they can
provide in improving governmental operations. However, translating
technological opportunities into concrete public value for public
administrations is still limited. One of the factors hindering this
progress is the lack of AI capability within public organisations. The
research found that various components of AI capability are essential
for successfully developing and using AI technologies, including
tangible, intangible, and human-related factors. There is a distinction
between the AI capability to develop and the AI capability to implement
AI technologies, with more administrations capable of the former but
finding difficulties in the latter. A lack of in-house technical
expertise to maintain and update the AI systems, legal challenges in
deploying developed AI systems, and the capability to introduce changes
in the organisation to ensure the system remains operational and used by
relevant end-users are among the most critical limiting factors for
long-term use of AI by public administrations. The research underlines
the strong complementarity between historical eGovernment developments
and the capability to deploy AI technologies. The study suggests that
funding alone may not be enough to acquire AI capability, and public
administrations need to focus on both the capability to develop and
implement AI technologies. The research emphasizes that human skillsets,
both technical and non-technical, are essential for the successful
implementation of AI in public administration.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ingrams, Alex</author></authors></contributors><titles><title>Big Data and Dahl's Challenge of Democratic Governance</title><secondary-title>REVIEW OF POLICY RESEARCH</secondary-title></titles><periodical><full-title>REVIEW OF POLICY RESEARCH</full-title></periodical><pages>357-377</pages><volume>36</volume><issue>3</issue><keywords><keyword>Internet; e-governance; governance; ICTs; Media</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1111/ropr.12331</electronic-resource-num><language>English</language><urls/><abstract>Big data applications have been acclaimed as potentially transformative
for the public sector. But, despite this acclaim, most theory of big
data is narrowly focused around technocratic goals. The conceptual
frameworks that situate big data within democratic governance systems
recognizing the role of citizens are still missing. This paper explores
the democratic governance impacts of big data in three policy areas
using Robert Dahl's dimensions of control and autonomy. Key impacts and
potential tensions are highlighted. There is evidence of impacts on both
dimensions, but the dimensions conflict as well as align in notable ways
and focused policy efforts will be needed to find a balance.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cobbe, Jennifer</author><author>Singh, Jatinder</author></authors></contributors><titles><title>Reviewable Automated Decision-Making</title><secondary-title>COMPUTER LAW &amp; SECURITY REVIEW</secondary-title></titles><periodical><full-title>COMPUTER LAW &amp; SECURITY REVIEW</full-title></periodical><volume>39</volume><keywords><keyword>automated decision-making; accountable systems; re</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.clsr.2020.105475</electronic-resource-num><language>English</language><urls/><abstract>In this paper we introduce the concept of `reviewability' as an
alternative approach to im-proving the accountability of automated
decision-making that involves machine learning systems. In doing so, we
draw on an understanding of automated decision-making as a
socio-technical process, involving both human (organisational) and
technical components, beginning before a decision is made and extending
beyond the decision itself. Although explanations for automated
decisions may be useful in some contexts, they focus more narrowly on
the model and therefore do not provide the information about that
process as a whole that is necessary for many aspects of accountability,
regulatory oversight, and assessments for legal compliance. Drawing on
previous work on the application of administrative law and judicial
review mechanisms to automated decision-making in the public sector, we
argue that breaking down the automated decision-making process into its
technical and organisational components allows us to consider how
appropriate record-keeping and logging mechanisms implemented at each
stage of that process would allow for the process as a whole to be
reviewed. Although significant research is needed to explore how it can
be implemented, we argue that a reviewability framework potentially
offers for a more useful and more holistic form of accountability for
automated decision-making than approaches focused more narrowly on
explanations. (C) 2020 Jennifer Cobbe and Jatinder Singh. Published by
Elsevier Ltd. All rights reserved.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Adamczyk, Willian Boschetti</author><author>Monasterio, Leonardo</author><author>Fochezatto, Adelar</author></authors></contributors><titles><title>Automation in the future of public sector employment: the case of
Brazilian Federal Government</title><secondary-title>TECHNOLOGY IN SOCIETY</secondary-title></titles><periodical><full-title>TECHNOLOGY IN SOCIETY</full-title></periodical><volume>67</volume><keywords><keyword>Automation; Machine learning; Public sector</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.techsoc.2021.101722</electronic-resource-num><language>English</language><urls/><abstract>What is the impact of automation on public sector employment? Using
machine learning and natural language processing algorithms, this study
estimates which occupations and agencies of the Brazilian Federal
Government are most susceptible to automation. We contribute to the
literature by introducing Bartik Occupational Tasks (BOT), an objective
method used to estimate automation susceptibility that avoids subjective
or ad hoc classifications. We show that approximately 20% of Brazilian
public sector employees work in jobs with a high potential of automation
in the coming decades. Government occupations with lower schooling and
lower salary levels are most susceptible to future automation.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ghorbany, Siavash</author><author>Yousefi, Saied</author><author>Noorzai, Esmatullah</author></authors></contributors><titles><title>Evaluating and optimizing performance of public-private partnership
projects using copula Bayesian network</title><secondary-title>ENGINEERING CONSTRUCTION AND ARCHITECTURAL MANAGEMENT</secondary-title></titles><periodical><full-title>ENGINEERING CONSTRUCTION AND ARCHITECTURAL MANAGEMENT</full-title></periodical><pages>290-323</pages><volume>31</volume><issue>1</issue><keywords><keyword>Project management; Integration; Optimization</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1108/ECAM-05-2022-0492</electronic-resource-num><language>English</language><urls/><abstract>Purpose Being an efficient mechanism for the value of money,
public-private partnership (PPP) is one of the most prominent approaches
for infrastructure construction. Hence, many controversies about the
performance effectiveness of these delivery systems have been debated.
This research aims to develop a novel performance management perspective
by revealing the causal effect of key performance indicators (KPIs) on
PPP infrastructures. Design/methodology/approach The literature review
was used in this study to extract the PPPs KPIs. Experts' judgment and
interviews, as well as questionnaires, were designed to obtain data.
Copula Bayesian network (CBN) has been selected to achieve the research
purpose. CBN is one of the most potent tools in statistics for analyzing
the causal relationship of different elements and considering their
quantitive impact on each other. By utilizing this technique and using
Python as one of the best programming languages, this research used
machine learning methods, SHAP and XGBoost, to optimize the network.
Findings The sensitivity analysis of the KPIs verified the causation
importance in PPPs performance management. This study determined the
causal structure of KPIs in PPP projects, assessed each indicator's
priority to performance, and found 7 of them as a critical cluster to
optimize the network. These KPIs include innovation for financing,
feasibility study, macro-environment impact, appropriate financing
option, risk identification, allocation, sharing, and transfer, finance
infrastructure, and compliance with the legal and regulatory framework.
Practical implications Identifying the most scenic indicators helps the
private sector to allocate the limited resources more rationally and
concentrate on the most influential parts of the project. It also
provides the KPIs' critical cluster that should be controlled and
monitored closely by PPP project managers. Additionally, the public
sector can evaluate the performance of the private sector more
accurately. Finally, this research provides a comprehensive causal
insight into the PPPs' performance management that can be used to
develop management systems in future research. Originality/value For the
first time, this research proposes a model to determine the causal
structure of KPIs in PPPs and indicate the importance of this insight.
The developed innovative model identifies the KPIs' behavior and takes a
non-linear approach based on CBN and machine learning methods while
providing valuable information for construction and performance managers
to allocate resources more efficiently.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Selten, Friso</author><author>Klievink, Bram</author></authors></contributors><titles><title>Organizing public sector AI adoption: Navigating between separation and
integration</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Artificial intelligence; Public sector; Management</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2023.101885</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Selten, Klievink - GOVERNMENT INFORMATION QUARTERLY(2).pdf</url></pdf-urls></urls><abstract>Artificial Intelligence (AI) has the potential to improve public
governance, but the use of AI in public organizations remains limited.
In this qualitative study, we explore how public organizations
strategically manage the adoption of AI. Managing AI adoption in the
public sector is complex because of the inherent tension between public
organizations' identity, characterized by formal and rigid structures,
and the demands of AI innovation that require experimentation and
flexibility. Our findings show that public organizations navigate this
tension either by creating separate departments for data science teams,
or by integrating data science teams into already existing operational
departments. The case studies reveal that separation improves the
technical expertise and capabilities of the organization, whereas
integration improves the alignment between AI and primary processes. The
findings also show that both approaches are characterized by different
AI adoption barriers. We empirically identify the processes and routines
public organizations develop to overcome these barriers.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schuelke-Leech, Beth-Anne</author><author>Jordan, Sara R</author><author>Barry, Betsy</author></authors></contributors><titles><title>Regulating Autonomy: An Assessment of Policy Language for Highly
Automated Vehicles Palabras clave</title><secondary-title>REVIEW OF POLICY RESEARCH</secondary-title></titles><periodical><full-title>REVIEW OF POLICY RESEARCH</full-title></periodical><pages>547-579</pages><volume>36</volume><issue>4</issue><keywords><keyword>highly automated vehicles; autonomous vehicles; dr</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1111/ropr.12332</electronic-resource-num><language>English</language><urls/><abstract>Self-driving cars (also known as driverless cars, autonomous vehicles,
and highly automated vehicles [HAVs]) will change the regulatory,
political, and ethical frameworks surrounding motor vehicles. At the
highest levels of automation, HAVs are operated by independent machine
agents, making decisions without the direct intervention of humans. The
current transportation system assumes human intervention though,
including legal and moral responsibilities of human operators. Has the
development of these artificial intelligence (AI) and autonomous system
(AS) technologies outpaced the ethical and political conversations? This
paper examines discussions of HAVs, driver responsibility, and
technology failure to highlight the differences between how the
policy-making institutions in the United States (Congress and the Public
Administration) and technology and transportation experts are or are not
speaking about responsibility in the context of autonomous systems
technologies. We report findings from a big data analysis of
corpus-level documents to find that enthusiasm for HAVs has outpaced
other discussions of the technology.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dunleavy, Patrick</author><author>Margetts, Helen</author></authors></contributors><titles><title>Data science, artificial intelligence and the third wave of digital era
governance</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>administrative organization and structures; govern</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231198737</electronic-resource-num><language>English</language><urls/><abstract>This article examines the model of digital era governance (DEG) in the
light of the latest-wave of data-driven technologies, such as data
science methodologies and artificial intelligence (labelled here DSAI).
It identifies four key top-level macro-themes through which digital
changes in response to these developments may be investigated. First,
the capability to store and analyse large quantities of digital data
obviates the need for data `compression' that characterises
Weberian-model bureaucracies, and facilitates data de-compression in
data-intensive information regimes, where the capabilities of public
agencies and civil society are both enhanced. Second, the increasing
capability of robotic devices have expanded the range of tasks that
machines extending or substituting workers' capabilities can perform,
with implications for a reshaping of state organisation. Third, DSAI
technologies allow new options for partitioning state functions in ways
that can maximise organisational productivity, in an `intelligent
centre, devolved delivery' model within vertical policy sectors. Fourth,
within each tier of government, DSAI technologies offer new
possibilities for `administrative holism' - the horizontal allocation of
power and functions between organisations, through state integration,
common capacity and needs-based joining-up of services. Together, these
four themes comprise a third wave of DEG changes, suggesting important
administrative choices to be made regarding information regimes, state
organisation, functional allocation and outsourcing arrangements, as
well as a long-term research agenda for public administration, requiring
extensive and detailed analysis.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Broomfield, Heather</author><author>Reutter, Lisa</author></authors></contributors><titles><title>In search of the citizen in the datafication of public administration</title><secondary-title>BIG DATA &amp; SOCIETY</secondary-title></titles><periodical><full-title>BIG DATA &amp; SOCIETY</full-title></periodical><volume>9</volume><issue>1</issue><keywords><keyword>Public administration; datafication; citizen parti</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/20539517221089302</electronic-resource-num><language>English</language><urls/><abstract>The administrative reform of the datafied public administration places
great emphasis on the classification, control, and prediction of citizen
behavior and therefore has the potential to significantly impact
citizen-state relations. There is a growing body of literature on
data-oriented activism which aims to resist and counteract existing
harmful data practices. However, little is known about the processes,
policies, and political-economic structures that make datafication
possible. There is a distinct research gap on situated and
context-specific empirical research, which critically interrogates the
premises, interests, and agendas of data-driven public administration
and how stakeholders can impact them. This paper therefore studies the
conditions of participation in public administration datafication. It
asks the overall research question of how citizens are problematized and
included in policy and practitioner discourse in the datafication of
public administration. The paper takes Norway as its case and applies
Cardullo and Kitchin's scaffold of smart citizen participation at the
system level. It makes use of a unique empirical insight into the field,
consisting of a survey, interviews, and an extensive document analysis.
Unexpectedly, we find that citizens and civil society are rarely engaged
in this administrative reform. Instead, we identify a paternalistic,
top-down, technocratic approach where the context, values, and agendas
of datafication are obscured from the citizen.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Scutella, Maryanne</author><author>Plewa, Carolin</author><author>Reaiche, Carmen</author></authors></contributors><titles><title>Virtual agents in the public service: examining citizens' value-in-use</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>73-88</pages><volume>26</volume><issue>1</issue><keywords><keyword>virtual agent; value-in-use; value co-creation; e-</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/14719037.2022.2044504</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Scutella, Plewa, Reaiche - PUBLIC MANAGEMENT REVIEW.pdf</url></pdf-urls></urls><abstract>The importance of today's public sector delivering citizen-centric
services enabled by technology is well recognized. To deliver such
services, the public sector is turning to artificial intelligence, and
in particular virtual agents (VA). This research examines how citizens
gain value from interacting with VAs in a public sector setting. Through
empirical research, utilizing transcripts from citizens' interactions
with a VA, four dimensions of value-in-use were identified. This adds to
the theoretical body of knowledge on value co-creation in public service
settings and provides practical insights into how citizens use VAs and
possible avenues for future investment and improvements.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cheong, So-Min</author><author>Sankaran, Kris</author><author>Bastani, Hamsa</author></authors></contributors><titles><title>Artificial intelligence for climate change adaptation</title><secondary-title>WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY</secondary-title></titles><periodical><full-title>WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY</full-title></periodical><volume>12</volume><issue>5</issue><keywords><keyword>AI; climate change adaptation; machine learning</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1002/widm.1459</electronic-resource-num><language>English</language><urls/><abstract>Although artificial intelligence (AI; inclusive of machine learning) is
gaining traction supporting climate change projections and impacts,
limited work has used AI to address climate change adaptation. We
identify this gap and highlight the value of AI especially in supporting
complex adaptation choices and implementation. We illustrate how AI can
effectively leverage precise, real-time information in data-scarce
settings. We focus on supervised learning, transfer learning,
reinforcement learning, and multimodal learning to illustrate how
innovative AI methods can enable better-informed choices, tailor
adaptation measures to heterogenous groups and generate effective
synergies and trade-offs. This article is categorized under: Application
Areas &gt; Government and Public Sector</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kowalski, Radoslaw</author><author>Esteve, Marc</author><author>Mikhaylov, Slava Jankin</author></authors></contributors><titles><title>Improving public services by mining citizen feedback: An application of
natural language processing</title><secondary-title>PUBLIC ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION</full-title></periodical><pages>1011-1026</pages><volume>98</volume><issue>4</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1111/padm.12656</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2020 - Kowalski, Esteve, Mikhaylov - PUBLIC ADMINISTRATION.pdf</url></pdf-urls></urls><abstract>Research on user satisfaction has increased substantially in recent
years. To date, most studies have tested the significance of predefined
factors thought to influence user satisfaction, with no scalable means
of verifying the validity of their assumptions. Digital technology has
created new methods of collecting user feedback where service users post
comments. As topic models can analyse large volumes of feedback, they
have been proposed as a feasible approach to aggregating user opinions.
This novel approach has been applied to process reviews of primary care
practices in England. Findings from an analysis of more than 200,000
reviews show that the quality of interactions with staff and
bureaucratic exigencies are the key drivers of user satisfaction. In
addition, patient satisfaction is strongly influenced by factors that
are not measured by state-of-the-art patient surveys. These results
highlight the potential benefits of text mining and machine learning for
public administration.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>James, Alexandra</author><author>Whelan, Andrew</author></authors></contributors><titles><title>`Ethical' artificial intelligence in the welfare state: Discourse and
discrepancy in Australian social services</title><secondary-title>CRITICAL SOCIAL POLICY</secondary-title></titles><periodical><full-title>CRITICAL SOCIAL POLICY</full-title></periodical><pages>22-42</pages><volume>42</volume><issue>1</issue><keywords><keyword>artificial intelligence; ethical artificial intell</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/0261018320985463</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - James, Whelan - CRITICAL SOCIAL POLICY.pdf</url></pdf-urls></urls><abstract>In recent years, a discourse of `ethical artificial intelligence' has
emerged and gained international traction in response to widely
publicised AI failures. In Australia, the discourse around ethical AI
does not accord with the reality of AI deployment in the public sector.
Drawing on institutional ethnographic approaches, this paper describes
the misalignments between how technology is described in government
documentation, and how it is deployed in social service delivery. We
argue that the propagation of ethical principles legitimates established
new public management strategies, and pre-empts questions regarding the
efficacy of AI development; instead positioning implementation as
inevitable and, provided an ethical framework is adopted, laudable. The
ethical AI discourse acknowledges, and ostensibly seeks to move past,
widely reported administrative failures involving new technologies. In
actuality, this discourse works to make AI implementation a reality,
ethical or not.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kempeneer, Shirley</author></authors></contributors><titles><title>A big data state of mind: Epistemological challenges to accountability
and transparency in data-driven regulation</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>38</volume><issue>3</issue><keywords><keyword>Big data; Transparency; Accountable AI; Epistemolo</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.giq.2021.101578</electronic-resource-num><language>English</language><urls/><abstract>In a sense, the 2008 financial crisis was a crisis of theory.
Regulators, banks, and financial markets all had encompassing
theoretical models about how the economy worked, but they all failed to
predict the looming crisis. As such, regulators increasingly turn to big
data to understand banks' health. Despite the prominence of big data in
society, its use in the public sector remains grossly understudied. This
paper explores the regulatory use of big data in the case of the EU-wide
banking stress test, a key regulatory indicator. The paper draws on
interviews with supervisors at the European Central Bank (ECB), European
Banking Authority (EBA) and National Bank of Belgium (NBB), as well as
with consultants and risk directors in Belgian banks, to explain how big
data-driven regulation affects the relationship between regulators and
regulated entities. It draws particular attention to the epistemological
component of using large data sets in decision-making: a big data state
of mind. The article more specifically shows how the underlying
epistemology, rather than simply the bigness of datasets, affects the
relationship between regulators and regulated entities, and the
regulatory process at large. The paper concludes that regulators' big
data state of mind calls for new practical and legal guidelines
regarding the validity of data-driven knowledge claims. Moreover, it
shows how accountability based on descriptive transparency no longer
makes sense in the `age of the algorithm', suggesting a shift towards
relational transparency and joint knowledge production.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dickinson, Helen</author><author>Yates, Sophie</author></authors></contributors><titles><title>From external provision to technological outsourcing: lessons for public
sector automation from the outsourcing literature</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>243-261</pages><volume>25</volume><issue>2</issue><keywords><keyword>Automation; artificial intelligence; robotics; out</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/14719037.2021.1972681</electronic-resource-num><language>English</language><urls/><abstract>Automation is not new, but the possibilities for automation have been
significantly expanded in recent years through advancements in
artificial intelligence. Such technologies may drive some improvements,
although they are not without risk and we lack a solid evidence base to
suggest the implications of these changes. Framing AI supported
automation as `technological outsourcing', we draw on the
well-established outsourcing literature to derive lessons about the
possible implications of public sector automation and outline some
principles that agencies can use to assist in their decision-making
about whether to invest in automation of particular processes.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Coulthart, Stephen</author><author>Riccucci, Ryan</author></authors></contributors><titles><title>Putting Big Data to Work in Government: The Case of the United States
Border Patrol</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>280-289</pages><volume>82</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1111/puar.13431</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Coulthart, Riccucci - PUBLIC ADMINISTRATION REVIEW.pdf</url></pdf-urls></urls><abstract>Investigating how the public sector adopts technologies to process and
analyze very large datasets is crucial for understanding governance in
the digital age. The authors of this article examine a large government
agency, the United States Border Patrol (USBP), an organization that is
in the early phases of building big data capabilities. They argue the
wide-scale adoption of big data analytics will require trial-and-error
processes coordinated by organizational leadership in partnership with
front-line employees who make the technology relevant to their needs in
the field. Absent engagement from both levels, organizations like USBP
that face significant barriers to adoption (e.g., limited data science
expertise) will struggle to leverage data at scale. The authors also
extend the literature on big data in the public sector and provide a
rich description of how factors, such as organizational leadership and
resources, impact the innovation process.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mergel, Ines</author><author>Dickinson, Helen</author><author>Stenvall, Jari</author><author>Gasco, Mila</author></authors></contributors><titles><title>Implementing AI in the public sector</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><keywords><keyword>Artificial intelligence (AI); implementation of te</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/14719037.2023.2231950</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has advanced as one of the most prominent
technological innovations to push the conversation about the digital
transformation of the public sector forward. This special issue focuses
on actual implementation approaches or challenges that public managers
are facing while they fulfil new policy that asks for the implementation
of AI in public administrations. In addition to assessing the
contributions of papers in this issue, we also provide a research agenda
on how future research can fill some of the methodological, theoretical,
and application gaps in the public management literature.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Desiere, Sam</author><author>Struyven, Ludo</author></authors></contributors><titles><title>Using Artificial Intelligence to classify Jobseekers: The
Accuracy-Equity Trade-off</title><secondary-title>JOURNAL OF SOCIAL POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF SOCIAL POLICY</full-title></periodical><pages>367-385</pages><volume>50</volume><issue>2</issue><keywords><keyword>profiling; statistical discrimination; public empl</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1017/S0047279420000203</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) is increasingly popular in the public
sector to improve the cost-efficiency of service delivery. One example
is AI-based profiling models in public employment services (PES), which
predict a jobseeker's probability of finding work and are used to
segment jobseekers in groups. Profiling models hold the potential to
improve identification of jobseekers at-risk of becoming long-term
unemployed, but also induce discrimination. Using a recently developed
AI-based profiling model of the Flemish PES, we assess to what extent
AI-based profiling `discriminates' against jobseekers of foreign origin
compared to traditional rule-based profiling approaches. At a maximum
level of accuracy, jobseekers of foreign origin who ultimately find a
job are 2.6 times more likely to be misclassified as `high-risk'
jobseekers. We argue that it is critical that policymakers and
caseworkers understand the inherent trade-offs of profiling models, and
consider the limitations when integrating these models in daily
operations. We develop a graphical tool to visualize the accuracy-equity
trade-off in order to facilitate policy discussions.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nitzberg, Mark</author><author>Zysman, John</author></authors></contributors><titles><title>Algorithms, data, and platforms: the diverse challenges of governing AI</title><secondary-title>JOURNAL OF EUROPEAN PUBLIC POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF EUROPEAN PUBLIC POLICY</full-title></periodical><pages>1753-1778</pages><volume>29</volume><issue>11, SI</issue><keywords><keyword>Artificial intelligence; AI governance; AI regulat</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1080/13501763.2022.2096668</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) poses a set of interwoven challenges. A new
general purpose technology likened to steam power or electricity, AI
must first be clearly defined before considering its global governance.
In this context, a useful definition is technology that uses advanced
computation to perform at human cognitive capacity in some task area.
Like electricity, AI cannot be governed in isolation, but in the context
of a broader digital technology toolbox. Establishing national and
community priorities on how to reap AI's benefits, while managing its
social and economic risks, will be an evolving debate. A fundamental
driver of the development and deployment of AI tools, of the algorithms
and data, are the dominant Digital Platform Firms (DPFs). Unless
specifically regulated, DPF's set de facto rules for use of data and
algorithms. That can shift the borderline between public and private,
and result in priorities that differ from those of the public sector or
civil society. Governance of AI and the toolbox is a critical component
of national success in the coming decades, as governments recognize
opportunities and geopolitical risks posed by the suite of technologies.
However, AI pries open a Pandora's box of questions that sweep across
the economy and society engaging diverse communities. Rather than strive
towards global agreement on a single set of market and social rules, one
must consider how to pursue objectives of interoperability amongst
nations with quite different political economies. Even such limited
agreements are complicated following the Russian invasion of Ukraine.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Giest, Sarah N</author><author>Klievink, Bram</author></authors></contributors><titles><title>More than a digital system: how AI is changing the role of bureaucrats
in different organizational contexts</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>379-398</pages><volume>26</volume><issue>2</issue><keywords><keyword>Public decision-making; artificial intelligence; d</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/14719037.2022.2095001</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2024 - Giest, Klievink - PUBLIC MANAGEMENT REVIEW.pdf</url></pdf-urls></urls><abstract>The paper highlights the effects of AI implementation on public sector
innovation. This is explored by asking how AI-driven technologies in
public decision-making in different organizational contexts impacts
innovation in the role definition of bureaucrats. We focus on
organizational as well as agency- and individual-level factors in two
cases: The Dutch Childcare Allowance case and the US Integrated Data
Automated System. We observe administrative process innovation in both
cases where organizational structures and tasks of bureaucrats are
transformed, and in the US case we also find conceptual innovation in
that welfare fraud is addressed by replacing bureaucrats all together.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ingrams, Alex</author></authors></contributors><titles><title>Public Values in the Age of Big Data: A Public Information Perspective</title><secondary-title>POLICY AND INTERNET</secondary-title></titles><periodical><full-title>POLICY AND INTERNET</full-title></periodical><pages>128-148</pages><volume>11</volume><issue>2</issue><keywords><keyword>big data; democracy; public information; public va</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1002/poi3.193</electronic-resource-num><language>English</language><urls/><abstract>Public administration scholars have so far largely viewed big data as a
kind of technocratic transformation. However, through citizens' digital
records, use of service apps, social media, digital sensors, and other
digital footprints, big data also gives policymakers insights into
citizen choices and is therefore potentially supportive of public values
such as participation and openness. Focusing on two underexplored
countries, Germany and the Netherlands, this article develops a public
values framework for big data that considers citizen values alongside
technocratic ones. It takes the particular case of public information
agencies such as ombudsmen and courts of audit, examining the functions
they play and whether they have the capacity to address tensions arising
between technocratic and citizen values. The study finds that, while
capacity does exist, it is heavily tilted toward technocratic values,
with no capacity to address participative values. Finally, five
propositions are advanced, which describe where the tensions lie and
therefore where the attention of public information agencies should best
be focused.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kankanamge, Nayomi</author><author>Yigitcanlar, Tan</author><author>Goonetilleke, Ashantha</author></authors></contributors><titles><title>Public perceptions on artificial intelligence driven disaster
management: Evidence from Sydney, Melbourne and Brisbane</title><secondary-title>TELEMATICS AND INFORMATICS</secondary-title></titles><periodical><full-title>TELEMATICS AND INFORMATICS</full-title></periodical><volume>65</volume><keywords><keyword>artificial intelligence (AI); Disaster management;</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.tele.2021.101729</electronic-resource-num><language>English</language><urls/><abstract>In recent years, artificial intelligence (AI) is being increasingly
utilised in disaster management activities. The public is engaged with
AI in various ways in these activities. For instance, crowdsourcing
applications developed for disaster management to handle the tasks of
collecting data through social media platforms, and increasing disaster
awareness through serious gaming applications. Nonetheless, there are
limited empirical investigations and understanding on public perceptions
concerning AI for disaster management. Bridging this knowledge gap is
the justification for this paper. The methodological approach adopted
involved: Initially, collecting data through an online survey from
residents (n = 605) of three major Australian cities; Then, analysis of
the data using statistical modelling. The analysis results revealed
that: (a) Younger generations have a greater appreciation of
opportunities created by AI-driven applications for disaster management;
(b) People with tertiary education have a greater understanding of the
benefits of AI in managing the pre- and post-disaster phases, and; (c)
Public sector administrative and safety workers, who play a vital role
in managing disasters, place a greater value on the contributions by AI
in disaster management. The study advocates relevant authorities to
consider public perceptions in their efforts in integrating AI in
disaster management.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gallego, Jorge</author><author>Rivero, Gonzalo</author><author>Martinez, Juan</author></authors></contributors><titles><title>Preventing rather than punishing: An early warning model of malfeasance
in public procurement</title><secondary-title>INTERNATIONAL JOURNAL OF FORECASTING</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF FORECASTING</full-title></periodical><pages>360-377</pages><volume>37</volume><issue>1</issue><keywords><keyword>Public procurement; Corruption; Inefficiency; Mach</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijforecast.2020.06.006</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2021 - Gallego, Rivero, Martinez - INTERNATIONAL JOURNAL OF FORECASTING.pdf</url></pdf-urls></urls><abstract>Is it possible to predict malfeasance in public procurement? With the
proliferation of e-procurement systems in the public sector,
anti-corruption agencies and watchdog organizations have access to
valuable sources of information with which to identify transactions that
are likely to become troublesome and why. In this article, we discuss
the promises and challenges of using machine learning models to predict
inefficiency and corruption in public procurement. We illustrate this
approach with a dataset with more than two million public procurement
contracts in Colombia. We trained machine learning models to predict
which of them will result in corruption investigations, a breach of
contract, or implementation inefficiencies. We then discuss how our
models can help practitioners better understand the drivers of
corruption and inefficiency in public procurement. Our approach will be
useful to governments interested in exploiting large administrative
datasets to improve the provision of public goods, and it highlights
some of the tradeoffs and challenges that they might face throughout
this process. (C) 2020 International Institute of Forecasters. Published
by Elsevier B.V. All rights reserved.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wilson, Christopher</author><author>van der Velden, Maja</author></authors></contributors><titles><title>Sustainable AI: An integrated model to guide public sector
decision-making</title><secondary-title>TECHNOLOGY IN SOCIETY</secondary-title></titles><periodical><full-title>TECHNOLOGY IN SOCIETY</full-title></periodical><volume>68</volume><keywords><keyword>Artificial intelligence; Public administration; Su</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.techsoc.2022.101926</electronic-resource-num><language>English</language><urls/><abstract>Ethics, explainability, responsibility, and accountability are important
concepts for questioning the societal impacts of artificial intelligence
and machine learning (AI), but are insufficient to guide the public
sector in regulating and implementing AI. Recent frameworks for AI
governance help to operationalize these by identifying the processes and
layers of governance in which they must be considered, but do not
provide public sector workers with guidance on how they should be
pursued or understood. This analysis explores how the concept of
sustainable AI can help to fill this gap. It does so by reviewing how
the concept has been used by the research community and aligning
research on sustainable development with research on public sector AI.
Doing so identifies the utility of boundary conditions that have been
asserted for social sustainability according to the Framework for
Strategic Sustainable Development, and which are here integrated with
prominent concepts from the discourse on AI and society. This results in
a conceptual model that integrates five boundary conditions to assist
public sector decision-making about how to govern AI: Diversity,
Capacity for learning, Capacity for selforganization Common meaning, and
Trust. These are presented together with practical approaches for their
presentation, and guiding questions to aid public sector workers in
making the decisions that are required by other operational frameworks
for ethical AI.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Yi</author><author>Wu, Mengjia</author><author>Tian, George Yijun</author><author>Zhang Guangquan
and Lu, Jie</author></authors></contributors><titles><title>Ethics and privacy of artificial intelligence: Understandings from
bibliometrics</title><secondary-title>KNOWLEDGE-BASED SYSTEMS</secondary-title></titles><periodical><full-title>KNOWLEDGE-BASED SYSTEMS</full-title></periodical><volume>222</volume><keywords><keyword>Artificial intelligence; Ethics; Privacy; Bibliome</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.knosys.2021.106994</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) and its broad applications are disruptively
transforming the daily lives of human beings and a discussion of the
ethical and privacy issues surrounding AI is a topic of growing
interest, not only among academics but also the general public This
review identifies the key entities (i.e., leading research institutions
and their affiliated countries/regions, core research journals, and
communities) that contribute to the research on the ethical and privacy
issues in relation to AI and their intersections using co-occurrence
analysis. Topic analyses profile the topical landscape of AI ethics
using a topical hierarchical tree and the changing interest of society
in AI ethics over time through scientific evolutionary pathways. We also
paired 15 selected AI techniques with 17 major ethical issues and
identify emerging ethical issues from a core set of the most recent
articles published in Nature, Science, and Proceedings of the National
Science Academy of the United States. These insights bridging the
knowledge base of AI techniques and ethical issues in the literature,
are of interest to the AI community and audiences in science policy,
technology management, and public administration. (C) 2021 Elsevier B.V.
All rights reserved.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hartmann, Kathrin</author><author>Wenzelburger, Georg</author></authors></contributors><titles><title>Uncertainty, risk and the use of algorithms in policy decisions: a case
study on criminal justice in the USA</title><secondary-title>POLICY SCIENCES</secondary-title></titles><periodical><full-title>POLICY SCIENCES</full-title></periodical><pages>269-287</pages><volume>54</volume><issue>2</issue><keywords><keyword>Artificial intelligence; Big data; Public policy;</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1007/s11077-020-09414-y</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2021 - Hartmann, Wenzelburger - POLICY SCIENCES.pdf</url></pdf-urls></urls><abstract>Algorithms are increasingly used in different domains of public policy.
They help humans to profile unemployed, support administrations to
detect tax fraud and give recidivism risk scores that judges or criminal
justice managers take into account when they make bail decisions. In
recent years, critics have increasingly pointed to ethical challenges of
these tools and emphasized problems of discrimination, opaqueness or
accountability, and computer scientists have proposed technical
solutions to these issues. In contrast to these important debates, the
literature on how these tools are implemented in the actual everyday
decision-making process has remained cursory. This is problematic
because the consequences of ADM systems are at least as dependent on the
implementation in an actual decision-making context as on their
technical features. In this study, we show how the introduction of risk
assessment tools in the criminal justice sector on the local level in
the USA has deeply transformed the decision-making process. We argue
that this is mainly due to the fact that the evidence generated by the
algorithm introduces a notion of statistical prediction to a situation
which was dominated by fundamental uncertainty about the outcome before.
While this expectation is supported by the case study evidence, the
possibility to shift blame to the algorithm does seem much less
important to the criminal justice actors.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gesk, Tanja Sophie</author><author>Leyer, Michael</author></authors></contributors><titles><title>Artificial intelligence in public services: When and why citizens accept
its usage</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Artificial intelligence; Public services; Acceptan</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101704</electronic-resource-num><language>English</language><urls/><abstract>Interest in implementing artificial intelligence (AI)-based software in
the public sector is growing. First implementations and research in
individual public services have already been carried out; however, a
better understanding of citizens' acceptance of this technology is
missing in the public sector, as insights from the private sector cannot
be transferred directly. For this purpose, we conduct policy-capturing
experiments to analyze AI's acceptance in six representative scenarios.
Based on behavioral reasoning theory, we gather evidence from 329
participants. The results show that AI solutions in general public
services are preferred over those provided by humans, but specific
services are still a human domain. Further analyses show that the major
drivers toward acceptance are the reasons against AI. The results
contribute to understanding of when and why AI is accepted in public
services. Public administration can use the results to identify AI-based
software to invest in and communicate their usage to perceive such
investments' high acceptance rates.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Alshahrani, Albandari</author><author>Dennehy, Denis</author><author>Mantymaki, Matti</author></authors></contributors><titles><title>An attention-based view of AI assimilation in public sector
organizations: The case of Saudi Arabia</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>4</issue><keywords><keyword>Artificial intelligence; Decision making; Attentio</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2021.101617</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Alshahrani, Dennehy, Mantymaki - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>Artificial Intelligence (AI) has been suggested to have transformative
potential for public sector organizations through enabling increased
productivity and novel ways to deliver public services. In order to
materialize the transformative potential of AI, public sector
organizations need to successfully assimilate AI in their operational
activities. However, AI assimilation in the public sector appears to be
fragmented and lagging the private sector, and the phenomena has really
limited attention from academic research community. To address this gap,
we adopt the case study approach to explore three Saudi-Arabian public
sector organizations and analyze the results using the attention-based
view of the organization (ABV) as the theoretical lens. This study
elucidates the challenges related AI assimilation in public sector in
terms of how organizational attention is focused situated and
distributed during the assimilation process. Five key challenges emerged
from the cases studied, namely (i) misalignment between AI and
management decision-making, (ii) tensions with linguistics and national
culture, (iii) developing and implementing AI infrastructure, (iv) data
integrity and sharing, and (v) ethical and governance concerns. The
findings reveal a re-enforcing relationship between the situated
attention and structural distribution of attention that can accelerate
the successful assimilation of AI in public sector organizations.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van Noordt, Colin</author><author>Misuraca, Gianluca</author></authors></contributors><titles><title>Exploratory Insights on Artificial Intelligence for Government in Europe</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><pages>426-444</pages><volume>40</volume><issue>2</issue><keywords><keyword>artificial intelligence; public sector innovation;</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/0894439320980449</electronic-resource-num><language>English</language><urls/><abstract>There is great interest to use artificial intelligence (AI) technologies
to improve government processes and public services. However, the
adoption of technologies has often been challenging for public
administrations. In this article, the adoption of AI in governmental
organizations has been researched as a form of information and
communication technologies (ICT)-enabled governance innovation in the
public sector. Based on findings from three cases of AI adoption in
public sector organizations, this article shows strong similarities
between the antecedents identified in previous academic literature and
the factors contributing to the use of AI in government. The adoption of
AI in government does not solely rely on having high-quality data but is
facilitated by numerous environmental, organizational, and other factors
that are strictly intertwined among each other. To address the specific
nature of AI in government and the complexity of its adoption in the
public sector, we thus propose a framework to provide a comprehensive
overview of the key factors contributing to the successful adoption of
AI systems, going beyond the narrow focus on data, processing power, and
algorithm development often highlighted in the mainstream AI literature
and policy discourse.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Campion, Averill</author><author>Gasco-Hernandez, Mila</author><author>Mikhaylov Slava Jankin
and Esteve, Marc</author></authors></contributors><titles><title>Overcoming the Challenges of Collaboratively Adopting Artificial
Intelligence in the Public Sector</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><pages>462-477</pages><volume>40</volume><issue>2</issue><keywords><keyword>adoption of AI; challenges of AI; organizational r</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/0894439320979953</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Campion, Gasco-Hernandez, Mikhaylov Slava Jankin and Esteve - SOCIAL SCIENCE COMPUTER REVIEW.pdf</url></pdf-urls></urls><abstract>Despite the current popularity of artificial intelligence (AI) and a
steady increase in publications over time, few studies have investigated
AI in public contexts. As a result, assumptions about the drivers,
challenges, and impacts of AI in government are far from conclusive. By
using a case study that involves a large research university in England
and two different county councils in a multiyear collaborative project
around AI, we study the challenges that interorganizational
collaborations face in adopting AI tools and implementing organizational
routines to address them. Our findings reveal the most important
challenges facing such collaborations: a resistance to sharing data due
to privacy and security concerns, insufficient understanding of the
required and available data, a lack of alignment between project
interests and expectations around data sharing, and a lack of engagement
across organizational hierarchy. Organizational routines capable of
overcoming such challenges include working on-site, presenting the
benefits of data sharing, reframing problems, designating joint
appointments and boundary spanners, and connecting participants in the
collaboration at all levels around project design and purpose.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Medaglia, Rony</author><author>Gil-Garcia, J Ramon</author><author>Pardo, Theresa A</author></authors></contributors><titles><title>Artificial Intelligence in Government: Taking Stock and Moving Forward</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><pages>123-140</pages><volume>41</volume><issue>1</issue><keywords><keyword>artificial intelligence; government; public sector</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/08944393211034087</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Medaglia, Gil-Garcia, Pardo - SOCIAL SCIENCE COMPUTER REVIEW.pdf</url></pdf-urls></urls><abstract>The use of artificial intelligence (AI) applications in government is
receiving increasing attention from global research and practice
communities. This article, introducing a Special Issue on Artificial
Intelligence in Government published in the Social Science Computer
Review, presents an overview of some of the main policy initiatives
across the world in relation to AI in government and discusses the state
of the art of existing research. Based on an analysis of current trends
in research and practice, we highlight four areas to be the focus of
future research on AI in government: governance of AI, trustworthy AI,
impact assessment methodologies, and data governance.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Alon-Barkat, Saar</author><author>Busuioc, Madalina</author></authors></contributors><titles><title>Human-AI Interactions in Public Sector Decision Making: ``Automation
Bias'' and ``Selective Adherence'' to Algorithmic Advice</title><secondary-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</full-title></periodical><pages>153-169</pages><volume>33</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1093/jopart/muac007</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Alon-Barkat, Busuioc - JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY.pdf</url></pdf-urls></urls><abstract>Artificial intelligence algorithms are increasingly adopted as
decisional aides by public bodies, with the promise of overcoming biases
of human decision-makers. At the same time, they may introduce new
biases in the human-algorithm interaction. Drawing on psychology and
public administration literatures, we investigate two key biases:
overreliance on algorithmic advice even in the face of ``warning
signals'' from other sources (automation bias), and selective adoption
of algorithmic advice when this corresponds to stereotypes (selective
adherence). We assess these via three experimental studies conducted in
the Netherlands: In study 1 (N = 605), we test automation bias by
exploring participants' adherence to an algorithmic prediction compared
to an equivalent human-expert prediction. We do not find evidence for
automation bias. In study 2 (N = 904), we replicate these findings, and
also test selective adherence. We find a stronger propensity for
adherence when the advice is aligned with group stereotypes, with no
significant differences between algorithmic and human-expert advice. In
study 3 (N = 1,345), we replicate our design with a sample of civil
servants. This study was conducted shortly after a major scandal
involving public authorities' reliance on an algorithm with
discriminatory outcomes (the ``childcare benefits scandal''). The
scandal is itself illustrative of our theory and patterns diagnosed
empirically in our experiment, yet in our study 3, while supporting our
prior findings as to automation bias, we do not find patterns of
selective adherence. We suggest this is driven by bureaucrats' enhanced
awareness of discrimination and algorithmic biases in the aftermath of
the scandal. We discuss the implications of our findings for public
sector decision making in the age of automation. Overall, our study
speaks to potential negative effects of automation of the administrative
state for already vulnerable and disadvantaged citizens.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Guenduez, Ali A</author><author>Mettler, Tobias</author><author>Schedler, Kuno</author></authors></contributors><titles><title>Technological frames in public administration: What do public managers
think of big data?</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>37</volume><issue>1</issue><keywords><keyword>Big data; Technological frame; Public manager; Pub</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.giq.2019.101406</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2020 - Guenduez, Mettler, Schedler - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>Being among the largest creators and gatherers of data in many
countries, public administrations are looking for ways to harness big
data technology. However, the de facto uses of big data in the public
sector remain very limited. Despite numerous studies aiming to clarify
the term big data, for many public managers, it remains unclear what
this technology does and does not offer public administration. Using the
concept of technological frames, we explore the assumptions,
expectations, and understandings that public managers possess in order
to interpret and make sense of big data. We identify nine big data
frames, ranging from inward-oriented technoenthusiasts to
outward-oriented techno-skeptics, each of which characterizes public
managers' specific viewpoints relating to the introduction of big data
in public administrations. Our findings highlight inconsistencies
between different perceptions and reveal widespread skepticism among
public managers, helping better understand why the de facto uses of big
data in the public sector remain very limited.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Asatiani, Aleksandre</author><author>Malo, Pekka</author><author>Nagbol, Per Radberg</author><author>Penttinen, Esko</author><author>Rinta-Kahila, Tapani</author><author>Salovaara, Antti</author></authors></contributors><titles><title>Sociotechnical Envelopment of Artificial Intelligence: An Approach to
Organizational Deployment of Inscrutable Artificial Intelligence Systems</title><secondary-title>JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS</secondary-title></titles><periodical><full-title>JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS</full-title></periodical><pages>325-352</pages><volume>22</volume><issue>2</issue><keywords><keyword>Artificial Intelligence; Explainable AI; XAI; Enve</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.17705/1jais.00664</electronic-resource-num><language>English</language><urls/><abstract>The paper presents an approach for implementing inscrutable (i.e.,
nonexplainable) artificial intelligence (AI) such as neural networks in
an accountable and safe manner in organizational settings. Drawing on an
exploratory case study and the recently proposed concept of envelopment,
it describes a case of an organization successfully ``enveloping'' its
AI solutions to balance the performance benefits of flexible AI models
with the risks that inscrutable models can entail. The authors present
several envelopment methods-establishing clear boundaries within which
the AI is to interact with its surroundings, choosing and curating the
training data well, and appropriately managing input and output
sources-alongside their influence on the choice of AI models within the
organization. This work makes two key contributions: It introduces the
concept of sociotechnical envelopment by demonstrating the ways in which
an organization's successful AI envelopment depends on the interaction
of social and technical factors, thus extending the literature's focus
beyond mere technical issues. Secondly, the empirical examples
illustrate how operationalizing a sociotechnical envelopment enables an
organization to manage the trade-off between low explainability and high
performance presented by inscrutable models. These contributions pave
the way for more responsible, accountable AI implementations in
organizations, whereby humans can gain better control of even
inscrutable machine-learning models.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zekic-Susac, Marijana</author><author>Has, Adela</author><author>Knezevic, Marinela</author></authors></contributors><titles><title>Predicting energy cost of public buildings by artificial neural
networks, CART, and random forest</title><secondary-title>NEUROCOMPUTING</secondary-title></titles><periodical><full-title>NEUROCOMPUTING</full-title></periodical><pages>223-233</pages><volume>439</volume><keywords><keyword>Energy cost; Machine learning; Neural networks; Pu</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.neucom.2020.01.124</electronic-resource-num><language>English</language><urls/><abstract>The paper deals with modeling the cost of energy consumed in public
buildings by leveraging three machine learning methods: artificial
neural networks, CART, and random forest regression trees. Energy
consumption is one of the major issues in global and national policies,
therefore scientific efforts in creating prediction models of energy
consumption and cost are highly important. One of the largest energy
consumers in every state is its public sector, consisting of
educational, health, public administration, military, and other types of
public buildings. Recent technologies based on sensor networks and Big
data platforms enable collection of large amounts of data that could be
used to analyze energy consumption and cost. A real data from Croatian
public sector is used in this paper including a large number of
constructional, energetic, occupational, climate and other attributes.
The algorithms for data pre-processing and modeling by optimizing
parameters are suggested. Three strategies were tested: (1) with all
available variables, (2) with a filter-based variable selection, and (3)
with a wrapper-based variable selection which integrates Boruta
algorithm and random forest. Prediction models of energy cost are
created using two approaches: (a) comparative usage of artificial neural
networks and two types of regression trees, CART and random forest, and
(b) integration of RF-Boruta variable selection and machine learning
methods for prediction. A cross-validation procedure was used to
optimize the artificial neural network and regression tree topology, as
well to select the most appropriate activation function. Along with
creating a prediction model, the aim of the paper was also to extract
the relevant predictors of energy cost in public buildings which are
important in planning the construction or renovation of buildings. The
results have shown that the second approach which integrates machine
learning with Boruta method, where the random forest algorithm is used
for both variable reduction and prediction modeling, has produced a
higher accuracy of prediction than the individual usage of three machine
learning methods. Such findings confirm the potential of hybrid machine
learning methods which are suggested in previous research, but in favor
of random forest method over CART and artificial neural networks.
Regarding the variable selection, the model has extracted heating and
occupational data as the most important, followed by constructional,
cooling, electricity, and lighting attributes. The model could be
implemented in public buildings information systems and their IoT
networks within the concept of smart buildings and smart cities. ? 2021
Elsevier B.V. All rights reserved.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van Noordt, Colin</author><author>Misuraca, Gianluca</author></authors></contributors><titles><title>Artificial intelligence for the public sector: results of landscaping
the use of AI in government across the European Union</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Artificial intelligence; Public administration; Pu</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101714</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence is increasingly being used by public sector
organisations. Previous research highlighted that the use of AI
technologies in government could improve policy making processes, public
service delivery and the internal management of public administrations.
In this article, we explore to which extent the use of AI in the public
sector impacts these core governance functions. Findings from the review
of a sample of 250 cases across the European Union, show that AI is used
mainly to support improving public service delivery, followed by
enhancing internal management and only in a limited number assist
directly or indirectly policy decision-making. The analysis suggests
that different types of AI technologies and applications are used in
different governance functions, highlighting the need to further
in-depth investigation to better understand the role and impact of use
in what is being defined the governance ``of, with and by AI''.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Anastasopoulos, L Jason</author><author>Whitford, Andrew B</author></authors></contributors><titles><title>Machine Learning for Public Administration Research, With Application to
Organizational Reputation</title><secondary-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</full-title></periodical><pages>491-510</pages><volume>29</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1093/jopart/muy060</electronic-resource-num><language>English</language><urls/><abstract>Machine learning (ML) methods have gained a great deal of popularity in
recent years among public administration scholars and practitioners.
These techniques open the door to the analysis of text, image and other
types of data that allow us to test foundational theories of public
administration and to develop new theories. Despite the excitement
surrounding ML methods, clarity regarding their proper use and potential
pitfalls is lacking. This article attempts to fill this gap in the
literature through providing an ML ``guide to practice'' for public
administration scholars and practitioners. Here, we take a foundational
view of ML and describe how these methods can enrich public
administration research and practice through their ability develop new
measures, tap into new sources of data and conduct statistical inference
and causal inference in a principled manner. We then turn our attention
to the pitfalls of using these methods such as unvalidated measures and
lack of interpretability. Finally, we demonstrate how ML techniques can
help us learn about organizational reputation in federal agencies
through an illustrated example using tweets from 13 executive federal
agencies. All R code, analyses, and data described in this article can
be found in the Supplementary Appendix.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Neumann, Oliver</author><author>Guirguis, Katharina</author><author>Steiner, Reto</author></authors></contributors><titles><title>Exploring artificial intelligence adoption in public organizations: a
comparative case study</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>114-141</pages><volume>26</volume><issue>1</issue><keywords><keyword>Artificial intelligence; AI; public organizations;</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/14719037.2022.2048685</electronic-resource-num><language>English</language><urls/><abstract>Despite the enormous potential of artificial intelligence (AI), many
public organizations struggle to adopt this technology. Simultaneously,
empirical research on what determines successful AI adoption in public
settings remains scarce. Using the technology organization environment
(TOE) framework, we address this gap with a comparative case study of
eight Swiss public organizations. Our findings suggest that the
importance of technological and organizational factors varies depending
on the organization's stage in the adoption process, whereas
environmental factors are generally less critical. Accordingly, this
study advances our theoretical understanding of the specificities of AI
adoption in public organizations throughout the different adoption
stages.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Vogl, Thomas M</author><author>Seidelin, Cathrine</author><author>Ganesh, Bharath</author><author>Bright, Jonathan</author></authors></contributors><titles><title>Smart Technology and the Emergence of Algorithmic Bureaucracy:
Artificial Intelligence in UK Local Authorities</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>946-961</pages><volume>80</volume><issue>6</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1111/puar.13286</electronic-resource-num><language>English</language><urls/><abstract>In recent years, local authorities in the UK have begun to adopt a
variety of ``smart'' technological changes to enhance service
delivery. These changes are having profound impacts on the structure of
public administration. Focusing on the particular case of artificial
intelligence, specifically autonomous agents and predictive analytics, a
combination of desk research, a survey questionnaire, and interviews
were used to better understand the extent and nature of these changes in
local government. Findings suggest that local authorities are beginning
to adopt smart technologies and that these technologies are having an
unanticipated impact on how public administrators and computational
algorithms become imbricated in the delivery of public services. This
imbrication is described as algorithmic bureaucracy, and it provides a
framework within which to explore how these technologies transform both
the socio-technical relationship between workers and their tools, as
well as the ways that work is organized in the public sector.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van der Voort, H G</author><author>Klievink, A J</author><author>Arnaboldi, M</author><author>Meijer, A. J</author></authors></contributors><titles><title>Rationality and politics of algorithms. Will the promise of big data
survive the dynamics of public decision making?</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><pages>27-38</pages><volume>36</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.10.011</electronic-resource-num><language>English</language><urls/><abstract>Big data promises to transform public decision-making for the better by
making it more responsive to actual needs and policy effects. However,
much recent work on big data in public decision-making assumes a
rational view of decision-making, which has been much criticized in the
public administration debate. In this paper, we apply this view, and a
more political one, to the context of big data and offer a qualitative
study. We question the impact of big data on decision-making, realizing
that big data including its new methods and functions must inevitably
encounter existing political and managerial institutions. By studying
two illustrative cases of big data use processes, we explore how these
two worlds meet. Specifically, we look at the interaction between data
analysts and decision makers. In this we distinguish between a rational
view and a political view, and between an information logic and a
decision logic. We find that big data provides ample opportunities for
both analysts and decision makers to do a better job, but this doesn't
necessarily imply better decision-making, because big data also provides
opportunities for actors to pursue their own interests. Big data enables
both data analysts and decision makers to act as autonomous agents
rather than as links in a functional chain. Therefore, big data's impact
cannot be interpreted only in terms of its functional promise; it must
also be acknowledged as a phenomenon set to impact our policymaking
institutions, including their legitimacy.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Changlin</author><author>Teo, Thompson S H</author><author>Janssen, Marijn</author></authors></contributors><titles><title>Public and private value creation using artificial intelligence: An
empirical study of AI voice robot users in Chinese public sector</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>61</volume><keywords><keyword>Value creation; Public value; Private value; Artif</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2021.102401</electronic-resource-num><language>English</language><urls/><abstract>Despite significant theoretical and empirical attention on public value
creation in the public sector, the relationship between artificial
intelligence (AI) use and value creation from the citizen perspective
remains poorly understood. We ground our study in Moore's public value
management to examine the relationship between AI use and value
creation. We conceptually categorize public service value into public
value and private value. We use procedural justice and trust in
government as indicators of public value and, based on motivation
theory, we use perceived usefulness and perceived enjoyment as
indicators of private value. A field survey of 492 AI voice robot users
in China was conducted to test our model. The results indicated that the
effective use of AI voice robots was significantly associated with
private value and procedural justice. However, the relationship between
the effective use of AI and trust in government was not found to be
significant. Surprisingly, the respondents indicated that private value
had a greater effect on overall value creation than public value. This
contrasts with the common idea that value creation from the government
perspective suggests that social objectives requiring public value are
more important to citizens. The results also show that gender and
citizens with different experiences show different AI usage behaviors.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wirtz, Bernd W</author><author>Mueller, Wilhelm M</author></authors></contributors><titles><title>An integrated artificial intelligence framework for public management</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>1076-1100</pages><volume>21</volume><issue>7</issue><keywords><keyword>Artificial intelligence; framework; conceptual stu</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1080/14719037.2018.1549268</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2019 - Wirtz, Mueller - PUBLIC MANAGEMENT REVIEW.pdf</url></pdf-urls></urls><abstract>Artificial intelligence (AI) extends the limits of current performance
in data processing and analysis many times over. Since this states a
great improvement in managing public data, this conceptual study
discusses the use of AI in public management structures in connection
with their risks and side effects. The exercise of state power and
public influence through intelligent machines make ethical and political
guidelines essential for their operation, constituting the cornerstones
of the AI framework model developed here. The organizational structure
and technical specification are additional aspects of the AI that
determine design and functionality of the framework model in practical
application.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Andrews, Leighton</author></authors></contributors><titles><title>Public administration, public leadership and the construction of public
value in the age of the algorithm and ``big data'</title><secondary-title>PUBLIC ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION</full-title></periodical><pages>296-310</pages><volume>97</volume><issue>2, SI</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1111/padm.12534</electronic-resource-num><language>English</language><urls/><abstract>Public administration scholarship has to a significant degree neglected
technological change. The age of the algorithm and big data' is throwing
up new challenges for public leadership, which are already being
confronted by public leaders in different jurisdictions. Algorithms may
be perceived as presenting new kinds of wicked problems' for public
authorities. The article offers a tentative overview of the kind of
algorithmic challenges facing public leaders in an environment where the
discursive context is shaped by corporate technology companies. Public
value theory is assessed as an analytical framework to examine how
public leaders are seeking to address the ethical and public value
issues affecting governance and regulation, drawing on recent UK
experience in particular. The article suggests that this is a fruitful
area for future research.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pencheva, Irina</author><author>Esteve, Marc</author><author>Mikhaylov, Slava Jankin</author></authors></contributors><titles><title>Big Data and AI - A transformational shift for government: So, what next
for research?</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><pages>24-44</pages><volume>35</volume><issue>1</issue><keywords><keyword>Big Data; literature review; policy process</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1177/0952076718780537</electronic-resource-num><language>English</language><urls/><abstract>Big Data and artificial intelligence will have a profound
transformational impact on governments around the world. Thus, it is
important for scholars to provide a useful analysis on the topic to
public managers and policymakers. This study offers an in-depth review
of the Policy and Administration literature on the role of Big Data and
advanced analytics in the public sector. It provides an overview of the
key themes in the research field, namely the application and benefits of
Big Data throughout the policy process, and challenges to its adoption
and the resulting implications for the public sector. It is argued that
research on the subject is still nascent and more should be done to
ensure that the theory adds real value to practitioners. A critical
assessment of the strengths and limitations of the existing literature
is developed, and a future research agenda to address these gaps and
enrich our understanding of the topic is proposed.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aoki, Naomi</author></authors></contributors><titles><title>An experimental study of public trust in AI chatbots in the public
sector</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>37</volume><issue>4</issue><keywords><keyword>Artificial intelligence; Chatbot; Public trust; Hu</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.giq.2020.101490</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2020 - Aoki - GOVERNMENT INFORMATION QUARTERLY.pdf</url></pdf-urls></urls><abstract>This study investigates the public's initial trust in so-called
``artificial intelligence'' (AI) chatbots about to be introduced into
use in the public sector. While the societal impacts of AI are widely
speculated about, empirical testing remains rare. To narrow this gap,
this study builds on theories of operators' trust in machines in
industrial settings and proposes that initial public trust in chatbot
responses depends on (i) the area of enquiry, since expectations about a
chatbot's performance vary with the topic, and (ii) the purposes that
governments communicate to the public for introducing the use of
chatbots. Analyses based on an experimental online survey in Japan
generated results indicating that, if a government were to announce its
intention to use ``AI'' chatbots to answer public enquiries, the
public's initial trust in their responses would be lower in the area of
parental support than in the area of waste separation, with a moderate
effect size. Communicating purposes that would directly benefit
citizens, such as achieving uniformity in response quality and
timeliness in responding, would enhance public trust in chatbots.
Although the effect sizes are small, communicating these purposes might
be still worthwhile, as it would be an inexpensive measure for a
government to take.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mohamed, Azlinah</author><author>Najafabadi, Maryam Khanian</author><author>Wah, Yap Bee</author><author>Zaman, Ezzatul Akmal Kamaru</author><author>Maskat, Ruhaila</author></authors></contributors><titles><title>The state of the art and taxonomy of big data analytics: view from new
big data framework</title><secondary-title>ARTIFICIAL INTELLIGENCE REVIEW</secondary-title></titles><periodical><full-title>ARTIFICIAL INTELLIGENCE REVIEW</full-title></periodical><pages>989-1037</pages><volume>53</volume><issue>2</issue><keywords><keyword>Parallel and distributed computing; Big data tools</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1007/s10462-019-09685-9</electronic-resource-num><language>English</language><urls/><abstract>Big data has become a significant research area due to the birth of
enormous data generated from various sources like social media, internet
of things and multimedia applications. Big data has played critical role
in many decision makings and forecasting domains such as recommendation
systems, business analysis, healthcare, web display advertising,
clinicians, transportation, fraud detection and tourism marketing. The
rapid development of various big data tools such as Hadoop, Storm,
Spark, Flink, Kafka and Pig in research and industrial communities has
allowed the huge number of data to be distributed, communicated and
processed. Big data applications use big data analytics techniques to
efficiently analyze large amounts of data. However, choosing the
suitable big data tools based on batch and stream data processing and
analytics techniques for development a big data system are difficult due
to the challenges in processing and applying big data. Practitioners and
researchers who are developing big data systems have inadequate
information about the current technology and requirement concerning the
big data platform. Hence, the strengths and weaknesses of big data
technologies and effective solutions for Big Data challenges are needed
to be discussed. Hence, due to that, this paper presents a review of the
literature that analyzes the use of big data tools and big data
analytics techniques in areas like health and medical care, social
networking and internet, government and public sector, natural resource
management, economic and business sector. The goals of this paper are to
(1) understand the trend of big data-related research and current frames
of big data technologies; (2) identify trends in the use or research of
big data tools based on batch and stream processing and big data
analytics techniques; (3) assist and provide new researchers and
practitioners to place new research activity in this domain
appropriately. The findings of this study will provide insights and
knowledge on the existing big data platforms and their application
domains, the advantages and disadvantages of big data tools, big data
analytics techniques and their use, and new research opportunities in
future development of big data systems.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zekic-Susac, Marijana</author><author>Mitrovic, Sasa</author><author>Has, Adela</author></authors></contributors><titles><title>Machine learning based system for managing energy efficiency of public
sector as an approach towards smart cities</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>58</volume><keywords><keyword>Planning models; Energy efficiency; Machine learni</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2020.102074</electronic-resource-num><language>English</language><urls/><abstract>Energy efficiency of public sector is an important issue in the context
of smart cities due to the fact that buildings are the largest energy
consumers, especially public buildings such as educational, health,
government and other public institutions that have a large usage
frequency. However, recent developments of machine learning within Big
Data environment have not been exploited enough in this domain. This
paper aims to answer the question of how to incorporate Big Data
platform and machine learning into an intelligent system for managing
energy efficiency of public sector as a substantial part of the smart
city concept. Deep neural networks, Rpart regression tree and Random
forest with variable reduction procedures were used to create prediction
models of specific energy consumption of Croatian public sector
buildings. The most accurate model was produced by Random forest method,
and a comparison of important predictors extracted by all three methods
has been conducted. The models could be implemented in the suggested
intelligent system named MERIDA which integrates Big Data collection and
predictive models of energy consumption for each energy source in public
buildings, and enables their synergy into a managing platform for
improving energy efficiency of the public sector within Big Data
environment. The paper also discusses technological requirements for
developing such a platform that could be used by public administration
to plan reconstruction measures of public buildings, to reduce energy
consumption and cost, as well as to connect such smart public buildings
as part of smart cities. Such digital transformation of energy
management can increase energy efficiency of public administration, its
higher quality of service and healthier environment.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Busuioc, Madalina</author></authors></contributors><titles><title>Accountable Artificial Intelligence: Holding Algorithms to Account</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>825-836</pages><volume>81</volume><issue>5</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1111/puar.13293</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) algorithms govern in subtle yet fundamental
ways the way we live and are transforming our societies. The promise of
efficient, low-cost, or ``neutral'' solutions harnessing the potential
of big data has led public bodies to adopt algorithmic systems in the
provision of public services. As AI algorithms have permeated
high-stakes aspects of our public existence-from hiring and education
decisions to the governmental use of enforcement powers (policing) or
liberty-restricting decisions (bail and sentencing)-this necessarily
raises important accountability questions: What accountability
challenges do AI algorithmic systems bring with them, and how can we
safeguard accountability in algorithmic decision-making? Drawing on a
decidedly public administration perspective, and given the current
challenges that have thus far become manifest in the field, we
critically reflect on and map out in a conceptually guided manner the
implications of these systems, and the limitations they pose, for public
accountability.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kuziemski, Maciej</author><author>Misuraca, Gianluca</author></authors></contributors><titles><title>AI governance in the public sector: Three tales from the frontiers of
automated decision-making in democratic settings</title><secondary-title>TELECOMMUNICATIONS POLICY</secondary-title></titles><periodical><full-title>TELECOMMUNICATIONS POLICY</full-title></periodical><volume>44</volume><issue>6</issue><keywords><keyword>Artificial intelligence; Public sector innovation;</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.telpol.2020.101976</electronic-resource-num><language>English</language><urls><pdf-urls><url>internal-pdf://2020 - Kuziemski, Misuraca - TELECOMMUNICATIONS POLICY.pdf</url></pdf-urls></urls><abstract>The rush to understand new socio-economic contexts created by the wide
adoption of AI is justified by its far-ranging consequences, spanning
almost every walk of life. Yet, the public sector's predicament is a
tragic double bind: its obligations to protect citizens from potential
algorithmic harms are at odds with the temptation to increase its own
efficiency - or in other words - to govern algorithms, while governing
by algorithms. Whether such dual role is even possible, has been a
matter of debate, the challenge stemming from algorithms' intrinsic
properties, that make them distinct from other digital solutions, long
embraced by the governments, create externalities that rule-based
programming lacks. As the pressures to deploy automated decision making
systems in the public sector become prevalent, this paper aims to
examine how the use of AI in the public sector in relation to existing
data governance regimes and national regulatory practices can be
intensifying existing power asymmetries. To this end, investigating the
legal and policy instruments associated with the use of AI for
strenghtening the immigration process control system in Canada;
``optimising'' the employment services'' in Poland, and
personalising the digital service experience in Finland, the paper
advocates for the need of a common framework to evaluate the potential
impact of the use of AI in the public sector. In this regard, it
discusses the specific effects of automated decision support systems on
public services and the growing expectations for governments to play a
more prevalent role in the digital society and to ensure that the
potential of technology is harnessed, while negative effects are
controlled and possibly avoided. This is of particular importance in
light of the current COVID-19 emergency crisis where AI and the
underpinning regulatory framework of data ecosystems, have become
crucial policy issues as more and more innovations are based on large
scale data collections from digital devices, and the real-time
accessibility of information and services, contact and relationships
between institutions and citizens could strengthen - or undermine -
trust in governance systems and democracy.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sun, Tara Qian</author><author>Medaglia, Rony</author></authors></contributors><titles><title>Mapping the challenges of Artificial Intelligence in the public sector:
Evidence from public healthcare</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><pages>368-383</pages><volume>36</volume><issue>2</issue><keywords><keyword>Artificial Intelligence; Public sector; Healthcare</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.09.008</electronic-resource-num><language>English</language><urls/><abstract>The nascent adoption of Artificial Intelligence (AI) in the public
sector is being assessed in contradictory ways. But while there is
increasing speculation about both its dangers and its benefits, there is
very little empirical research to substantiate them. This study aims at
mapping the challenges in the adoption of AI in the public sector as
perceived by key stakeholders. Drawing on the theoretical lens of
framing, we analyse a case of adoption of the AI system IBM Watson in
public healthcare in China, to map how three groups of stakeholders
(government policy-makers, hospital managers/doctors, and Information
Technology (IT) firm managers) perceive the challenges of AI adoption in
the public sector. Findings show that different stakeholders have
diverse, and sometimes contradictory, framings of the challenges. We
contribute to research by providing an empirical basis to claims of AI
challenges in the public sector, and to practice by providing four sets
of guidelines for the governance of AI adoption in the public sector.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dwivedi, Yogesh K</author><author>Hughes, Laurie</author><author>Ismagilova, Elvira</author><author>Aarts, Gert</author><author>Coombs, Crispin</author><author>Crick, Tom</author><author>Duan, Yanqing</author><author>Dwivedi, Rohita</author><author>Edwards, John</author><author>Eirug, Aled</author><author>Galanos, Vassilis</author><author>Ilavarasan, P Vigneswara</author><author>Janssen, Marijn</author><author>Jones, Paul</author><author>Kar, Arpan Kumar</author><author>Kizgin, Hatice</author><author>Kronemann, Bianca</author><author>Lal, Banita</author><author>Lucini, Biagio</author><author>Medaglia, Rony</author><author>Le Meunier-FitzHugh, Kenneth</author><author>Le Meunier-FitzHugh, Leslie Caroline</author><author>Misra, Santosh</author><author>Mogaji, Emmanuel</author><author>Sharma, Sujeet Kumar</author><author>Singh, Jang Bahadur</author><author>Raghavan, Vishnupriya</author><author>Raman, Ramakrishnan</author><author>Rana, Nripendra P</author><author>Samothrakis, Spyridon</author><author>Spencer, Jak</author><author>Tamilmani, Kuttimani</author><author>Tubadji, Annie</author><author>Walton, Paul</author><author>Williams, Michael D</author></authors></contributors><titles><title>Artificial Intelligence (AI): Multidisciplinary perspectives on emerging
challenges, opportunities, and agenda for research, practice and policy</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>57</volume><keywords><keyword>Artificial intelligence; AI; Cognitive computing;</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2019.08.002</electronic-resource-num><language>English</language><urls/><abstract>As far back as the industrial revolution, significant development in
technical innovation has succeeded in transforming numerous manual tasks
and processes that had been in existence for decades where humans had
reached the limits of physical capacity. Artificial Intelligence (AI)
offers this same transformative potential for the augmentation and
potential replacement of human tasks and activities within a wide range
of industrial, intellectual and social applications. The pace of change
for this new AI technological age is staggering, with new breakthroughs
in algorithmic machine learning and autonomous decision-making,
engendering new opportunities for continued innovation. The impact of AI
could be significant, with industries ranging from: finance, healthcare,
manufacturing, retail, supply chain, logistics and utilities, all
potentially disrupted by the onset of AI technologies. The study brings
together the collective insight from a number of leading expert
contributors to highlight the significant opportunities, realistic
assessment of impact, challenges and potential research agenda posed by
the rapid emergence of AI within a number of domains: business and
management, government, public sector, and science and technology. This
research offers significant and timely insight to AI technology and its
impact on the future of industry and society in general, whilst
recognising the societal and industrial influence on pace and direction
of AI development.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jobin, Anna</author><author>Ienca, Marcello</author><author>Vayena, Effy</author></authors></contributors><titles><title>The global landscape of AI ethics guidelines</title><secondary-title>NATURE MACHINE INTELLIGENCE</secondary-title></titles><periodical><full-title>NATURE MACHINE INTELLIGENCE</full-title></periodical><pages>389-399</pages><volume>1</volume><issue>9</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s42256-019-0088-2</electronic-resource-num><language>English</language><urls/><abstract>In the past five years, private companies, research institutions and
public sector organizations have issued principles and guidelines for
ethical artificial intelligence (AI). However, despite an apparent
agreement that AI should be `ethical', there is debate about both what
constitutes `ethical AI' and which ethical requirements, technical
standards and best practices are needed for its realization. To
investigate whether a global agreement on these questions is emerging,
we mapped and analysed the current corpus of principles and guidelines
on ethical AI. Our results reveal a global convergence emerging around
five ethical principles (transparency, justice and fairness,
non-maleficence, responsibility and privacy), with substantive
divergence in relation to how these principles are interpreted, why they
are deemed important, what issue, domain or actors they pertain to, and
how they should be implemented. Our findings highlight the importance of
integrating guideline-development efforts with substantive ethical
analysis and adequate implementation strategies. As AI technology
develops rapidly, it is widely recognized that ethical guidelines are
required for safe and fair implementation in society. But is it possible
to agree on what is `ethical AI'? A detailed analysis of 84 AI ethics
reports around the world, from national and international organizations,
companies and institutes, explores this question, finding a convergence
around core principles but substantial divergence on practical
implementation.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Gang</author><author>Li, Hao</author><author>He, Rong</author><author>Lu, Peng</author></authors></contributors><titles><title>Agent-based modeling and life cycle dynamics of COVID-19-related online collective actions</title><secondary-title>Complex and Intelligent Systems</secondary-title></titles><periodical><full-title>Complex and Intelligent Systems</full-title></periodical><pages>1369 - 1387</pages><volume>8</volume><issue>2</issue><keywords><keyword>Agent-Based Modeling (ABM)</keyword><keyword>Attention shift and attention allocation</keyword><keyword>COVID-19</keyword><keyword>Online collective actions</keyword><keyword>Substitution effects</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1007/s40747-021-00595-4</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Zhang et al. - Complex and Intelligent Systems.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134068532&amp;doi=10.1007%2Fs40747-021-00595-4&amp;partnerID=40&amp;md5=121f28c4910c0a553519156e9c12c154</url></web-urls></urls><abstract>The outbreak of COVID-19 has greatly threatened global public health and produced social problems, which includes relative online collective actions. Based on the life cycle law, focusing on the life cycle process of COVID-19 online collective actions, we carried out both macro-level analysis (big data mining) and micro-level behaviors (Agent-Based Modeling) on pandemic-related online collective actions. We collected 138 related online events with macro-level big data characteristics, and used Agent-Based Modeling to capture micro-level individual behaviors of netizens. We set two kinds of movable agents, Hots (events) and Netizens (individuals), which behave smartly and autonomously. Based on multiple simulations and parametric traversal, we obtained the optimal parameter solution. Under the optimal solutions, we repeated simulations by ten times, and took the mean values as robust outcomes. Simulation outcomes well match the real big data of life cycle trends, and validity and robustness can be achieved. According to multiple criteria (spans, peaks, ratios, and distributions), the fitness between simulations and real big data has been substantially supported. Therefore, our Agent-Based Modeling well grasps the micro-level mechanisms of real-world individuals (netizens), based on which we can predict individual behaviors of netizens and big data trends of specific online events. Based on our model, it is feasible to model, calculate, and even predict evolutionary dynamics and life cycles trends of online collective actions. It facilitates public administrations and social governance. © 2021, The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Giest, Sarah</author></authors></contributors><titles><title>Big data for policymaking: fad or fasttrack?</title><secondary-title>Policy Sciences</secondary-title></titles><periodical><full-title>Policy Sciences</full-title></periodical><pages>367 - 382</pages><volume>50</volume><issue>3</issue><keywords><keyword>Big data</keyword><keyword>Data readiness</keyword><keyword>Digital-era governance</keyword><keyword>Evidence-based policymaking</keyword><keyword>Policy design</keyword><keyword>Policy instruments</keyword></keywords><dates><year>2017</year></dates><electronic-resource-num>10.1007/s11077-017-9293-1</electronic-resource-num><notes>Cited by: 132</notes><research-notes>Cited by: 132</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2017 - Giest - Policy Sciences.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027009690&amp;doi=10.1007%2Fs11077-017-9293-1&amp;partnerID=40&amp;md5=95d8382918059aad38fe07b4e430fa08</url></web-urls></urls><abstract>The buzz surrounding big data has taken shape in various theoretical and practical forms when it comes to policymaking. The paper combines current research streams with long-standing discussions on government and technology in public policy and public administration, such as e-government and evidence-based policymaking. The goal is to answer the question whether big data is a fleeting trend or has long-lasting effects on policymaking. Three larger themes in the literature are identified: First, the role that institutional capacity has within government to utilize big data analytics; second, government use of big data analytics in the context of digital public services; and finally, the way that big data information enters the policy cycle, focusing on substantive and procedural policy instruments. Examples from the education, crisis management, environmental and healthcare domain highlight the opportunities and challenges for each of these themes. Exploring the various aspects of big data and policymaking shows that big data is here to stay, but that its utilization by government will take time due to institutional barriers and capacity bottlenecks. © 2017, The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Choi, Youngseok</author><author>Lee, Habin</author><author>Irani, Zahir</author></authors></contributors><titles><title>Big data-driven fuzzy cognitive map for prioritising IT service procurement in the public sector</title><secondary-title>Annals of Operations Research</secondary-title></titles><periodical><full-title>Annals of Operations Research</full-title></periodical><pages>75 - 104</pages><volume>270</volume><issue>1-2</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1007/s10479-016-2281-6</electronic-resource-num><notes>Cited by: 54</notes><research-notes>Cited by: 54</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2018 - Choi, Lee, Irani - Annals of Operations Research.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982292325&amp;doi=10.1007%2Fs10479-016-2281-6&amp;partnerID=40&amp;md5=1677c94bef289f0e0a4a40409a88a2c5</url></web-urls></urls><abstract>The prevalence of big data is starting to spread across the public and private sectors however, an impediment to its widespread adoption orientates around a lack of appropriate big data analytics (BDA) and resulting skills to exploit the full potential of big data availability. In this paper, we propose a novel BDA to contribute towards this void, using a fuzzy cognitive map (FCM) approach that will enhance decision-making thus prioritising IT service procurement in the public sector. This is achieved through the development of decision models that capture the strengths of both data analytics and the established intuitive qualitative approach. By taking advantages of both data analytics and FCM, the proposed approach captures the strength of data-driven decision-making and intuitive model-driven decision modelling. This approach is then validated through a decision-making case regarding IT service procurement in public sector, which is the fundamental step of IT infrastructure supply for publics in a regional government in the Russia federation. The analysis result for the given decision-making problem is then evaluated by decision makers and e-government expertise to confirm the applicability of the proposed BDA. In doing so, demonstrating the value of this approach in contributing towards robust public decision-making regarding IT service procurement. © 2016, The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mattei, Paola</author></authors></contributors><titles><title>Digital governance in tax-funded European healthcare systems: From the Back office to patient empowerment</title><secondary-title>Israel Journal of Health Policy Research</secondary-title></titles><periodical><full-title>Israel Journal of Health Policy Research</full-title></periodical><volume>9</volume><issue>1</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1186/s13584-020-0361-1</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2020 - Mattei - Israel Journal of Health Policy Research.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078000204&amp;doi=10.1186%2Fs13584-020-0361-1&amp;partnerID=40&amp;md5=9b3f60175ef8fd242ecebc3b8934cad4</url></web-urls></urls><abstract>Digital healthcare promises to achieve cost-efficiency gains, improve clinical effectiveness, support better public sector governance by enhancing transparency and accountability, and increase confidence in medical diagnoses, especially in the field of oncology. This article aims to discuss the benefits offered by digital technologies in tax-based European healthcare systems against the backdrop of structural bureaucratic rigidities and a slow pace of implementation. Artificial intelligence (AI) will transform the existing delivery of healthcare services, inducing a redesign of public accountability systems and the traditional relationships between professionals and patients. Despite legitimate ethical and accountability concerns, which call for clearer guidance and regulation, digital governance of healthcare is a powerful means of empowering patients and improving their medical treatment in terms of quality and effectiveness. On the path to better health, the use of digital technologies has moved beyond the back office of administrative processes and procedures, and is now being applied to clinical activities and direct patient engagement. © 2020 The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rocca, Laura</author><author>Giacomini, Davide</author><author>Zola, Paola</author></authors></contributors><titles><title>Environmental disclosure and sentiment analysis: state of the art and opportunities for public-sector organisations</title><secondary-title>Meditari Accountancy Research</secondary-title></titles><periodical><full-title>Meditari Accountancy Research</full-title></periodical><pages>617 - 646</pages><volume>29</volume><issue>3</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1108/MEDAR-09-2019-0563</electronic-resource-num><notes>Cited by: 18</notes><research-notes>Cited by: 18</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2020 - Rocca, Giacomini, Zola - Meditari Accountancy Research.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089603646&amp;doi=10.1108%2FMEDAR-09-2019-0563&amp;partnerID=40&amp;md5=2893337cbc86223283a88a0ddac02f9d</url></web-urls></urls><abstract>Purpose: Because of the expansion of the internet and Web 2.0 phenomenon, new challenges are emerging in the disclosure practises adopted by organisations in the public-sector. This study aims to examine local governments’ (LGOs) use of social media (SM) in disclosing environmental actions/plans/information as a new way to improve accountability to citizens to obtain organisational legitimacy and the related sentiment of citizens’ judgements. Design/methodology/approach: This paper analyses the content of 39 Italian LGOs’ public pages on Facebook. After the distinction between five classes of environmental issues (air, water, energy, waste and territory), an initial study is performed to detect possible sub-topics applying latent Dirichlet allocation. Having a list of posts related to specific environmental themes, the researchers computed the sentiment of citizens’ comments. To measure sentiment, two different approaches were implemented: one based on a lexicon dictionary and the other based on convolutional neural networks. Findings: Facebook is used by LGOs to disclose environmental issues, focussing on their main interest in obtaining organisational legitimacy, and the analysis shows an increasing impact of Web 2.0 in the direct interaction of LGOs with citizens. On the other hand, there is a clear divergence of interest on environmental topics between LGOs and citizens in a dialogic accountability framework. Practical implications: Sentiment analysis (SA) could be used by politicians, but also by managers/entrepreneurs in the business sector, to analyse stakeholders’ judgements of their communications/actions and plans on corporate social responsibility. This tool gives a result on time (i.e. not months or years after, as for the reporting system). It is cheaper than a survey and allows a first “photograph” of stakeholders’ sentiment. It can also be a useful tool for supporting, developing and improving environmental reporting. Originality/value: To the best of the authors’ knowledge, this paper is one of the first to apply SA to environmental disclosure via SM in the public sphere. The study links modern techniques in natural language processing and machine learning with the important aspects of environmental communication between LGOs and citizens. © 2020, Laura Rocca, Davide Giacomini and Paola Zola.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cong, Wanshu</author></authors></contributors><titles><title>From Pandemic Control to Data-Driven Governance: The Case of China’s Health Code</title><secondary-title>Frontiers in Political Science</secondary-title></titles><periodical><full-title>Frontiers in Political Science</full-title></periodical><volume>3</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.3389/fpos.2021.627959</electronic-resource-num><notes>Cited by: 29</notes><research-notes>Cited by: 29</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2021 - Cong - Frontiers in Political Science.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118887215&amp;doi=10.3389%2Ffpos.2021.627959&amp;partnerID=40&amp;md5=7f33ab4bc6e1a8f866c51a9640ce3ce4</url></web-urls></urls><abstract>Current debates over digital contact tracing mainly focus on the tools and experiences in the West. China’s health code, while often seen as one of the earliest and most widely adopted apps since the outbreak of COVID-19, has not been studied specifically. This article provides a detailed analysis of the health code, draws comparison with the contact tracing apps developed by Google and Apple, and seeks to understand the specifications and contradictions internal to the health code’s development and deployment in China. Looking at both technical features and the mode and process of its adoption, the article argues that the health code is strictly speaking not a contact tracing tool, but a technology of population control which is integrated in traditional forms of control and facilitates the enhancement of such control. As a technology of ruling the population, rather than the virus as such, the health code also reveals crucial problems in the modernization and informatization of the state governance and public administration. A critique on the health code solely informed by privacy and personal data protection runs the risk of being co-opted by the government and technology companies deploying such tools to expand their surveillance and regulatory power. Copyright © 2021 Cong.</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cetera, Wiesław</author><author>Gogołek, Włodzimierz</author><author>Żołnierski, Aleksander</author><author>Jaruga, Dariusz</author></authors></contributors><titles><title>Potential for the use of large unstructured data resources by public innovation support institutions</title><secondary-title>Journal of Big Data</secondary-title></titles><periodical><full-title>Journal of Big Data</full-title></periodical><volume>9</volume><issue>1</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1186/s40537-022-00610-6</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2022 - Cetera et al. - Journal of Big Data.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128957082&amp;doi=10.1186%2Fs40537-022-00610-6&amp;partnerID=40&amp;md5=e83541274fd8d5c2c2577ced2015ad4b</url></web-urls></urls><abstract>Effective programming of research and development (R&amp;D) support, adjusted to the actual potential of beneficiaries, requires the use of modern analytical tools. An efficient R&amp;D support system requires up-to-date data on technological trends, ongoing (and planning) research, market needs and developing innovation. The most popular programming methods were based on the analysis of data with a 4 to 5-year time delay until recently. Having described the method of refining information from unstructured data, we explore how to make it possible not only to solve the issue of up-to-date data but to identify of the latest trends in R&amp;D activities. The analytical tools we describe were already fully functional in 2018 and are constantly being improved. The article presents the potential of one tool that can be applied in public support institutions. Methods of identifying and diagnosing technology trends are presented within the case study of the electric car technology trend. The presented case study shows the effectiveness of the method we developed for identifying and diagnosing areas requiring support from public funds. Public institutions, including public institutions supporting R&amp;D and innovation processes, can apply tools that allow an increase in the quality of public support programmes offered, but also beneficial for the quality of strategic resources management within the institution itself. The comparison of the predictions made by the described tools with the classifications made by experts, the former are more accurate and precise. Moreover, the results of the analyses performed by the presented model are not influenced by distorting factors—fads, trends, political pressures, or processes with an unidentified, non-substantive background. It should be emphasized that the accuracy of the whole model is 0.84. The described tools and methods are already directly applicable in many areas related to the support of R&amp;D activity worldwide. The article presents a solution that effectively enables the management of more precise programmes supporting innovative activities used for the first time in Poland. It is also one of the first uses of these methods by public administration in the world. Our approach not only strengthens improved adjustment of the support offered for R&amp;D activity, but also makes it possible to apply and improve management methods in public institutions. © 2022, The Author(s).</abstract></record><record><database name="consolidated-sample-174.enl" path="consolidated-sample-174.enl">consolidated-sample-174.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ekimova, Ksenia V</author></authors></contributors><titles><title>Development of the potential of the digital economy of Russian regions through artificial intelligence humanisation</title><secondary-title>Humanities and Social Sciences Communications</secondary-title></titles><periodical><full-title>Humanities and Social Sciences Communications</full-title></periodical><volume>10</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1057/s41599-023-02444-w</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><pdf-urls><url>internal-pdf://2023 - Ekimova - Humanities and Social Sciences Communications.pdf</url></pdf-urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179709244&amp;doi=10.1057%2Fs41599-023-02444-w&amp;partnerID=40&amp;md5=03335b28e497c1416848e28cebf96913</url></web-urls></urls><abstract>This paper is aimed at balancing the interests of business and society in the digital economy, to reduce the social risks of the Fourth Industrial Revolution. The goal of this paper is to study the experience and prospects of the humanisation of AI through the improvement of the practice of corporate social responsibility in Russia. By the example of the experience of Russian regions in 2021, we use econometric modelling to prove that the digital regional economy has a large potential in the sphere of humanisation of AI. The potential for the humanisation of AI in the digital economy of Russian regions is determined by responsible innovations, responsible production and logistics, as well as responsible marketing and sales, which contribute to the implementation of SDGs 9–12. The theoretical significance of the paper lies in its presenting smart region as a socio-economic environment for the humanisation of AI. The scientific novelty of the paper lies in its offering a new—meso-level—view of the humanisation of AI. The advantages of the new view include, first, consideration of socio-economic conditions for the humanisation of AI in a region; second, the most precise identification and correct measuring of the consequences of humanisation of AI for the quality of life in a region. The practical significance of the research results consists in the fact that the new proposed approach to the humanisation of AI, which implies public administration of this process at the level of a region, allows accelerating the considered process. © 2023, The Author(s).</abstract></record></records></xml>
