@article{Schmid2017,
abstract = {The @ is the link between the name of the recipient and its address. The e-mail has revolutionized the communication behavior. It represents a new era of information and data exchange. The speed of information exchange and the possibility of non-physical data transport have fundamentally changed human communication. Big Data has become the synonym for a new technological age. Generally Big Data collects data and delivers valuable and useful information (Baron, 2013, 1). A general definition of the term has not yet taken place in science and practice. The work of the public sector is based on the collection, identification and use of data in many areas. Public organizations are often data monopolists and the only provider of public goods. The acquisition of new information in the sense of Big Data requires a connection between existing data and the use of new information. This gives the public administration a whole new potential. The organizational function "Controlling" supports decision-makers in the context of management and control (Horv{\'{a}}th, 2011, 16). The proximity of Big Data and Controlling is obvious. This article describes the potentials resulting from the use of Big Data and its effects on Public Controlling. Big Data will revolutionize Public Controlling and thus the public administration as a whole.},
annote = {Cited by: 3},
author = {Schmid, Andreas},
doi = {10.13165/VPA-17-16-2-11},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Schmid - Public Policy and Administration.pdf:pdf},
issn = {16482603},
journal = {Public Policy and Administration},
keywords = {Big Data,Public Controlling,effectiveness,efficiency,public sector},
language = {English},
number = {2},
pages = {325 -- 334},
title = {{BigData-PublicControlling Fundamental changes in Public Management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028679650&doi=10.13165%2FVPA-17-16-2-11&partnerID=40&md5=b7dced8ec6f98b5dfa3d94de9c0b1bd4},
volume = {16},
year = {2017}
}
@article{Intezari2017,
abstract = {Purpose: The purpose of this paper is to provide a theoretical framework of how knowledge management (KM) systems can facilitate the incorporation of big data into strategic decisions. Advanced analytics are becoming increasingly critical in making strategic decisions in any organization from the private to public sectors and from for-profit companies to not-for-profit organizations. Despite the growing importance of capturing, sharing and implementing people's knowledge in organizations, it is still unclear how big data and the need for advanced analytics can inform and, if necessary, reform the design and implementation of KM systems. Design/methodology/approach: To address this gap, a combined approach has been applied. The KM and data analysis systems implemented by companies were analyzed, and the analysis was complemented by a review of the extant literature. Findings: Four types of data-based decisions and a set of ground rules are identified toward enabling KM systems to handle big data and advanced analytics. Practical implications: The paper proposes a practical framework that takes into account the diverse combinations of data-based decisions. Suggestions are provided about how KM systems can be reformed to facilitate the incorporation of big data and advanced analytics into organizations' strategic decision-making. Originality/value: This is the first typology of data-based decision-making considering advanced analytics. {\textcopyright} 2017, {\textcopyright} Emerald Publishing Limited.},
annote = {Cited by: 104},
author = {Intezari, Ali and Gressel, Simone},
doi = {10.1108/JKM-07-2015-0293},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Intezari, Gressel - Journal of Knowledge Management.pdf:pdf},
issn = {1367-3270},
journal = {Journal of Knowledge Management},
keywords = {Advanced analytics,Big data,Data-based decisions,Knowledge management systems,Strategic decision-making},
language = {English},
month = {feb},
number = {1},
pages = {71--91},
title = {{Information and reformation in KM systems: big data and strategic decision-making}},
url = {https://www.emerald.com/insight/content/doi/10.1108/JKM-07-2015-0293/full/html},
volume = {21},
year = {2017}
}
@article{Madsen2018,
abstract = {This paper presents an analysis of interviews, focus groups and workshops with employees in the technical administration in the municipality of Copenhagen in the year after it won a prestigious Smart City award. The administration is interpreted as a ‘most likely' to succeed in translating the idealised version of the smart city into a workable bureaucratic practice. Drawing on the work of Orlikowski and Gash, the empirical analysis identifies and describes two incongruent ‘technological frames' that illustrates different ways of making sense of data and the smart city within this single organisational unit. One is called the experimentalist's credo and it is characterised by inspiration from the development of an Internet of Things as well as a readiness to learn from the open source community in software development. The other is called the data-owners vocation and it is characterised by a more situated approach that interprets data as strategic and political. It is argued that the existence of these frames provides two insights relevant for the literature on smart cities. First, they illustrate that one should be careful not to reify the smart city as a phenomenon that can be criticised in generic terms. Second, they suggest that even if there exists a transition toward the implementation of a technocratic smart city paradigm across public administrations, this paradigm is not unique in its focus on markets and evidence in governance.},
annote = {Cited by: 25},
author = {Madsen, Anders Koed},
doi = {10.1177/2053951718802321},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Madsen - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Big Data,Smart city,This,sense-making,technological frames},
language = {English},
month = {jul},
number = {2},
pages = {205395171880232},
title = {{Data in the smart city: How incongruent frames challenge the transition from ideal to practice}},
url = {http://journals.sagepub.com/doi/10.1177/2053951718802321},
volume = {5},
year = {2018}
}
@article{Giest2017,
abstract = {The buzz surrounding big data has taken shape in various theoretical and practical forms when it comes to policymaking. The paper combines current research streams with long-standing discussions on government and technology in public policy and public administration, such as e-government and evidence-based policymaking. The goal is to answer the question whether big data is a fleeting trend or has long-lasting effects on policymaking. Three larger themes in the literature are identified: First, the role that institutional capacity has within government to utilize big data analytics; second, government use of big data analytics in the context of digital public services; and finally, the way that big data information enters the policy cycle, focusing on substantive and procedural policy instruments. Examples from the education, crisis management, environmental and healthcare domain highlight the opportunities and challenges for each of these themes. Exploring the various aspects of big data and policymaking shows that big data is here to stay, but that its utilization by government will take time due to institutional barriers and capacity bottlenecks. {\textcopyright} 2017, The Author(s).},
annote = {Cited by: 132},
author = {Giest, Sarah},
doi = {10.1007/s11077-017-9293-1},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Giest - Policy Sciences.pdf:pdf},
issn = {00322687},
journal = {Policy Sciences},
keywords = {Big data,Data readiness,Digital-era governance,Evidence-based policymaking,Policy design,Policy instruments},
language = {English},
number = {3},
pages = {367 -- 382},
title = {{Big data for policymaking: fad or fasttrack?}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027009690&doi=10.1007%2Fs11077-017-9293-1&partnerID=40&md5=95d8382918059aad38fe07b4e430fa08},
volume = {50},
year = {2017}
}
@article{Oswald2018,
abstract = {As is common across the public sector, the UK police service is under pressure to do more with less, to target resources more efficiently and take steps to identify threats proactively; for example under riskassessment schemes such as ‘Clare's Law' and ‘Sarah's Law'. Algorithmic tools promise to improve a police force's decisionmaking and prediction abilities by making better use of data (including intelligence), both from inside and outside the force. This article uses Durham Constabulary's Harm Assessment Risk Tool (HART) as a case-study. HART is one of the first algorithmic models to be deployed by a UK police force in an operational capacity. Our article comments upon the potential benefits of such tools, explains the concept and method of HART and considers the results of the first validation of the model's use and accuracy. The article then critiques the use of algorithmic tools within policing from a societal and legal perspective, focusing in particular upon substantive common law grounds for judicial review. It considers a concept of ‘experimental' proportionality to permit the use of unproven algorithms in the public sector in a controlled and time-limited way, and as part of a combination of approaches to combat algorithmic opacity, proposes ‘ALGO-CARE', a guidance framework of some of the key legal and practical concerns that should be considered in relation to the use of algorithmic risk assessment tools by the police. The article concludes that for the use of algorithmic tools in a policing context to result in a ‘better' outcome, that is to say, a more efficient use of police resources in a landscape of more consistent, evidence-based decision-making, then an ‘experimental' proportionality approach should be developed to ensure that new solutions from ‘big data' can be found for criminal justice problems traditionally arising from clouded, non-augmented decision-making. Finally, this article notes that there is a sub-set of decisions around which there is too great an impact upon society and upon the welfare of individuals for them to be influenced by an emerging technology; to an extent, in fact, that they should be removed from the influence of algorithmic decision-making altogether. {\textcopyright} 2018 The Author(s).},
annote = {Cited by: 105},
author = {Oswald, Marion and Grace, Jamie and Urwin, Sheena and Barnes, Geoffrey C.},
doi = {10.1080/13600834.2018.1458455},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Oswald et al. - Information & Communications Technology Law.pdf:pdf},
issn = {1360-0834},
journal = {Information & Communications Technology Law},
keywords = {Keywords Algorithms,criminal justice,law,predictions,proportionality,risk assessment},
language = {English},
month = {may},
number = {2},
pages = {223--250},
title = {{Algorithmic risk assessment policing models: lessons from the Durham HART model and ‘Experimental' proportionality}},
url = {https://www.tandfonline.com/doi/full/10.1080/13600834.2018.1458455},
volume = {27},
year = {2018}
}
@article{Klievink2017,
abstract = {Big data is being implemented with success in the private sector and science. Yet the public sector seems to be falling behind, despite the potential value of big data for government. Government organizations do recognize the opportunities of big data but seem uncertain about whether they are ready for the introduction of big data, and if they are adequately equipped to use big data. This paper addresses those uncertainties. It presents an assessment framework for evaluating public organizations' big data readiness. Doing so demystifies the concept of big data, as it is expressed in terms of specific and measureable organizational characteristics. The framework was tested by applying it to organizations in the Dutch public sector. The results suggest that organizations may be technically capable of using big data, but they will not significantly gain from these activities if the applications do not fit their organizations and main statutory tasks. The framework proved helpful in pointing out areas where public sector organizations could improve, providing guidance on how government can become more big data ready in the future. {\textcopyright} 2016, The Author(s).},
annote = {Cited by: 157},
author = {Klievink, Bram and Romijn, Bart-Jan and Cunningham, Scott and de Bruijn, Hans},
doi = {10.1007/s10796-016-9686-2},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Klievink et al. - Information Systems Frontiers.pdf:pdf},
issn = {13873326},
journal = {Information Systems Frontiers},
keywords = {Assessment,Big data,Bold Readiness,E-government,Use},
language = {English},
number = {2},
pages = {267 -- 283},
title = {{Big data in the public sector: Uncertainties and readiness}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982126226&doi=10.1007%2Fs10796-016-9686-2&partnerID=40&md5=84822de6a52d6dd0aeaa989cce50369e},
volume = {19},
year = {2017}
}
@article{Desouza2017,
abstract = {In this essay, we consider the role of Big Data in the public sector. Motivating our work is the recognition that Big Data is still in its infancy and many important questions regarding the true value of Big Data remain unanswered. The question we consider is as follows: What are the limits, or potential, of Big Data in the public sector? By reviewing the literature and summarizing insights from a series of interviews from public sector Chief Information Officers (CIOs), we offer a scholarly foundation for both practitioners and researchers interested in understanding Big Data in the public sector.},
annote = {Cited by: 121},
author = {Desouza, Kevin C. and Jacob, Benoy},
doi = {10.1177/0095399714555751},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Desouza, Jacob - Administration & Society.pdf:pdf},
issn = {0095-3997},
journal = {Administration & Society},
keywords = {big data,policy analysis,public management,public organizations},
language = {English},
month = {aug},
number = {7},
pages = {1043--1064},
title = {{Big Data in the Public Sector: Lessons for Practitioners and Scholars}},
url = {http://journals.sagepub.com/doi/10.1177/0095399714555751},
volume = {49},
year = {2017}
}
@article{Shah2017,
abstract = {This research highlights a contextual application for big data within a HR case study setting. This is achieved through the development of a normative conceptual model that seeks to envelop employee behaviors and attitudes in the context of organizational change readiness. This empirical application considers a data sample from a large public sector organization and through applying Structural Equation Modelling (SEM) identifies salary, job promotion, organizational loyalty and organizational identity influences on employee job satisfaction (suggesting and mediating employee readiness for organizational change). However in considering this specific context, the authors highlight how, where and why such a normative approach to employee factors may be limited and thus, proposes through a framework which brings together big data principles, implementation approaches and management commitment requirements can be applied and harnessed more effectively in order to assess employee attitudes and behaviors as part of wider HR predictive analytics (HRPA) approaches. The researchers conclude with a discussion on these research elements and a set of practical, conceptual and management implications of the findings along with recommendations for future research in the area. {\textcopyright} 2016 Elsevier Inc.},
annote = {Cited by: 149},
author = {Shah, Naimatullah and Irani, Zahir and Sharif, Amir M.},
doi = {10.1016/j.jbusres.2016.08.010},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Shah, Irani, Sharif - Journal of Business Research.pdf:pdf},
issn = {01482963},
journal = {Journal of Business Research},
keywords = {Big data,Employee readiness,Extrinsic and intrinsic satisfaction,HR predictive analytics,Job satisfaction,Organizational change},
language = {English},
month = {jan},
pages = {366--378},
title = {{Big data in an HR context: Exploring organizational change readiness, employee attitudes and behaviors}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0148296316304970},
volume = {70},
year = {2017}
}
@article{Baur2017,
abstract = {Transparency, participation, and collaboration are the core pillars of open government. For the systematic integration of citizens and other stakeholders into the policy and public value creation process, their opinions, wishes, and complaints first need to be received. In the future, including user-generated content from social media will become a main channel for the enrichment of this information base for public administrative bodies and commercial firms. However, the sheer speed of growth of this constantly updated data pool makes manual work infeasible. The automated gathering, combination, analysis, and visualization of user-generated content from various sources and multiple languages is therefore imperative. In this study, we present a design science research approach to develop a general framework (‘MarketMiner') to handle large amounts of foreign-language user-generated content. As a first empirical application, we implement the framework in the automotive industry by analyzing Chinese automotive forums for the benefit of English-speaking users. At the same time, the ideas, methods, and insights are transferred to the public sector context, especially in light of the current challenges of a high number of political refugees from Arabic countries entering into the European Union. The results are promising in that MarketMiner can dramatically improve the utilization of multi-language, multi-source social media content. The modular set-up of the artifact allows an easy transfer to additional areas of application. {\textcopyright} 2016, Springer Science+Business Media New York.},
annote = {Cited by: 42},
author = {Baur, Aaron W.},
doi = {10.1007/s10796-016-9681-7},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Baur - Information Systems Frontiers.pdf:pdf},
issn = {1387-3326},
journal = {Information Systems Frontiers},
keywords = {Open government . Open data . Participation . Publ},
language = {English},
month = {apr},
number = {2},
pages = {231--251},
title = {{Harnessing the social web to enhance insights into people's opinions in business, government and public administration}},
url = {http://link.springer.com/10.1007/s10796-016-9681-7},
volume = {19},
year = {2017}
}
@article{Malomo2017,
abstract = {The concept of Big Data has become very popular over the last decade, with large technology companies successfully building their business models around its exploitation. The public sector in the United Kingdom has tried to follow suit and local governments in particular have tried to introduce new models of service delivery based on the routine extraction of information from their own Big Data. These attempts have been hailed as the beginning of a new era for the public sector where service delivery and commissioning are shaped by data intelligence on local needs and by evidence on the outcomes. In this article we assess this claim and the extent to which it captures the way local governments in the United Kingdom use intelligence from Big Data in light of the structural barriers they face when trying to exploit their data. We also present a case study on the development and deployment of an integrated data model for children services in a large county council in the South-East of England. {\textcopyright} 2016 Policy Studies Organization},
annote = {Cited by: 61},
author = {Malomo, Fola and Sena, Vania},
doi = {10.1002/poi3.141},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Malomo, Sena - Policy & Internet.pdf:pdf},
issn = {1944-2866},
journal = {Policy & Internet},
keywords = {Big Data,Introduction,data ecosystem,integrated data model,local government,public sector,service delivery},
language = {English},
month = {mar},
number = {1},
pages = {7--27},
title = {{Data Intelligence for Local Government? Assessing the Benefits and Barriers to Use of Big Data in the Public Sector}},
url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.141},
volume = {9},
year = {2017}
}
@article{Lee2019,
abstract = {The Internet of Things (IoT) has the potential to transform the way we live, work, do business, and meet the needs of the public. While IoT's potential benefits for economic growth and social welfare appear to be indisputable, IoT faces several technological, social, legal, and regulatory policy challenges, ranging from interoperability and spectrum availability to cybersecurity and privacy. These challenges can and should be addressed by the joint efforts of a wide range of stakeholders from the public and private sector. The advancement of IoT depends in part on how policymakers respond to the opportunities and challenges associated with it. This research aims to identify the potential roles for the government in fostering the advancement of IoT innovation and adoption. To this end, we analyze data collected from 177 documents of public comments submitted to the U.S. National Telecommunications and Information Administration and from a focus group discussion with senior managers. Our content data analysis results in a set of recommendations for the government in terms of general policy principles, specific policy prescriptions, and governance and process approach that facilitate policy development. {\textcopyright} 2018 Elsevier Ltd},
annote = {Cited by: 24},
author = {Lee, Gwanhoo},
doi = {10.1016/j.telpol.2018.12.002},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Lee - Telecommunications Policy.pdf:pdf},
issn = {03085961},
journal = {Telecommunications Policy},
keywords = {Content analysis,Governance,Internet of things,Policy,Process,Public comments,Qualitative research,Regulation,Role of government},
language = {English},
month = {jun},
number = {5},
pages = {434--444},
title = {{What roles should the government play in fostering the advancement of the internet of things?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0308596118303951},
volume = {43},
year = {2019}
}
@article{Wang2020,
abstract = {The issuance and implementation of intellectual property policies have promoted the rapid development of intellectual property intermediary services in China, bringing new opportunities and challenges for public sectors of the government. With their continuous development, Internet of Things (IoT) technology and big data have become the analytical tools widely applied in many technical fields. Through the analysis of IoT data, the optimal resource configuration could be obtained, which would guide both governments and enterprise managers to make scientific decisions in terms of future development. {\textcopyright} 2020 Informa UK Limited, trading as Taylor & Francis Group.},
annote = {Cited by: 9},
author = {Wang, Wenjing},
doi = {10.1080/17517575.2020.1712744},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Wang - Enterprise Information Systems.pdf:pdf},
issn = {1751-7575},
journal = {Enterprise Information Systems},
keywords = {Internet of Things,data analysis,data mining,intellectual property policy},
language = {English},
month = {nov},
number = {9-10},
pages = {1475--1493},
title = {{Data analysis of intellectual property policy system based on Internet of Things}},
url = {https://www.tandfonline.com/doi/full/10.1080/17517575.2020.1712744},
volume = {14},
year = {2020}
}
@article{Androutsopoulou2019,
abstract = {Driven by ‘success stories' reported by private sector firms, government agencies have also started adopting various Artificial Intelligence (AI) technologies in diverse domains (e.g. health, taxation, and education); however, extensive research is required in order to exploit the full potential of AI in the public sector, and leverage various AI technologies to address important problems/needs. This paper makes a contribution in this direction: it presents a novel approach, as well as the architecture of an ICT platform supporting it, for the advanced exploitation of a specific AI technology, namely chatbots, in the public sector in order to address a crucial issue: the improvement of communication between government and citizens (which has for long time been problematic). The proposed approach builds on natural language processing, machine learning and data mining technologies, and leverages existing data of various forms (such as documents containing legislation and directives, structured data from government agencies' operational systems, social media data, etc.), in order to develop a new digital channel of communication between citizens and government. Making use of appropriately structured and semantically annotated data, this channel enables ‘richer' and more expressive interaction of citizens with government in everyday language, facilitating and advancing both information seeking and conducting of transactions. Compared to existing digital channels, the proposed approach is appropriate for a wider range of citizens' interactions, with higher levels of complexity, ambiguity and uncertainty. In close co-operation with three Greek government agencies (the Ministry of Finance, a social security organization, and a big local government organization), this approach has been validated through a series of application scenarios. {\textcopyright} 2018 Elsevier Inc.},
annote = {Cited by: 300},
author = {Androutsopoulou, Aggeliki and Karacapilidis, Nikos and Loukis, Euripidis and Charalabidis, Yannis},
doi = {10.1016/j.giq.2018.10.001},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley//2019 - Androutsopoulou et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
language = {English},
number = {2},
pages = {358 -- 367},
title = {{Transforming the communication between citizens and government through AI-guided chatbots}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054685951&doi=10.1016%2Fj.giq.2018.10.001&partnerID=40&md5=ce8ec8ad15c56a4fce6c0f4d8eaa89ec},
volume = {36},
year = {2019}
}
@article{Anejionu2019,
abstract = {The Spatial Urban Data System (SUDS) is a spatial big data infrastructure to support UK-wide analytics of the social and economic aspects of cities and city-regions. It utilises data generated from traditional as well as new and emerging sources of urban data. The SUDS deploys geospatial technology, synthetic small area urban metrics, and cloud computing to enable urban analytics, and geovisualization with the goal of deriving actionable knowledge for better urban management and data-driven urban decision making. At the core of the system is a programme of urban indicators generated by using novel forms of data and urban modelling and simulation programme. SUDS differs from other similar systems by its emphasis on the generation and use of regularly updated spatially-activated urban area metrics from real or near-real time data sources, to enhance understanding of intra-city interactions and dynamics. By deploying public transport, labour market accessibility and housing advertisement data in the system, we were able to identify spatial variations of key urban services at intra-city levels as well as social and economically-marginalised output areas in major cities across the UK. This paper discusses the design and implementation of SUDS, the challenges and limitations encountered, and considerations made during its development. The innovative approach adopted in the design of SUDS will enable it to support research and analysis of urban areas, policy and city administration, business decision-making, private sector innovation, and public engagement. Having been tested with housing, transport and employment metrics, efforts are ongoing to integrate information from other sources such as IoT, and User Generated Content into the system to enable urban predictive analytics. {\textcopyright} 2019},
annote = {Cited by: 42},
author = {Anejionu, Obinna C.D. and Thakuriah, Piyushimita (Vonu) and McHugh, Andrew and Sun, Yeran and McArthur, David and Mason, Phil and Walpole, Rod},
doi = {10.1016/j.future.2019.03.052},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Anejionu et al. - Future Generation Computer Systems.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Small area assessment,Spatial big data,Spatial urban indicators,Urban analytics,Urban big data infrastructure},
language = {English},
month = {sep},
pages = {456--473},
title = {{Spatial urban data system: A cloud-enabled big data infrastructure for social and economic urban analytics}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X18319046},
volume = {98},
year = {2019}
}
@article{Huang2019,
abstract = {Most recent discussion of the adaptive reuse of school land has focused almost exclusively on repurposing or redeploying vacant school space rather than comprehensively re-planning and constructing the entire school land for the overall needs of society and urban development. The relevant government agencies for school land reuse in Taiwan, such as the Ministry of Education and municipal governments, mostly provide subjective regulations or revitalization provisions for the sustainable development of school resources; however, no specific scientific assessment or a planning procedure has been proposed to revitalize school land. Therefore, constructing a scientific, quantitative, and objective planning framework and procedure is necessary for the adaptive reuse of school land based on the needs of overall society and urban development in order to replace the existing and outdated planning philosophy and to correct prominent shortcomings of past planning operations that were solely in accordance with the qualitative judgment and decision making of official agencies. In this study, we mainly adopted the analytic network process (ANP) and big data, including demographics, facility usage, and social welfare indicators, to assist the Taipei City government to construct or reform land reuse strategies for junior high and elementary schools facing immediate or future closure, consolidation, or downsizing. To take a more realistic approach to improve final decision making, the investigation of expert questionnaires through the ANP was based on the consideration of future trends that were objectively evaluated by big datasets. The novel planning philosophy and concise decision framework for reuse strategies we designed are expected to improve public decision-making transparency, adaptive reuse effectiveness, and quality of urban life. Ultimately, our proposed strategies and suggestions can not only assist local public sectors to promote the policy of adaptive reuse of surplus school lands but also serve as an appropriate blueprint of urban sustainability for the central government in the near future. {\textcopyright} 2018, Springer Nature B.V.},
annote = {Cited by: 16},
author = {Huang, Jhong-You and Wey, Wann-Ming},
doi = {10.1007/s11205-018-1951-y},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Huang, Wey - Social Indicators Research.pdf:pdf},
issn = {0303-8300},
journal = {Social Indicators Research},
keywords = {Reuse of school land {\textperiodcentered} Analytic network process {\textperiodcentered}},
language = {English},
month = {apr},
number = {3},
pages = {1075--1102},
title = {{Application of Big Data and Analytic Network Process for the Adaptive Reuse Strategies of School Land}},
url = {http://link.springer.com/10.1007/s11205-018-1951-y},
volume = {142},
year = {2019}
}
@article{Agarwal2018,
abstract = {<p> <italic>Technology‐driven disruption is taking place at a pace and scale not witnessed before in history. Waves of technology, such as the internet of things, big data, machine learning, and artificial intelligence, are reshaping our personal and professional lives in profound ways. A new world is emerging in which many of the current job classes will disappear, while new ones, requiring entirely different sets of skills, are emerging. Public administrators are unprepared for the challenges they must face in order to cope with this nonincremental and exponential change. Many of the existing government structures and processes that have evolved over the last few centuries will likely become irrelevant in the near future. There is a compelling need to lay the groundwork for governments to rethink how they will be able to best serve their constituents</italic> . </p>},
annote = {Cited by: 107},
author = {Agarwal, P. K.},
doi = {10.1111/puar.12979},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Agarwal - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {nov},
number = {6},
pages = {917--921},
title = {{Public Administration Challenges in the World of AI and Bots}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.12979},
volume = {78},
year = {2018}
}
@article{Choi2018,
abstract = {The prevalence of big data is starting to spread across the public and private sectors however, an impediment to its widespread adoption orientates around a lack of appropriate big data analytics (BDA) and resulting skills to exploit the full potential of big data availability. In this paper, we propose a novel BDA to contribute towards this void, using a fuzzy cognitive map (FCM) approach that will enhance decision-making thus prioritising IT service procurement in the public sector. This is achieved through the development of decision models that capture the strengths of both data analytics and the established intuitive qualitative approach. By taking advantages of both data analytics and FCM, the proposed approach captures the strength of data-driven decision-making and intuitive model-driven decision modelling. This approach is then validated through a decision-making case regarding IT service procurement in public sector, which is the fundamental step of IT infrastructure supply for publics in a regional government in the Russia federation. The analysis result for the given decision-making problem is then evaluated by decision makers and e-government expertise to confirm the applicability of the proposed BDA. In doing so, demonstrating the value of this approach in contributing towards robust public decision-making regarding IT service procurement. {\textcopyright} 2016, The Author(s).},
annote = {Cited by: 54},
author = {Choi, Youngseok and Lee, Habin and Irani, Zahir},
doi = {10.1007/s10479-016-2281-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2018 - Choi, Lee, Irani - Annals of Operations Research.pdf:pdf},
issn = {02545330},
journal = {Annals of Operations Research},
keywords = {Big data analytics,Decision modeling,Fuzzy cognitive map,IT service procurement,simulation},
language = {English},
number = {1-2},
pages = {75 -- 104},
title = {{Big data-driven fuzzy cognitive map for prioritising IT service procurement in the public sector}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982292325&doi=10.1007%2Fs10479-016-2281-6&partnerID=40&md5=1677c94bef289f0e0a4a40409a88a2c5},
volume = {270},
year = {2018}
}
@article{Mohabeer2019,
abstract = {This study examines how big data analytics could optimize the use of public funds while ensuring delivery of quality service by public organizations to the citizens of Mauritius. Political Economic Social Technological (PEST) analysis has been carried out to scan the environment to identify at least two major policies and initiatives corresponding to big data that will be impacting the Mauritian Economy in the next 10 years. Subsequently, causal layered analysis (CLA) has been applied for the two signals to create transformative spaces for the creation of alternative futures. Indeed, the findings have demonstrated that open data initiative and the implementation of e-health project in Mauritius would certainly contribute positively to the government of Mauritius. However, this study has revealed through a matrix diagram for probable futures that the Mauritian government should bring amendments to existing conventional laws through reforms and regulations to fully take advantage of big data analytics applications. This is also one of the recommendations of the Mauritius e-Government 2013–2017–Formulation and Implementation of Data Sharing Policy. Considering only the recent emergence of big data analytics in governments, still there is certain aspect of it that needs careful consideration before the full potential of big data could be realized. This research also highlights the factors that need to be addressed for the successful use of Big Data in this particular context. {\textcopyright} 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
annote = {Cited by: 2},
author = {Mohabeer, Preethivirajsingh and Santally, Mohammad Issack and Sungkur, Roopesh Kevin},
doi = {10.1007/s13132-018-0524-2},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Mohabeer, Santally, Sungkur - Journal of the Knowledge Economy.pdf:pdf},
issn = {1868-7865},
journal = {Journal of the Knowledge Economy},
keywords = {Big data,Causal layer,Mauritius,Public sector},
language = {English},
month = {sep},
number = {3},
pages = {1230--1247},
title = {{An Investigation of the Potential Benefits of Big Data in the Public Sector of Mauritius}},
url = {http://link.springer.com/10.1007/s13132-018-0524-2},
volume = {10},
year = {2019}
}
@article{Schug2020,
abstract = {This case study examines the experience of the interdisciplinary Measuring the Effects of Catch Shares (MECS) project, a five-year demonstration project designed to explore the opportunities and constraints for third-party acquisition, organization, and communication of government fisheries statistics in order to track the ecological, economic, social, and governance outcomes of catch share programs. Catch share programs, whereby fishery managers allocate to private entities percentages of the total amount of fish that can be caught in a year, have been used to manage some US fisheries since the 1990s. Given the high financial stakes of commercial fisheries and the wide-ranging impacts ascribed to these programs, they are among the most controversial and contentious tools of contemporary fisheries management. The goal of the MECS project was to create an interactive, web-based platform for conveying a set of neutral, scientific indicators based on the best available fisheries data that could be used by fishing industry participants, fishery managers, and other interested parties to supplement and inform their own understanding of catch share program effects. The MECS project focused on the effects of two US catch share programs: the Northeast Multispecies Sector Program implemented in 2010 in the Northeast groundfish fishery and the Shorebased IFQ Program implemented in 2011 in the West Coast groundfish trawl fishery. The MECS project encountered data access challenges but ultimately succeeded in developing a website that has been received by members of the private and public sector alike as a useful tool that brings together and communicates disparate information that is not otherwise readily accessible. {\textcopyright} 2020 Elsevier Ltd},
annote = {Cited by: 2},
author = {Schug, Donald M. and Taylor, Peter H. and Iudicello, Suzanne and Swasey, Jill H.},
doi = {10.1016/j.marpol.2020.104272},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Schug et al. - Marine Policy.pdf:pdf},
issn = {0308597X},
journal = {Marine Policy},
keywords = {Catch shares,Data confidentiality,Data visualization,Fisheries management,Performance indicators,Stakeholder engagement},
language = {English},
month = {dec},
pages = {104272},
title = {{Using online data visualization and analysis to facilitate public involvement in management of catch share programs}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0308597X20309180},
volume = {122},
year = {2020}
}
@article{Desouza2020,
abstract = {Artificial intelligence applications in cognitive computing systems can be found in organizations across every market, including chatbots that help customers navigate websites, predictive analytics systems used for fraud detection, and augmented decision-support systems for knowledge workers. In this article, we share reflections and insights from our experience with AI projects in the public sector that can add value to any organization. We organized our findings into four thematic domains—(1) data, (2) technology, (3) organizational, and (4) environmental—and examine them relative to the phases of AI. We conclude with best practices for capturing value with cognitive computing systems. {\textcopyright} 2019 Kelley School of Business, Indiana University},
annote = {Cited by: 143},
author = {Desouza, Kevin C. and Dawson, Gregory S. and Chenok, Daniel},
doi = {10.1016/j.bushor.2019.11.004},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Desouza, Dawson, Chenok - Business Horizons.pdf:pdf},
issn = {00076813},
journal = {Business Horizons},
keywords = {Artificial intelligence applications,Cognitive computing systems,Innovation management,Technology adoption},
language = {English},
month = {mar},
number = {2},
pages = {205--213},
title = {{Designing, developing, and deploying artificial intelligence systems: Lessons from and for the public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0007681319301582},
volume = {63},
year = {2020}
}
@article{Mattei2020,
abstract = {Digital healthcare promises to achieve cost-efficiency gains, improve clinical effectiveness, support better public sector governance by enhancing transparency and accountability, and increase confidence in medical diagnoses, especially in the field of oncology. This article aims to discuss the benefits offered by digital technologies in tax-based European healthcare systems against the backdrop of structural bureaucratic rigidities and a slow pace of implementation. Artificial intelligence (AI) will transform the existing delivery of healthcare services, inducing a redesign of public accountability systems and the traditional relationships between professionals and patients. Despite legitimate ethical and accountability concerns, which call for clearer guidance and regulation, digital governance of healthcare is a powerful means of empowering patients and improving their medical treatment in terms of quality and effectiveness. On the path to better health, the use of digital technologies has moved beyond the back office of administrative processes and procedures, and is now being applied to clinical activities and direct patient engagement. {\textcopyright} 2020 The Author(s).},
annote = {Cited by: 3},
author = {Mattei, Paola},
doi = {10.1186/s13584-020-0361-1},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Mattei - Israel Journal of Health Policy Research.pdf:pdf},
issn = {20454015},
journal = {Israel Journal of Health Policy Research},
keywords = {Accountability,Artificial intelligence,Digital health,Health care organizations,Patients' engagement,Tax-funded health care systems},
language = {English},
number = {1},
title = {{Digital governance in tax-funded European healthcare systems: From the Back office to patient empowerment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078000204&doi=10.1186%2Fs13584-020-0361-1&partnerID=40&md5=9b3f60175ef8fd242ecebc3b8934cad4},
volume = {9},
year = {2020}
}
@article{Al-Ruithe2020,
abstract = {Businesses have grown more sophisticated in their use of data, which drives new demands that require different ways to handle this data. Data management solutions on their own are becoming very expensive and unable to cope with the reality of everlasting data complexity. Forward-thinking organisations believe that the only way to solve the data problem will be the implementation of effective data governance. Attempts to govern data failed before, as they were driven by information technology (IT), and affected by rigid processes and fragmented activities carried out on a system-by-system basis. Until very recently, governance remained mostly informal, with very ambiguous and generic regulations in silos around specific enterprise repositories, lacking structure and the wider support of the organisation. Despite its highly recognised importance, the area of data governance is still underdeveloped and under-researched. In the cloud computing context, the cloud brings new issues of data governance, where the loss of governance is one of the top risks of cloud computing. Thus, before adopting the cloud, the organisations should develop a cloud data governance programme. It is important, therefore, to understand the enabling factors for successful implementation of cloud data governance in organisations. However, as every organisation has its own constraints and requirements, the phrase ‘no one size fits all' applies in this case. This study focuses on the case of the public sector in the Kingdom of Saudi Arabia. Therefore, the aim of this research is to identify the enabling factors in adopting and implementing cloud data governance in the Saudi public sector. The study's sample covered the largest and most important Saudi public sector organisations, with questionnaires distributed to relevant employees. The results of the study were based on 206 respondents, and structural equation modelling (SEM) was used to evaluate these results. {\textcopyright} 2018 Elsevier B.V.},
annote = {Cited by: 11},
author = {Al-Ruithe, Majid and Benkhelifa, Elhadj},
doi = {10.1016/j.future.2017.12.057},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Al-Ruithe, Benkhelifa - Future Generation Computer Systems.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud computing,Cloud data governance,Data governance,Data science,Saudi Arabia,Saudi vision 2030,Structural Equation Modelling (SEM)},
language = {English},
month = {jun},
pages = {1061--1076},
title = {{Determining the enabling factors for implementing cloud data governance in the Saudi public sector by structural equation modelling}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X17321489},
volume = {107},
year = {2020}
}
@article{Rocca2020,
abstract = {Purpose: Because of the expansion of the internet and Web 2.0 phenomenon, new challenges are emerging in the disclosure practises adopted by organisations in the public-sector. This study aims to examine local governments' (LGOs) use of social media (SM) in disclosing environmental actions/plans/information as a new way to improve accountability to citizens to obtain organisational legitimacy and the related sentiment of citizens' judgements. Design/methodology/approach: This paper analyses the content of 39 Italian LGOs' public pages on Facebook. After the distinction between five classes of environmental issues (air, water, energy, waste and territory), an initial study is performed to detect possible sub-topics applying latent Dirichlet allocation. Having a list of posts related to specific environmental themes, the researchers computed the sentiment of citizens' comments. To measure sentiment, two different approaches were implemented: one based on a lexicon dictionary and the other based on convolutional neural networks. Findings: Facebook is used by LGOs to disclose environmental issues, focussing on their main interest in obtaining organisational legitimacy, and the analysis shows an increasing impact of Web 2.0 in the direct interaction of LGOs with citizens. On the other hand, there is a clear divergence of interest on environmental topics between LGOs and citizens in a dialogic accountability framework. Practical implications: Sentiment analysis (SA) could be used by politicians, but also by managers/entrepreneurs in the business sector, to analyse stakeholders' judgements of their communications/actions and plans on corporate social responsibility. This tool gives a result on time (i.e. not months or years after, as for the reporting system). It is cheaper than a survey and allows a first “photograph” of stakeholders' sentiment. It can also be a useful tool for supporting, developing and improving environmental reporting. Originality/value: To the best of the authors' knowledge, this paper is one of the first to apply SA to environmental disclosure via SM in the public sphere. The study links modern techniques in natural language processing and machine learning with the important aspects of environmental communication between LGOs and citizens. {\textcopyright} 2020, Laura Rocca, Davide Giacomini and Paola Zola.},
annote = {Cited by: 18},
author = {Rocca, Laura and Giacomini, Davide and Zola, Paola},
doi = {10.1108/MEDAR-09-2019-0563},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Rocca, Giacomini, Zola - Meditari Accountancy Research.pdf:pdf},
issn = {2049372X},
journal = {Meditari Accountancy Research},
keywords = {Dialogical accountability,Environment,Facebook,Local governments,Natural language processing,Organisational legitimacy,Sentiment analysis},
language = {English},
number = {3},
pages = {617 -- 646},
title = {{Environmental disclosure and sentiment analysis: state of the art and opportunities for public-sector organisations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089603646&doi=10.1108%2FMEDAR-09-2019-0563&partnerID=40&md5=2893337cbc86223283a88a0ddac02f9d},
volume = {29},
year = {2020}
}
@article{Uras2020,
abstract = {A UN report states that in 2050, about 70% of the total world population will live in cities. This increases the complexity of the services that the local public administrations have to provide the citizens with to keep an acceptable level of quality of life. For an appropriate design, deployment and management of these services, there is the need for tools to extract data on how the people move, which activities they conduct out and their behaviour (in an anonymous way). This need has justified extensive efforts towards the design of effective solutions for extracting this information. In this work, we present the People Mobility Analytics (PmA) solution, which collects probe requests generated by Wi-Fi devices when scanning the radio channels to detect Access Points. The PmA system processes the collected data to extract key insights on the people mobility, such as: crowd density per area of interest, people flows, time of permanence, time of return, heat maps, origin-destination matrices and estimation of people positions. The major novelty with respect to the state of the art is related to new powerful indicators that are needed for some key city services, such as security management and people transport services, and the experimental activities carried out in real scenarios. {\textcopyright} 2020 Elsevier Ltd},
annote = {Cited by: 18},
author = {Uras, Marco and Cossu, Raimondo and Ferrara, Enrico and Liotta, Antonio and Atzori, Luigi},
doi = {10.1016/j.jclepro.2020.122084},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Uras et al. - Journal of Cleaner Production.pdf:pdf},
issn = {09596526},
journal = {Journal of Cleaner Production},
keywords = {Crowd density,Crowdsensed data,Mobility patterns,Passive Wi-Fi sniffer,Pedestrian flow,Trajectory mining},
language = {English},
month = {oct},
pages = {122084},
title = {{PmA: A real-world system for people mobility monitoring and analysis based on Wi-Fi probes}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652620321314},
volume = {270},
year = {2020}
}
@article{Fatima2020,
abstract = {Nations have recognized the transformational potential of artificial intelligence (AI). Advances in AI will impact all facets of society. A spate of recently released national strategic AI plans provides valuable insights into how nations are considering their future trajectories. These strategic plans offer a rich source of evidence to understand national-level strategic actions, both proactive and reactive, in the face of rapid technological innovation. Based on a comprehensive content analysis of thirty-four national strategic plans, this article reports on (1) opportunities for AI to modernize the public sector and enhance industry competitiveness, (2) the role of the public sector in ensuring that the two most critical elements of AI systems, data and algorithms, are managed responsibly, (3) the role of the public sector in the governance of AI systems, and (4) how nations plan to invest in capacity development initiatives to strengthen their AI capabilities. {\textcopyright} 2020 Economic Society of Australia, Queensland},
annote = {Cited by: 77},
author = {Fatima, Samar and Desouza, Kevin C. and Dawson, Gregory S.},
doi = {10.1016/j.eap.2020.07.008},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Fatima, Desouza, Dawson - Economic Analysis and Policy.pdf:pdf},
issn = {03135926},
journal = {Economic Analysis and Policy},
keywords = {Artificial intelligence,Autonomous systems,Intelligent systems,Public agencies,Science and technology policy,Strategic plans,Technological innovation},
language = {English},
month = {sep},
pages = {178--194},
title = {{National strategic artificial intelligence plans: A multi-dimensional analysis}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0313592620304021},
volume = {67},
year = {2020}
}
@article{Fertier2020,
abstract = {An effective crisis response requires up-to-date information. The crisis cell must reach for new, external, data sources. However, new data lead to new issues: their volume, veracity, variety or velocity cannot be managed by humans only, especially under high stress and time pressure. This paper proposes (i) a framework to enhance situation awareness while managing the 5Vs of Big Data, (ii) general principles to be followed and (iii) a new architecture implementing the proposed framework. The latter merges event-driven and model-driven architectures. It has been tested on a realistic flood scenario set up by official French services. {\textcopyright} 2019, {\textcopyright} 2019 Informa UK Limited, trading as Taylor & Francis Group.},
annote = {Cited by: 10},
author = {Fertier, Audrey and Montarnal, Aur{\'{e}}lie and Barthe-Delano{\"{e}}, Anne-Marie and Truptil, S{\'{e}}bastien and B{\'{e}}naben, Fr{\'{e}}d{\'{e}}rick},
doi = {10.1080/17517575.2019.1691268},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Fertier et al. - Enterprise Information Systems.pdf:pdf},
issn = {1751-7575},
journal = {Enterprise Information Systems},
keywords = {EIS for public sector,Situation awareness,complex event processing,crisis management,event-driven architecture,model-driven architecture},
language = {English},
month = {jul},
number = {6},
pages = {769--796},
title = {{Real-time data exploitation supported by model- and event-driven architecture to enhance situation awareness, application to crisis management}},
url = {https://www.tandfonline.com/doi/full/10.1080/17517575.2019.1691268},
volume = {14},
year = {2020}
}
@article{Conejero2021,
abstract = {Education and employment are key aspects of a country's well-being. Governments expend valuable resources on designing education plans and employment programs. These two aspects are usually analysed separately, although, as they are closely related, considering them together might improve their efficacy. The problem lies, at least in part, in the fact that different public entities manage their own data with their own isolated systems, and do not develop joint educational and employment policies. In order to facilitate working towards this goal, in this manuscript, we make use of Data Engineering, Data Visualization, and Intelligent Data Analytics methods to create a decision support system for the Government of Extremadura. Extremadura is a European Union Objective 1 region in Spain with high rates of unemployment and secondary school drop-out. Data Engineering is used to create a Data Warehouse that unifies the different data sources into a central repository for quick access and control. This allows dealing with the challenge of transforming, processing, storing and accessing the data. Data Visualization techniques are applied to create an interactive dashboard that assists users in analysing and interpreting the data in the Data Warehouse repository. Thus, charts, diagrams, and maps are created specifically to help technical or political decision-makers. Finally, Intelligent Data Analytics techniques are used to incorporate Association Rules into the visualization dashboard. Its goal is to identify associations, relationships, and patterns in data that, at least in plain sight, are not readable or interpretable by humans. It does this by inferring knowledge that humans cannot pick out by themselves. As a result, a complete system was defined and implemented to support public administrations in their decision-making and definition of precise evidence-based policies in the areas of education and employment. In particular, it allows the definition of unified strategies to reduce the unemployment rate. {\textcopyright} 2020 Elsevier Ltd},
annote = {Cited by: 10},
author = {Conejero, Jose Mar{\'{i}}a and Preciado, Juan Carlos and Fern{\'{a}}ndez-Garc{\'{i}}a, Antonio Jes{\'{u}}s and Prieto, Alvaro E. and Rodr{\'{i}}guez-Echeverr{\'{i}}a, Roberto},
doi = {10.1016/j.eswa.2020.114509},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Conejero et al. - Expert Systems with Applications.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Association rules,Data mining,Decision-making tool,Education-employment,Intelligent systems,Machine learning},
language = {English},
month = {may},
pages = {114509},
title = {{Towards the use of Data Engineering, Advanced Visualization techniques and Association Rules to support knowledge discovery for public policies}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417420311532},
volume = {170},
year = {2021}
}
@article{Merhi2021,
abstract = {This study aims to fill a gap in the literature by identifying, defining, and evaluating the critical success factors that impact the implementation of data intelligence in the public sector. Fourteen factors were identified, and then divided into three categories: organization, process, and technology. We used the analytical hierarchy process, a quantitative method of decision-making, to evaluate the importance of the factors presented in the study using data collected from nine experts. The results showed that technology, as a category, is the most important. The analysis also indicated that project management, information systems & data, and data quality are the most important factors among all fourteen critical success factors. We discuss the implications of the analysis for practitioners and researchers in the paper. {\textcopyright} 2021},
annote = {Cited by: 21},
author = {Merhi, Mohammad I.},
doi = {10.1016/j.techfore.2021.121180},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Merhi - Technological Forecasting and Social Change.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {AHP,Data analytics,Data intelligence,Public sector,Success factors,Systems implementation},
language = {English},
month = {dec},
pages = {121180},
title = {{Evaluating the critical success factors of data intelligence implementation in the public sector using analytical hierarchy process}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162521006132},
volume = {173},
year = {2021}
}
@article{Chen2021a,
abstract = {Background: The use of digital health technologies was an integral part to China's early response to coronavirus disease 2019 (COVID-19). Existing literatures have analyzed and discussed implemented digital health innovations from the perspective of technologies, whereas how policy mechanisms contributed to the formulation of the digital health landscape for COVID-19 was overlooked. This study aimed to examine the contexts and key mechanisms in China's rapid mobilization of digital health interventions in response to COVID-19, and to document and share lessons learned. Methods: Policy documents were identified and retrieved from government portals and recognized media outlets. Data on digital health interventions were collected through three consecutive surveys administered between 23 January 2020 and 31 March 2020 by China Academy of Information and Communication Technology (CAICT) affiliated to the Ministry of Industry and Information Technology (MIIT). Participants were member companies of the Internet Health alliance established by MIIT and the National Health Commission (NHC) in June 2016. Self-report digital interventions focusing on social and economic recovery were excluded. Two hundred and sixty-six unique digital health interventions meeting our criteria were extracted from 175 narratives on digital health interventions submitted by 116 participating companies. Thematic analysis was conducted to describe the scope and priority of policies advocating for the use of digital health technologies and the implementation pattern of digital health interventions. Data limitations precluded an evaluation of the impact of digital health interventions over a longer time frame. Results: Between January and March 2020, national policy directives promoting the use of digital technologies for the containment of COVID-19 collectively advocated for use cases in emergency planning and preparedness, public health response, and clinical services. Interventions to strengthen clinical services were mentioned more than the other two themes (n = 15, 62.5% (15/24)). Using digital technologies for public health response was mentioned much less than clinical services (n = 5, 20.8% (5/24)). Emergency planning and preparedness was least mentioned (n = 4, 16.7% (4/24)). Interventions in support of clinical services disproportionately favored healthcare facilities in less resource-constraint settings. Digital health interventions shared the same pattern of distribution. More digital health technologies were implemented in clinical services (n = 103, 38.7% (103/266)) than that in public health response (n = 91, 34.2% (91/266)). Emergency planning and preparedness had the least self-reported digital health interventions (n = 72, 27.1% (72/266)). We further identified case studies under each theme in which the wide use of digital health technologies highlighted contextual factors and key enabling mechanisms. Conclusions: The contextual factors and key enabling mechanisms through the use of policy instruments to promote digital health interventions for COVID-19 in China include pathway of policy directives influencing the private sector using a decentralized system, the booming digital health landscape before COVID-19, agility of the public sector in introducing regulatory flexibilities and incentives to mobilize the private sector. {\textcopyright} 2021},
annote = {Cited by: 14},
author = {Chen, Mengji and Xu, Shan and Husain, Lewis and Galea, Gauden},
doi = {10.1016/j.imed.2021.03.001},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Chen et al. - Intelligent Medicine.pdf:pdf},
issn = {26671026},
journal = {Intelligent Medicine},
keywords = {Artificial intelligence,Big data,Coronavirus disease 2019,Digital health,Telemedicine},
language = {English},
month = {may},
number = {1},
pages = {29--36},
title = {{Digital health interventions for COVID-19 in China: a retrospective analysis}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2667102621000024},
volume = {1},
year = {2021}
}
@article{Shah2021,
abstract = {The public sector, private firms, business community, and civil society are generating data that is high in volume, veracity, velocity and comes from a diversity of sources. This kind of data is known as big data. Public Administrations (PAs) pursue big data as “new oil” and implement data-centric policies to transform data into knowledge, to promote good governance, transparency, innovative digital services, and citizens' engagement in public policy. From the above, the Government Big Data Ecosystem (GBDE) emerges. Managing big data throughout its lifecycle becomes a challenging task for governmental organizations. Despite the vast interest in this ecosystem, appropriate big data management is still a challenge. This study intends to fill the above-mentioned gap by proposing a data lifecycle framework for data-driven governments. Through a Systematic Literature Review, we identified and analysed 76 data lifecycles models to propose a data lifecycle framework for data-driven governments (DaliF). In this way, we contribute to the ongoing discussion around big data management, which attracts researchers' and practitioners' interest. {\textcopyright} 2021, The Author(s).},
annote = {Cited by: 21},
author = {Shah, Syed Iftikhar Hussain and Peristeras, Vassilios and Magnisalis, Ioannis},
doi = {10.1186/s40537-021-00481-3},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Shah, Peristeras, Magnisalis - Journal of Big Data.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {Big data,Data lifecycle,Data management,Data-driven government,Government Big Data Ecosystem},
language = {English},
number = {1},
title = {{DaLiF: a data lifecycle framework for data-driven governments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107949250&doi=10.1186%2Fs40537-021-00481-3&partnerID=40&md5=7e2b6c38f966b0ec182fc8db046b6f01},
volume = {8},
year = {2021}
}
@article{Aerts2021,
abstract = {Rising rates of NCDs threaten fragile healthcare systems in low- and middle-income countries. Fortunately, new digital technology provides tools to more effectively address the growing dual burden of disease. Two-thirds of the world's population subscribed to mobile services by the end of 2018, while the falling price of connectivity and the 5G networks rollout promise to accelerate the use of digital technology. Properly leveraged, we can employ digital solutions and applications to transform health systems from reactive to proactive and even preventive, helping people stay healthy. With artificial intelligence (AI), health systems can be made more predictive by detecting risk factors and helping health professionals respond faster to prevent disease. Yet this rapid pace of growth has also complicated the digital health landscape. Myriad digital health apps compete and overlap in the public and private sectors, and significant gaps in the collection and analysis of digital data threaten to leave some behind. Established in 2010, the Broadband Commission for Sustainable Development is led by ITU and UNESCO and advocates for the transformational impact of broadband technologies for development. Its working group on digital and AI in health, co-chaired by the Novartis Foundation and at different times Nokia, Intel and Microsoft, identifies best practices for countries to realize the potential of digital technology in health and care. Interviewing more than 100 key stakeholders and reviewing over 200 documents, the Working Group set out to identify common challenges that countries face in implementing digital health solutions, and to develop a framework that countries can use to build systems for supporting digital health solutions. Common challenges include a lack of coordination leading to fragmented digital health solutions; lack of systems and workforce capacity to manage data and digital technology, and inadequate financing to support digital health. The working group proposes six building blocks for digital health systems: formulate and execute a national digital health strategy; create policy and regulatory frameworks that support innovation while protecting security and privacy; ensure access to digital infrastructure; ensure interoperability of digital health system components; establish effective partnerships; and sustain adequate financing. {\textcopyright} 2021},
annote = {Cited by: 24},
author = {Aerts, Ann and Bogdan-Martin, Doreen},
doi = {10.1016/j.ijmedinf.2021.104456},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Aerts, Bogdan-Martin - International Journal of Medical Informatics.pdf:pdf},
issn = {13865056},
journal = {International Journal of Medical Informatics},
keywords = {Digital technology,Health systems,Intersectoral collaboration,Noncommunicable diseases,Sustainable Development Goals},
language = {English},
month = {jun},
pages = {104456},
title = {{Leveraging data and AI to deliver on the promise of digital health}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1386505621000824},
volume = {150},
year = {2021}
}
@article{Rosecky2021,
abstract = {Nowadays, the European municipal waste management policy based on the circular economy paradigm demands the closing of material and financial loops at all territorial levels of public administration. The effective planning of treatment capacities (especially sorting plants, recycling, and energy recovery facilities) and municipal waste management policy requires an accurate prognosis of municipal waste generation, and therefore, the knowledge of behavioral, socio-economic, and demographic factors influencing the waste management (and recycling) behavior of households, and other municipal waste producers. To enable public bodies at different territorial levels to undertake an effective action resulting in circular economy we evaluated various factors influencing the generation of municipal waste fractions at regional, micro-regional and municipal level in the Czech Republic. Principal components were used as input for traditional models (multivariable linear regression, generalized linear model) as well as tree-based machine learning models (regression trees, random forest, gradient boosted regression trees). Study results suggest that the linear regression model usually offers a good trade-off between model accuracy and interpretability. When the most important goal of the prediction is supposed to be accuracy, the random forest is generally the best choice. The quality of developed models depends mostly on the chosen territorial level and municipal waste fraction. The performance of these models deteriorates significantly for lower territorial levels because of worse data quality and bigger variability. Only the age structure seems to be important across territorial levels and municipal waste fractions. Nevertheless, also other factors are of high significance in explaining the generation of municipal waste fractions at different territorial levels (e.g. number of economic subjects, expenditures, population density and the level of education). Therefore, there is not one single effective public policy dealing with circular economy strategy that fits all territorial levels. Public representatives should focus on policies effective at specific territorial level. However, performance of the models is poor for lower territorial levels (municipality and micro-regions). Thus, results for municipalities and micro-regions are weak and should be treated as such. {\textcopyright} 2021 Elsevier Ltd},
annote = {Cited by: 39},
author = {Roseck{\'{y}}, Martin and {\v{S}}ompl{\'{a}}k, Radovan and Slav{\'{i}}k, Jan and Kalina, Jiř{\'{i}} and Bulkov{\'{a}}, Gabriela and Bedn{\'{a}}ř, Josef},
doi = {10.1016/j.jenvman.2021.112584},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Roseck{\'{y}} et al. - Journal of Environmental Management.pdf:pdf},
issn = {03014797},
journal = {Journal of Environmental Management},
keywords = {Machine learning,Municipal waste generation,Public policy,Regression modelling,Socio-economic factors,Territorial levels},
language = {English},
title = {{Predictive modelling as a tool for effective municipal waste management policy at different territorial levels}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105836019&doi=10.1016%2Fj.jenvman.2021.112584&partnerID=40&md5=c8d07d817d38ecd149aca24836cb81d4},
volume = {291},
year = {2021}
}
@article{Chen2021,
abstract = {Public sectors are utilizing AI-based self-service technology (SST) at an accelerating rate, given its potential for improving work efficiency and user experience, reducing service costs, and relieving human workloads. However, there is a limited understanding of the factors influencing citizens' user experience when services supported by AI-based SST are provided. Thus, with insights from the Consumer Value Theory, this paper aims to explore the factors that are important to AI-based SST user experience and the conditional role of trust in government. The on-site survey of 379 citizens in a public service center in China indicates that user experience positively relates to personalization and aesthetics and negatively associates with perceived time spent on the AI-based self-service machines. In addition, the results suggest that citizens with more trust in government are more likely to have a pleasant experience coming from AI-based SST's personalization and aesthetics. Public managers should ensure that the AI-based SST is aesthetically appealing and should be able to personalize the delivery of the right contents to the right person at the right time. Furthermore, they should always prioritize cultivating more trust from citizens to achieve a more positive user experience. {\textcopyright} 2020 Elsevier Inc.},
annote = {Cited by: 92},
author = {Chen, Tao and Guo, Wenshan and Gao, Xian and Liang, Zhehao},
doi = {10.1016/j.giq.2020.101520},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Chen et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Self-service technology,Trust in government,User experience},
language = {English},
month = {oct},
number = {4},
pages = {101520},
title = {{AI-based self-service technology in public service delivery: User experience and influencing factors}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X20302999},
volume = {38},
year = {2021}
}
@article{Cong2021,
abstract = {Current debates over digital contact tracing mainly focus on the tools and experiences in the West. China's health code, while often seen as one of the earliest and most widely adopted apps since the outbreak of COVID-19, has not been studied specifically. This article provides a detailed analysis of the health code, draws comparison with the contact tracing apps developed by Google and Apple, and seeks to understand the specifications and contradictions internal to the health code's development and deployment in China. Looking at both technical features and the mode and process of its adoption, the article argues that the health code is strictly speaking not a contact tracing tool, but a technology of population control which is integrated in traditional forms of control and facilitates the enhancement of such control. As a technology of ruling the population, rather than the virus as such, the health code also reveals crucial problems in the modernization and informatization of the state governance and public administration. A critique on the health code solely informed by privacy and personal data protection runs the risk of being co-opted by the government and technology companies deploying such tools to expand their surveillance and regulatory power. Copyright {\textcopyright} 2021 Cong.},
annote = {Cited by: 29},
author = {Cong, Wanshu},
doi = {10.3389/fpos.2021.627959},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Cong - Frontiers in Political Science.pdf:pdf},
issn = {26733145},
journal = {Frontiers in Political Science},
keywords = {big data,contact tracing,digital platform,health emergency,privacy,surveillance},
language = {English},
title = {{From Pandemic Control to Data-Driven Governance: The Case of China's Health Code}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118887215&doi=10.3389%2Ffpos.2021.627959&partnerID=40&md5=7f33ab4bc6e1a8f866c51a9640ce3ce4},
volume = {3},
year = {2021}
}
@article{Scannapieco2021,
abstract = {The paper highlights how each step of a data science pipeline can be performed in a “responsible” way, taking into account privacy, ethics, and quality issues. Several examples from the Italian public sector contribute to clarifying how data collections and data analyses can be carried out under a responsible view. {\textcopyright} 2021 The Authors},
annote = {Cited by: 0},
author = {Scannapieco, Monica and Virgillito, Antonino},
doi = {10.1016/j.patter.2021.100393},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Scannapieco, Virgillito - Patterns(2).pdf:pdf},
issn = {26663899},
journal = {Patterns},
keywords = {Artificial intelligence,Self-service technology,Trust in government,User experience},
language = {English},
month = {dec},
number = {12},
pages = {100393},
title = {{How to be responsible in all the steps of a data science pipeline: The case of the Italian public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2666389921002609},
volume = {2},
year = {2021}
}
@article{Wirtz2022,
abstract = {This study addresses the growing challenge of governing artificial intelligence (AI) arising from the risks that it increasingly poses to the public sector and society. Based on an in-depth literature analysis, we first identify AI risks and guidelines and classify them into six categories, including technological, data, and analytical risks and guidelines, informational and communicational risks and guidelines, economic risks and guidelines, social risks and guidelines, ethical risks and guidelines, as well as legal and regulatory risks and guidelines. These risks and guidelines are then elaborated and transferred into a four-layered conceptual framework for AI governance. The framework interrelates AI risks and AI guidelines by means of a risk management and guidance process, resulting in an AI governance layer depicting the process for implementation of customised risk mitigation guidelines. The framework constitutes a comprehensive reference point for developing and implementing AI governance strategies and measures in the public sector. {\textcopyright} 2022 Elsevier Inc.},
annote = {Cited by: 38},
author = {Wirtz, Bernd W and Weyerer, Jan C and Kehl, Ines},
doi = {10.1016/j.giq.2022.101685},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Wirtz, Weyerer, Kehl - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Framework,Governance,Guidelines,Regulation,Risks},
language = {English},
number = {4},
title = {{Governance of artificial intelligence: A risk and guideline-based integrative framework}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126090396&doi=10.1016%2Fj.giq.2022.101685&partnerID=40&md5=ba7bab1e031c65b0fd444ce43f61599f},
volume = {39},
year = {2022}
}
@article{Ahn2022,
abstract = {Government employees play a critical role in adopting and using new technologies in government, and their attitude and willingness to use them matter in creating a sustainable and meaningful digital transformation. This study explores how the perception of government employees shapes the willingness to support the use of AI technologies in government. Based on a survey data on current government employees in the U.S., our analysis reveals that the willingness to implement and use AI technologies in government was contingent upon a series of positive and negative perceptions about the new technologies, long-term outlook on the role of AI technologies in society, and the familiarity and experience in using some form of AI applications in the past. In particular, the perception of AI enhancing the efficiency and effectiveness of the work and a positive and longer-term outlook on AI's future about human labor (as an assistant or a competitor), the perception of the technology's ultimate harm or benefit (does it harm or benefit humanity), its ability to eventually make ethical and moral judgments influenced the willingness to support AI technologies in government. A substantial proportion of the government employees in the survey sample responded that they had experienced using some form of AI applications in their work and this familiarity had a strong positive influence on their support for AI. Our findings point to the importance of training the government employees in AI technologies to improve their understanding and perception about the new technologies as well as their potentials in government that will foster a culture of innovation toward sustainable and impactful digital transformation. {\textcopyright} 2021 Elsevier Inc.},
annote = {Cited by: 73},
author = {Ahn, Michael J. and Chen, Yu-Che},
doi = {10.1016/j.giq.2021.101664},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Ahn, Chen - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Frontier technology,Perception Adoption},
language = {English},
month = {apr},
number = {2},
pages = {101664},
title = {{Digital transformation toward AI-augmented public administration: The perception of government employees and the willingness to use AI in government}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X21001003},
volume = {39},
year = {2022}
}
@article{Bodo2022,
abstract = {Emerging technologies permeate and potentially disrupt a wide spectrum of our social, economic, and political relations. Various state institutions, including education, law enforcement, and healthcare, increasingly rely on technical components, such as automated decision-making systems, e-government systems, and other digital tools to provide cheap, efficient public services, and supposedly fair, transparent, disinterested, and accountable public administration. The increased interest in various blockchain-based solutions from central bank digital currencies, via tokenized educational credentials, and distributed ledger-based land registries to self-sovereign identities is the latest, still mostly unwritten chapter in a long history of standardized, objectified, automated, technocratic, and technologized public administration. The rapid, (often) unplanned, and uncontrolled technologization of public services (as happened in the hasty adoption of distance-learning and teleconferencing systems during Corona Virus Disease (COVID) lockdowns) raises complex questions about the use of novel technological components, which may or may not be ultimately adequate for the task for which they are used. The question whether we can trust the technical infrastructures the public sector uses when providing public services is a central concern in an age where trust in government is declining: If the government's artificial intelligence system that detects welfare fraud fails, the public's confidence in the government is ultimately hit. In this paper, we provide a critical assessment of how the use of potentially untrustworthy (private) technological systems including blockchain-based systems in the public sector may affect trust in government. We then propose several policy options to protect the trust in government even if some of their technological components prove fundamentally untrustworthy.},
annote = {Cited by: 13},
author = {Bod{\'{o}}, Bal{\'{a}}zs and Janssen, Heleen},
doi = {10.1093/polsoc/puac019},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley//2022 - Bod{\'{o}}, Janssen - Policy and Society.pdf:pdf},
issn = {1449-4035},
journal = {Policy and Society},
keywords = {blockchain,emerging technologies,public policy,risk-based policy,trust},
language = {English},
month = {jul},
number = {3},
pages = {414--429},
title = {{Maintaining trust in a technologized public sector}},
url = {https://academic.oup.com/policyandsociety/article/41/3/414/6586682},
volume = {41},
year = {2022}
}
@article{Criado2022,
abstract = {Artificial Intelligence (AI) policies and strategies have been designed and adopted in the public sector during the last few years, with Chief Information Officers (CIOs) playing a key role. Using socio-cognitive and institutional approaches on Information Technologies (ITs) in (public) organizations, we consider that the assumptions, expectations, and knowledge (technological frames) of those in charge (CIOs) of designing AI strategies are guiding the future of these emerging systems in the public sector. In this study, we focus on the technological frames of CIOs in the largest Spanish local governments. Based on a survey administered to CIOs leading IT departments, this article presents original data about their technological frames on AI. Our results: (1) provide insights about how CIOs tend to focus on the technological features of AI implementation while often overlook some of the social, political, and ethical challenges in the public sector; (2) expand the theory on AI by enabling the construction of propositions and testable hypotheses for future research in the field. Therefore, the comparative study of technological frames will be key to successfully design and implement AI policies and strategies in the public sector and to tackle future challenges and opportunities. {\textcopyright} 2022 The Authors},
annote = {Cited by: 24},
author = {Criado, J Ignacio and {O.de Zarate-Alcarazo}, Lucia},
doi = {10.1016/j.giq.2022.101688},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Criado, O.de Zarate-Alcarazo - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial Intelligence,Chief Information Officers,Exploratory research,Governance,Public administration,Technological frames},
language = {English},
number = {3},
title = {{Technological frames, CIOs, and Artificial Intelligence in public administration: A socio-cognitive exploratory study in Spanish local governments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126864088&doi=10.1016%2Fj.giq.2022.101688&partnerID=40&md5=a69857fd60b8092c99df31f6439403b3},
volume = {39},
year = {2022}
}
@article{Hong2022,
abstract = {This study explores the determinants of digital innovation in the public sector. Focusing specifically on new digital technologies, such as big data, artificial intelligence, Internet of things, and augmented reality, we explained the wide variation in how Korean local governments used these technologies to transform their services. We found support for four theoretical mechanisms. First, our findings support the existence of demand-pull innovation in the public sector: public organizations respond to citizen demands or needs for innovation. Second, we also find support for an electoral incentive hypothesis, which posits that local governments' motivation for digital innovation is influenced by local politicians' electoral incentives. Third, our results show the existence of isomorphic pressure as a driver for public sector innovation: public organizations emulate their neighbors in adopting innovative practices. Fourth, the results support the upper echelons theory, as younger policymakers are more active innovators. {\textcopyright} 2022 Elsevier Inc.},
annote = {Cited by: 25},
author = {Hong, Sounman and Kim, Sun Hyoung and Kwon, Myungjung},
doi = {10.1016/j.giq.2022.101723},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Hong, Kim, Kwon - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Digital innovation,Electoral competitiveness,Public sector innovation,Upper echelons theory},
language = {English},
number = {4},
title = {{Determinants of digital innovation in the public sector}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133403917&doi=10.1016%2Fj.giq.2022.101723&partnerID=40&md5=f4f02fdfa1824d074697e0abbbbf63a5},
volume = {39},
year = {2022}
}
@article{Yesmagambetov2022,
abstract = {The issue of public procurement effectiveness is becoming increasingly relevant in the context of the observed budget deficit in Kazakhstan. In this article, business processes related to ensuring the best combination of low price and quality in public procurement as the main indicators of procurement efficiency are studied and described in more depth. Considering the problems of public procurement efficiency, many researchers analyze the supplier identification stage. However, in the procurement of works, the execution phase is equally, if not more, important for efficiency. Analysis of the work execution process in Kazakhstan revealed problems related to quality control of the work performed and the construction materials used, as well as limited competition in their procurement. The high degree of the human factor's presence in the quality assurance process and the low availability of information about the demand for goods creates the risk of purchasing poor-quality goods at a high price. While the effectiveness of using big data in the decision-making process is universally proven, information in the public procurement system is not accumulated properly. In this regard, to ensure the best combination of price and quality of work, the authors propose a model of public procurement of works using digital tools. {\textcopyright} 2022 Uspekhi Khimii, ZIOC RAS, Russian Academy of Sciences.},
annote = {Cited by: 0},
author = {Yesmagambetov, Daulet and Kussainova, Larisa and Junusbekova, Gulsara},
doi = {10.13165/VPA-22-21-4-04},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Yesmagambetov, Kussainova, Junusbekova - Public Policy and Administration.pdf:pdf},
issn = {16482603},
journal = {Public Policy and Administration},
keywords = {competition,digitalization,e-procurement,procurement efficiency,public administration,public procurement,quality of work},
language = {English},
number = {4},
pages = {395 -- 406},
title = {{DIGITAL TOOLS FOR IMPROVING THE EFFICIENCY OF PUBLIC PROCUREMENT OF WORKS IN THE REPUBLIC OF KAZAKHSTAN; [SKAITMENINES PRIEMONES VIE{\v{S}}UJU PIRKIMU EFEKTYVUMUI GERINTI KAZACHSTANO RESPUBLIKOJE]}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149005773&doi=10.13165%2FVPA-22-21-4-04&partnerID=40&md5=02e8baaf6bb3bc4c8802d8a5dd21c78f},
volume = {21},
year = {2022}
}
@article{Zhang2022,
abstract = {The outbreak of COVID-19 has greatly threatened global public health and produced social problems, which includes relative online collective actions. Based on the life cycle law, focusing on the life cycle process of COVID-19 online collective actions, we carried out both macro-level analysis (big data mining) and micro-level behaviors (Agent-Based Modeling) on pandemic-related online collective actions. We collected 138 related online events with macro-level big data characteristics, and used Agent-Based Modeling to capture micro-level individual behaviors of netizens. We set two kinds of movable agents, Hots (events) and Netizens (individuals), which behave smartly and autonomously. Based on multiple simulations and parametric traversal, we obtained the optimal parameter solution. Under the optimal solutions, we repeated simulations by ten times, and took the mean values as robust outcomes. Simulation outcomes well match the real big data of life cycle trends, and validity and robustness can be achieved. According to multiple criteria (spans, peaks, ratios, and distributions), the fitness between simulations and real big data has been substantially supported. Therefore, our Agent-Based Modeling well grasps the micro-level mechanisms of real-world individuals (netizens), based on which we can predict individual behaviors of netizens and big data trends of specific online events. Based on our model, it is feasible to model, calculate, and even predict evolutionary dynamics and life cycles trends of online collective actions. It facilitates public administrations and social governance. {\textcopyright} 2021, The Author(s).},
annote = {Cited by: 2},
author = {Zhang, Gang and Li, Hao and He, Rong and Lu, Peng},
doi = {10.1007/s40747-021-00595-4},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Zhang et al. - Complex and Intelligent Systems.pdf:pdf},
issn = {21994536},
journal = {Complex and Intelligent Systems},
keywords = {Agent-Based Modeling (ABM),Attention shift and attention allocation,COVID-19,Online collective actions,Substitution effects},
language = {English},
number = {2},
pages = {1369 -- 1387},
title = {{Agent-based modeling and life cycle dynamics of COVID-19-related online collective actions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134068532&doi=10.1007%2Fs40747-021-00595-4&partnerID=40&md5=121f28c4910c0a553519156e9c12c154},
volume = {8},
year = {2022}
}
@article{Newman2022,
abstract = {Bureaucracies are often criticized for their inflexibility, budget-maximizing wastefulness, and excessive rules and procedures. Rapid advances in technology, including the expansion of digital government, the use of artificial intelligence, and the ability to collect and analyze big data, promise to make public sector organizations leaner, more efficient, and more responsive to citizens' needs. While these technological changes have prompted some observers to forecast the end of bureaucracy, data from many countries show that bureaucratic public organizations are not disappearing. In this article, we argue that this paradox can be explained by revisiting some of the foundational work of sociologist Max Weber, who envisioned public administration itself as a bureaucratic machine. Advanced computing technologies, like artificial intelligence, are reinforcing bureaucratic tendencies in the public sector, not eliminating them. While advances in technology may transform the way public sector organizations operate, they can also serve to strengthen bureaucracy's core purpose. {\textcopyright} 2021 Elsevier Ltd},
annote = {Cited by: 31},
author = {Newman, Joshua and Mintrom, Michael and O'Neill, Deirdre},
doi = {10.1016/j.futures.2021.102886},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Newman, Mintrom, O'Neill - Futures.pdf:pdf},
issn = {00163287},
journal = {Futures},
keywords = {Artificial intelligence,Bureaucracy,Bureaucratic transformation,Digital technologies,Max Weber},
language = {English},
month = {feb},
pages = {102886},
title = {{Digital technologies, artificial intelligence, and bureaucratic transformation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328721001956},
volume = {136},
year = {2022}
}
@article{Carlsson2022,
abstract = {Artificial intelligence (AI) and digitalisation have become an integral part of public governance. While digital technology is expected to enhance neutrality and accuracy in decision-making, it raises concerns about the status of public values and democratic principles. Guided by the theoretical concepts of input, throughput and output democracy, this article analyses how democratic principles have been interpreted and defended in EU policy formulations relating to digital technology over the last decade. The emergence of AI policy has changed the conditions for democratic input and throughput legitimacy, which is an expression of a shift in power and influence between public and private sectors. Democratic input values in AI production are promoted by ethical guidelines directed towards the industry, while democratic throughput, e.g., accountability and transparency, receive less attention in EU AI policy. This indicates future political implications for the ability of citizens to influence technological change and pass judgement on accountable actors. {\textcopyright} 2022 The Authors},
annote = {Cited by: 11},
author = {Carlsson, Vanja and R{\"{o}}nnblom, Malin},
doi = {10.1016/j.techsoc.2022.102145},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Carlsson, R{\"{o}}nnblom - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {AI ethics,AI policy,Democracy,European union,Public sector,The political},
language = {English},
month = {nov},
pages = {102145},
title = {{From politics to ethics: Transformations in EU policies on digital technology}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0160791X2200286X},
volume = {71},
year = {2022}
}
@article{Cetera2022,
abstract = {Effective programming of research and development (R&D) support, adjusted to the actual potential of beneficiaries, requires the use of modern analytical tools. An efficient R&D support system requires up-to-date data on technological trends, ongoing (and planning) research, market needs and developing innovation. The most popular programming methods were based on the analysis of data with a 4 to 5-year time delay until recently. Having described the method of refining information from unstructured data, we explore how to make it possible not only to solve the issue of up-to-date data but to identify of the latest trends in R&D activities. The analytical tools we describe were already fully functional in 2018 and are constantly being improved. The article presents the potential of one tool that can be applied in public support institutions. Methods of identifying and diagnosing technology trends are presented within the case study of the electric car technology trend. The presented case study shows the effectiveness of the method we developed for identifying and diagnosing areas requiring support from public funds. Public institutions, including public institutions supporting R&D and innovation processes, can apply tools that allow an increase in the quality of public support programmes offered, but also beneficial for the quality of strategic resources management within the institution itself. The comparison of the predictions made by the described tools with the classifications made by experts, the former are more accurate and precise. Moreover, the results of the analyses performed by the presented model are not influenced by distorting factors—fads, trends, political pressures, or processes with an unidentified, non-substantive background. It should be emphasized that the accuracy of the whole model is 0.84. The described tools and methods are already directly applicable in many areas related to the support of R&D activity worldwide. The article presents a solution that effectively enables the management of more precise programmes supporting innovative activities used for the first time in Poland. It is also one of the first uses of these methods by public administration in the world. Our approach not only strengthens improved adjustment of the support offered for R&D activity, but also makes it possible to apply and improve management methods in public institutions. {\textcopyright} 2022, The Author(s).},
annote = {Cited by: 2},
author = {Cetera, Wies{\l}aw and Gogo{\l}ek, W{\l}odzimierz and {\.{Z}}o{\l}nierski, Aleksander and Jaruga, Dariusz},
doi = {10.1186/s40537-022-00610-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Cetera et al. - Journal of Big Data.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {Big Data,Business statistics,Data management,Information refining,Information technologies management,Innovation,Research and development management,Research and development support programming},
language = {English},
number = {1},
title = {{Potential for the use of large unstructured data resources by public innovation support institutions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128957082&doi=10.1186%2Fs40537-022-00610-6&partnerID=40&md5=e83541274fd8d5c2c2577ced2015ad4b},
volume = {9},
year = {2022}
}
@article{Wilson2023,
abstract = {This analysis applies boundary theory to public manager efforts to overcome AI capacity gaps through a public sector collaborative learning forum. Administrative and interview data identify the types of knowledge managers are able to access, the types of organizational differences that influence learning, and the strategies public managers use to overcome them. Analysis suggests that unstructured learning fora are better suited to the transfer of tacit procedural knowledge than declarative knowledge about AI, and emphasizes the importance of social trust and network structure to overcome knowledge gaps through peer learning. {\textcopyright} 2022 Informa UK Limited, trading as Taylor & Francis Group.},
annote = {Cited by: 7},
author = {Wilson, Christopher and Broomfield, Heather},
doi = {10.1080/14719037.2022.2055119},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Wilson, Broomfield - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {Artificial intelligence,boundary objects,government networks,know-how,knowledge management,organizational learning,peer learning,technology transfer},
language = {English},
month = {oct},
number = {10},
pages = {1938--1957},
title = {{Learning how to do AI: managing organizational boundaries in an intergovernmental learning forum}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2055119},
volume = {25},
year = {2023}
}
@article{Smith2023,
abstract = {As governments around the world become increasingly datafied, debates are emerging about the best ways to attend to the complex socio-political implications of big data and the datafication of the state. Drawing on semi-structured interviews with senior executives and data experts within Australian government agencies, high-level privacy experts, and other experts in public sector data integration, this article examines how a sociotechnical imaginary about data-driven, democratic government acts within and alongside routinely bureaucratised forms of techno-legal risk management to inform the work of Australia's data integration experts. Notably, these techno-legal experts recognised the limitations of techno-legal data management, and mobilised notions of the social license when seeking to (re)orient the trajectories of data integration towards the democratic, data-driven government they envisage. Contributing to debates about the datafication of the state, we argue that while a social license will not be a panacea to all the complexities of datafication, a social license with institutional roots is essential to deepen accountability towards publics, and to help ensure that datafication can be co-produced by, and reflective of, the sociotechnical futures envisaged by a broader range of publics. {\textcopyright} 2023 The Authors},
annote = {Cited by: 0},
author = {Smith, Catherine and Vajdic, Claire M. and Stephenson, Niamh},
doi = {10.1016/j.futures.2023.103263},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Smith, Vajdic, Stephenson - Futures.pdf:pdf},
issn = {00163287},
journal = {Futures},
keywords = {Big data,Data-driven futures,Public sector data integration,Social license,Sociotechnical imaginaries,The datafied state},
language = {English},
month = {dec},
pages = {103263},
title = {{Techno-legal expertise and the datafication of the state: Big data, accountability and the value of a social license with institutional roots}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328723001672},
volume = {154},
year = {2023}
}
@article{Ekimova2023,
abstract = {<p>This paper is aimed at balancing the interests of business and society in the digital economy, to reduce the social risks of the Fourth Industrial Revolution. The goal of this paper is to study the experience and prospects of the humanisation of AI through the improvement of the practice of corporate social responsibility in Russia. By the example of the experience of Russian regions in 2021, we use econometric modelling to prove that the digital regional economy has a large potential in the sphere of humanisation of AI. The potential for the humanisation of AI in the digital economy of Russian regions is determined by responsible innovations, responsible production and logistics, as well as responsible marketing and sales, which contribute to the implementation of SDGs 9–12. The theoretical significance of the paper lies in its presenting smart region as a socio-economic environment for the humanisation of AI. The scientific novelty of the paper lies in its offering a new—meso-level—view of the humanisation of AI. The advantages of the new view include, first, consideration of socio-economic conditions for the humanisation of AI in a region; second, the most precise identification and correct measuring of the consequences of humanisation of AI for the quality of life in a region. The practical significance of the research results consists in the fact that the new proposed approach to the humanisation of AI, which implies public administration of this process at the level of a region, allows accelerating the considered process.</p>},
annote = {Cited by: 0},
author = {Ekimova, Ksenia V.},
doi = {10.1057/s41599-023-02444-w},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Ekimova - Humanities and Social Sciences Communications.pdf:pdf},
issn = {2662-9992},
journal = {Humanities and Social Sciences Communications},
language = {English},
month = {dec},
number = {1},
pages = {943},
title = {{Development of the potential of the digital economy of Russian regions through artificial intelligence humanisation}},
url = {https://www.nature.com/articles/s41599-023-02444-w},
volume = {10},
year = {2023}
}
@article{Nai2023,
abstract = {With the proliferation of e-procurement systems in the public sector, valuable and open information sources can be jointly accessed. Our research aims to explore different legal Open Data; in particular, we explored the data set of the National Anti-Corruption Authority in Italy on public procurement and the judges' sentences related to public procurement, published on the website of the Italian Administrative Justice from 2007 to 2022. Our first goal was to train machine learning models capable of automatically recognizing which procurement has led to disputes and consequently complaints to the Administrative Justice, identifying the relevant features of procurement that correspond to certain anomalies. Our second goal was to develop a recommender system on procurement to return similar procurement to a given one and find companies for bidders, depending on the procurement requirements. {\textcopyright} 2023 Roberto Nai, Rosa Meo, Gabriele Morina, Paolo Pasteris},
annote = {Cited by: 1},
author = {Nai, Roberto and Meo, Rosa and Morina, Gabriele and Pasteris, Paolo},
doi = {10.1016/j.clsr.2023.105887},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Nai et al. - Computer Law & Security Review.pdf:pdf},
issn = {02673649},
journal = {Computer Law & Security Review},
keywords = {Complaint detection,Knowledge discovery,Legal prediction,Machine learning,Natural language processing,Public procurement,Recommender system},
language = {English},
month = {nov},
pages = {105887},
title = {{Public tenders, complaints, machine learning and recommender systems: a case study in public administration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364923000973},
volume = {51},
year = {2023}
}
@article{Henriksen2023,
abstract = {Recent policies and research articles call for turning AI into a form of IA (‘intelligence augmentation'), by envisioning systems that center on and enhance humans. Based on a field study at an AI company, this article studies how AI is performed as developers enact two predictive systems along with stakeholders in public sector accounting and public sector healthcare. Inspired by STS theories about values in design, we analyze our empirical data focusing especially on how objectives, structured performances, and divisions of labor are built into the two systems and at whose expense. Our findings reveal that the development of the two AI systems is informed by politically motivated managerial interests in cost-efficiency. This results in AI systems that are (1) designed as managerial tools meant to enable efficiency improvements and cost reductions, and (2) enforced on professionals on the ‘shop floor' in a top-down manner. Based on our findings and a discussion drawing on literature on the original visions of human-centered systems design from the 1960s, we argue that turning AI into IA seems dubious, and ask what human-centered AI really means and whether it remains an ideal not easily realizable in practice. More work should be done to rethink human-machine relationships in the age of big data and AI, in this way making the call for ethical and responsible AI more genuine and trustworthy.},
annote = {Cited by: 3},
author = {Henriksen, Anne and Blond, Lasse},
doi = {10.1177/03063127231163756},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Henriksen, Blond - Social Studies of Science.pdf:pdf},
issn = {0306-3127},
journal = {Social Studies of Science},
keywords = {artificial intelligence,computer systems design,human-centered systems,intelligence augmentation,machine learning,responsible AI},
language = {English},
month = {oct},
number = {5},
pages = {738--760},
title = {{Executive-centered AI? Designing predictive systems for the public sector}},
url = {http://journals.sagepub.com/doi/10.1177/03063127231163756},
volume = {53},
year = {2023}
}
@article{Ronnblom2023,
abstract = {Over the past few decades, Sweden has established itself as a “world leader” in gender equality. Alongside this development, Swedish politicians have also initiated ambitious plans that aim to establish the country as “world class” in terms of digitalization. International research shows that women and racialized groups are in a minority in the design processes, that AI facial recognition systems are built with white male faces as the norm, and that digital tools replicate racial injustices. In this paper, we are interested in if, and if so how, gender equality is articulated and thus filled with meaning in national policies on AI and digitalization. The overall aim is to discuss the potential of gender (equality) mainstreaming to challenge systems of privilege in the implementation of AI systems in the public sector. The paper analyses how gender equality is filled with meaning in national policy documents on AI and gender equality. The main findings show that gender equality is turned into a question of lack of knowledge and information, which in turn blocks out an understanding of gender equality as something that is related to gendered power relations.},
annote = {Cited by: 9},
author = {R{\"{o}}nnblom, Malin and Carlsson, Vanja and {\"{O}}jehag‐Pettersson, Andreas},
doi = {10.1111/ropr.12547},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - R{\"{o}}nnblom, Carlsson, {\"{O}}jehag‐Pettersson - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {Sweden,artificial intelligence,critical policy analysis,gender equality,public policy},
language = {English},
month = {sep},
number = {5},
pages = {688--704},
title = {{Gender equality in Swedish AI policies. What's the problem represented to be?}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12547},
volume = {40},
year = {2023}
}
@article{Hashim2024,
abstract = {Information and communication technologies (ICT) have a recent impact on governance and public administration. Electronic government (e-government) services were created to streamline administrative processes and enhance citizen engagement on the one hand, and to build new governance models that would empower individuals, involve them in the decision-making process, and increase transparency on the other. Many individuals are doubtful about smart city projects because of the security issues that arise in such environments. In essence, internet of things gadgets are security flaws. Concerns about the proliferation of IoT sensors and the tighter coupling of infrastructure silos in cities are well-founded. The major objective of the study is to identify the influencing factors of smart cities on e-government in Saudi Arabia. Additionally, this research explores the definition of e-government, and its supporting technologies like smart cities, IoT, big data, cloud computing and other digital government platforms. After exploring the detailed definitions, the study identifies the challenging scenarios of e-government in Saudi Arabia, and discusses the different opportunities. This study also concentrates on the good practices to be followed to overcome the challenges. Furthermore, this study can be used in future research for solving real time challenges of e-government. {\textcopyright} 2024 The Authors},
annote = {Cited by: 2},
author = {Hashim, Hasan},
doi = {10.1016/j.aej.2024.04.008},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Hashim - Alexandria Engineering Journal.pdf:pdf},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Big data framework for e-government,City assets,Connecting e-government with smart city initiative,Digital Government,Digital Government platforms,E-government,Hybrid cloud set up for government department,Mobile government,Public administration,Services Laws,Smart cities using IoT framework,Smart city as a service,Smart governance for smart city,The role of e-government in smart city},
language = {English},
month = {jun},
pages = {124--131},
title = {{E-government impact on developing smart cities initiative in Saudi Arabia: Opportunities & challenges}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016824003818},
volume = {96},
year = {2024}
}
@article{Aranha2024,
abstract = {This study investigates the selection of the best partners while merging the public sector banks in India. It is set in the context of the announcement of the mega-merger of multiple Indian public sector banks on 30th August 2019. Using the clustering technique (a machine learning approach) and Data Envelopment Analysis (DEA), we identify ideal merger combinations with better efficiency. The findings highlight the possibility of identifying ideal merger combinations using objective techniques. {\textcopyright} 2024 Elsevier Inc.},
annote = {Cited by: 0},
author = {Aranha, Meera Laetitia B and Mahapatra, Mrutyunjay and Jacob, Remya Tressa},
doi = {10.1016/j.frl.2024.105297},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Aranha, Mahapatra, Jacob - Finance Research Letters.pdf:pdf},
issn = {15446123},
journal = {Finance Research Letters},
keywords = {Bank mergers,Clustering,Data envelopment analysis,Partner selection for mergers,Total Economic Efficiency},
language = {English},
month = {may},
pages = {105297},
title = {{Mergers of public sector banks: Best partner selection using a data-driven approach}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612324003271},
volume = {63},
year = {2024}
}
@article{Jain2024,
abstract = {Effective contractor selection is crucial for successful execution of construction projects. In contrast to the conventional lowest-bid approach prevalent in the public sector, this study focuses on developing a framework that minimizes time and cost overruns by considering diverse criteria for contractor selection. A variety of machine learning models, including multi-linear regression, random forest, Support Vector Machine, and Artificial Neural Network, have been employed, with multi-linear regression proving to be the most effective, achieving the lowest Mean Squared Error of 0.00003366. To determine the final order allocation, a multi-objective mathematical model was utilized to optimize conflicting criteria, such as time and cost overruns, sustainability, risk, and safety aspects related to shortlisted contractors. The findings highlight the significance of specific selection criteria, such as turnover, experience in similar projects, qualification of staff, technology utilization, client satisfaction, accident records, available bid capacity, and socioeconomic factors. This study emphasizes a three-phase decision-making framework for contractor selection and order allocation, particularly in public construction projects, with a focus on sustainability. By adopting this approach, government agencies can enhance infrastructure projects and minimize overruns through optimization and analytical tools, which aligns with the Gati-Shakti scheme of the Indian government. It is recommended that clients embrace a holistic approach to contractor selection, considering both technical and non-technical factors, to ensure successful project outcomes. {\textcopyright} The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
annote = {Cited by: 2},
author = {Jain, Shrey and Jauhar, Sunil Kumar and Piyush},
doi = {10.1007/s10479-024-05898-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Jain, Jauhar, Piyush - Annals of Operations Research.pdf:pdf},
issn = {0254-5330},
journal = {Annals of Operations Research},
keywords = {construction project management,goal programming,multi-objective optimization,order allocation,safety and risk management,sustainable contractor selection},
language = {English},
month = {jul},
number = {1},
pages = {225--267},
title = {{A machine-learning-based framework for contractor selection and order allocation in public construction projects considering sustainability, risk, and safety}},
url = {https://link.springer.com/10.1007/s10479-024-05898-6},
volume = {338},
year = {2024}
}
@article{Kurmangali2024,
abstract = {Digitalization and new technologies are now firmly on the agendas of governments worldwide. New technological trends have not only become catalysts for economic development, but are also reshaping how the public sector works and implements its policies. Amid technological transformations, the countries of Central Asia are searching for new ways to adapt to these changes. This paper aims to assess these attempts by exploring the digitalization policies of the five Central Asian countries. By using qualitative methods and expert interviews, the article identifies key limitations and potential areas of development for the Central Asian states regarding digitalization and artificial intelligence. By providing valuable insights, the article contributes to a deeper understanding of the digitalization challenges faced by developing countries. Through the analysis of local expert opinions, the article seeks to contribute valuable insights to the distinct approaches adopted by these countries, thus enriching the understanding of the region's trajectory in the digital era. {\textcopyright} 2024 Mykolo Romerio Universitetas. All rights reserved.},
annote = {Cited by: 0},
author = {Kurmangali, Medeu and Yeraliyeva, Yana and Beimisheva, Aigul},
doi = {10.13165/VPA-24-23-2-03},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Kurmangali, Yeraliyeva, Beimisheva - Public Policy and Administration.pdf:pdf},
issn = {16482603},
journal = {Public Policy and Administration},
keywords = {Central Asia,artificial intelligence,digitalization,governance on digitalization and artificial intell,public administration,public policy},
language = {English},
number = {2},
pages = {146 -- 159},
title = {{DIGITALIZATION AND ARTIFICIAL INTELLIGENCE IN CENTRAL ASIA: GOVERNMENTAL RESPONSES AND FURTHER IMPLICATIONS}},
url = {https://ojs.mruni.eu/ojs/public-policy-and-administration/article/view/7841},
volume = {23},
year = {2023}
}
@article{Berman2024,
abstract = {This paper investigates the deployment of Artificial Intelligence (AI) in the Swedish Public Employment Service (PES), focusing on the concept of trustworthy AI in public decision-making. Despite Sweden's advanced digitalization efforts and the widespread application of AI in the public sector, our study reveals significant gaps between theoretical ambitions and practical outcomes, particularly in the context of AI's trustworthiness. We employ a robust theoretical framework comprising Institutional Theory, the Resource-Based View (RBV), and Ambidexterity Theory, to analyze the challenges and discrepancies in AI implementation within PES. Our analysis shows that while AI promises enhanced decision-making efficiency, the reality is marred by issues of transparency, interpretability, and stakeholder engagement. The opacity of the neural network used by the agency to assess jobseekers' need for support and the lack of comprehensive technical understanding among PES management contribute to the challenges in achieving transparent and interpretable AI systems. Economic pressures for efficiency often overshadow the need for ethical considerations and stakeholder involvement, leading to decisions that may not be in the best interest of jobseekers. We propose recommendations for enhancing AI's trustworthiness in public services, emphasizing the importance of stakeholder engagement, particularly involving jobseekers in the decision-making process. Our study advocates for a more nuanced balance between the use of advanced AI technologies and the leveraging of internal resources such as skilled personnel and organizational knowledge. We also highlight the need for improved AI literacy among both management and personnel to effectively navigate AI's integration into public decision-making processes. Our findings contribute to the ongoing debate on trustworthy AI, offering a detailed case study that bridges the gap between theoretical exploration and practical application. By scrutinizing the AI implementation in the Swedish PES, we provide valuable insights and guidelines for other public sector organizations grappling with the integration of AI into their decision-making processes. {\textcopyright} 2024 The Authors},
annote = {Cited by: 6},
author = {Berman, Alexander and {de Fine Licht}, Karl and Carlsson, Vanja},
doi = {10.1016/j.techsoc.2024.102471},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley//2024 - Berman, de Fine Licht, Carlsson - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {Artificial Intelligence,Decision-support systems,Public employment services,Public sector,Trustworthy AI},
language = {English},
title = {{Trustworthy AI in the public sector: An empirical analysis of a Swedish labor market decision-support system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184027069&doi=10.1016%2Fj.techsoc.2024.102471&partnerID=40&md5=a99c3caeb3fcce4eb7e14c5134647d3d},
volume = {76},
year = {2024}
}
@article{Misra2024,
abstract = {Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI. {\textcopyright} 2024 Elsevier Inc.},
annote = {Cited by: 0},
author = {Misra, Shalini and Katz, Benjamin and Roberts, Patrick and Carney, Mackenzie and Valdivia, Isabel},
doi = {10.1016/j.giq.2024.101962},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Misra et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {AI attitudes,AI implementation in the public sector,Decision-making,Emergency managers,Person-environment fit},
language = {English},
month = {sep},
number = {3},
pages = {101962},
title = {{Toward a person-environment fit framework for artificial intelligence implementation in the public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X24000546},
volume = {41},
year = {2024}
}
@article{Hulter2024,
abstract = {The technological capabilities of Human Resource Analytics (HRA), enhanced by recent innovations in Machine Learning (ML), offer exciting opportunities. However, organisations often fail to realise these potentials because of a limited understanding of why individuals choose to adopt or disregard respective tools. Prior research on innovation adoption offers preliminary insights but fails to aggregate the determinants of individual adoption into actionable suggestions for decisions in the ML adoption process. Our study applies focused interviews to examine non-ML experts' reasoning for using a specific tool tailored to a public sector organisation, which corresponds to the usual end-user perspective of ML-based HRA adoption. By drawing from the HRA adoption framework, provided by Vargas et al. (2018), we contribute to the literature by identifying relevant beliefs and experiences influencing one's intention to adopt ML-based HRA and by qualitatively linking these beliefs to ML characteristics such as transparency, automation and fairness. For practitioners, we provide actionable guidance emphasising the need to ensure fairness proactively, as interviewees do not consider this aspect when deciding to adopt ML-based HRA. {\textcopyright} 2024 The Authors},
annote = {Cited by: 0},
author = {H{\"{u}}lter, Svenja M. and Ertel, Christian and Heidemann, Ansgar},
doi = {10.1016/j.techfore.2024.123709},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - H{\"{u}}lter, Ertel, Heidemann - Technological Forecasting and Social Change.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Employee turnover prediction,Explainable artificial intelligence,Human resource analytics,Machine learning adoption,Theory of planned behaviour},
language = {English},
month = {nov},
pages = {123709},
title = {{Exploring the individual adoption of human resource analytics: Behavioural beliefs and the role of machine learning characteristics}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162524005079},
volume = {208},
year = {2024}
}
@article{Delfos2024,
abstract = {This paper introduces systems theory and system safety concepts to ongoing academic debates about the safety of Machine Learning (ML) systems in the public sector. In particular, we analyze the risk factors of ML systems and their respective institutional context, which impact the ability to control such systems. We use interview data to abductively show what risk factors of such systems are present in public professionals' perceptions and what factors are expected based on systems theory but are missing. Based on the hypothesis that ML systems are best addressed with a systems theory lens, we argue that the missing factors deserve greater attention in ongoing efforts to address ML systems safety. These factors include the explication of safety goals and constraints, the inclusion of systemic factors in system design, the development of safety control structures, and the tendency of ML systems to migrate towards higher risk. Our observations support the hypothesis that ML systems can be best regarded through a systems theory lens. Therefore, we conclude that system safety concepts can be useful aids for policymakers who aim to improve ML system safety. {\textcopyright} 2024},
annote = {Cited by: 0},
author = {Delfos, J. and Zuiderwijk, A.M.G. and van Cranenburgh, S. and Chorus, C.G. and Dobbe, R.I.J.},
doi = {10.1016/j.giq.2024.101963},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Delfos et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Governance,Machine learning,Public policy,Public sector,System safety,Systems theory},
language = {English},
month = {sep},
number = {3},
pages = {101963},
title = {{Integral system safety for machine learning in the public sector: An empirical account}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X24000558},
volume = {41},
year = {2024}
}
@article{Ballestar2024,
abstract = {Tutoring programs are effective in reducing school failures among at-risk students. However, there is still room for improvement in maximising the social returns they provide on investments. Many factors and components can affect student engagement in a program and academic success. This complexity presents a challenge for Public Administrations to use their budgets as efficiently as possible. Our research focuses on providing public administration with advanced decision-making tools. First, we analyse a database with information on 2066 students of the Programa para la Mejora de {\'{E}}xito Educativo (Programme for the Improvement of Academic Success) of the Junta de Comunidades de Castilla y L{\'{e}}on in Spain, in 2018–2019, the academic year previous to the pandemic. This program is designed to help schools with students at risk of failure in Spanish, literature, mathematics, and English. We developed a machine learning model (ML) based on Kohonen self-organising maps (SOMs), which are a type of unsupervised (ANN), to group students based on their characteristics, the type of tutoring program in which they were enrolled, and their results in both the completion of the program and the 4th year of Compulsory Secondary Education (ESO). Second, we evaluated the results of tutoring programs and identified and explained how different factors and components affect student engagement and academic success. Our findings provide Public Administrations with better decision-making tools to evaluate and measure the results of tutoring programs in terms of social return on investment, improve the design of these programs, and choose the students to enrol. {\textcopyright} 2023 The Author(s)},
annote = {Cited by: 0},
author = {Ballestar, Mar{\'{i}}a Teresa and Mir, Miguel Cuerdo and Pedrera, Luis Miguel Doncel and Sainz, Jorge},
doi = {10.1016/j.techfore.2023.123043},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Ballestar et al. - Technological Forecasting and Social Change.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Artificial neural networks,Machine learning,Public policy analysis,Tutoring program},
language = {English},
month = {feb},
pages = {123043},
title = {{Effectiveness of tutoring at school: A machine learning evaluation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S004016252300728X},
volume = {199},
year = {2024}
}
@article{Zaidi2024,
abstract = {Introduction Pakistan has significantly strengthened its capacity for active case finding (ACF) for tuberculosis (TB) that is being implemented at scale in the country. However, yields of ACF have been lower than expected, raising concerns on its effectiveness in the programmatic setting. Distribution of TB in communities is likely to be spatially heterogeneous and targeting of ACF in areas with higher TB prevalence may help improve yields. The primary aim of SPOT-TB is to investigate whether a policy change to use a geographically targeted approach towards ACF supported by an artificial intelligence (AI) software, MATCH-AI, can improve yields in Pakistan. Methods and analysis SPOT-TB will use a pragmatic, stepped wedge cluster randomised design. A total of 30 mobile X-ray units and their field teams will be randomised to receive the intervention. Site selection for ACF in the intervention areas will be guided primarily through the use of MATCH-AI software that models subdistrict TB prevalence and identifies potential disease hotspots. Control areas will use existing approaches towards site selection that are based on staff knowledge, experience and analysis of historical data. The primary outcome measure is the difference in bacteriologically confirmed incident TB detected in the intervention relative to control areas. All remaining ACF-related procedures and algorithms will remain unaffected by this trial. Ethics and dissemination Ethical approval has been obtained from the Health Services Academy, Islamabad, Pakistan (7-82/IERC-HSA/2022-52) and from the Common Management Unit for TB, HIV and Malaria, Ministry of Health Services, Regulation and Coordination, Islamabad, Pakistan (26-IRB-CMU-2023). Findings from this study will be disseminated through publications in peer-reviewed journals and stakeholder meetings in Pakistan with the implementing partners and public-sector officials. Findings will also be presented at local and international medical and public health conferences.  {\textcopyright} Author(s) (or their employer(s)) 2024.},
annote = {Cited by: 0},
author = {Zaidi, Syed Mohammad Asad and Mahfooz, Amna and Latif, Abdullah and Nawaz, Nainan and Fatima, Razia and Rehman, Fazal Ur and Reza, Tahira Ezra and Emmanuel, Faran},
doi = {10.1136/bmjresp-2023-002079},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Zaidi et al. - BMJ Open Respiratory Research.pdf:pdf},
issn = {2052-4439},
journal = {BMJ Open Respiratory Research},
language = {English},
month = {jul},
number = {1},
pages = {e002079},
title = {{Geographical targeting of active case finding for tuberculosis in Pakistan using hotspots identified by artificial intelligence software (SPOT-TB): study protocol for a pragmatic stepped wedge cluster randomised control trial}},
url = {https://bmjopenrespres.bmj.com/lookup/doi/10.1136/bmjresp-2023-002079},
volume = {11},
year = {2024}
}
@article{Madan2024,
abstract = {Public administrators receive conflicting signals on the transformative benefits of Artificial Intelligence (AI) and the counternarratives of AI's ethical impacts on society and democracy. Against this backdrop, this paper explores the factors that affect the sensemaking of AI benefits in Canadian public administration. A mixed-method research design using PLS-SEM ( n = 272) and interviews ( n = 38) tests and explains the effect of institutional and consultant pressures on the perceived benefits of AI use. The quantitative study shows only service coercive pressures have a significant effect on perceived benefits of AI use and consultant pressures are significant in generating all institutional pressures. The qualitative study explains the results and highlights the underlying mechanisms. The key conclusion is that in the earlier stages of AI adoption, demand pull is the main driver rather than technology push. A processual sensemaking model is developed extending the theory on institutions and sensemaking. And several managerial implications are discussed.},
author = {Madan, Rohit and Ashok, Mona},
doi = {10.1007/s10796-024-10475-0},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Madan, Ashok - Information Systems Frontiers.pdf:pdf},
issn = {1387-3326},
journal = {Information Systems Frontiers},
language = {English},
month = {feb},
title = {{Making Sense of AI Benefits: A Mixed-method Study in Canadian Public Administration}},
url = {https://link.springer.com/10.1007/s10796-024-10475-0},
year = {2024}
}
@article{Mokander2024,
abstract = {In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens' sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means – it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.},
author = {M{\"{o}}kander, Jakob and Schroeder, Ralph},
doi = {10.1177/08944393241235175},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - M{\"{o}}kander, Schroeder - Social Science Computer Review.pdf:pdf},
issn = {0894-4393},
journal = {Social Science Computer Review},
keywords = {Weber,artificial intelligence,automated decision-making,bureaucratization,equality,governance,policymaking,rationalization,tax policy},
language = {English},
month = {mar},
title = {{Artificial Intelligence, Rationalization, and the Limits of Control in the Public Sector: The Case of Tax Policy Optimization}},
url = {https://journals.sagepub.com/doi/10.1177/08944393241235175},
year = {2024}
}
@article{Chen2024,
abstract = {In recent years, the application of artificial intelligence (AI) technology has become increasingly common in the public sector. Users have been switching their experiences in handling businesses from interactions with human staff to those with robots. Prior studies have focused on investigating the key factors that influence users' adoption of public service robots; however, only a few have considered users' switching behaviors from traditional human services to robotic ones. This study employs a push-pull-mooring (PPM) framework derived from the human migration field to understand the factors that affect users' switching intentions in the context of public service robot applications. The research model was tested with 419 valid responses among users who had experienced both human services and public service robots in Chinese government service halls. The structural equation modeling (SEM) method was applied to quantitatively analyze the data. This study sheds new light on the key determinants of users' switching intentions toward public service robots from the perspectives of push, pull, and mooring effects. The results can help practitioners and managers understand users' intentions for such switches and make scientific decisions to encourage citizens' positive responses to service robots.},
author = {Chen, Tao and Li, Siqi and Zeng, Zhongping and Liang, Zhehao and Chen, Yuxi and Guo, Wenshan},
doi = {10.1016/j.giq.2024.101933},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Chen et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Public service robot,Push-pull-mooring framework,Switching behavior},
language = {English},
month = {jun},
number = {2},
pages = {101933},
title = {{An empirical investigation of users' switching intention to public service robots: From the perspective of PPM framework}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X2400025X},
volume = {41},
year = {2024}
}
@article{Enqvist2024,
abstract = {This article focuses on the legal implications of the growing reliance on automated systems in public administrations, using the example of social security benefits administration. It specifically addresses the deployment of automated systems for decisions on benefits eligibility within the frameworks of the General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AIA). It compares how these two legal frameworks, each targeting different regulatory objects (personal data versus AI systems) and employing different protective measures, apply for two common system types: rule-based systems utilised for making fully automated decisions on eligibility, and machine learning AI systems utilised for assisting case administrators in their decision-making. It concludes on the combined impact that the GDPR and the AIA will have on each of these types of systems, as well as on differences in how these instruments determines the basic legality of utilising such systems within social security administration.},
author = {Enqvist, Lena},
doi = {10.1080/13600834.2024.2349835},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Enqvist - Information & Communications Technology Law.pdf:pdf},
issn = {1360-0834},
journal = {Information & Communications Technology Law},
keywords = {Artificial Intelligence Act,Automated decision-making,GDPR,public administration,social security administration},
language = {English},
month = {may},
number = {2},
pages = {222--246},
title = {{Rule-based versus AI-driven benefits allocation: GDPR and AIA legal implications and challenges for automation in public social security administration}},
url = {https://www.tandfonline.com/doi/full/10.1080/13600834.2024.2349835},
volume = {33},
year = {2024}
}
@article{Fattah2024,
abstract = {PurposeThis study investigates the relationships between data governance (DG), business analytics capabilities (BAC), and decision-making performance (DMP), with a focus on the mediating effects of big data literacy (BDL) and data analytics competency (DAC).Design/methodology/approachThe study was conducted with 178 experienced managers in public service organizations, using a quantitative approach. Structural equation modeling (SEM) and mediation tests were employed to analyze the data.FindingsThe findings reveal that DG and BDL are critical antecedents for developing analytical capabilities. Big data literacy mediates the relationship between DG and BAC, while BAC mediates the relationship between DG and DMP. Furthermore, DAC mediates the relationship between BA capabilities and DMP, explaining most of the effect of BAC on DMP.Practical implicationsThese results highlight the importance of DG in fostering BDL and analytical skills for improved decision-making in organizations.Originality/valueBy prioritizing DG practices that promote BDL and analytical capabilities, organizations can leverage business analytics to enhance decision-making.},
author = {Fattah, Ikhsan A.},
doi = {10.1108/BPMJ-11-2023-0894},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Fattah - Business Process Management Journal.pdf:pdf},
issn = {1463-7154},
journal = {Business Process Management Journal},
keywords = {Analytics competency,Big data literacy,Business analytics capabilities,Decision making performance,Public sector institutions},
language = {English},
month = {jul},
title = {{Decision making performance of business analytics capabilities: the role of big data literacy and analytics competency}},
url = {https://www.emerald.com/insight/content/doi/10.1108/BPMJ-11-2023-0894/full/html},
year = {2024}
}
@article{Sundberg2024,
abstract = {Machine learning (ML) offers widely-recognized, but complex, opportunities for both public and private sector organizations to generate value from data. A key requirement is that organizations must find ways to develop new knowledge by merging crucial `domain knowledge ` of experts in relevant fields with `machine knowledge `, i.e., data that can be used to inform predictive models. In this paper, we argue that understanding the process of generating such knowledge is essential to strategically develop ML. In efforts to contribute to such understanding, we examine the generation of new knowledge from domain knowledge through ML via an exploratory study of two cases in the Swedish public sector. The findings reveal the roles of three mechanisms - dubbed consolidation, algorithmic mediation, and naturalization - in tying domain knowledge to machine knowledge. The study contributes a theory of knowledge production related to organizational use of ML, with important implications for its strategic governance, particularly in the public sector.},
author = {Sundberg, Leif and Holmstr{\"{o}}m, Jonny},
doi = {10.1016/j.jsis.2024.101848},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Sundberg, Holmstr{\"{o}}m - The Journal of Strategic Information Systems.pdf:pdf},
issn = {09638687},
journal = {The Journal of Strategic Information Systems},
keywords = {Artificial Intelligence,Knowledge production,Machine Learning,Natural Language Processing,Public Sector},
language = {English},
month = {sep},
number = {3},
pages = {101848},
title = {{Fusing domain knowledge with machine learning: A public sector perspective}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0963868724000301},
volume = {33},
year = {2024}
}
@article{Botta2024,
abstract = {The effective and ethical use of data to inform decision-making offers huge value to the public sector, especially when delivered by transparent, reproducible, and robust data processing workflows. One way that governments are unlocking this value is through making their data publicly available, allowing more people and organisations to derive insights. However, open data is not enough in many cases: publicly available datasets need to be accessible in an analysis-ready form from popular data science tools, such as R and Python, for them to realise their full potential. This paper explores ways to maximise the impact of open data with reference to a case study of packaging code to facilitate reproducible analysis. We present the jtstats project, which consists of a main Python package, and a smaller R version, for importing, processing, and visualising large and complex datasets representing journey times, for many transport modes and trip purposes at multiple geographic levels, released by the UK Department for Transport (DfT). jtstats shows how domain specific packages can enable reproducible research within the public sector and beyond, saving duplicated effort and reducing the risks of errors from repeated analyses. We hope that the jtstats project inspires others, particularly those in the public sector, to add value to their data sets by making them more accessible.},
author = {Botta, Federico and Lovelace, Robin and Gilbert, Laura and Turrell, Arthur},
doi = {10.1177/23998083241267331},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Botta et al. - Environment and Planning B Urban Analytics and City Science.pdf:pdf},
issn = {2399-8083},
journal = {Environment and Planning B: Urban Analytics and City Science},
keywords = {Data science for public good,government data,open source},
language = {English},
month = {jul},
title = {{Packaging code and data for reproducible research: A case study of journey time statistics}},
url = {https://journals.sagepub.com/doi/10.1177/23998083241267331},
year = {2024}
}
@article{Frost2024,
abstract = {The increasing use of machine learning (ML) in public administration requires that we think carefully about the political and legal constraints imposed on public decision making. These developments confront us with the following interrelated questions: can algorithmic public decisions be truly ‘public'? And, to what extent does the use of ML models compromise the ‘publicness' of such decisions? This article is part of a broader inquiry into the myriad ways in which digital and AI technologies transform the fabric of our democratic existence by mutating the ‘public'. Focusing on the site of public administration, the article develops a conception of publicness that is grounded in a view of public administrations as communities of practice. These communities operate through dialogical, critical and synergetic interactions that allow them to track—as faithfully as possible—the public's heterogeneous view of its interests, and reify these interests in decision making. Building on this theorisation, the article suggests that the use of ML models in public decision making inevitably generates an impoverished publicness, and thus undermines the potential of public administrations to operate as a locus of democratic construction. The article thus advocates for a reconsideration of the ways in which administrative law problematises and addresses the harms of algorithmic decision making.},
author = {Frost, Neli},
doi = {10.1093/ojls/gqae027},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Frost - Oxford Journal of Legal Studies.pdf:pdf},
issn = {0143-6503},
journal = {Oxford Journal of Legal Studies},
keywords = {administrative law,artificial intelligence,law & technology,machine learning,public administration,public decision making},
language = {English},
month = {aug},
title = {{The Impoverished Publicness of Algorithmic Decision Making}},
url = {https://academic.oup.com/ojls/advance-article/doi/10.1093/ojls/gqae027/7731417},
year = {2024}
}
@article{Bignami2022,
author = {Bignami, Francesca},
doi = {10.1093/ajcl/avac012},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Bignami - The American Journal of Comparative Law.pdf:pdf},
issn = {0002-919X},
journal = {The American Journal of Comparative Law},
language = {English},
month = {oct},
number = {Supplement_1},
pages = {i312--i346},
title = {{Artificial Intelligence Accountability of Public Administration}},
url = {https://academic.oup.com/ajcl/article/70/Supplement_1/i312/6596541},
volume = {70},
year = {2022}
}
@article{Wanckel2022,
abstract = {Public sector organizations at all levels of government increasingly rely on Big Data Algorithmic Systems (BDAS) to support decision-making along the entire policy cycle. But while our knowledge on the use of big data continues to grow for government agencies implementing and delivering public services, empirical research on applications for anticipatory policy design is still in its infancy. Based on the concept of policy analytical capacity (PAC), this case study examines the application of BDAS for early crisis detection within the German Federal Government-that is, the German Federal Foreign Office (FFO) and the Federal Ministry of Defence (FMoD). It uses the nested model of PAC to reflect on systemic, organizational, and individual capacity-building from a neoinstitutional perspective and allow for the consideration of embedded institutional contexts. Results from semi-structured interviews indicate that governments seeking to exploit BDAS in policymaking depend on their institutional environment (e.g., through research and data governance infrastructure). However, specific capacity-building strategies may differ according to the departments' institutional framework, with the FMoD relying heavily on subordinate agencies and the FFO creating network-like structures with external researchers. Government capacity-building at the individual and organizational level is similarly affected by long-established institutional structures, roles, and practices within the organization and beyond, making it important to analyze these three levels simultaneously instead of separately.},
author = {Wanckel, Camilla},
doi = {10.1016/j.giq.2022.101705},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Wanckel - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence (AI),Big data algorithm system (BDAS),Central government organizations,Early crisis detection,Neo-institutionalism,Policy analytical capacity (PAC),Policymaking},
language = {English},
month = {oct},
number = {4},
pages = {101705},
title = {{An ounce of prevention is worth a pound of cure – Building capacities for the use of big data algorithm systems (BDAS) in early crisis detection}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X22000387},
volume = {39},
year = {2022}
}
@article{Jeong2022,
abstract = {South Korea introduced the artificial intelligence impact assessment and was the first case of introducing the artificial intelligence impact assessment as national-level legislation. Artificial intelligence impact assessments will be helpful in deciding whether to introduce artificial intelligence by comparing costs and benefits. However, South Korea's approach had limitations. First, an impact assessment was introduced only in the public sector. Second, artificial intelligence impact assessments were voluntary. Third, the subject of artificial intelligence impact assessments was limited to society. Fourth, it is necessary to establish a relationship with other impact assessments. Fifth, specific details were incomplete.},
author = {Jeong, Jonggu},
doi = {10.3390/laws11050073},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Jeong - LAWS.pdf:pdf},
journal = {LAWS},
keywords = {AI,AI impact assessment,South Korea,intelligent information service},
language = {English},
month = {oct},
number = {5},
title = {{Introduction of the First AI Impact Assessment and Future Tasks: South Korea Discussion}},
volume = {11},
year = {2022}
}
@article{Ruvalcaba-Gomez2023,
abstract = {Artificial Intelligence (AI) as a technological development is being implemented in the public sector with the intention of improving service delivery, as well as to help solve complex problems. However, there is a wide range of capabilities that AI can perform and that public officials perceive and implement in different ways. This paper aims to describe and analyze some categories into which AI capabilities in the public sector are divided. Using an Exploratory Factor Analysis (EFA), our results show that the capabilities of AI from the perspective of public officials can be classified into two aspects: systematic factors and axiological factors. Systematic factors are related to the analysis and behavior of data, including monitoring, analyzing, interacting, remembering, and anticipation. Axiological factors refer to the impacts of values, ethics, and decisions, including acting, feeling, moralizing, creating, and deciding capacities. This categorization of AI capabilities in the public sector sheds light on the perception of public officials about the implementation of this technological development.},
author = {Ruvalcaba-Gomez, Edgar A.},
doi = {10.1177/09520767231170321},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Ruvalcaba-Gomez - Public Policy and Administration.pdf:pdf},
issn = {0952-0767},
journal = {Public Policy and Administration},
keywords = {Artificial intelligence,capabilities,exploratory factor analysis,public sector},
language = {English},
month = {apr},
pages = {095207672311703},
title = {{Systematic and axiological capacities in artificial intelligence applied in the public sector}},
url = {http://journals.sagepub.com/doi/10.1177/09520767231170321},
year = {2023}
}
@article{Zahid2023,
abstract = {The rapid generation of data from various sources by the public sector, private corporations, business associations, and local communities is referred to as big data. This large and complex dataset is often regarded as the ‘new oil' by public administrations (PAs), and data-driven approaches are employed to transform it into valuable insights that can improve governance, transparency, digital services, and public engagement. The government's big-data ecosystem (GBDE) is a result of this initiative. Effective data management is the first step towards large-scale data analysis, which yields insights that benefit your work and your customers. However, managing big data throughout its life cycle is a daunting challenge for public agencies. Despite its widespread use, big data management is still a significant obstacle. To address this issue, this study proposes a hybrid approach to secure the data management life cycle for GBDE. Specifically, we use a combination of the ECC algorithm with AES 128 BITS encryption to ensure that the data remain confidential and secure. We identified and analyzed various data life cycle models through a systematic literature review to create a data management life cycle for data-driven governments. This approach enhances the security and privacy of data management and addresses the challenges faced by public agencies.},
author = {Zahid, Reeba and Altaf, Ayesha and Ahmad, Tauqir and Iqbal, Faiza and Vera, Yini Airet Mir{\'{o}} and Flores, Miguel Angel L{\'{o}}pez and Ashraf, Imran},
doi = {10.3390/systems11080380},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Zahid et al. - Systems.pdf:pdf},
issn = {2079-8954},
journal = {Systems},
keywords = {GBDE,big data,data life cycle,secure data life cycle},
language = {English},
month = {jul},
number = {8},
pages = {380},
title = {{Secure Data Management Life Cycle for Government Big-Data Ecosystem: Design and Development Perspective}},
url = {https://www.mdpi.com/2079-8954/11/8/380},
volume = {11},
year = {2023}
}
@article{Abbas2023,
abstract = {Efficient monitoring and achievement of the Sustainable Development Goals (SDGs) has increased the need for a variety of data and statistics. The massive increase in data gathering through social networks, traditional business systems, and Internet of Things (IoT)-based sensor devices raises real questions regarding the capacity of national statistical systems (NSS) for utilizing big data sources. Further, in this current era, big data is captured through sensor-based systems in public sector organizations. To gauge the capacity of public sector institutions in this regard, this work provides an indicator to monitor the processing capacity of the public sector organizations within the country (Pakistan). Some of the indicators related to measuring the capacity of the NSS were captured through a census-based survey. At the same time, convex logistic principal component analysis was used to develop scores and relative capacity indicators. The findings show that most organizations hesitate to disseminate data due to concerns about data privacy and that public sector organizations' IT personnel are unable to deal with big data sources to generate official statistics. Artificial intelligence (AI) techniques can be used to overcome these challenges, such as automating data processing, improving data privacy and security, and enhancing the capabilities of IT human resources. This research helps to design capacity-building initiatives for public sector organizations in weak dimensions, focusing on leveraging AI to enhance the production of quality and reliable statistics.},
author = {Abbas, Syed Wasim and Hamid, Muhammad and Alkanhel, Reem and Abdallah, Hanaa A.},
doi = {10.3390/systems11080424},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Abbas et al. - Systems.pdf:pdf},
issn = {2079-8954},
journal = {Systems},
keywords = {artificial intelligence,big data,capacity indicator,convex logistic principal component analysis,sensor-based systems},
language = {English},
month = {aug},
number = {8},
pages = {424},
title = {{Official Statistics and Big Data Processing with Artificial Intelligence: Capacity Indicators for Public Sector Organizations}},
url = {https://www.mdpi.com/2079-8954/11/8/424},
volume = {11},
year = {2023}
}
@article{Pautz2023,
abstract = {The article presents an exploratory qualitative single case study about whether and how artificial intelligence (AI) is used by the Scottish Government, about the key concerns relating to its usage, and about obstacles to, and drivers of AI usage. Besides the academic literature and published reports, the analysis rests on 12 semi-structured interviews. Interviewees include Scottish Government employees, experts from academia and representatives of commercial and non-commercial AI and Big Data organisations. The article finds that the Scottish Government has, so far, made little use of AI. Currently, AI is used in very limited ways in process automation and for gaining `cognitive insights' with the human in control. There are no `strategic' AI applications where advanced reasoning and `decision-making by algorithm' play a role. Data-driven e-policy making is not currently on the cards. The reasons are the Scottish Government's wariness of AI, a lack of `digital maturity' (concerning Big Data and digital infrastructure, but also expertise) in the public sector, and ethical concerns around the use of AI. Governments need to conduct a debate about the extent of AI usage to avoid `AI creep' in their institutions and to assure that AI does not have negative consequences for democracy.},
author = {Pautz, Hartwig},
doi = {10.1080/21582041.2023.2293822},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Pautz - Contemporary Social Science.pdf:pdf},
issn = {2158-2041},
journal = {Contemporary Social Science},
keywords = {Artificial intelligence,Big Data,Scotland,policy making},
language = {English},
month = {oct},
number = {5},
pages = {618--636},
title = {{Policy making and artificial intelligence in Scotland}},
url = {https://www.tandfonline.com/doi/full/10.1080/21582041.2023.2293822},
volume = {18},
year = {2023}
}
@article{Marty2024,
abstract = {<p>Household surveys give a precise estimate of poverty; however, surveys are costly and are fielded infrequently. We demonstrate the importance of jointly using multiple public and private sector data sources to estimate levels and changes in wealth for a large set of countries. We train models using 63,854 survey cluster locations across 59 countries, relying on data from satellites, Facebook Marketing information, and OpenStreetMaps. The model generalizes previous approaches to a wide set of countries. On average, across countries, the model explains 55% (min = 14%; max = 85%) of the variation in levels of wealth at the survey cluster level and 59% (min = 0%; max = 93%) of the variation at the district level, and the model explains 4% (min = 0%; max = 17%) and 6% (min = 0%; max = 26%) of the variation of changes in wealth at the cluster and district levels. Models perform best in lower-income countries and in countries with higher variance in wealth. Features from nighttime lights, OpenStreetMaps, and land cover data are most important in explaining levels of wealth, and features from nighttime lights are most important in explaining changes in wealth.</p>},
author = {Marty, Robert and Duhaut, Alice},
doi = {10.1038/s41598-023-49564-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Marty, Duhaut - Scientific Reports.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
language = {English},
month = {feb},
number = {1},
pages = {3160},
title = {{Global poverty estimation using private and public sector big data sources}},
url = {https://www.nature.com/articles/s41598-023-49564-6},
volume = {14},
year = {2024}
}
@article{Hjaltalin2024,
abstract = {Governments worldwide are strategically investing in artificial intelligence (AI) to improve public services and streamline internal operations. In this context, national AI strategies play a pivotal role. This study uses combined qualitative research methods analyzing 28 national AI strategies (i.e., the texts). Our aim is to delve into how governments define and position AI applications within the public sector. Specifically, the study explores how the texts convey AI's application in this context employing a public value(s) perspective. Its discursive analytical approach coupled with a comprehensive take on public value theory (Moore, 1995) engenders novel insights into national discourses on AI in the public sector. Against this background we draw on public administration and policy research in our analysis of three dominant discourses that we identify in the texts, i.e. empowerment through information, enhanced administrative practices, and improved service delivery. We find that the discourses involve different positions in relation to governments' use of AI and depend on particular actors and types of public service. Commonly, they concern government objectives to tackle critical societal issues through AI, such as in the areas of health and social care and employment. In particular, the discourse of enhanced administrative practices commonly positioned AI as a tool to optimize internal processes, resource allocation, and organizational management. On the other hand, the discourse of improved service delivery similarly placed public services front and center, while the discourse of empowerment through information framed AI as being able to enhance citizens' service experiences. Interestingly, discourses emphasizing the policymaking function, i.e., AI applied to the development of public policy,-receives limited attention. Our findings underscore strategic prioritizations. While efficiency and service delivery dominate the discourse, citizen engagement remains underemphasized. We argue that policymakers must strike a balance, ensuring AI aligns with broader societal outcomes while addressing democratic imperatives.},
author = {Hjaltalin, Illugi Torfason and Sigurdarson, Hallur Thor},
doi = {10.1016/j.giq.2024.101914},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Hjaltalin, Sigurdarson - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Discourse analysis,E-government,National strategy,Public value,Strategy,Technology application},
language = {English},
month = {mar},
number = {1},
pages = {101914},
title = {{The strategic use of AI in the public sector: A public values analysis of national AI strategies}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X24000066},
volume = {41},
year = {2024}
}
@article{Kaushal2022,
abstract = {<p> A united front from all the stakeholders including public, administration and academia alike is required to counter the growing threat of climate change. The recent rise of social media as the new public address system, makes it an ideal source of information to assess public discussions and responses in real time. We mine c.1.7 m posts from 55 climate related subreddits on social media platform Reddit since its inception. Using USE, a state-of-the-art sentence encoder, and K-means clustering algorithm, we develop a machine learning based approach to identify, store, process and classify the posts automatically, and at a scale. In the broad and multifaceted theme of climate change, our approach narrows down the focus to 10 critical underlying themes comprising the public discussions on social media over time. Furthermore, we employ a full order partial correlation analysis to assess the relationship between the different identified themes. We show that in line with Paris Agreement, while the <italic>climate science</italic> community has been successful in influencing the discussions on both the causes and effects of climate change, the <italic>public administration</italic> has failed to appropriately communicate the causes of climate change and has been able to influence only the discussions on the effects of it. Hence, our study shows a clear gap in the public communication by the administration, wherein counter-intuitively less emphasis has been given on the drivers of climate change. This information can be particularly beneficial to policymakers and climate activists in decision making as they try to close the gap between public and academia. </p>},
author = {Kaushal, Akshay and Acharjee, Animesh and Mandal, Anandadeep},
doi = {10.1038/s41598-022-22034-1},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Kaushal, Acharjee, Mandal - Scientific Reports.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
language = {English},
month = {nov},
number = {1},
pages = {19033},
title = {{Machine learning based attribution mapping of climate related discussions on social media}},
url = {https://www.nature.com/articles/s41598-022-22034-1},
volume = {12},
year = {2022}
}
@article{Cho2022,
abstract = {Purpose The revitalization of big data has gained attention in the public sector. However, such open government data (OGD) is facing major challenges with respect to data quality and limited use. To solve this problem, this study analyzes the factors driving the use of OGD from the perspective of data providers in the public sector. Design/methodology/approach Using the analytic hierarchy process and analytic network process methodologies, the importance of the factors driving the use of big data in the public sector was ranked. In addition, the different characteristics of tasks among the departments in a public agency were compared based on expert interviews. Findings The factors driving OGD use are not only political environment or the technological environment. The importance of the institutional culture within the organization increases with the motivation of the data provider. The priorities of the OGD factors also depend on the objectives of the department involved. Originality/value This study provides implications for improving the publication of open data by analyzing the priorities of the factors driving its use from the perspective of big data providers. It focuses on different perceptions of the factors valued by public officials in charge of data in institutions. The results suggest the need to explore officials' perceptions of value creation in big data fields.},
author = {Cho, Ji Yeon and Lee, Bong Gyou},
doi = {10.1108/ITP-04-2019-0169},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Cho, Lee - Information Technology & People.pdf:pdf},
issn = {0959-3845},
journal = {Information Technology & People},
keywords = {Analytic hierarchy process,Analytic network process,Big data,Data value,Open government data,Public sector},
language = {English},
month = {mar},
number = {2},
pages = {467--493},
title = {{Creating value using public big data: comparison of driving factors from the provider's perspective}},
url = {https://www.emerald.com/insight/content/doi/10.1108/ITP-04-2019-0169/full/html},
volume = {35},
year = {2022}
}
@article{Buttow2022,
abstract = {Algorithmic technologies and artificial intelligence are centred on data and generate new business models, known as the data-driven economy. In the European Union context, the development of such new business is accompanied by a regulatory and political framework. An important aspect of this regulatory framework regards the legal conditions that enable the data collection, availability, sharing, use and reuse. Within the larger context, this article analyses the development of the European Union regulatory framework governing the availability, sharing and reuse of public sector data, also referred to as Public Sector Information policy. Anchored in the analytical tools provided by Discursive Institutionalism and Critical Data Studies and after studying the evolution of this policy over 25 years, this article argues that economic considerations have been overwhelmingly decisive in the European Union Public Sector Information policy and much less attention has been paid to fundamental rights and democracy issues. It also shows how European Union Public Sector Information policy contributes to the data infrastructure, enabling a thriving data-driven economy. In doing so, this article argues that the possible problematic effects of this new data-driven economy are not only affordances of the technology itself but are also the result of political and regulatory choices. More globally, the article stresses the need for policymakers to inscribe each of the policies and regulations affecting the digital transformation in the framework of fundamental rights and democracy.},
author = {{Valli Buttow}, Clarissa and Weerts, Sophie},
doi = {10.1177/20539517221124587},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Valli Buttow, Weerts - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Public sector information,critical data studies,data economy,discursive institutionalism,open government data,regulation},
language = {English},
month = {jul},
number = {2},
pages = {205395172211245},
title = {{Public sector information in the European Union policy: The misbalance between economy and individuals}},
url = {http://journals.sagepub.com/doi/10.1177/20539517221124587},
volume = {9},
year = {2022}
}
@article{Engstrom2023,
abstract = {Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.},
author = {Engstrom, David Freeman and Haim, Amit},
doi = {10.1146/annurev-lawsocsci-120522-091626},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Engstrom, Haim - Annual Review of Law and Social Science.pdf:pdf},
issn = {1550-3585},
journal = {Annual Review of Law and Social Science},
keywords = {artificial intelligence,government,institutional design,public administration,regulation},
language = {English},
month = {oct},
number = {1},
pages = {277--298},
title = {{Regulating Government AI and the Challenge of Sociotechnical Design}},
url = {https://www.annualreviews.org/doi/10.1146/annurev-lawsocsci-120522-091626},
volume = {19},
year = {2023}
}
@article{Haesevoets2024,
abstract = {Artificial Intelligence (AI) has become increasingly prevalent in almost every aspect of our lives. At the same time, a debate about its applications, safety, and privacy is raging. In three studies, we explored how UK respondents perceive the usage of AI in various public sector decisions. Our results are fourfold. First, we found that people prefer AI to have considerably less decisional weight than various human decision-makers; those being: politicians, citizens, and (human) experts. Secondly, our findings revealed that people prefer AI to provide input and advice to these human decision-makers, rather than letting AI make decisions by itself. Thirdly, although AI is seen as contributing less to perceived legitimacy than these human decision-makers, similar to (human) experts, its contribution is seen more in terms of output legitimacy than in terms of input and throughput legitimacy. Finally, our results suggest that the involvement of AI is perceived more suitable for decisions that are low (instead of high) ideologically-charged. Overall, our findings thus show that people are rather skeptical towards using AI in the public domain, but this does not imply that they want to exclude AI entirely from the decision-making process.},
author = {Haesevoets, Tessa and Verschuere, Bram and {Van Severen}, Ruben and Roets, Arne},
doi = {10.1016/j.giq.2023.101906},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Haesevoets et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial Intelligence (AI),Decision type,Decisional weight,Hybrid decision-making,Public sector decisions,Roles Legitimacy},
language = {English},
month = {mar},
number = {1},
pages = {101906},
title = {{How do citizens perceive the use of Artificial Intelligence in public sector decisions?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23001065},
volume = {41},
year = {2024}
}
@article{Dunleavy2019,
abstract = {Within long-lived public sector bureaucracies, the organizational cultures developed by administrative elites have strong filtering and focusing effects on the kinds of technological changes adopted, especially in the modern era. Normally seen as very slow-moving and hard to alter, senior officials' attitudes towards digital changes have recently begun to alter in more substantial ways in Australia. We review first a considerable reappraisal of the priority given to digital changes by top public service managers. This cultural shift has followed on from tech-lead disruptive societal changes affecting most areas of government now, and from the rise of global-scaled ICT corporations to become key management exemplars for officials. Second, we look at the chequered history of political leaders' interventions to speed up digital change, showing that in the period 2015-19 Australia witnessed both the initial power and later limits of such involvement. Finally, we consider Australia's recent experience with big data/ artificial intelligence (BDAI), a key area of technological change for public service officials, but one that in a liberal democracy can also easily spark public resistance to their plans.},
author = {Dunleavy, Patrick and Evans, Mark},
doi = {10.1080/23812346.2019.1596544},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Dunleavy, Evans - Journal of Chinese Governance.pdf:pdf},
issn = {2381-2346},
journal = {Journal of Chinese Governance},
keywords = {Bureaucracy,In,artificial intelligence,digital,public service officials,service reform},
language = {English},
month = {apr},
number = {2},
pages = {181--200},
title = {{Australian administrative elites and the challenges of digital-era change}},
url = {https://www.tandfonline.com/doi/full/10.1080/23812346.2019.1596544},
volume = {4},
year = {2019}
}
@article{Cerrillo-Martinez2021,
abstract = {Public transparency is becoming increasingly complex due to the volume of data generated by government, the plurality of uses given to public data, their dispersal over different organizations, bodies and units and the diversity of mecha­nisms through which they are channelled. All this requires government agencies not only to improve data management but also to adopt procedures and structures that facilitate decision-making regarding data's use and quality. In this context, this study defines data governance as the set of principles, values and standards that guide interaction in decision-making among stakeholders who create, manage and use data. This study uses the analysis of three data governance cases to identify the defining characteristics of data governance (data governance's design, the institutional position on data governance in the organizational structure, the stakeholders involved in data governance, the interaction channels provided and the functions attributed to them). Based on these elements, three models of data governance promoted by government agencies are observed. In the light of the data governance models analysed, the final reflection identifies how data governance can contribute to improve public transparency.},
author = {Cerrillo-Mart{\'{i}}nez, Agust{\'{i}} and Casades{\'{u}}s-de-Mingo, Anah{\'{i}}},
doi = {10.3145/epi.2021.jul.02},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Cerrillo-Mart{\'{i}}nez, Casades{\'{u}}s-de-Mingo - El Profesional de la informaci{\'{o}}n.pdf:pdf},
issn = {16992407},
journal = {El Profesional de la informaci{\'{o}}n},
keywords = {Accountability,Big data,Case studies,Compliance,Data,Data governance,Data management,Data re-use,Legal frameworks,Local administration,Open data,Open government,Policies,Public administration,Public policy,Public sector,Transparency},
language = {English},
month = {jul},
number = {4},
title = {{Data governance for public transparency}},
url = {https://revista.profesionaldelainformacion.com/index.php/EPI/article/view/86362},
volume = {30},
year = {2021}
}
@article{Sovrano2022,
abstract = {We are recently witnessing a radical shift towards digitisation in many aspects of our daily life, including law, public administration and governance. This has sometimes been done with the aim of reducing costs and human errors by improving data analysis and management, but not without raising major technological challenges. One of these challenges is certainly the need to cope with relatively small amounts of data, without sacrificing performance. Indeed, cutting-edge approaches to (natural) language processing and understanding are often data-hungry, especially those based on deep learning. With this paper we seek to address the problem of data scarcity in automatic Legalese (or legal English) processing and understanding. What we propose is an ensemble of shallow and deep learning techniques called SyntagmTuner, designed to combine the accuracy of deep learning with the ability of shallow learning to work with little data. Our contribution is based on the assumption that Legalese differs from its spoken language in the way the meaning is encoded by the structure of the text and the co-occurrence of words. As result, we show with SyntagmTuner how we can perform important tasks for e-governance, as multi-label classification of the United Nations General Assembly (UNGA) Resolutions or legal question answering, with data-sets of roughly 100 samples or even less.},
author = {Sovrano, Francesco and Palmirani, Monica and Vitali, Fabio},
doi = {10.1016/j.giq.2022.101715},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Sovrano, Palmirani, Vitali - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Data scarcity,Deep learning,Law,Syntagmatic relations,TF-IDF},
language = {English},
month = {jul},
number = {3},
pages = {101715},
title = {{Combining shallow and deep learning approaches against data scarcity in legal domains}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X2200048X},
volume = {39},
year = {2022}
}
@article{Jorgensen2022,
abstract = {Decision support systems, which incorporate artificial intelligence and big data, are receiving significant attention in the public sector. Decision support systems are sociocultural artefacts that are subject to a mix of technical and political choices, and critical investigation of these choices and the rationales they reflect are paramount since they are inscribed into and may cause harm, violate fundamental rights and reproduce negative social patterns. Applying and merging the concepts of sense-making and translation, this article investigates the rationales, translations and critical reflections that shape the development of a decision support system to support social workers assessing referrals concerning child neglect. It presents findings from a qualitative case study conducted in 2019–2020 at the Citizen Centre Children and Young People, Copenhagen Municipality, Denmark. The analysis shows how key actors through processes of translation construct, negotiate and readjust problem definitions, roles, interests, responsibilities and ideas of ambiguity and accountability. Although technological solutionism is present in these processes, it is not the only rationale invested. Rather, technological and data-driven rationales are adjusted to and merged with rationales of efficiency, return on investment and child welfare. Through continuous renegotiation of roles, responsibilities and problems according to these rationales, the key actors attempt to orchestrate ways of managing the complexity facing child welfare services by projecting images of future potentials of the decision support system that are yet to be realised.},
author = {J{\o}rgensen, Andreas M{\o}ller and Nissen, Maria Appel},
doi = {10.1177/20539517221125163},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - J{\o}rgensen, Nissen - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Algorithms,artificial intelligence,big data,child protection,decision support system,risk assessment},
language = {English},
month = {jul},
number = {2},
pages = {205395172211251},
title = {{Making sense of decision support systems: Rationales, translations and potentials for critical reflections on the reality of child protection}},
url = {http://journals.sagepub.com/doi/10.1177/20539517221125163},
volume = {9},
year = {2022}
}
@article{Papyshev2023,
abstract = {Numerous governments worldwide have issued national artificial intelligence (AI) strategies in the last five years to deal with the opportunities and challenges posed by this technology. However, a systematic understanding of the roles and functions that the governments are taking is lacking in the academic literature. Therefore, this research uses qualitative content analysis and Latent Dirichlet Allocation (LDA) topic modeling methodologies to investigate the texts of 31 strategies from across the globe. The findings of the qualitative content analysis highlight thirteen functions of the state, which include human capital, ethics, R&D, regulation, data, private sector support, public sector applications, diffusion and awareness, digital infrastructure, national security, national challenges, international cooperation, and financial support. We combine these functions into three general themes, representing the state's role: development, control, and promotion. LDA topic modeling results are also reflective of these themes. Each general theme is present in every national strategy's text, but the proportion they occupy in the text is different. The combined typology based on two methods reveals that the countries from the post-soviet bloc and East Asia prioritize the theme ``development,'' highlighting the high level of the state's involvement in AI innovation. The countries from the EU focus on ``control,'' which reflects the union's hard stance on AI regulation, whereas countries like the UK, the US, and Ireland emphasize a more hands-off governance arrangement with the leading role of the private sector by prioritizing ``promotion.''},
author = {Papyshev, Gleb and Yarime, Masaru},
doi = {10.1080/25741292.2022.2162252},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Papyshev, Yarime - Policy Design and Practice.pdf:pdf},
issn = {2574-1292},
journal = {Policy Design and Practice},
keywords = {Artificial intelligence,Latent Dirichlet Allocation topic modeling,national AI strategy,qualitative content analysis,state's role},
language = {English},
month = {jan},
number = {1},
pages = {79--102},
title = {{The state's role in governing artificial intelligence: development, control, and promotion through national strategies}},
url = {https://www.tandfonline.com/doi/full/10.1080/25741292.2022.2162252},
volume = {6},
year = {2023}
}
@article{Robles2023,
abstract = {Advancement in information technology continues to evolve especially in the field of artificial intelligence (AI). Research studies have been conducted to evaluate the perceptions of Americans on the development and utilization of AI technology and if it is appropriate to use AI in public administrative duties. The research revealed that society is fragmented regarding the acceptance of AI, and whether AI decisions could have long‐term effects on the labor industry, legal system, and national security. The 2018 AI Public Opinion Survey revealed significant concerns among the American public regarding AI, yet also a recognition of its promise. The goal of this article is to further develop a governance framework for AI that considers the importance of public trust in AI policy. First, it discusses the necessity of public trust for the effective governance of emergent technology. Then, it evaluates public opinion on AI technology that specifically pertains to governance. The article concludes with a discussion of why public trust is central to good AI governance.},
author = {Robles, Pedro and Mallinson, Daniel J.},
doi = {10.1111/ropr.12555},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Robles, Mallinson - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {AI governance,AI policy,artificial intelligence framework,information technology governance,public sector,public values},
language = {English},
month = {may},
title = {{Artificial intelligence technology, public trust, and effective governance}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12555},
year = {2023}
}
@article{Fest2022,
abstract = {Recent years have seen a massive growth in ethical and legal frameworks
to govern data science practices. Yet one of the core questions
associated with ethical and legal frameworks is the extent to which they
are implemented in practice. A particularly interesting case in this
context comes to public officials, for whom higher standards typically
exist. We are thus trying to understand how ethical and legal frameworks
influence the everyday practices on data and algorithms of public sector
data professionals. The following paper looks at two cases: public
sector data professionals (1) at municipalities in the Netherlands and
(2) at the Netherlands Police. We compare these two cases based on an
analytical research framework we develop in this article to help
understanding of everyday professional practices. We conclude that there
is a wide gap between legal and ethical governance rules and the
everyday practices.},
author = {Fest, Isabelle and Wieringa, Maranke and Wagner, Ben},
doi = {10.1016/j.patter.2022.100604},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Fest, Wieringa, Wagner - Patterns.pdf:pdf},
issn = {26663899},
journal = {Patterns},
language = {English},
month = {oct},
number = {10},
pages = {100604},
title = {{Paper vs. practice: How legal and ethical frameworks influence public sector data professionals in the Netherlands}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S266638992200229X},
volume = {3},
year = {2022}
}
@article{Johnson2022,
abstract = {Advances in big data and artificial intelligence (AI), including machine learning (ML) and other cognitive computing technologies (CCT), have facilitated the development of human resource management (HRM) applications promising greater efficiency, economy, and effectiveness for public administration (Maciejewski, 2017) and better alignment with the modern, constantly evolving employment landscape. It is not surprising then that these advanced technologies are featured in proposals to elevate the government's human capital. This article discusses current and emerging AI applications that stand to impact most (if not all) HRM functions and their prospects for elevating public human capital. In particular, this article (a) reviews the current state of the field with regards to AI and HRM, (b) discusses AI's current and potential impact upon the core functional areas of HRM, (c) identifies the main challenges AI poses to such concerns as public values, equity, and traditional merit system principles, and (d) concludes by identifying research needs for public HRM scholarship and practice that highlight the growing role and influence of AI applications in the workplace.},
author = {Johnson, Brad A. M. and Coggburn, Jerrell D. and Llorens, Jared J.},
doi = {10.1177/00910260221126498},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Johnson, Coggburn, Llorens - Public Personnel Management.pdf:pdf},
issn = {0091-0260},
journal = {Public Personnel Management},
keywords = {artificial intelligence (AI),public human capital,public human resource management},
language = {English},
month = {dec},
number = {4},
pages = {538--562},
title = {{Artificial Intelligence and Public Human Resource Management: Questions for Research and Practice}},
url = {http://journals.sagepub.com/doi/10.1177/00910260221126498},
volume = {51},
year = {2022}
}
@article{Keppeler2024,
abstract = {<p>Applications based on artificial intelligence (AI) play an increasing role in the public sector and invoke political discussions. Research gaps exist regarding the disclosure effects—reactions to disclosure of the use of AI applications—and the deployment effect—efficiency gains in data savvy tasks. This study analyzes disclosure effects and explores the deployment of an AI application in a preregistered field experiment (n = 2,000) co-designed with a public organization in the context of employer-driven recruitment. The linear regression results show that disclosing the use of the AI application leads to significantly less interest in an offer among job candidates. The explorative analysis of the deployment of the AI application indicates that the person–job fit determined by the leaders can be predicted by the AI application. Based on the literature on algorithm aversion and digital discretion, this study provides a theoretical and empirical disentanglement of the disclosure effect and the deployment effect to inform future evaluations of AI applications in the public sector. It contributes to the understanding of how AI applications can shape public policy and management decisions, and discusses the potential benefits and downsides of disclosing and deploying AI applications in the public sector and in employer-driven recruitment.</p>},
author = {Keppeler, Florian},
doi = {10.1093/jopart/muad009},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Keppeler - Journal of Public Administration Research and Theory.pdf:pdf},
issn = {1053-1858},
journal = {Journal of Public Administration Research and Theory},
language = {English},
month = {jan},
number = {1},
pages = {39--52},
title = {{No Thanks, Dear AI! Understanding the Effects of Disclosure and Deployment of Artificial Intelligence in Public Sector Recruitment}},
url = {https://academic.oup.com/jpart/article/34/1/39/7174960},
volume = {34},
year = {2024}
}
@article{Newman2023,
abstract = {Scholarship on evidence-based policy, a subset of the policy analysis literature, largely assumes information is produced and consumed by humans. However, due to the expansion of artificial intelligence in the public sector, debates no longer capture the full range concerns. Here, we derive a typology of arguments on evidence-based policy that performs two functions: taken separately, the categories serve as directions in which debates may proceed, in light of advances in technology; taken together, the categories act as a set of frames through which the use of evidence in policy making might be understood. Using a case of welfare fraud detection in the Netherlands, we show how the acknowledgement of divergent frames can enable a holistic analysis of evidence use in policy making that considers the ethical issues inherent in automated data processing. We argue that such an analysis will enhance the real-world relevance of the evidence-based policy paradigm.},
author = {Newman, Joshua and Mintrom, Michael},
doi = {10.1080/13501763.2023.2193223},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Newman, Mintrom - Journal of European Public Policy.pdf:pdf},
issn = {1350-1763},
journal = {Journal of European Public Policy},
keywords = {Policy analysis,artificial intelligence,ethics,evidence-based policy,frame reflection,public service delivery},
language = {English},
month = {sep},
number = {9},
pages = {1839--1859},
title = {{Mapping the discourse on evidence-based policy, artificial intelligence, and the ethical practice of policy analysis}},
url = {https://www.tandfonline.com/doi/full/10.1080/13501763.2023.2193223},
volume = {30},
year = {2023}
}
@article{Li2023,
abstract = {As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance—“AI cage” and “AI colleague.” The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.},
author = {Li, Yiran and Fan, Yingying and Nie, Lin},
doi = {10.1177/09520767231188229},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Li, Fan, Nie - Public Policy and Administration.pdf:pdf},
issn = {0952-0767},
journal = {Public Policy and Administration},
keywords = {Artificial intelligence,agile governance,government as a platform,public value},
language = {English},
month = {jul},
title = {{Making governance agile: Exploring the role of artificial intelligence in China's local governance}},
url = {http://journals.sagepub.com/doi/10.1177/09520767231188229},
year = {2023}
}
@article{Maragno2023,
abstract = {Artificial Intelligence (AI) is viewed as having great potential for the public sector to improve the management of internal activities and the delivery of public services. However, realizing its potential depends on the proper implementation of the technology, which is characterized by unique factors, that afford or constrain its use. What these factors are and how they affect AI implementation is still poorly understood, and scholars call for studies to add empirical evidence to the existing knowledge. This study relies on a case study methodology and, by adopting an abductive approach, applies a double theoretical perspective: the Technology-OrganizationEnvironment (TOE) framework and the Technology Affordances and Constraints Theory (TACT). Drawing on these combined lenses, we develop a conceptual framework that extends previous studies by showing how AI implementation is the result of a combination of contextual factors that are deeply interrelated and, specifically, how AI-related factors bring new affordances and constraints to the application domain.},
author = {Maragno, Giulia and Tangi, Luca and Gastaldi, Luca and Benedetti, Michele},
doi = {10.1016/j.ijinfomgt.2023.102686},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Maragno et al. - International Journal of Information Management.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Artificial Intelligence,Public Sector Organizations,TOE framework,Technology Affordances and Constraints},
language = {English},
month = {dec},
pages = {102686},
title = {{Exploring the factors, affordances and constraints outlining the implementation of Artificial Intelligence in public sector organizations}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401223000671},
volume = {73},
year = {2023}
}
@article{VanNoordt2023,
abstract = {Artificial Intelligence (AI) technologies in public administration are gaining increasing attention due to the potential benefits they can provide in improving governmental operations. However, translating technological opportunities into concrete public value for public administrations is still limited. One of the factors hindering this progress is the lack of AI capability within public organisations. The research found that various components of AI capability are essential for successfully developing and using AI technologies, including tangible, intangible, and human-related factors. There is a distinction between the AI capability to develop and the AI capability to implement AI technologies, with more administrations capable of the former but finding difficulties in the latter. A lack of in-house technical expertise to maintain and update the AI systems, legal challenges in deploying developed AI systems, and the capability to introduce changes in the organisation to ensure the system remains operational and used by relevant end-users are among the most critical limiting factors for long-term use of AI by public administrations. The research underlines the strong complementarity between historical eGovernment developments and the capability to deploy AI technologies. The study suggests that funding alone may not be enough to acquire AI capability, and public administrations need to focus on both the capability to develop and implement AI technologies. The research emphasizes that human skillsets, both technical and non-technical, are essential for the successful implementation of AI in public administration.},
author = {van Noordt, Colin and Tangi, Luca},
doi = {10.1016/j.giq.2023.101860},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - van Noordt, Tangi - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {AI-capability,Artificial intelligence,Digital government,Digital government transformation,Emerging technologies,Public sector innovation},
language = {English},
month = {oct},
number = {4},
pages = {101860},
title = {{The dynamics of AI capability and its influence on public value creation of AI within public administration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23000606},
volume = {40},
year = {2023}
}
@article{Ingrams2019a,
abstract = {<p>Big data applications have been acclaimed as potentially transformative for the public sector. But, despite this acclaim, most theory of big data is narrowly focused around technocratic goals. The conceptual frameworks that situate big data within democratic governance systems recognizing the role of citizens are still missing. This paper explores the democratic governance impacts of big data in three policy areas using Robert Dahl's dimensions of control and autonomy. Key impacts and potential tensions are highlighted. There is evidence of impacts on both dimensions, but the dimensions conflict as well as align in notable ways and focused policy efforts will be needed to find a balance.</p>},
author = {Ingrams, Alex},
doi = {10.1111/ropr.12331},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Ingrams - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {Internet; e-governance; governance; ICTs; Media},
language = {English},
month = {may},
number = {3},
pages = {357--377},
title = {{Big Data and Dahl's Challenge of Democratic Governance}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12331},
volume = {36},
year = {2019}
}
@article{Cobbe2020,
abstract = {In this paper we introduce the concept of `reviewability' as an alternative approach to im-proving the accountability of automated decision-making that involves machine learning systems. In doing so, we draw on an understanding of automated decision-making as a socio-technical process, involving both human (organisational) and technical components, beginning before a decision is made and extending beyond the decision itself. Although explanations for automated decisions may be useful in some contexts, they focus more narrowly on the model and therefore do not provide the information about that process as a whole that is necessary for many aspects of accountability, regulatory oversight, and assessments for legal compliance. Drawing on previous work on the application of administrative law and judicial review mechanisms to automated decision-making in the public sector, we argue that breaking down the automated decision-making process into its technical and organisational components allows us to consider how appropriate record-keeping and logging mechanisms implemented at each stage of that process would allow for the process as a whole to be reviewed. Although significant research is needed to explore how it can be implemented, we argue that a reviewability framework potentially offers for a more useful and more holistic form of accountability for automated decision-making than approaches focused more narrowly on explanations. (C) 2020 Jennifer Cobbe and Jatinder Singh. Published by Elsevier Ltd. All rights reserved.},
author = {Cobbe, Jennifer and Singh, Jatinder},
doi = {10.1016/j.clsr.2020.105475},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Cobbe, Singh - Computer Law & Security Review.pdf:pdf},
issn = {02673649},
journal = {Computer Law & Security Review},
keywords = {accountable systems,automated decision-making,reviewability},
language = {English},
month = {nov},
pages = {105475},
title = {{Reviewable Automated Decision-Making}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364920300807},
volume = {39},
year = {2020}
}
@article{Adamczyk2021,
abstract = {What is the impact of automation on public sector employment? Using machine learning and natural language processing algorithms, this study estimates which occupations and agencies of the Brazilian Federal Government are most susceptible to automation. We contribute to the literature by introducing Bartik Occupational Tasks (BOT), an objective method used to estimate automation susceptibility that avoids subjective or ad hoc classifications. We show that approximately 20% of Brazilian public sector employees work in jobs with a high potential of automation in the coming decades. Government occupations with lower schooling and lower salary levels are most susceptible to future automation.},
author = {Adamczyk, Willian Boschetti and Monasterio, Leonardo and Fochezatto, Adelar},
doi = {10.1016/j.techsoc.2021.101722},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Adamczyk, Monasterio, Fochezatto - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {Automation,machine learning,public sector},
language = {English},
month = {nov},
pages = {101722},
title = {{Automation in the future of public sector employment: the case of Brazilian Federal Government}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0160791X21001974},
volume = {67},
year = {2021}
}
@article{Selten2024,
abstract = {Artificial Intelligence (AI) has the potential to improve public governance, but the use of AI in public organizations remains limited. In this qualitative study, we explore how public organizations strategically manage the adoption of AI. Managing AI adoption in the public sector is complex because of the inherent tension between public organizations' identity, characterized by formal and rigid structures, and the demands of AI innovation that require experimentation and flexibility. Our findings show that public organizations navigate this tension either by creating separate departments for data science teams, or by integrating data science teams into already existing operational departments. The case studies reveal that separation improves the technical expertise and capabilities of the organization, whereas integration improves the alignment between AI and primary processes. The findings also show that both approaches are characterized by different AI adoption barriers. We empirically identify the processes and routines public organizations develop to overcome these barriers.},
author = {Selten, Friso and Klievink, Bram},
doi = {10.1016/j.giq.2023.101885},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Selten, Klievink - Government Information Quarterly(2).pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Adoption,Ambidexterity,Artificial intelligence,Contextual integration,Public sector Management,Structural separation},
language = {English},
month = {mar},
number = {1},
pages = {101885},
title = {{Organizing public sector AI adoption: Navigating between separation and integration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23000850},
volume = {41},
year = {2024}
}
@article{Schuelke-Leech2019,
abstract = {Self‐driving cars (also known as driverless cars, autonomous vehicles, and highly automated vehicles [HAVs]) will change the regulatory, political, and ethical frameworks surrounding motor vehicles. At the highest levels of automation, HAVs are operated by independent machine agents, making decisions without the direct intervention of humans. The current transportation system assumes human intervention though, including legal and moral responsibilities of human operators. Has the development of these artificial intelligence (AI) and autonomous system (AS) technologies outpaced the ethical and political conversations? This paper examines discussions of HAVs, driver responsibility, and technology failure to highlight the differences between how the policy‐making institutions in the United States (Congress and the Public Administration) and technology and transportation experts are or are not speaking about responsibility in the context of autonomous systems technologies. We report findings from a big data analysis of corpus‐level documents to find that enthusiasm for HAVs has outpaced other discussions of the technology.},
author = {Schuelke‐Leech, Beth‐Anne and Jordan, Sara R. and Barry, Betsy},
doi = {10.1111/ropr.12332},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Schuelke‐Leech, Jordan, Barry - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {autonomous vehicles,big data analysis,driverless cars,highly automated vehicles,policy making,responsibility},
language = {English},
month = {jul},
number = {4},
pages = {547--579},
title = {{Regulating Autonomy: An Assessment of Policy Language for Highly Automated Vehicles}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12332},
volume = {36},
year = {2019}
}
@article{Dunleavy2023,
abstract = {This article examines the model of digital era governance (DEG) in the light of the latest-wave of data-driven technologies, such as data science methodologies and artificial intelligence (labelled here DSAI). It identifies four key top-level macro-themes through which digital changes in response to these developments may be investigated. First, the capability to store and analyse large quantities of digital data obviates the need for data ‘compression' that characterises Weberian-model bureaucracies, and facilitates data de-compression in data-intensive information regimes, where the capabilities of public agencies and civil society are both enhanced. Second, the increasing capability of robotic devices have expanded the range of tasks that machines extending or substituting workers' capabilities can perform, with implications for a reshaping of state organisation. Third, DSAI technologies allow new options for partitioning state functions in ways that can maximise organisational productivity, in an ‘intelligent centre, devolved delivery' model within vertical policy sectors. Fourth, within each tier of government, DSAI technologies offer new possibilities for ‘administrative holism' - the horizontal allocation of power and functions between organisations, through state integration, common capacity and needs-based joining-up of services. Together, these four themes comprise a third wave of DEG changes, suggesting important administrative choices to be made regarding information regimes, state organisation, functional allocation and outsourcing arrangements, as well as a long-term research agenda for public administration, requiring extensive and detailed analysis.},
author = {Dunleavy, Patrick and Margetts, Helen},
doi = {10.1177/09520767231198737},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Dunleavy, Margetts - Public Policy and Administration.pdf:pdf},
issn = {0952-0767},
journal = {Public Policy and Administration},
keywords = {administrative organization and structures,artificial intelligence,data science,governance,new public management,policy making and public management},
language = {English},
month = {sep},
title = {{Data science, artificial intelligence and the third wave of digital era governance}},
url = {http://journals.sagepub.com/doi/10.1177/09520767231198737},
year = {2023}
}
@article{Broomfield2022,
abstract = {The administrative reform of the datafied public administration places great emphasis on the classification, control, and prediction of citizen behavior and therefore has the potential to significantly impact citizen–state relations. There is a growing body of literature on data-oriented activism which aims to resist and counteract existing harmful data practices. However, little is known about the processes, policies, and political-economic structures that make datafication possible. There is a distinct research gap on situated and context-specific empirical research, which critically interrogates the premises, interests, and agendas of data-driven public administration and how stakeholders can impact them. This paper therefore studies the conditions of participation in public administration datafication. It asks the overall research question of how citizens are problematized and included in policy and practitioner discourse in the datafication of public administration. The paper takes Norway as its case and applies Cardullo and Kitchin's scaffold of smart citizen participation at the system level. It makes use of a unique empirical insight into the field, consisting of a survey, interviews, and an extensive document analysis. Unexpectedly, we find that citizens and civil society are rarely engaged in this administrative reform. Instead, we identify a paternalistic, top-down, technocratic approach where the context, values, and agendas of datafication are obscured from the citizen.},
author = {Broomfield, Heather and Reutter, Lisa},
doi = {10.1177/20539517221089302},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Broomfield, Reutter - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Norway,Public administration,artificial intelligence,citizen participation,civil society,datafication},
language = {English},
month = {jan},
number = {1},
pages = {205395172210893},
title = {{In search of the citizen in the datafication of public administration}},
url = {http://journals.sagepub.com/doi/10.1177/20539517221089302},
volume = {9},
year = {2022}
}
@article{Scutella2024,
abstract = {The importance of today's public sector delivering citizen-centric services enabled by technology is well recognized. To deliver such services, the public sector is turning to artificial intelligence, and in particular virtual agents (VA). This research examines how citizens gain value from interacting with VAs in a public sector setting. Through empirical research, utilizing transcripts from citizens' interactions with a VA, four dimensions of value-in-use were identified. This adds to the theoretical body of knowledge on value co-creation in public service settings and provides practical insights into how citizens use VAs and possible avenues for future investment and improvements.},
author = {Scutella, Maryanne and Plewa, Carolin and Reaiche, Carmen},
doi = {10.1080/14719037.2022.2044504},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Scutella, Plewa, Reaiche - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {e-government,value co-creation,value-in-use,virtual agent},
language = {English},
month = {jan},
number = {1},
pages = {73--88},
title = {{Virtual agents in the public service: examining citizens' value-in-use}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2044504},
volume = {26},
year = {2024}
}
@article{Kowalski2020,
abstract = {<p>Research on user satisfaction has increased substantially in recent years. To date, most studies have tested the significance of predefined factors thought to influence user satisfaction, with no scalable means of verifying the validity of their assumptions. Digital technology has created new methods of collecting user feedback where service users post comments. As topic models can analyse large volumes of feedback, they have been proposed as a feasible approach to aggregating user opinions. This novel approach has been applied to process reviews of primary care practices in England. Findings from an analysis of more than 200,000 reviews show that the quality of interactions with staff and bureaucratic exigencies are the key drivers of user satisfaction. In addition, patient satisfaction is strongly influenced by factors that are not measured by state‐of‐the‐art patient surveys. These results highlight the potential benefits of text mining and machine learning for public administration.</p>},
author = {Kowalski, Radoslaw and Esteve, Marc and {Jankin Mikhaylov}, Slava},
doi = {10.1111/padm.12656},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Kowalski, Esteve, Jankin Mikhaylov - Public Administration.pdf:pdf},
issn = {0033-3298},
journal = {Public Administration},
language = {English},
month = {dec},
number = {4},
pages = {1011--1026},
title = {{Improving public services by mining citizen feedback: An application of natural language processing}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/padm.12656},
volume = {98},
year = {2020}
}
@article{James2022,
abstract = {In recent years, a discourse of ‘ethical artificial intelligence' has emerged and gained international traction in response to widely publicised AI failures. In Australia, the discourse around ethical AI does not accord with the reality of AI deployment in the public sector. Drawing on institutional ethnographic approaches, this paper describes the misalignments between how technology is described in government documentation, and how it is deployed in social service delivery. We argue that the propagation of ethical principles legitimates established new public management strategies, and pre-empts questions regarding the efficacy of AI development; instead positioning implementation as inevitable and, provided an ethical framework is adopted, laudable. The ethical AI discourse acknowledges, and ostensibly seeks to move past, widely reported administrative failures involving new technologies. In actuality, this discourse works to make AI implementation a reality, ethical or not.},
author = {James, Alexandra and Whelan, Andrew},
doi = {10.1177/0261018320985463},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - James, Whelan - Critical Social Policy.pdf:pdf},
issn = {0261-0183},
journal = {Critical Social Policy},
keywords = {artificial intelligence,digitised welfare delivery,ethical artificial intelligence,new public management,public sector technology},
language = {English},
month = {feb},
number = {1},
pages = {22--42},
title = {{‘Ethical' artificial intelligence in the welfare state: Discourse and discrepancy in Australian social services}},
url = {http://journals.sagepub.com/doi/10.1177/0261018320985463},
volume = {42},
year = {2022}
}
@article{Kempeneer2021,
abstract = {In a sense, the 2008 financial crisis was a crisis of theory. Regulators, banks, and financial markets all had encompassing theoretical models about how the economy worked, but they all failed to predict the looming crisis. As such, regulators increasingly turn to big data to understand banks' health. Despite the prominence of big data in society, its use in the public sector remains grossly understudied. This paper explores the regulatory use of big data in the case of the EU-wide banking stress test, a key regulatory indicator. The paper draws on interviews with supervisors at the European Central Bank (ECB), European Banking Authority (EBA) and National Bank of Belgium (NBB), as well as with consultants and risk directors in Belgian banks, to explain how big data-driven regulation affects the relationship between regulators and regulated entities. It draws particular attention to the epistemological component of using large data sets in decision-making: a big data state of mind. The article more specifically shows how the underlying epistemology, rather than simply the bigness of datasets, affects the relationship between regulators and regulated entities, and the regulatory process at large. The paper concludes that regulators' big data state of mind calls for new practical and legal guidelines regarding the validity of data-driven knowledge claims. Moreover, it shows how accountability based on descriptive transparency no longer makes sense in the `age of the algorithm', suggesting a shift towards relational transparency and joint knowledge production.},
author = {Kempeneer, Shirley},
doi = {10.1016/j.giq.2021.101578},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Kempeneer - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Accountable AI,Banking stress test,Big data,Epistemology,Financial regulation,Transparency},
language = {English},
month = {jul},
number = {3},
pages = {101578},
title = {{A big data state of mind: Epistemological challenges to accountability and transparency in data-driven regulation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X21000149},
volume = {38},
year = {2021}
}
@article{Coulthart2022,
abstract = {Investigating how the public sector adopts technologies to process and
analyze very large datasets is crucial for understanding governance in
the digital age. The authors of this article examine a large government
agency, the United States Border Patrol (USBP), an organization that is
in the early phases of building big data capabilities. They argue the
wide-scale adoption of big data analytics will require trial-and-error
processes coordinated by organizational leadership in partnership with
front-line employees who make the technology relevant to their needs in
the field. Absent engagement from both levels, organizations like USBP
that face significant barriers to adoption (e.g., limited data science
expertise) will struggle to leverage data at scale. The authors also
extend the literature on big data in the public sector and provide a
rich description of how factors, such as organizational leadership and
resources, impact the innovation process.},
author = {Coulthart, Stephen and Riccucci, Ryan},
doi = {10.1111/puar.13431},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Coulthart, Riccucci - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {mar},
number = {2},
pages = {280--289},
title = {{Putting Big Data to Work in Government: The Case of the United States Border Patrol}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13431},
volume = {82},
year = {2022}
}
@article{Giest2024,
abstract = {The paper highlights the effects of AI implementation on public sector innovation. This is explored by asking how AI-driven technologies in public decision-making in different organizational contexts impacts innovation in the role definition of bureaucrats. We focus on organizational as well as agency- and individual-level factors in two cases: The Dutch Childcare Allowance case and the US Integrated Data Automated System. We observe administrative process innovation in both cases where organizational structures and tasks of bureaucrats are transformed, and in the US case we also find conceptual innovation in that welfare fraud is addressed by replacing bureaucrats all together.},
author = {Giest, Sarah N. and Klievink, Bram},
doi = {10.1080/14719037.2022.2095001},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Giest, Klievink - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {Public decision-making,artificial intelligence,bureaucrats,digital welfare system,public sector innovation},
language = {English},
month = {feb},
number = {2},
pages = {379--398},
title = {{More than a digital system: how AI is changing the role of bureaucrats in different organizational contexts}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2095001},
volume = {26},
year = {2024}
}
@article{Ingrams2019,
abstract = {Public administration scholars have so far largely viewed big data as a kind of technocratictransformation. However, through citizens' digital records, use of service apps, social media, digitalsensors, and other digital footprints, big data also gives policymakers insights into citizen choicesand is therefore potentially supportive of public values such as participation and openness. Focusingon two underexplored countries, Germany and the Netherlands, this article develops a public valuesframework for big data that considers citizen values alongside technocratic ones. It takes theparticular case of public information agencies such as ombudsmen and courts of audit, examiningthe functions they play and whether they have the capacity to address tensions arising betweentechnocratic and citizen values. The study ﬁnds that, while capacity does exist, it is heavily tiltedtoward technocratic values, with no capacity to address participative values. Finally, ﬁvepropositions are advanced, which describe where the tensions lie and therefore where the attention ofpublic information agencies should best be focused},
author = {Ingrams, Alex},
doi = {10.1002/poi3.193},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Ingrams - Policy & Internet.pdf:pdf},
issn = {1944-2866},
journal = {Policy & Internet},
keywords = {big data,democracy,public information,public policy,public values,technocracy},
language = {English},
month = {jun},
number = {2},
pages = {128--148},
title = {{Public Values in the Age of Big Data: A Public Information Perspective}},
url = {https://onlinelibrary.wiley.com/doi/10.1002/poi3.193},
volume = {11},
year = {2019}
}
@article{Gallego2021,
abstract = {Is it possible to predict malfeasance in public procurement? With the proliferation of e-procurement systems in the public sector, anti-corruption agencies and watchdog organizations have access to valuable sources of information with which to identify transactions that are likely to become troublesome and why. In this article, we discuss the promises and challenges of using machine learning models to predict inefficiency and corruption in public procurement. We illustrate this approach with a dataset with more than two million public procurement contracts in Colombia. We trained machine learning models to predict which of them will result in corruption investigations, a breach of contract, or implementation inefficiencies. We then discuss how our models can help practitioners better understand the drivers of corruption and inefficiency in public procurement. Our approach will be useful to governments interested in exploiting large administrative datasets to improve the provision of public goods, and it highlights some of the tradeoffs and challenges that they might face throughout this process. (C) 2020 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.},
author = {Gallego, Jorge and Rivero, Gonzalo and Mart{\'{i}}nez, Juan},
doi = {10.1016/j.ijforecast.2020.06.006},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Gallego, Rivero, Mart{\'{i}}nez - International Journal of Forecasting.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Corruption,Forecasting,Inefficiency,Machine learning,Public procurement},
language = {English},
month = {jan},
number = {1},
pages = {360--377},
title = {{Preventing rather than punishing: An early warning model of malfeasance in public procurement}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207020300935},
volume = {37},
year = {2021}
}
@article{Wilson2022,
abstract = {Ethics, explainability, responsibility, and accountability are important concepts for questioning the societal impacts of artificial intelligence and machine learning (AI), but are insufficient to guide the public sector in regulating and implementing AI. Recent frameworks for AI governance help to operationalize these by identifying the processes and layers of governance in which they must be considered, but do not provide public sector workers with guidance on how they should be pursued or understood. This analysis explores how the concept of sustainable AI can help to fill this gap. It does so by reviewing how the concept has been used by the research community and aligning research on sustainable development with research on public sector AI. Doing so identifies the utility of boundary conditions that have been asserted for social sustainability according to the Framework for Strategic Sustainable Development, and which are here integrated with prominent concepts from the discourse on AI and society. This results in a conceptual model that integrates five boundary conditions to assist public sector decision-making about how to govern AI: Diversity, Capacity for learning, Capacity for selforganization Common meaning, and Trust. These are presented together with practical approaches for their presentation, and guiding questions to aid public sector workers in making the decisions that are required by other operational frameworks for ethical AI.},
author = {Wilson, Christopher and van der Velden, Maja},
doi = {10.1016/j.techsoc.2022.101926},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Wilson, van der Velden - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {AI governance,Artificial intelligence,Public administration,Social sustainability,Sustainability},
language = {English},
month = {feb},
pages = {101926},
title = {{Sustainable AI: An integrated model to guide public sector decision-making}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0160791X22000677},
volume = {68},
year = {2022}
}
@article{Hartmann2021,
abstract = {Algorithms are increasingly used in different domains of public policy. They help humans to profile unemployed, support administrations to detect tax fraud and give recidivism risk scores that judges or criminal justice managers take into account when they make bail decisions. In recent years, critics have increasingly pointed to ethical challenges of these tools and emphasized problems of discrimination, opaqueness or accountability, and computer scientists have proposed technical solutions to these issues. In contrast to these important debates, the literature on how these tools are implemented in the actual everyday decision-making process has remained cursory. This is problematic because the consequences of ADM systems are at least as dependent on the implementation in an actual decision-making context as on their technical features. In this study, we show how the introduction of risk assessment tools in the criminal justice sector on the local level in the USA has deeply transformed the decision-making process. We argue that this is mainly due to the fact that the evidence generated by the algorithm introduces a notion of statistical prediction to a situation which was dominated by fundamental uncertainty about the outcome before. While this expectation is supported by the case study evidence, the possibility to shift blame to the algorithm does seem much less important to the criminal justice actors.},
author = {Hartmann, Kathrin and Wenzelburger, Georg},
doi = {10.1007/s11077-020-09414-y},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Hartmann, Wenzelburger - Policy Sciences.pdf:pdf},
issn = {0032-2687},
journal = {Policy Sciences},
keywords = {Artificial intelligence,Big data,Public administration,Public policy,criminal justice},
language = {English},
month = {jun},
number = {2},
pages = {269--287},
title = {{Uncertainty, risk and the use of algorithms in policy decisions: a case study on criminal justice in the USA}},
url = {https://link.springer.com/10.1007/s11077-020-09414-y},
volume = {54},
year = {2021}
}
@article{Gesk2022,
abstract = {Interest in implementing artificial intelligence (AI)-based software in the public sector is growing. First implementations and research in individual public services have already been carried out; however, a better understanding of citizens' acceptance of this technology is missing in the public sector, as insights from the private sector cannot be transferred directly. For this purpose, we conduct policy-capturing experiments to analyze AI's acceptance in six representative scenarios. Based on behavioral reasoning theory, we gather evidence from 329 participants. The results show that AI solutions in general public services are preferred over those provided by humans, but specific services are still a human domain. Further analyses show that the major drivers toward acceptance are the reasons against AI. The results contribute to understanding of when and why AI is accepted in public services. Public administration can use the results to identify AI-based software to invest in and communicate their usage to perceive such investments' high acceptance rates.},
author = {Gesk, Tanja Sophie and Leyer, Michael},
doi = {10.1016/j.giq.2022.101704},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Gesk, Leyer - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Acceptance,Artificial intelligence,Behavioral reasoning theory,Public services},
language = {English},
month = {jul},
number = {3},
pages = {101704},
title = {{Artificial intelligence in public services: When and why citizens accept its usage}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X22000375},
volume = {39},
year = {2022}
}
@article{Alshahrani2022,
abstract = {Artificial Intelligence (AI) has been suggested to have transformative potential for public sector organizations through enabling increased productivity and novel ways to deliver public services. In order to materialize the transformative potential of AI, public sector organizations need to successfully assimilate AI in their operational activities. However, AI assimilation in the public sector appears to be fragmented and lagging the private sector, and the phenomena has really limited attention from academic research community. To address this gap, we adopt the case study approach to explore three Saudi-Arabian public sector organizations and analyze the results using the attention-based view of the organization (ABV) as the theoretical lens. This study elucidates the challenges related AI assimilation in public sector in terms of how organizational attention is focused situated and distributed during the assimilation process. Five key challenges emerged from the cases studied, namely (i) misalignment between AI and management decision-making, (ii) tensions with linguistics and national culture, (iii) developing and implementing AI infrastructure, (iv) data integrity and sharing, and (v) ethical and governance concerns. The findings reveal a re-enforcing relationship between the situated attention and structural distribution of attention that can accelerate the successful assimilation of AI in public sector organizations.},
author = {Alshahrani, Albandari and Dennehy, Denis and M{\"{a}}ntym{\"{a}}ki, Matti},
doi = {10.1016/j.giq.2021.101617},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Alshahrani, Dennehy, M{\"{a}}ntym{\"{a}}ki - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Attention-based view,Decision making,Public sector},
language = {English},
month = {oct},
number = {4},
pages = {101617},
title = {{An attention-based view of AI assimilation in public sector organizations: The case of Saudi Arabia}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X21000538},
volume = {39},
year = {2022}
}
@article{VanNoordt2022a,
abstract = {There is great interest to use artificial intelligence (AI) technologies to improve government processes and public services. However, the adoption of technologies has often been challenging for public administrations. In this article, the adoption of AI in governmental organizations has been researched as a form of information and communication technologies (ICT)–enabled governance innovation in the public sector. Based on findings from three cases of AI adoption in public sector organizations, this article shows strong similarities between the antecedents identified in previous academic literature and the factors contributing to the use of AI in government. The adoption of AI in government does not solely rely on having high-quality data but is facilitated by numerous environmental, organizational, and other factors that are strictly intertwined among each other. To address the specific nature of AI in government and the complexity of its adoption in the public sector, we thus propose a framework to provide a comprehensive overview of the key factors contributing to the successful adoption of AI systems, going beyond the narrow focus on data, processing power, and algorithm development often highlighted in the mainstream AI literature and policy discourse.},
author = {van Noordt, Colin and Misuraca, Gianluca},
doi = {10.1177/0894439320980449},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - van Noordt, Misuraca - Social Science Computer Review.pdf:pdf},
issn = {0894-4393},
journal = {Social Science Computer Review},
keywords = {AI-enabled innovation,adoption,artificial intelligence,digital transformation,public sector innovation},
language = {English},
month = {apr},
number = {2},
pages = {426--444},
title = {{Exploratory Insights on Artificial Intelligence for Government in Europe}},
url = {http://journals.sagepub.com/doi/10.1177/0894439320980449},
volume = {40},
year = {2022}
}
@article{Campion2022,
abstract = {Despite the current popularity of artificial intelligence (AI) and a steady increase in publications over time, few studies have investigated AI in public contexts. As a result, assumptions about the drivers, challenges, and impacts of AI in government are far from conclusive. By using a case study that involves a large research university in England and two different county councils in a multiyear collaborative project around AI, we study the challenges that interorganizational collaborations face in adopting AI tools and implementing organizational routines to address them. Our findings reveal the most important challenges facing such collaborations: a resistance to sharing data due to privacy and security concerns, insufficient understanding of the required and available data, a lack of alignment between project interests and expectations around data sharing, and a lack of engagement across organizational hierarchy. Organizational routines capable of overcoming such challenges include working on-site, presenting the benefits of data sharing, reframing problems, designating joint appointments and boundary spanners, and connecting participants in the collaboration at all levels around project design and purpose.},
author = {Campion, Averill and Gasco-Hernandez, Mila and {Jankin Mikhaylov}, Slava and Esteve, Marc},
doi = {10.1177/0894439320979953},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Campion et al. - Social Science Computer Review.pdf:pdf},
issn = {0894-4393},
journal = {Social Science Computer Review},
keywords = {adoption of AI,challenges of AI,interorganizational collaboration,organizational routines,public sector},
language = {English},
month = {apr},
number = {2},
pages = {462--477},
title = {{Overcoming the Challenges of Collaboratively Adopting Artificial Intelligence in the Public Sector}},
url = {http://journals.sagepub.com/doi/10.1177/0894439320979953},
volume = {40},
year = {2022}
}
@article{Alon-Barkat2023,
abstract = {<p>Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants' adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities' reliance on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of selective adherence. We suggest this is driven by bureaucrats' enhanced awareness of discrimination and algorithmic biases in the aftermath of the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.</p>},
author = {Alon-Barkat, Saar and Busuioc, Madalina},
doi = {10.1093/jopart/muac007},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Alon-Barkat, Busuioc - Journal of Public Administration Research and Theory.pdf:pdf},
issn = {1053-1858},
journal = {Journal of Public Administration Research and Theory},
language = {English},
month = {jan},
number = {1},
pages = {153--169},
title = {{Human–AI Interactions in Public Sector Decision Making: “Automation Bias” and “Selective Adherence” to Algorithmic Advice}},
url = {https://academic.oup.com/jpart/article/33/1/153/6524536},
volume = {33},
year = {2023}
}
@article{Guenduez2020,
abstract = {Being among the largest creators and gatherers of data in many countries, public administrations are looking for ways to harness big data technology. However, the de facto uses of big data in the public sector remain very limited. Despite numerous studies aiming to clarify the term big data, for many public managers, it remains unclear what this technology does and does not offer public administration. Using the concept of technological frames, we explore the assumptions, expectations, and understandings that public managers possess in order to interpret and make sense of big data. We identify nine big data frames, ranging from inward-oriented technoenthusiasts to outward-oriented techno-skeptics, each of which characterizes public managers' specific viewpoints relating to the introduction of big data in public administrations. Our findings highlight inconsistencies between different perceptions and reveal widespread skepticism among public managers, helping better understand why the de facto uses of big data in the public sector remain very limited.},
author = {Guenduez, Ali A. and Mettler, Tobias and Schedler, Kuno},
doi = {10.1016/j.giq.2019.101406},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Guenduez, Mettler, Schedler - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Big data,Public administration,Public manager,Q methodology,Technological frame},
language = {English},
month = {jan},
number = {1},
pages = {101406},
title = {{Technological frames in public administration: What do public managers think of big data?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X18305173},
volume = {37},
year = {2020}
}
@article{Asatiani2021,
abstract = {The paper presents an approach for implementing inscrutable (i.e., nonexplainable) artificial intelligence (AI) such as neural networks in an accountable and safe manner in organizational settings. Drawing on an exploratory case study and the recently proposed concept of envelopment, it describes a case of an organization successfully “enveloping” its AI solutions to balance the performance benefits of flexible AI models with the risks that inscrutable models can entail. The authors present several envelopment methods—establishing clear boundaries within which the AI is to interact with its surroundings, choosing and curating the training data well, and appropriately managing input and output sources—alongside their influence on the choice of AI models within the organization. This work makes two key contributions: It introduces the concept of sociotechnical envelopment by demonstrating the ways in which an organization's successful AI envelopment depends on the interaction of social and technical factors, thus extending the literature's focus beyond mere technical issues. Secondly, the empirical examples illustrate how operationalizing a sociotechnical envelopment enables an organization to manage the trade-off between low explainability and high performance presented by inscrutable models. These contributions pave the way for more responsible, accountable AI implementations in organizations, whereby humans can gain better control of even inscrutable machine-learning models.},
author = {Asatiani, Aleksandre and Malo, Pekka and Nagb{\o}l, Per R{\aa}dberg and Penttinen, Esko and Rinta-Kahila, Tapani and Salovaara, Antti},
doi = {10.17705/1jais.00664},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Asatiani et al. - Journal of the Association for Information Systems.pdf:pdf},
issn = {15369323},
journal = {Journal of the Association for Information Systems},
keywords = {Artificial Intelligence,Envelopment,Explainable AI,Machine Learning,Public Sector,Sociotechnical Systems,XAI},
language = {English},
number = {2},
pages = {325--352},
title = {{Sociotechnical Envelopment of Artificial Intelligence: An Approach to Organizational Deployment of Inscrutable Artificial Intelligence Systems}},
url = {https://aisel.aisnet.org/jais/vol22/iss2/8/},
volume = {22},
year = {2021}
}
@article{Zekic-Susac2021,
abstract = {The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities. ? 2021 Elsevier B.V. All rights reserved.},
author = {Zeki{\'{c}}-Su{\v{s}}ac, Marijana and Has, Adela and Kne{\v{z}}evi{\'{c}}, Marinela},
doi = {10.1016/j.neucom.2020.01.124},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Zeki{\'{c}}-Su{\v{s}}ac, Has, Kne{\v{z}}evi{\'{c}} - Neurocomputing.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Energy cost,Machine learning,Neural networks,Public building,Regression trees,Variable reduction},
language = {English},
month = {jun},
pages = {223--233},
title = {{Predicting energy cost of public buildings by artificial neural networks, CART, and random forest}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231221001430},
volume = {439},
year = {2021}
}
@article{VanNoordt2022,
abstract = {Artificial Intelligence is increasingly being used by public sector organisations. Previous research highlighted that the use of AI technologies in government could improve policy making processes, public service delivery and the internal management of public administrations. In this article, we explore to which extent the use of AI in the public sector impacts these core governance functions. Findings from the review of a sample of 250 cases across the European Union, show that AI is used mainly to support improving public service delivery, followed by enhancing internal management and only in a limited number assist directly or indirectly policy decision-making. The analysis suggests that different types of AI technologies and applications are used in different governance functions, highlighting the need to further in-depth investigation to better understand the role and impact of use in what is being defined the governance ``of, with and by AI''.},
author = {van Noordt, Colin and Misuraca, Gianluca},
doi = {10.1016/j.giq.2022.101714},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - van Noordt, Misuraca - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Policy making,Public administration,Public sector management,Public services},
language = {English},
month = {jul},
number = {3},
pages = {101714},
title = {{Artificial intelligence for the public sector: results of landscaping the use of AI in government across the European Union}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X22000478},
volume = {39},
year = {2022}
}
@article{Anastasopoulos2019,
abstract = {Machine learning (ML) methods have gained a great deal of popularity in
recent years among public administration scholars and practitioners.
These techniques open the door to the analysis of text, image and other
types of data that allow us to test foundational theories of public
administration and to develop new theories. Despite the excitement
surrounding ML methods, clarity regarding their proper use and potential
pitfalls is lacking. This article attempts to fill this gap in the
literature through providing an ML ``guide to practice'' for public
administration scholars and practitioners. Here, we take a foundational
view of ML and describe how these methods can enrich public
administration research and practice through their ability develop new
measures, tap into new sources of data and conduct statistical inference
and causal inference in a principled manner. We then turn our attention
to the pitfalls of using these methods such as unvalidated measures and
lack of interpretability. Finally, we demonstrate how ML techniques can
help us learn about organizational reputation in federal agencies
through an illustrated example using tweets from 13 executive federal
agencies. All R code, analyses, and data described in this article can
be found in the Supplementary Appendix.},
author = {Anastasopoulos, L Jason and Whitford, Andrew B},
doi = {10.1093/jopart/muy060},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Anastasopoulos, Whitford - Journal of Public Administration Research and Theory.pdf:pdf},
issn = {1053-1858},
journal = {Journal of Public Administration Research and Theory},
language = {English},
month = {jun},
number = {3},
pages = {491--510},
title = {{Machine Learning for Public Administration Research, With Application to Organizational Reputation}},
url = {https://academic.oup.com/jpart/article/29/3/491/5161227},
volume = {29},
year = {2019}
}
@article{Neumann2024,
abstract = {Despite the enormous potential of artificial intelligence (AI), many public organizations struggle to adopt this technology. Simultaneously, empirical research on what determines successful AI adoption in public settings remains scarce. Using the technology organization environment (TOE) framework, we address this gap with a comparative case study of eight Swiss public organizations. Our findings suggest that the importance of technological and organizational factors varies depending on the organization's stage in the adoption process, whereas environmental factors are generally less critical. Accordingly, this study advances our theoretical understanding of the specificities of AI adoption in public organizations throughout the different adoption stages.},
author = {Neumann, Oliver and Guirguis, Katharina and Steiner, Reto},
doi = {10.1080/14719037.2022.2048685},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Neumann, Guirguis, Steiner - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {AI,Artificial intelligence,TOE framework,public administration,public organizations,technology adoption},
language = {English},
month = {jan},
number = {1},
pages = {114--141},
title = {{Exploring artificial intelligence adoption in public organizations: a comparative case study}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2048685},
volume = {26},
year = {2024}
}
@article{Vogl2020,
abstract = {In recent years, local authorities in the UK have begun to adopt a
variety of ``smart'' technological changes to enhance service
delivery. These changes are having profound impacts on the structure of
public administration. Focusing on the particular case of artificial
intelligence, specifically autonomous agents and predictive analytics, a
combination of desk research, a survey questionnaire, and interviews
were used to better understand the extent and nature of these changes in
local government. Findings suggest that local authorities are beginning
to adopt smart technologies and that these technologies are having an
unanticipated impact on how public administrators and computational
algorithms become imbricated in the delivery of public services. This
imbrication is described as algorithmic bureaucracy, and it provides a
framework within which to explore how these technologies transform both
the socio-technical relationship between workers and their tools, as
well as the ways that work is organized in the public sector.},
author = {Vogl, Thomas M. and Seidelin, Cathrine and Ganesh, Bharath and Bright, Jonathan},
doi = {10.1111/puar.13286},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Vogl et al. - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {nov},
number = {6},
pages = {946--961},
title = {{Smart Technology and the Emergence of Algorithmic Bureaucracy: Artificial Intelligence in UK Local Authorities}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13286},
volume = {80},
year = {2020}
}
@article{VanderVoort2019,
abstract = {Big data promises to transform public decision-making for the better by
making it more responsive to actual needs and policy effects. However,
much recent work on big data in public decision-making assumes a
rational view of decision-making, which has been much criticized in the
public administration debate. In this paper, we apply this view, and a
more political one, to the context of big data and offer a qualitative
study. We question the impact of big data on decision-making, realizing
that big data including its new methods and functions must inevitably
encounter existing political and managerial institutions. By studying
two illustrative cases of big data use processes, we explore how these
two worlds meet. Specifically, we look at the interaction between data
analysts and decision makers. In this we distinguish between a rational
view and a political view, and between an information logic and a
decision logic. We find that big data provides ample opportunities for
both analysts and decision makers to do a better job, but this doesn't
necessarily imply better decision-making, because big data also provides
opportunities for actors to pursue their own interests. Big data enables
both data analysts and decision makers to act as autonomous agents
rather than as links in a functional chain. Therefore, big data's impact
cannot be interpreted only in terms of its functional promise; it must
also be acknowledged as a phenomenon set to impact our policymaking
institutions, including their legitimacy.},
author = {van der Voort, H.G. and Klievink, A.J. and Arnaboldi, M. and Meijer, A.J.},
doi = {10.1016/j.giq.2018.10.011},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - van der Voort et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
language = {English},
month = {jan},
number = {1},
pages = {27--38},
title = {{Rationality and politics of algorithms. Will the promise of big data survive the dynamics of public decision making?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X17304951},
volume = {36},
year = {2019}
}
@article{Wang2021,
abstract = {Despite significant theoretical and empirical attention on public value creation in the public sector, the relationship between artificial intelligence (AI) use and value creation from the citizen perspective remains poorly understood. We ground our study in Moore's public value management to examine the relationship between AI use and value creation. We conceptually categorize public service value into public value and private value. We use procedural justice and trust in government as indicators of public value and, based on motivation theory, we use perceived usefulness and perceived enjoyment as indicators of private value. A field survey of 492 AI voice robot users in China was conducted to test our model. The results indicated that the effective use of AI voice robots was significantly associated with private value and procedural justice. However, the relationship between the effective use of AI and trust in government was not found to be significant. Surprisingly, the respondents indicated that private value had a greater effect on overall value creation than public value. This contrasts with the common idea that value creation from the government perspective suggests that social objectives requiring public value are more important to citizens. The results also show that gender and citizens with different experiences show different AI usage behaviors.},
author = {Wang, Changlin and Teo, Thompson S.H. and Janssen, Marijn},
doi = {10.1016/j.ijinfomgt.2021.102401},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Wang, Teo, Janssen - International Journal of Information Management.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Artificial intelligence,Private value,Public value,Value creation,Voice robot},
language = {English},
month = {dec},
pages = {102401},
title = {{Public and private value creation using artificial intelligence: An empirical study of AI voice robot users in Chinese public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401221000943},
volume = {61},
year = {2021}
}
@article{Wirtz2019,
abstract = {Artificial intelligence (AI) extends the limits of current performance in data processing and analysis many times over. Since this states a great improvement in managing public data, this conceptual study discusses the use of AI in public management structures in connection with their risks and side effects. The exercise of state power and public influence through intelligent machines make ethical and political guidelines essential for their operation, constituting the cornerstones of the AI framework model developed here. The organizational structure and technical specification are additional aspects of the AI that determine design and functionality of the framework model in practical application.},
author = {Wirtz, Bernd W. and M{\"{u}}ller, Wilhelm M.},
doi = {10.1080/14719037.2018.1549268},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Wirtz, M{\"{u}}ller - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {Artificial intelligence,conceptual study,framework,public administration,public business model},
language = {English},
month = {jul},
number = {7},
pages = {1076--1100},
title = {{An integrated artificial intelligence framework for public management}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2018.1549268},
volume = {21},
year = {2019}
}
@article{Andrews2019,
abstract = {<p>Public administration scholarship has to a significant degree neglected technological change. The age of the algorithm and ‘big data' is throwing up new challenges for public leadership, which are already being confronted by public leaders in different jurisdictions. Algorithms may be perceived as presenting new kinds of ‘wicked problems' for public authorities. The article offers a tentative overview of the kind of algorithmic challenges facing public leaders in an environment where the discursive context is shaped by corporate technology companies. Public value theory is assessed as an analytical framework to examine how public leaders are seeking to address the ethical and public value issues affecting governance and regulation, drawing on recent UK experience in particular. The article suggests that this is a fruitful area for future research.</p>},
author = {Andrews, Leighton},
doi = {10.1111/padm.12534},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Andrews - Public Administration.pdf:pdf},
issn = {0033-3298},
journal = {Public Administration},
language = {English},
month = {jun},
number = {2},
pages = {296--310},
title = {{Public administration, public leadership and the construction of public value in the age of the algorithm and ‘big data'}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/padm.12534},
volume = {97},
year = {2019}
}
@article{Aoki2020,
abstract = {This study investigates the public's initial trust in so-called ``artificial intelligence'' (AI) chatbots about to be introduced into use in the public sector. While the societal impacts of AI are widely speculated about, empirical testing remains rare. To narrow this gap, this study builds on theories of operators' trust in machines in industrial settings and proposes that initial public trust in chatbot responses depends on (i) the area of enquiry, since expectations about a chatbot's performance vary with the topic, and (ii) the purposes that governments communicate to the public for introducing the use of chatbots. Analyses based on an experimental online survey in Japan generated results indicating that, if a government were to announce its intention to use ``AI'' chatbots to answer public enquiries, the public's initial trust in their responses would be lower in the area of parental support than in the area of waste separation, with a moderate effect size. Communicating purposes that would directly benefit citizens, such as achieving uniformity in response quality and timeliness in responding, would enhance public trust in chatbots. Although the effect sizes are small, communicating these purposes might be still worthwhile, as it would be an inexpensive measure for a government to take.},
author = {Aoki, Naomi},
doi = {10.1016/j.giq.2020.101490},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Aoki - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Administrative discretion,Artificial intelligence,Chatbot,Human-machine relationship,Public service,Public trust,Street-level bureaucracy},
language = {English},
month = {oct},
number = {4},
pages = {101490},
title = {{An experimental study of public trust in AI chatbots in the public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X1930406X},
volume = {37},
year = {2020}
}
@article{Zekic-Susac2021a,
abstract = {Energy efficiency of public sector is an important issue in the context of smart cities due to the fact that buildings are the largest energy consumers, especially public buildings such as educational, health, government and other public institutions that have a large usage frequency. However, recent developments of machine learning within Big Data environment have not been exploited enough in this domain. This paper aims to answer the question of how to incorporate Big Data platform and machine learning into an intelligent system for managing energy efficiency of public sector as a substantial part of the smart city concept. Deep neural networks, Rpart regression tree and Random forest with variable reduction procedures were used to create prediction models of specific energy consumption of Croatian public sector buildings. The most accurate model was produced by Random forest method, and a comparison of important predictors extracted by all three methods has been conducted. The models could be implemented in the suggested intelligent system named MERIDA which integrates Big Data collection and predictive models of energy consumption for each energy source in public buildings, and enables their synergy into a managing platform for improving energy efficiency of the public sector within Big Data environment. The paper also discusses technological requirements for developing such a platform that could be used by public administration to plan reconstruction measures of public buildings, to reduce energy consumption and cost, as well as to connect such smart public buildings as part of smart cities. Such digital transformation of energy management can increase energy efficiency of public administration, its higher quality of service and healthier environment.},
author = {Zeki{\'{c}}-Su{\v{s}}ac, Marijana and Mitrovi{\'{c}}, Sa{\v{s}}a and Has, Adela},
doi = {10.1016/j.ijinfomgt.2020.102074},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Zeki{\'{c}}-Su{\v{s}}ac, Mitrovi{\'{c}}, Has - International Journal of Information Management.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Planning models Energy efficiency Machine learning},
language = {English},
month = {jun},
pages = {102074},
title = {{Machine learning based system for managing energy efficiency of public sector as an approach towards smart cities}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401219302968},
volume = {58},
year = {2021}
}
@article{Busuioc2021,
abstract = {Artificial intelligence (AI) algorithms govern in subtle yet fundamental
ways the way we live and are transforming our societies. The promise of
efficient, low-cost, or ``neutral'' solutions harnessing the potential
of big data has led public bodies to adopt algorithmic systems in the
provision of public services. As AI algorithms have permeated
high-stakes aspects of our public existence-from hiring and education
decisions to the governmental use of enforcement powers (policing) or
liberty-restricting decisions (bail and sentencing)-this necessarily
raises important accountability questions: What accountability
challenges do AI algorithmic systems bring with them, and how can we
safeguard accountability in algorithmic decision-making? Drawing on a
decidedly public administration perspective, and given the current
challenges that have thus far become manifest in the field, we
critically reflect on and map out in a conceptually guided manner the
implications of these systems, and the limitations they pose, for public
accountability.},
author = {Busuioc, Madalina},
doi = {10.1111/puar.13293},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Busuioc - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {sep},
number = {5},
pages = {825--836},
title = {{Accountable Artificial Intelligence: Holding Algorithms to Account}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13293},
volume = {81},
year = {2021}
}
@article{Sun2019,
abstract = {The nascent adoption of Artificial Intelligence (AI) in the public sector is being assessed in contradictory ways. But while there is increasing speculation about both its dangers and its benefits, there is very little empirical research to substantiate them. This study aims at mapping the challenges in the adoption of AI in the public sector as perceived by key stakeholders. Drawing on the theoretical lens of framing, we analyse a case of adoption of the AI system IBM Watson in public healthcare in China, to map how three groups of stakeholders (government policy-makers, hospital managers/doctors, and Information Technology (IT) firm managers) perceive the challenges of AI adoption in the public sector. Findings show that different stakeholders have diverse, and sometimes contradictory, framings of the challenges. We contribute to research by providing an empirical basis to claims of AI challenges in the public sector, and to practice by providing four sets of guidelines for the governance of AI adoption in the public sector.},
author = {Sun, Tara Qian and Medaglia, Rony},
doi = {10.1016/j.giq.2018.09.008},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2019 - Sun, Medaglia - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial Intelligence,Challenges,China,Framing,Healthcare,Public sector},
language = {English},
month = {apr},
number = {2},
pages = {368--383},
title = {{Mapping the challenges of Artificial Intelligence in the public sector: Evidence from public healthcare}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X17304781},
volume = {36},
year = {2019}
}
@article{Straub2023,
abstract = {Recent advances in artificial intelligence (AI), especially in
generative language modelling, hold the promise of transforming
government. Given the advanced capabilities of new AI systems, it is
critical that these are embedded using standard operational procedures,
clear epistemic criteria, and behave in alignment with the normative
expectations of society. Scholars in multiple domains have subsequently
begun to conceptualize the different forms that AI applications may
take, highlighting both their potential benefits and pitfalls. However,
the literature remains fragmented, with researchers in social science
disciplines like public administration and political science, and the
fast-moving fields of AI, ML, and robotics, all developing concepts in
relative isolation. Although there are calls to formalize the emerging
study of AI in government, a balanced account that captures the full
depth of theoretical perspectives needed to understand the consequences
of embedding AI into a public sector context is lacking. Here, we unify
efforts across social and technical disciplines by first conducting an
integrative literature review to identify and cluster 69 key terms that
frequently co-occur in the multidisciplinary study of AI. We then build
on the results of this bibliometric analysis to propose three new
multifaceted concepts for understanding and analysing AI-based systems
for government (AI-GOV) in a more unified way: (1) operational fitness,
(2) epistemic alignment, and (3) normative divergence. Finally, we put
these concepts to work by using them as dimensions in a conceptual
typology of AI-GOV and connecting each with emerging AI technical
measurement standards to encourage operationalization, foster
cross-disciplinary dialogue, and stimulate debate among those aiming to
rethink government with AI.},
author = {Straub, Vincent J. and Morgan, Deborah and Bright, Jonathan and Margetts, Helen},
doi = {10.1016/j.giq.2023.101881},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Straub et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Government; Public administration; Artificial inte},
language = {English},
month = {oct},
number = {4},
pages = {101881},
title = {{Artificial intelligence in government: Concepts, standards, and a unified framework}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23000813},
volume = {40},
year = {2023}
}
@article{Beccali2017,
abstract = {The public buildings sector represents one of the most intensive items of EU energy consumption; the application of retrofit solutions in existing buildings is a crucial way to reduce its impact. To facilitate the knowledge of the energy performance of existing non-residential buildings and the choice of the more adequate actions, Public Administrations (PA) should have the availability of proper tools. Within the Italian project “POI 2007-13”, a database and a decision support tool, for easy use, even to a non-technical user, have been developed. A large set of data, obtained from the energy audits of 151 existing public buildings located in four regions of South Italy have been analysed, elaborated, and organised in a database. This was used to identify the best architectures of two ANNs and to train them. The first ANN provides the actual energy performance of any building; the second ANN assesses key economic indicators. A decision support tool, based on the use of these ANNs is conceived for a fast prediction of the energy performance of buildings and for a first selection of energy retrofit actions that can be applied. {\textcopyright} 2017 Elsevier Ltd},
annote = {Cited by: 78},
author = {Beccali, Marco and Ciulla, Giuseppina and {Lo Brano}, Valerio and Galatioto, Alessandra and Bonomolo, Marina},
doi = {10.1016/j.energy.2017.05.200},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2017 - Beccali et al. - Energy.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {ANN,Decision support tool,Energy audit,Energy efficiency,Non-residential building,Retrofit action},
language = {English},
month = {oct},
pages = {1201--1218},
title = {{Artificial neural network decision support tool for assessment of the energy performance and the refurbishment actions for the non-residential building stock in Southern Italy}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360544217310186},
volume = {137},
year = {2017}
}
@article{Kuziemski2020,
abstract = {The rush to understand new socio-economic contexts created by the wide adoption of AI is justified by its far-ranging consequences, spanning almost every walk of life. Yet, the public sector's predicament is a tragic double bind: its obligations to protect citizens from potential algorithmic harms are at odds with the temptation to increase its own efficiency - or in other words - to govern algorithms, while governing by algorithms. Whether such dual role is even possible, has been a matter of debate, the challenge stemming from algorithms' intrinsic properties, that make them distinct from other digital solutions, long embraced by the governments, create externalities that rule-based programming lacks. As the pressures to deploy automated decision making systems in the public sector become prevalent, this paper aims to examine how the use of AI in the public sector in relation to existing data governance regimes and national regulatory practices can be intensifying existing power asymmetries. To this end, investigating the legal and policy instruments associated with the use of AI for strenghtening the immigration process control system in Canada; ``optimising'' the employment services'' in Poland, and personalising the digital service experience in Finland, the paper advocates for the need of a common framework to evaluate the potential impact of the use of AI in the public sector. In this regard, it discusses the specific effects of automated decision support systems on public services and the growing expectations for governments to play a more prevalent role in the digital society and to ensure that the potential of technology is harnessed, while negative effects are controlled and possibly avoided. This is of particular importance in light of the current COVID-19 emergency crisis where AI and the underpinning regulatory framework of data ecosystems, have become crucial policy issues as more and more innovations are based on large scale data collections from digital devices, and the real-time accessibility of information and services, contact and relationships between institutions and citizens could strengthen - or undermine - trust in governance systems and democracy.},
author = {Kuziemski, Maciej and Misuraca, Gianluca},
doi = {10.1016/j.telpol.2020.101976},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2020 - Kuziemski, Misuraca - Telecommunications Policy.pdf:pdf},
issn = {03085961},
journal = {Telecommunications Policy},
keywords = {Algorithmic accountability,Artificial intelligence,Automated decision making,Public sector innovation},
language = {English},
month = {jul},
number = {6},
pages = {101976},
title = {{AI governance in the public sector: Three tales from the frontiers of automated decision-making in democratic settings}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0308596120300689},
volume = {44},
year = {2020}
}
