@article{Hashim2024,
abstract = {Information and communication technologies (ICT) have a recent impact on governance and public administration. Electronic government (e-government) services were created to streamline administrative processes and enhance citizen engagement on the one hand, and to build new governance models that would empower individuals, involve them in the decision-making process, and increase transparency on the other. Many individuals are doubtful about smart city projects because of the security issues that arise in such environments. In essence, internet of things gadgets are security flaws. Concerns about the proliferation of IoT sensors and the tighter coupling of infrastructure silos in cities are well-founded. The major objective of the study is to identify the influencing factors of smart cities on e-government in Saudi Arabia. Additionally, this research explores the definition of e-government, and its supporting technologies like smart cities, IoT, big data, cloud computing and other digital government platforms. After exploring the detailed definitions, the study identifies the challenging scenarios of e-government in Saudi Arabia, and discusses the different opportunities. This study also concentrates on the good practices to be followed to overcome the challenges. Furthermore, this study can be used in future research for solving real time challenges of e-government. {\textcopyright} 2024 The Authors},
annote = {Cited by: 2},
author = {Hashim, Hasan},
doi = {10.1016/j.aej.2024.04.008},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Hashim - Alexandria Engineering Journal.pdf:pdf},
issn = {11100168},
journal = {Alexandria Engineering Journal},
keywords = {Big data framework for e-government,City assets,Connecting e-government with smart city initiative,Digital Government,Digital Government platforms,E-government,Hybrid cloud set up for government department,Mobile government,Public administration,Services Laws,Smart cities using IoT framework,Smart city as a service,Smart governance for smart city,The role of e-government in smart city},
language = {English},
month = {jun},
pages = {124--131},
title = {{E-government impact on developing smart cities initiative in Saudi Arabia: Opportunities & challenges}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016824003818},
volume = {96},
year = {2024}
}
@article{Aranha2024,
abstract = {This study investigates the selection of the best partners while merging the public sector banks in India. It is set in the context of the announcement of the mega-merger of multiple Indian public sector banks on 30th August 2019. Using the clustering technique (a machine learning approach) and Data Envelopment Analysis (DEA), we identify ideal merger combinations with better efficiency. The findings highlight the possibility of identifying ideal merger combinations using objective techniques. {\textcopyright} 2024 Elsevier Inc.},
annote = {Cited by: 0},
author = {Aranha, Meera Laetitia B and Mahapatra, Mrutyunjay and Jacob, Remya Tressa},
doi = {10.1016/j.frl.2024.105297},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Aranha, Mahapatra, Jacob - Finance Research Letters.pdf:pdf},
issn = {15446123},
journal = {Finance Research Letters},
keywords = {Bank mergers,Clustering,Data envelopment analysis,Partner selection for mergers,Total Economic Efficiency},
language = {English},
month = {may},
pages = {105297},
title = {{Mergers of public sector banks: Best partner selection using a data-driven approach}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612324003271},
volume = {63},
year = {2024}
}
@article{Jain2024,
abstract = {Effective contractor selection is crucial for successful execution of construction projects. In contrast to the conventional lowest-bid approach prevalent in the public sector, this study focuses on developing a framework that minimizes time and cost overruns by considering diverse criteria for contractor selection. A variety of machine learning models, including multi-linear regression, random forest, Support Vector Machine, and Artificial Neural Network, have been employed, with multi-linear regression proving to be the most effective, achieving the lowest Mean Squared Error of 0.00003366. To determine the final order allocation, a multi-objective mathematical model was utilized to optimize conflicting criteria, such as time and cost overruns, sustainability, risk, and safety aspects related to shortlisted contractors. The findings highlight the significance of specific selection criteria, such as turnover, experience in similar projects, qualification of staff, technology utilization, client satisfaction, accident records, available bid capacity, and socioeconomic factors. This study emphasizes a three-phase decision-making framework for contractor selection and order allocation, particularly in public construction projects, with a focus on sustainability. By adopting this approach, government agencies can enhance infrastructure projects and minimize overruns through optimization and analytical tools, which aligns with the Gati-Shakti scheme of the Indian government. It is recommended that clients embrace a holistic approach to contractor selection, considering both technical and non-technical factors, to ensure successful project outcomes. {\textcopyright} The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
annote = {Cited by: 2},
author = {Jain, Shrey and Jauhar, Sunil Kumar and Piyush},
doi = {10.1007/s10479-024-05898-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Jain, Jauhar, Piyush - Annals of Operations Research.pdf:pdf},
issn = {0254-5330},
journal = {Annals of Operations Research},
keywords = {construction project management,goal programming,multi-objective optimization,order allocation,safety and risk management,sustainable contractor selection},
language = {English},
month = {jul},
number = {1},
pages = {225--267},
title = {{A machine-learning-based framework for contractor selection and order allocation in public construction projects considering sustainability, risk, and safety}},
url = {https://link.springer.com/10.1007/s10479-024-05898-6},
volume = {338},
year = {2024}
}
@article{Berman2024,
abstract = {This paper investigates the deployment of Artificial Intelligence (AI) in the Swedish Public Employment Service (PES), focusing on the concept of trustworthy AI in public decision-making. Despite Sweden's advanced digitalization efforts and the widespread application of AI in the public sector, our study reveals significant gaps between theoretical ambitions and practical outcomes, particularly in the context of AI's trustworthiness. We employ a robust theoretical framework comprising Institutional Theory, the Resource-Based View (RBV), and Ambidexterity Theory, to analyze the challenges and discrepancies in AI implementation within PES. Our analysis shows that while AI promises enhanced decision-making efficiency, the reality is marred by issues of transparency, interpretability, and stakeholder engagement. The opacity of the neural network used by the agency to assess jobseekers' need for support and the lack of comprehensive technical understanding among PES management contribute to the challenges in achieving transparent and interpretable AI systems. Economic pressures for efficiency often overshadow the need for ethical considerations and stakeholder involvement, leading to decisions that may not be in the best interest of jobseekers. We propose recommendations for enhancing AI's trustworthiness in public services, emphasizing the importance of stakeholder engagement, particularly involving jobseekers in the decision-making process. Our study advocates for a more nuanced balance between the use of advanced AI technologies and the leveraging of internal resources such as skilled personnel and organizational knowledge. We also highlight the need for improved AI literacy among both management and personnel to effectively navigate AI's integration into public decision-making processes. Our findings contribute to the ongoing debate on trustworthy AI, offering a detailed case study that bridges the gap between theoretical exploration and practical application. By scrutinizing the AI implementation in the Swedish PES, we provide valuable insights and guidelines for other public sector organizations grappling with the integration of AI into their decision-making processes. {\textcopyright} 2024 The Authors},
annote = {Cited by: 6},
author = {Berman, Alexander and {de Fine Licht}, Karl and Carlsson, Vanja},
doi = {10.1016/j.techsoc.2024.102471},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley//2024 - Berman, de Fine Licht, Carlsson - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {Artificial Intelligence,Decision-support systems,Public employment services,Public sector,Trustworthy AI},
language = {English},
title = {{Trustworthy AI in the public sector: An empirical analysis of a Swedish labor market decision-support system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184027069&doi=10.1016%2Fj.techsoc.2024.102471&partnerID=40&md5=a99c3caeb3fcce4eb7e14c5134647d3d},
volume = {76},
year = {2024}
}
@article{Misra2024,
abstract = {Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI. {\textcopyright} 2024 Elsevier Inc.},
annote = {Cited by: 0},
author = {Misra, Shalini and Katz, Benjamin and Roberts, Patrick and Carney, Mackenzie and Valdivia, Isabel},
doi = {10.1016/j.giq.2024.101962},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Misra et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {AI attitudes,AI implementation in the public sector,Decision-making,Emergency managers,Person-environment fit},
language = {English},
month = {sep},
number = {3},
pages = {101962},
title = {{Toward a person-environment fit framework for artificial intelligence implementation in the public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X24000546},
volume = {41},
year = {2024}
}
@article{Hulter2024,
abstract = {The technological capabilities of Human Resource Analytics (HRA), enhanced by recent innovations in Machine Learning (ML), offer exciting opportunities. However, organisations often fail to realise these potentials because of a limited understanding of why individuals choose to adopt or disregard respective tools. Prior research on innovation adoption offers preliminary insights but fails to aggregate the determinants of individual adoption into actionable suggestions for decisions in the ML adoption process. Our study applies focused interviews to examine non-ML experts' reasoning for using a specific tool tailored to a public sector organisation, which corresponds to the usual end-user perspective of ML-based HRA adoption. By drawing from the HRA adoption framework, provided by Vargas et al. (2018), we contribute to the literature by identifying relevant beliefs and experiences influencing one's intention to adopt ML-based HRA and by qualitatively linking these beliefs to ML characteristics such as transparency, automation and fairness. For practitioners, we provide actionable guidance emphasising the need to ensure fairness proactively, as interviewees do not consider this aspect when deciding to adopt ML-based HRA. {\textcopyright} 2024 The Authors},
annote = {Cited by: 0},
author = {H{\"{u}}lter, Svenja M. and Ertel, Christian and Heidemann, Ansgar},
doi = {10.1016/j.techfore.2024.123709},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - H{\"{u}}lter, Ertel, Heidemann - Technological Forecasting and Social Change.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Employee turnover prediction,Explainable artificial intelligence,Human resource analytics,Machine learning adoption,Theory of planned behaviour},
language = {English},
month = {nov},
pages = {123709},
title = {{Exploring the individual adoption of human resource analytics: Behavioural beliefs and the role of machine learning characteristics}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162524005079},
volume = {208},
year = {2024}
}
@article{Delfos2024,
abstract = {This paper introduces systems theory and system safety concepts to ongoing academic debates about the safety of Machine Learning (ML) systems in the public sector. In particular, we analyze the risk factors of ML systems and their respective institutional context, which impact the ability to control such systems. We use interview data to abductively show what risk factors of such systems are present in public professionals' perceptions and what factors are expected based on systems theory but are missing. Based on the hypothesis that ML systems are best addressed with a systems theory lens, we argue that the missing factors deserve greater attention in ongoing efforts to address ML systems safety. These factors include the explication of safety goals and constraints, the inclusion of systemic factors in system design, the development of safety control structures, and the tendency of ML systems to migrate towards higher risk. Our observations support the hypothesis that ML systems can be best regarded through a systems theory lens. Therefore, we conclude that system safety concepts can be useful aids for policymakers who aim to improve ML system safety. {\textcopyright} 2024},
annote = {Cited by: 0},
author = {Delfos, J. and Zuiderwijk, A.M.G. and van Cranenburgh, S. and Chorus, C.G. and Dobbe, R.I.J.},
doi = {10.1016/j.giq.2024.101963},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Delfos et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Governance,Machine learning,Public policy,Public sector,System safety,Systems theory},
language = {English},
month = {sep},
number = {3},
pages = {101963},
title = {{Integral system safety for machine learning in the public sector: An empirical account}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X24000558},
volume = {41},
year = {2024}
}
@article{Ballestar2024,
abstract = {Tutoring programs are effective in reducing school failures among at-risk students. However, there is still room for improvement in maximising the social returns they provide on investments. Many factors and components can affect student engagement in a program and academic success. This complexity presents a challenge for Public Administrations to use their budgets as efficiently as possible. Our research focuses on providing public administration with advanced decision-making tools. First, we analyse a database with information on 2066 students of the Programa para la Mejora de {\'{E}}xito Educativo (Programme for the Improvement of Academic Success) of the Junta de Comunidades de Castilla y L{\'{e}}on in Spain, in 2018–2019, the academic year previous to the pandemic. This program is designed to help schools with students at risk of failure in Spanish, literature, mathematics, and English. We developed a machine learning model (ML) based on Kohonen self-organising maps (SOMs), which are a type of unsupervised (ANN), to group students based on their characteristics, the type of tutoring program in which they were enrolled, and their results in both the completion of the program and the 4th year of Compulsory Secondary Education (ESO). Second, we evaluated the results of tutoring programs and identified and explained how different factors and components affect student engagement and academic success. Our findings provide Public Administrations with better decision-making tools to evaluate and measure the results of tutoring programs in terms of social return on investment, improve the design of these programs, and choose the students to enrol. {\textcopyright} 2023 The Author(s)},
annote = {Cited by: 0},
author = {Ballestar, Mar{\'{i}}a Teresa and Mir, Miguel Cuerdo and Pedrera, Luis Miguel Doncel and Sainz, Jorge},
doi = {10.1016/j.techfore.2023.123043},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Ballestar et al. - Technological Forecasting and Social Change.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Artificial neural networks,Machine learning,Public policy analysis,Tutoring program},
language = {English},
month = {feb},
pages = {123043},
title = {{Effectiveness of tutoring at school: A machine learning evaluation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S004016252300728X},
volume = {199},
year = {2024}
}
@article{Zaidi2024,
abstract = {Introduction Pakistan has significantly strengthened its capacity for active case finding (ACF) for tuberculosis (TB) that is being implemented at scale in the country. However, yields of ACF have been lower than expected, raising concerns on its effectiveness in the programmatic setting. Distribution of TB in communities is likely to be spatially heterogeneous and targeting of ACF in areas with higher TB prevalence may help improve yields. The primary aim of SPOT-TB is to investigate whether a policy change to use a geographically targeted approach towards ACF supported by an artificial intelligence (AI) software, MATCH-AI, can improve yields in Pakistan. Methods and analysis SPOT-TB will use a pragmatic, stepped wedge cluster randomised design. A total of 30 mobile X-ray units and their field teams will be randomised to receive the intervention. Site selection for ACF in the intervention areas will be guided primarily through the use of MATCH-AI software that models subdistrict TB prevalence and identifies potential disease hotspots. Control areas will use existing approaches towards site selection that are based on staff knowledge, experience and analysis of historical data. The primary outcome measure is the difference in bacteriologically confirmed incident TB detected in the intervention relative to control areas. All remaining ACF-related procedures and algorithms will remain unaffected by this trial. Ethics and dissemination Ethical approval has been obtained from the Health Services Academy, Islamabad, Pakistan (7-82/IERC-HSA/2022-52) and from the Common Management Unit for TB, HIV and Malaria, Ministry of Health Services, Regulation and Coordination, Islamabad, Pakistan (26-IRB-CMU-2023). Findings from this study will be disseminated through publications in peer-reviewed journals and stakeholder meetings in Pakistan with the implementing partners and public-sector officials. Findings will also be presented at local and international medical and public health conferences.  {\textcopyright} Author(s) (or their employer(s)) 2024.},
annote = {Cited by: 0},
author = {Zaidi, Syed Mohammad Asad and Mahfooz, Amna and Latif, Abdullah and Nawaz, Nainan and Fatima, Razia and Rehman, Fazal Ur and Reza, Tahira Ezra and Emmanuel, Faran},
doi = {10.1136/bmjresp-2023-002079},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Zaidi et al. - BMJ Open Respiratory Research.pdf:pdf},
issn = {2052-4439},
journal = {BMJ Open Respiratory Research},
language = {English},
month = {jul},
number = {1},
pages = {e002079},
title = {{Geographical targeting of active case finding for tuberculosis in Pakistan using hotspots identified by artificial intelligence software (SPOT-TB): study protocol for a pragmatic stepped wedge cluster randomised control trial}},
url = {https://bmjopenrespres.bmj.com/lookup/doi/10.1136/bmjresp-2023-002079},
volume = {11},
year = {2024}
}
@article{Madan2024,
abstract = {Public administrators receive conflicting signals on the transformative benefits of Artificial Intelligence (AI) and the counternarratives of AI's ethical impacts on society and democracy. Against this backdrop, this paper explores the factors that affect the sensemaking of AI benefits in Canadian public administration. A mixed-method research design using PLS-SEM ( n = 272) and interviews ( n = 38) tests and explains the effect of institutional and consultant pressures on the perceived benefits of AI use. The quantitative study shows only service coercive pressures have a significant effect on perceived benefits of AI use and consultant pressures are significant in generating all institutional pressures. The qualitative study explains the results and highlights the underlying mechanisms. The key conclusion is that in the earlier stages of AI adoption, demand pull is the main driver rather than technology push. A processual sensemaking model is developed extending the theory on institutions and sensemaking. And several managerial implications are discussed.},
author = {Madan, Rohit and Ashok, Mona},
doi = {10.1007/s10796-024-10475-0},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Madan, Ashok - Information Systems Frontiers.pdf:pdf},
issn = {1387-3326},
journal = {Information Systems Frontiers},
language = {English},
month = {feb},
title = {{Making Sense of AI Benefits: A Mixed-method Study in Canadian Public Administration}},
url = {https://link.springer.com/10.1007/s10796-024-10475-0},
year = {2024}
}
@article{Mokander2024,
abstract = {In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens' sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means – it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.},
author = {M{\"{o}}kander, Jakob and Schroeder, Ralph},
doi = {10.1177/08944393241235175},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - M{\"{o}}kander, Schroeder - Social Science Computer Review.pdf:pdf},
issn = {0894-4393},
journal = {Social Science Computer Review},
keywords = {Weber,artificial intelligence,automated decision-making,bureaucratization,equality,governance,policymaking,rationalization,tax policy},
language = {English},
month = {mar},
title = {{Artificial Intelligence, Rationalization, and the Limits of Control in the Public Sector: The Case of Tax Policy Optimization}},
url = {https://journals.sagepub.com/doi/10.1177/08944393241235175},
year = {2024}
}
@article{Chen2024,
abstract = {In recent years, the application of artificial intelligence (AI) technology has become increasingly common in the public sector. Users have been switching their experiences in handling businesses from interactions with human staff to those with robots. Prior studies have focused on investigating the key factors that influence users' adoption of public service robots; however, only a few have considered users' switching behaviors from traditional human services to robotic ones. This study employs a push-pull-mooring (PPM) framework derived from the human migration field to understand the factors that affect users' switching intentions in the context of public service robot applications. The research model was tested with 419 valid responses among users who had experienced both human services and public service robots in Chinese government service halls. The structural equation modeling (SEM) method was applied to quantitatively analyze the data. This study sheds new light on the key determinants of users' switching intentions toward public service robots from the perspectives of push, pull, and mooring effects. The results can help practitioners and managers understand users' intentions for such switches and make scientific decisions to encourage citizens' positive responses to service robots.},
author = {Chen, Tao and Li, Siqi and Zeng, Zhongping and Liang, Zhehao and Chen, Yuxi and Guo, Wenshan},
doi = {10.1016/j.giq.2024.101933},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Chen et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Public service robot,Push-pull-mooring framework,Switching behavior},
language = {English},
month = {jun},
number = {2},
pages = {101933},
title = {{An empirical investigation of users' switching intention to public service robots: From the perspective of PPM framework}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X2400025X},
volume = {41},
year = {2024}
}
@article{Enqvist2024,
abstract = {This article focuses on the legal implications of the growing reliance on automated systems in public administrations, using the example of social security benefits administration. It specifically addresses the deployment of automated systems for decisions on benefits eligibility within the frameworks of the General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AIA). It compares how these two legal frameworks, each targeting different regulatory objects (personal data versus AI systems) and employing different protective measures, apply for two common system types: rule-based systems utilised for making fully automated decisions on eligibility, and machine learning AI systems utilised for assisting case administrators in their decision-making. It concludes on the combined impact that the GDPR and the AIA will have on each of these types of systems, as well as on differences in how these instruments determines the basic legality of utilising such systems within social security administration.},
author = {Enqvist, Lena},
doi = {10.1080/13600834.2024.2349835},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Enqvist - Information & Communications Technology Law.pdf:pdf},
issn = {1360-0834},
journal = {Information & Communications Technology Law},
keywords = {Artificial Intelligence Act,Automated decision-making,GDPR,public administration,social security administration},
language = {English},
month = {may},
number = {2},
pages = {222--246},
title = {{Rule-based versus AI-driven benefits allocation: GDPR and AIA legal implications and challenges for automation in public social security administration}},
url = {https://www.tandfonline.com/doi/full/10.1080/13600834.2024.2349835},
volume = {33},
year = {2024}
}
@article{Fattah2024,
abstract = {PurposeThis study investigates the relationships between data governance (DG), business analytics capabilities (BAC), and decision-making performance (DMP), with a focus on the mediating effects of big data literacy (BDL) and data analytics competency (DAC).Design/methodology/approachThe study was conducted with 178 experienced managers in public service organizations, using a quantitative approach. Structural equation modeling (SEM) and mediation tests were employed to analyze the data.FindingsThe findings reveal that DG and BDL are critical antecedents for developing analytical capabilities. Big data literacy mediates the relationship between DG and BAC, while BAC mediates the relationship between DG and DMP. Furthermore, DAC mediates the relationship between BA capabilities and DMP, explaining most of the effect of BAC on DMP.Practical implicationsThese results highlight the importance of DG in fostering BDL and analytical skills for improved decision-making in organizations.Originality/valueBy prioritizing DG practices that promote BDL and analytical capabilities, organizations can leverage business analytics to enhance decision-making.},
author = {Fattah, Ikhsan A.},
doi = {10.1108/BPMJ-11-2023-0894},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Fattah - Business Process Management Journal.pdf:pdf},
issn = {1463-7154},
journal = {Business Process Management Journal},
keywords = {Analytics competency,Big data literacy,Business analytics capabilities,Decision making performance,Public sector institutions},
language = {English},
month = {jul},
title = {{Decision making performance of business analytics capabilities: the role of big data literacy and analytics competency}},
url = {https://www.emerald.com/insight/content/doi/10.1108/BPMJ-11-2023-0894/full/html},
year = {2024}
}
@article{Sundberg2024,
abstract = {Machine learning (ML) offers widely-recognized, but complex, opportunities for both public and private sector organizations to generate value from data. A key requirement is that organizations must find ways to develop new knowledge by merging crucial `domain knowledge ` of experts in relevant fields with `machine knowledge `, i.e., data that can be used to inform predictive models. In this paper, we argue that understanding the process of generating such knowledge is essential to strategically develop ML. In efforts to contribute to such understanding, we examine the generation of new knowledge from domain knowledge through ML via an exploratory study of two cases in the Swedish public sector. The findings reveal the roles of three mechanisms - dubbed consolidation, algorithmic mediation, and naturalization - in tying domain knowledge to machine knowledge. The study contributes a theory of knowledge production related to organizational use of ML, with important implications for its strategic governance, particularly in the public sector.},
author = {Sundberg, Leif and Holmstr{\"{o}}m, Jonny},
doi = {10.1016/j.jsis.2024.101848},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Sundberg, Holmstr{\"{o}}m - The Journal of Strategic Information Systems.pdf:pdf},
issn = {09638687},
journal = {The Journal of Strategic Information Systems},
keywords = {Artificial Intelligence,Knowledge production,Machine Learning,Natural Language Processing,Public Sector},
language = {English},
month = {sep},
number = {3},
pages = {101848},
title = {{Fusing domain knowledge with machine learning: A public sector perspective}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0963868724000301},
volume = {33},
year = {2024}
}
@article{Botta2024,
abstract = {The effective and ethical use of data to inform decision-making offers huge value to the public sector, especially when delivered by transparent, reproducible, and robust data processing workflows. One way that governments are unlocking this value is through making their data publicly available, allowing more people and organisations to derive insights. However, open data is not enough in many cases: publicly available datasets need to be accessible in an analysis-ready form from popular data science tools, such as R and Python, for them to realise their full potential. This paper explores ways to maximise the impact of open data with reference to a case study of packaging code to facilitate reproducible analysis. We present the jtstats project, which consists of a main Python package, and a smaller R version, for importing, processing, and visualising large and complex datasets representing journey times, for many transport modes and trip purposes at multiple geographic levels, released by the UK Department for Transport (DfT). jtstats shows how domain specific packages can enable reproducible research within the public sector and beyond, saving duplicated effort and reducing the risks of errors from repeated analyses. We hope that the jtstats project inspires others, particularly those in the public sector, to add value to their data sets by making them more accessible.},
author = {Botta, Federico and Lovelace, Robin and Gilbert, Laura and Turrell, Arthur},
doi = {10.1177/23998083241267331},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Botta et al. - Environment and Planning B Urban Analytics and City Science.pdf:pdf},
issn = {2399-8083},
journal = {Environment and Planning B: Urban Analytics and City Science},
keywords = {Data science for public good,government data,open source},
language = {English},
month = {jul},
title = {{Packaging code and data for reproducible research: A case study of journey time statistics}},
url = {https://journals.sagepub.com/doi/10.1177/23998083241267331},
year = {2024}
}
@article{Frost2024,
abstract = {The increasing use of machine learning (ML) in public administration requires that we think carefully about the political and legal constraints imposed on public decision making. These developments confront us with the following interrelated questions: can algorithmic public decisions be truly ‘public'? And, to what extent does the use of ML models compromise the ‘publicness' of such decisions? This article is part of a broader inquiry into the myriad ways in which digital and AI technologies transform the fabric of our democratic existence by mutating the ‘public'. Focusing on the site of public administration, the article develops a conception of publicness that is grounded in a view of public administrations as communities of practice. These communities operate through dialogical, critical and synergetic interactions that allow them to track—as faithfully as possible—the public's heterogeneous view of its interests, and reify these interests in decision making. Building on this theorisation, the article suggests that the use of ML models in public decision making inevitably generates an impoverished publicness, and thus undermines the potential of public administrations to operate as a locus of democratic construction. The article thus advocates for a reconsideration of the ways in which administrative law problematises and addresses the harms of algorithmic decision making.},
author = {Frost, Neli},
doi = {10.1093/ojls/gqae027},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Frost - Oxford Journal of Legal Studies.pdf:pdf},
issn = {0143-6503},
journal = {Oxford Journal of Legal Studies},
keywords = {administrative law,artificial intelligence,law & technology,machine learning,public administration,public decision making},
language = {English},
month = {aug},
title = {{The Impoverished Publicness of Algorithmic Decision Making}},
url = {https://academic.oup.com/ojls/advance-article/doi/10.1093/ojls/gqae027/7731417},
year = {2024}
}
@article{Marty2024,
abstract = {<p>Household surveys give a precise estimate of poverty; however, surveys are costly and are fielded infrequently. We demonstrate the importance of jointly using multiple public and private sector data sources to estimate levels and changes in wealth for a large set of countries. We train models using 63,854 survey cluster locations across 59 countries, relying on data from satellites, Facebook Marketing information, and OpenStreetMaps. The model generalizes previous approaches to a wide set of countries. On average, across countries, the model explains 55% (min = 14%; max = 85%) of the variation in levels of wealth at the survey cluster level and 59% (min = 0%; max = 93%) of the variation at the district level, and the model explains 4% (min = 0%; max = 17%) and 6% (min = 0%; max = 26%) of the variation of changes in wealth at the cluster and district levels. Models perform best in lower-income countries and in countries with higher variance in wealth. Features from nighttime lights, OpenStreetMaps, and land cover data are most important in explaining levels of wealth, and features from nighttime lights are most important in explaining changes in wealth.</p>},
author = {Marty, Robert and Duhaut, Alice},
doi = {10.1038/s41598-023-49564-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Marty, Duhaut - Scientific Reports.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
language = {English},
month = {feb},
number = {1},
pages = {3160},
title = {{Global poverty estimation using private and public sector big data sources}},
url = {https://www.nature.com/articles/s41598-023-49564-6},
volume = {14},
year = {2024}
}
@article{Hjaltalin2024,
abstract = {Governments worldwide are strategically investing in artificial intelligence (AI) to improve public services and streamline internal operations. In this context, national AI strategies play a pivotal role. This study uses combined qualitative research methods analyzing 28 national AI strategies (i.e., the texts). Our aim is to delve into how governments define and position AI applications within the public sector. Specifically, the study explores how the texts convey AI's application in this context employing a public value(s) perspective. Its discursive analytical approach coupled with a comprehensive take on public value theory (Moore, 1995) engenders novel insights into national discourses on AI in the public sector. Against this background we draw on public administration and policy research in our analysis of three dominant discourses that we identify in the texts, i.e. empowerment through information, enhanced administrative practices, and improved service delivery. We find that the discourses involve different positions in relation to governments' use of AI and depend on particular actors and types of public service. Commonly, they concern government objectives to tackle critical societal issues through AI, such as in the areas of health and social care and employment. In particular, the discourse of enhanced administrative practices commonly positioned AI as a tool to optimize internal processes, resource allocation, and organizational management. On the other hand, the discourse of improved service delivery similarly placed public services front and center, while the discourse of empowerment through information framed AI as being able to enhance citizens' service experiences. Interestingly, discourses emphasizing the policymaking function, i.e., AI applied to the development of public policy,-receives limited attention. Our findings underscore strategic prioritizations. While efficiency and service delivery dominate the discourse, citizen engagement remains underemphasized. We argue that policymakers must strike a balance, ensuring AI aligns with broader societal outcomes while addressing democratic imperatives.},
author = {Hjaltalin, Illugi Torfason and Sigurdarson, Hallur Thor},
doi = {10.1016/j.giq.2024.101914},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Hjaltalin, Sigurdarson - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Discourse analysis,E-government,National strategy,Public value,Strategy,Technology application},
language = {English},
month = {mar},
number = {1},
pages = {101914},
title = {{The strategic use of AI in the public sector: A public values analysis of national AI strategies}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X24000066},
volume = {41},
year = {2024}
}
@article{Haesevoets2024,
abstract = {Artificial Intelligence (AI) has become increasingly prevalent in almost every aspect of our lives. At the same time, a debate about its applications, safety, and privacy is raging. In three studies, we explored how UK respondents perceive the usage of AI in various public sector decisions. Our results are fourfold. First, we found that people prefer AI to have considerably less decisional weight than various human decision-makers; those being: politicians, citizens, and (human) experts. Secondly, our findings revealed that people prefer AI to provide input and advice to these human decision-makers, rather than letting AI make decisions by itself. Thirdly, although AI is seen as contributing less to perceived legitimacy than these human decision-makers, similar to (human) experts, its contribution is seen more in terms of output legitimacy than in terms of input and throughput legitimacy. Finally, our results suggest that the involvement of AI is perceived more suitable for decisions that are low (instead of high) ideologically-charged. Overall, our findings thus show that people are rather skeptical towards using AI in the public domain, but this does not imply that they want to exclude AI entirely from the decision-making process.},
author = {Haesevoets, Tessa and Verschuere, Bram and {Van Severen}, Ruben and Roets, Arne},
doi = {10.1016/j.giq.2023.101906},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Haesevoets et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial Intelligence (AI),Decision type,Decisional weight,Hybrid decision-making,Public sector decisions,Roles Legitimacy},
language = {English},
month = {mar},
number = {1},
pages = {101906},
title = {{How do citizens perceive the use of Artificial Intelligence in public sector decisions?}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23001065},
volume = {41},
year = {2024}
}
@article{Keppeler2024,
abstract = {<p>Applications based on artificial intelligence (AI) play an increasing role in the public sector and invoke political discussions. Research gaps exist regarding the disclosure effects—reactions to disclosure of the use of AI applications—and the deployment effect—efficiency gains in data savvy tasks. This study analyzes disclosure effects and explores the deployment of an AI application in a preregistered field experiment (n = 2,000) co-designed with a public organization in the context of employer-driven recruitment. The linear regression results show that disclosing the use of the AI application leads to significantly less interest in an offer among job candidates. The explorative analysis of the deployment of the AI application indicates that the person–job fit determined by the leaders can be predicted by the AI application. Based on the literature on algorithm aversion and digital discretion, this study provides a theoretical and empirical disentanglement of the disclosure effect and the deployment effect to inform future evaluations of AI applications in the public sector. It contributes to the understanding of how AI applications can shape public policy and management decisions, and discusses the potential benefits and downsides of disclosing and deploying AI applications in the public sector and in employer-driven recruitment.</p>},
author = {Keppeler, Florian},
doi = {10.1093/jopart/muad009},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Keppeler - Journal of Public Administration Research and Theory.pdf:pdf},
issn = {1053-1858},
journal = {Journal of Public Administration Research and Theory},
language = {English},
month = {jan},
number = {1},
pages = {39--52},
title = {{No Thanks, Dear AI! Understanding the Effects of Disclosure and Deployment of Artificial Intelligence in Public Sector Recruitment}},
url = {https://academic.oup.com/jpart/article/34/1/39/7174960},
volume = {34},
year = {2024}
}
@article{Selten2024,
abstract = {Artificial Intelligence (AI) has the potential to improve public governance, but the use of AI in public organizations remains limited. In this qualitative study, we explore how public organizations strategically manage the adoption of AI. Managing AI adoption in the public sector is complex because of the inherent tension between public organizations' identity, characterized by formal and rigid structures, and the demands of AI innovation that require experimentation and flexibility. Our findings show that public organizations navigate this tension either by creating separate departments for data science teams, or by integrating data science teams into already existing operational departments. The case studies reveal that separation improves the technical expertise and capabilities of the organization, whereas integration improves the alignment between AI and primary processes. The findings also show that both approaches are characterized by different AI adoption barriers. We empirically identify the processes and routines public organizations develop to overcome these barriers.},
author = {Selten, Friso and Klievink, Bram},
doi = {10.1016/j.giq.2023.101885},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Selten, Klievink - Government Information Quarterly(2).pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Adoption,Ambidexterity,Artificial intelligence,Contextual integration,Public sector Management,Structural separation},
language = {English},
month = {mar},
number = {1},
pages = {101885},
title = {{Organizing public sector AI adoption: Navigating between separation and integration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23000850},
volume = {41},
year = {2024}
}
@article{Scutella2024,
abstract = {The importance of today's public sector delivering citizen-centric services enabled by technology is well recognized. To deliver such services, the public sector is turning to artificial intelligence, and in particular virtual agents (VA). This research examines how citizens gain value from interacting with VAs in a public sector setting. Through empirical research, utilizing transcripts from citizens' interactions with a VA, four dimensions of value-in-use were identified. This adds to the theoretical body of knowledge on value co-creation in public service settings and provides practical insights into how citizens use VAs and possible avenues for future investment and improvements.},
author = {Scutella, Maryanne and Plewa, Carolin and Reaiche, Carmen},
doi = {10.1080/14719037.2022.2044504},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Scutella, Plewa, Reaiche - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {e-government,value co-creation,value-in-use,virtual agent},
language = {English},
month = {jan},
number = {1},
pages = {73--88},
title = {{Virtual agents in the public service: examining citizens' value-in-use}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2044504},
volume = {26},
year = {2024}
}
@article{Giest2024,
abstract = {The paper highlights the effects of AI implementation on public sector innovation. This is explored by asking how AI-driven technologies in public decision-making in different organizational contexts impacts innovation in the role definition of bureaucrats. We focus on organizational as well as agency- and individual-level factors in two cases: The Dutch Childcare Allowance case and the US Integrated Data Automated System. We observe administrative process innovation in both cases where organizational structures and tasks of bureaucrats are transformed, and in the US case we also find conceptual innovation in that welfare fraud is addressed by replacing bureaucrats all together.},
author = {Giest, Sarah N. and Klievink, Bram},
doi = {10.1080/14719037.2022.2095001},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Giest, Klievink - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {Public decision-making,artificial intelligence,bureaucrats,digital welfare system,public sector innovation},
language = {English},
month = {feb},
number = {2},
pages = {379--398},
title = {{More than a digital system: how AI is changing the role of bureaucrats in different organizational contexts}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2095001},
volume = {26},
year = {2024}
}
@article{Neumann2024,
abstract = {Despite the enormous potential of artificial intelligence (AI), many public organizations struggle to adopt this technology. Simultaneously, empirical research on what determines successful AI adoption in public settings remains scarce. Using the technology organization environment (TOE) framework, we address this gap with a comparative case study of eight Swiss public organizations. Our findings suggest that the importance of technological and organizational factors varies depending on the organization's stage in the adoption process, whereas environmental factors are generally less critical. Accordingly, this study advances our theoretical understanding of the specificities of AI adoption in public organizations throughout the different adoption stages.},
author = {Neumann, Oliver and Guirguis, Katharina and Steiner, Reto},
doi = {10.1080/14719037.2022.2048685},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2024 - Neumann, Guirguis, Steiner - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {AI,Artificial intelligence,TOE framework,public administration,public organizations,technology adoption},
language = {English},
month = {jan},
number = {1},
pages = {114--141},
title = {{Exploring artificial intelligence adoption in public organizations: a comparative case study}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2048685},
volume = {26},
year = {2024}
}
@article{Wilson2023,
abstract = {This analysis applies boundary theory to public manager efforts to overcome AI capacity gaps through a public sector collaborative learning forum. Administrative and interview data identify the types of knowledge managers are able to access, the types of organizational differences that influence learning, and the strategies public managers use to overcome them. Analysis suggests that unstructured learning fora are better suited to the transfer of tacit procedural knowledge than declarative knowledge about AI, and emphasizes the importance of social trust and network structure to overcome knowledge gaps through peer learning. {\textcopyright} 2022 Informa UK Limited, trading as Taylor & Francis Group.},
annote = {Cited by: 7},
author = {Wilson, Christopher and Broomfield, Heather},
doi = {10.1080/14719037.2022.2055119},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Wilson, Broomfield - Public Management Review.pdf:pdf},
issn = {1471-9037},
journal = {Public Management Review},
keywords = {Artificial intelligence,boundary objects,government networks,know-how,knowledge management,organizational learning,peer learning,technology transfer},
language = {English},
month = {oct},
number = {10},
pages = {1938--1957},
title = {{Learning how to do AI: managing organizational boundaries in an intergovernmental learning forum}},
url = {https://www.tandfonline.com/doi/full/10.1080/14719037.2022.2055119},
volume = {25},
year = {2023}
}
@article{Smith2023,
abstract = {As governments around the world become increasingly datafied, debates are emerging about the best ways to attend to the complex socio-political implications of big data and the datafication of the state. Drawing on semi-structured interviews with senior executives and data experts within Australian government agencies, high-level privacy experts, and other experts in public sector data integration, this article examines how a sociotechnical imaginary about data-driven, democratic government acts within and alongside routinely bureaucratised forms of techno-legal risk management to inform the work of Australia's data integration experts. Notably, these techno-legal experts recognised the limitations of techno-legal data management, and mobilised notions of the social license when seeking to (re)orient the trajectories of data integration towards the democratic, data-driven government they envisage. Contributing to debates about the datafication of the state, we argue that while a social license will not be a panacea to all the complexities of datafication, a social license with institutional roots is essential to deepen accountability towards publics, and to help ensure that datafication can be co-produced by, and reflective of, the sociotechnical futures envisaged by a broader range of publics. {\textcopyright} 2023 The Authors},
annote = {Cited by: 0},
author = {Smith, Catherine and Vajdic, Claire M. and Stephenson, Niamh},
doi = {10.1016/j.futures.2023.103263},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Smith, Vajdic, Stephenson - Futures.pdf:pdf},
issn = {00163287},
journal = {Futures},
keywords = {Big data,Data-driven futures,Public sector data integration,Social license,Sociotechnical imaginaries,The datafied state},
language = {English},
month = {dec},
pages = {103263},
title = {{Techno-legal expertise and the datafication of the state: Big data, accountability and the value of a social license with institutional roots}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328723001672},
volume = {154},
year = {2023}
}
@article{Ekimova2023,
abstract = {<p>This paper is aimed at balancing the interests of business and society in the digital economy, to reduce the social risks of the Fourth Industrial Revolution. The goal of this paper is to study the experience and prospects of the humanisation of AI through the improvement of the practice of corporate social responsibility in Russia. By the example of the experience of Russian regions in 2021, we use econometric modelling to prove that the digital regional economy has a large potential in the sphere of humanisation of AI. The potential for the humanisation of AI in the digital economy of Russian regions is determined by responsible innovations, responsible production and logistics, as well as responsible marketing and sales, which contribute to the implementation of SDGs 9–12. The theoretical significance of the paper lies in its presenting smart region as a socio-economic environment for the humanisation of AI. The scientific novelty of the paper lies in its offering a new—meso-level—view of the humanisation of AI. The advantages of the new view include, first, consideration of socio-economic conditions for the humanisation of AI in a region; second, the most precise identification and correct measuring of the consequences of humanisation of AI for the quality of life in a region. The practical significance of the research results consists in the fact that the new proposed approach to the humanisation of AI, which implies public administration of this process at the level of a region, allows accelerating the considered process.</p>},
annote = {Cited by: 0},
author = {Ekimova, Ksenia V.},
doi = {10.1057/s41599-023-02444-w},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Ekimova - Humanities and Social Sciences Communications.pdf:pdf},
issn = {2662-9992},
journal = {Humanities and Social Sciences Communications},
language = {English},
month = {dec},
number = {1},
pages = {943},
title = {{Development of the potential of the digital economy of Russian regions through artificial intelligence humanisation}},
url = {https://www.nature.com/articles/s41599-023-02444-w},
volume = {10},
year = {2023}
}
@article{Nai2023,
abstract = {With the proliferation of e-procurement systems in the public sector, valuable and open information sources can be jointly accessed. Our research aims to explore different legal Open Data; in particular, we explored the data set of the National Anti-Corruption Authority in Italy on public procurement and the judges' sentences related to public procurement, published on the website of the Italian Administrative Justice from 2007 to 2022. Our first goal was to train machine learning models capable of automatically recognizing which procurement has led to disputes and consequently complaints to the Administrative Justice, identifying the relevant features of procurement that correspond to certain anomalies. Our second goal was to develop a recommender system on procurement to return similar procurement to a given one and find companies for bidders, depending on the procurement requirements. {\textcopyright} 2023 Roberto Nai, Rosa Meo, Gabriele Morina, Paolo Pasteris},
annote = {Cited by: 1},
author = {Nai, Roberto and Meo, Rosa and Morina, Gabriele and Pasteris, Paolo},
doi = {10.1016/j.clsr.2023.105887},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Nai et al. - Computer Law & Security Review.pdf:pdf},
issn = {02673649},
journal = {Computer Law & Security Review},
keywords = {Complaint detection,Knowledge discovery,Legal prediction,Machine learning,Natural language processing,Public procurement,Recommender system},
language = {English},
month = {nov},
pages = {105887},
title = {{Public tenders, complaints, machine learning and recommender systems: a case study in public administration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364923000973},
volume = {51},
year = {2023}
}
@article{Henriksen2023,
abstract = {Recent policies and research articles call for turning AI into a form of IA (‘intelligence augmentation'), by envisioning systems that center on and enhance humans. Based on a field study at an AI company, this article studies how AI is performed as developers enact two predictive systems along with stakeholders in public sector accounting and public sector healthcare. Inspired by STS theories about values in design, we analyze our empirical data focusing especially on how objectives, structured performances, and divisions of labor are built into the two systems and at whose expense. Our findings reveal that the development of the two AI systems is informed by politically motivated managerial interests in cost-efficiency. This results in AI systems that are (1) designed as managerial tools meant to enable efficiency improvements and cost reductions, and (2) enforced on professionals on the ‘shop floor' in a top-down manner. Based on our findings and a discussion drawing on literature on the original visions of human-centered systems design from the 1960s, we argue that turning AI into IA seems dubious, and ask what human-centered AI really means and whether it remains an ideal not easily realizable in practice. More work should be done to rethink human-machine relationships in the age of big data and AI, in this way making the call for ethical and responsible AI more genuine and trustworthy.},
annote = {Cited by: 3},
author = {Henriksen, Anne and Blond, Lasse},
doi = {10.1177/03063127231163756},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Henriksen, Blond - Social Studies of Science.pdf:pdf},
issn = {0306-3127},
journal = {Social Studies of Science},
keywords = {artificial intelligence,computer systems design,human-centered systems,intelligence augmentation,machine learning,responsible AI},
language = {English},
month = {oct},
number = {5},
pages = {738--760},
title = {{Executive-centered AI? Designing predictive systems for the public sector}},
url = {http://journals.sagepub.com/doi/10.1177/03063127231163756},
volume = {53},
year = {2023}
}
@article{Ronnblom2023,
abstract = {Over the past few decades, Sweden has established itself as a “world leader” in gender equality. Alongside this development, Swedish politicians have also initiated ambitious plans that aim to establish the country as “world class” in terms of digitalization. International research shows that women and racialized groups are in a minority in the design processes, that AI facial recognition systems are built with white male faces as the norm, and that digital tools replicate racial injustices. In this paper, we are interested in if, and if so how, gender equality is articulated and thus filled with meaning in national policies on AI and digitalization. The overall aim is to discuss the potential of gender (equality) mainstreaming to challenge systems of privilege in the implementation of AI systems in the public sector. The paper analyses how gender equality is filled with meaning in national policy documents on AI and gender equality. The main findings show that gender equality is turned into a question of lack of knowledge and information, which in turn blocks out an understanding of gender equality as something that is related to gendered power relations.},
annote = {Cited by: 9},
author = {R{\"{o}}nnblom, Malin and Carlsson, Vanja and {\"{O}}jehag‐Pettersson, Andreas},
doi = {10.1111/ropr.12547},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - R{\"{o}}nnblom, Carlsson, {\"{O}}jehag‐Pettersson - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {Sweden,artificial intelligence,critical policy analysis,gender equality,public policy},
language = {English},
month = {sep},
number = {5},
pages = {688--704},
title = {{Gender equality in Swedish AI policies. What's the problem represented to be?}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12547},
volume = {40},
year = {2023}
}
@article{Kurmangali2024,
abstract = {Digitalization and new technologies are now firmly on the agendas of governments worldwide. New technological trends have not only become catalysts for economic development, but are also reshaping how the public sector works and implements its policies. Amid technological transformations, the countries of Central Asia are searching for new ways to adapt to these changes. This paper aims to assess these attempts by exploring the digitalization policies of the five Central Asian countries. By using qualitative methods and expert interviews, the article identifies key limitations and potential areas of development for the Central Asian states regarding digitalization and artificial intelligence. By providing valuable insights, the article contributes to a deeper understanding of the digitalization challenges faced by developing countries. Through the analysis of local expert opinions, the article seeks to contribute valuable insights to the distinct approaches adopted by these countries, thus enriching the understanding of the region's trajectory in the digital era. {\textcopyright} 2024 Mykolo Romerio Universitetas. All rights reserved.},
annote = {Cited by: 0},
author = {Kurmangali, Medeu and Yeraliyeva, Yana and Beimisheva, Aigul},
doi = {10.13165/VPA-24-23-2-03},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Kurmangali, Yeraliyeva, Beimisheva - Public Policy and Administration.pdf:pdf},
issn = {16482603},
journal = {Public Policy and Administration},
keywords = {Central Asia,artificial intelligence,digitalization,governance on digitalization and artificial intell,public administration,public policy},
language = {English},
number = {2},
pages = {146 -- 159},
title = {{DIGITALIZATION AND ARTIFICIAL INTELLIGENCE IN CENTRAL ASIA: GOVERNMENTAL RESPONSES AND FURTHER IMPLICATIONS}},
url = {https://ojs.mruni.eu/ojs/public-policy-and-administration/article/view/7841},
volume = {23},
year = {2023}
}
@article{Ruvalcaba-Gomez2023,
abstract = {Artificial Intelligence (AI) as a technological development is being implemented in the public sector with the intention of improving service delivery, as well as to help solve complex problems. However, there is a wide range of capabilities that AI can perform and that public officials perceive and implement in different ways. This paper aims to describe and analyze some categories into which AI capabilities in the public sector are divided. Using an Exploratory Factor Analysis (EFA), our results show that the capabilities of AI from the perspective of public officials can be classified into two aspects: systematic factors and axiological factors. Systematic factors are related to the analysis and behavior of data, including monitoring, analyzing, interacting, remembering, and anticipation. Axiological factors refer to the impacts of values, ethics, and decisions, including acting, feeling, moralizing, creating, and deciding capacities. This categorization of AI capabilities in the public sector sheds light on the perception of public officials about the implementation of this technological development.},
author = {Ruvalcaba-Gomez, Edgar A.},
doi = {10.1177/09520767231170321},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Ruvalcaba-Gomez - Public Policy and Administration.pdf:pdf},
issn = {0952-0767},
journal = {Public Policy and Administration},
keywords = {Artificial intelligence,capabilities,exploratory factor analysis,public sector},
language = {English},
month = {apr},
pages = {095207672311703},
title = {{Systematic and axiological capacities in artificial intelligence applied in the public sector}},
url = {http://journals.sagepub.com/doi/10.1177/09520767231170321},
year = {2023}
}
@article{Zahid2023,
abstract = {The rapid generation of data from various sources by the public sector, private corporations, business associations, and local communities is referred to as big data. This large and complex dataset is often regarded as the ‘new oil' by public administrations (PAs), and data-driven approaches are employed to transform it into valuable insights that can improve governance, transparency, digital services, and public engagement. The government's big-data ecosystem (GBDE) is a result of this initiative. Effective data management is the first step towards large-scale data analysis, which yields insights that benefit your work and your customers. However, managing big data throughout its life cycle is a daunting challenge for public agencies. Despite its widespread use, big data management is still a significant obstacle. To address this issue, this study proposes a hybrid approach to secure the data management life cycle for GBDE. Specifically, we use a combination of the ECC algorithm with AES 128 BITS encryption to ensure that the data remain confidential and secure. We identified and analyzed various data life cycle models through a systematic literature review to create a data management life cycle for data-driven governments. This approach enhances the security and privacy of data management and addresses the challenges faced by public agencies.},
author = {Zahid, Reeba and Altaf, Ayesha and Ahmad, Tauqir and Iqbal, Faiza and Vera, Yini Airet Mir{\'{o}} and Flores, Miguel Angel L{\'{o}}pez and Ashraf, Imran},
doi = {10.3390/systems11080380},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Zahid et al. - Systems.pdf:pdf},
issn = {2079-8954},
journal = {Systems},
keywords = {GBDE,big data,data life cycle,secure data life cycle},
language = {English},
month = {jul},
number = {8},
pages = {380},
title = {{Secure Data Management Life Cycle for Government Big-Data Ecosystem: Design and Development Perspective}},
url = {https://www.mdpi.com/2079-8954/11/8/380},
volume = {11},
year = {2023}
}
@article{Abbas2023,
abstract = {Efficient monitoring and achievement of the Sustainable Development Goals (SDGs) has increased the need for a variety of data and statistics. The massive increase in data gathering through social networks, traditional business systems, and Internet of Things (IoT)-based sensor devices raises real questions regarding the capacity of national statistical systems (NSS) for utilizing big data sources. Further, in this current era, big data is captured through sensor-based systems in public sector organizations. To gauge the capacity of public sector institutions in this regard, this work provides an indicator to monitor the processing capacity of the public sector organizations within the country (Pakistan). Some of the indicators related to measuring the capacity of the NSS were captured through a census-based survey. At the same time, convex logistic principal component analysis was used to develop scores and relative capacity indicators. The findings show that most organizations hesitate to disseminate data due to concerns about data privacy and that public sector organizations' IT personnel are unable to deal with big data sources to generate official statistics. Artificial intelligence (AI) techniques can be used to overcome these challenges, such as automating data processing, improving data privacy and security, and enhancing the capabilities of IT human resources. This research helps to design capacity-building initiatives for public sector organizations in weak dimensions, focusing on leveraging AI to enhance the production of quality and reliable statistics.},
author = {Abbas, Syed Wasim and Hamid, Muhammad and Alkanhel, Reem and Abdallah, Hanaa A.},
doi = {10.3390/systems11080424},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Abbas et al. - Systems.pdf:pdf},
issn = {2079-8954},
journal = {Systems},
keywords = {artificial intelligence,big data,capacity indicator,convex logistic principal component analysis,sensor-based systems},
language = {English},
month = {aug},
number = {8},
pages = {424},
title = {{Official Statistics and Big Data Processing with Artificial Intelligence: Capacity Indicators for Public Sector Organizations}},
url = {https://www.mdpi.com/2079-8954/11/8/424},
volume = {11},
year = {2023}
}
@article{Pautz2023,
abstract = {The article presents an exploratory qualitative single case study about whether and how artificial intelligence (AI) is used by the Scottish Government, about the key concerns relating to its usage, and about obstacles to, and drivers of AI usage. Besides the academic literature and published reports, the analysis rests on 12 semi-structured interviews. Interviewees include Scottish Government employees, experts from academia and representatives of commercial and non-commercial AI and Big Data organisations. The article finds that the Scottish Government has, so far, made little use of AI. Currently, AI is used in very limited ways in process automation and for gaining `cognitive insights' with the human in control. There are no `strategic' AI applications where advanced reasoning and `decision-making by algorithm' play a role. Data-driven e-policy making is not currently on the cards. The reasons are the Scottish Government's wariness of AI, a lack of `digital maturity' (concerning Big Data and digital infrastructure, but also expertise) in the public sector, and ethical concerns around the use of AI. Governments need to conduct a debate about the extent of AI usage to avoid `AI creep' in their institutions and to assure that AI does not have negative consequences for democracy.},
author = {Pautz, Hartwig},
doi = {10.1080/21582041.2023.2293822},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Pautz - Contemporary Social Science.pdf:pdf},
issn = {2158-2041},
journal = {Contemporary Social Science},
keywords = {Artificial intelligence,Big Data,Scotland,policy making},
language = {English},
month = {oct},
number = {5},
pages = {618--636},
title = {{Policy making and artificial intelligence in Scotland}},
url = {https://www.tandfonline.com/doi/full/10.1080/21582041.2023.2293822},
volume = {18},
year = {2023}
}
@article{Engstrom2023,
abstract = {Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.},
author = {Engstrom, David Freeman and Haim, Amit},
doi = {10.1146/annurev-lawsocsci-120522-091626},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Engstrom, Haim - Annual Review of Law and Social Science.pdf:pdf},
issn = {1550-3585},
journal = {Annual Review of Law and Social Science},
keywords = {artificial intelligence,government,institutional design,public administration,regulation},
language = {English},
month = {oct},
number = {1},
pages = {277--298},
title = {{Regulating Government AI and the Challenge of Sociotechnical Design}},
url = {https://www.annualreviews.org/doi/10.1146/annurev-lawsocsci-120522-091626},
volume = {19},
year = {2023}
}
@article{Papyshev2023,
abstract = {Numerous governments worldwide have issued national artificial intelligence (AI) strategies in the last five years to deal with the opportunities and challenges posed by this technology. However, a systematic understanding of the roles and functions that the governments are taking is lacking in the academic literature. Therefore, this research uses qualitative content analysis and Latent Dirichlet Allocation (LDA) topic modeling methodologies to investigate the texts of 31 strategies from across the globe. The findings of the qualitative content analysis highlight thirteen functions of the state, which include human capital, ethics, R&D, regulation, data, private sector support, public sector applications, diffusion and awareness, digital infrastructure, national security, national challenges, international cooperation, and financial support. We combine these functions into three general themes, representing the state's role: development, control, and promotion. LDA topic modeling results are also reflective of these themes. Each general theme is present in every national strategy's text, but the proportion they occupy in the text is different. The combined typology based on two methods reveals that the countries from the post-soviet bloc and East Asia prioritize the theme ``development,'' highlighting the high level of the state's involvement in AI innovation. The countries from the EU focus on ``control,'' which reflects the union's hard stance on AI regulation, whereas countries like the UK, the US, and Ireland emphasize a more hands-off governance arrangement with the leading role of the private sector by prioritizing ``promotion.''},
author = {Papyshev, Gleb and Yarime, Masaru},
doi = {10.1080/25741292.2022.2162252},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Papyshev, Yarime - Policy Design and Practice.pdf:pdf},
issn = {2574-1292},
journal = {Policy Design and Practice},
keywords = {Artificial intelligence,Latent Dirichlet Allocation topic modeling,national AI strategy,qualitative content analysis,state's role},
language = {English},
month = {jan},
number = {1},
pages = {79--102},
title = {{The state's role in governing artificial intelligence: development, control, and promotion through national strategies}},
url = {https://www.tandfonline.com/doi/full/10.1080/25741292.2022.2162252},
volume = {6},
year = {2023}
}
@article{Robles2023,
abstract = {Advancement in information technology continues to evolve especially in the field of artificial intelligence (AI). Research studies have been conducted to evaluate the perceptions of Americans on the development and utilization of AI technology and if it is appropriate to use AI in public administrative duties. The research revealed that society is fragmented regarding the acceptance of AI, and whether AI decisions could have long‐term effects on the labor industry, legal system, and national security. The 2018 AI Public Opinion Survey revealed significant concerns among the American public regarding AI, yet also a recognition of its promise. The goal of this article is to further develop a governance framework for AI that considers the importance of public trust in AI policy. First, it discusses the necessity of public trust for the effective governance of emergent technology. Then, it evaluates public opinion on AI technology that specifically pertains to governance. The article concludes with a discussion of why public trust is central to good AI governance.},
author = {Robles, Pedro and Mallinson, Daniel J.},
doi = {10.1111/ropr.12555},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Robles, Mallinson - Review of Policy Research.pdf:pdf},
issn = {1541-132X},
journal = {Review of Policy Research},
keywords = {AI governance,AI policy,artificial intelligence framework,information technology governance,public sector,public values},
language = {English},
month = {may},
title = {{Artificial intelligence technology, public trust, and effective governance}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/ropr.12555},
year = {2023}
}
@article{Newman2023,
abstract = {Scholarship on evidence-based policy, a subset of the policy analysis literature, largely assumes information is produced and consumed by humans. However, due to the expansion of artificial intelligence in the public sector, debates no longer capture the full range concerns. Here, we derive a typology of arguments on evidence-based policy that performs two functions: taken separately, the categories serve as directions in which debates may proceed, in light of advances in technology; taken together, the categories act as a set of frames through which the use of evidence in policy making might be understood. Using a case of welfare fraud detection in the Netherlands, we show how the acknowledgement of divergent frames can enable a holistic analysis of evidence use in policy making that considers the ethical issues inherent in automated data processing. We argue that such an analysis will enhance the real-world relevance of the evidence-based policy paradigm.},
author = {Newman, Joshua and Mintrom, Michael},
doi = {10.1080/13501763.2023.2193223},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Newman, Mintrom - Journal of European Public Policy.pdf:pdf},
issn = {1350-1763},
journal = {Journal of European Public Policy},
keywords = {Policy analysis,artificial intelligence,ethics,evidence-based policy,frame reflection,public service delivery},
language = {English},
month = {sep},
number = {9},
pages = {1839--1859},
title = {{Mapping the discourse on evidence-based policy, artificial intelligence, and the ethical practice of policy analysis}},
url = {https://www.tandfonline.com/doi/full/10.1080/13501763.2023.2193223},
volume = {30},
year = {2023}
}
@article{Li2023,
abstract = {As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance—“AI cage” and “AI colleague.” The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.},
author = {Li, Yiran and Fan, Yingying and Nie, Lin},
doi = {10.1177/09520767231188229},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Li, Fan, Nie - Public Policy and Administration.pdf:pdf},
issn = {0952-0767},
journal = {Public Policy and Administration},
keywords = {Artificial intelligence,agile governance,government as a platform,public value},
language = {English},
month = {jul},
title = {{Making governance agile: Exploring the role of artificial intelligence in China's local governance}},
url = {http://journals.sagepub.com/doi/10.1177/09520767231188229},
year = {2023}
}
@article{Maragno2023,
abstract = {Artificial Intelligence (AI) is viewed as having great potential for the public sector to improve the management of internal activities and the delivery of public services. However, realizing its potential depends on the proper implementation of the technology, which is characterized by unique factors, that afford or constrain its use. What these factors are and how they affect AI implementation is still poorly understood, and scholars call for studies to add empirical evidence to the existing knowledge. This study relies on a case study methodology and, by adopting an abductive approach, applies a double theoretical perspective: the Technology-OrganizationEnvironment (TOE) framework and the Technology Affordances and Constraints Theory (TACT). Drawing on these combined lenses, we develop a conceptual framework that extends previous studies by showing how AI implementation is the result of a combination of contextual factors that are deeply interrelated and, specifically, how AI-related factors bring new affordances and constraints to the application domain.},
author = {Maragno, Giulia and Tangi, Luca and Gastaldi, Luca and Benedetti, Michele},
doi = {10.1016/j.ijinfomgt.2023.102686},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Maragno et al. - International Journal of Information Management.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Artificial Intelligence,Public Sector Organizations,TOE framework,Technology Affordances and Constraints},
language = {English},
month = {dec},
pages = {102686},
title = {{Exploring the factors, affordances and constraints outlining the implementation of Artificial Intelligence in public sector organizations}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401223000671},
volume = {73},
year = {2023}
}
@article{VanNoordt2023,
abstract = {Artificial Intelligence (AI) technologies in public administration are gaining increasing attention due to the potential benefits they can provide in improving governmental operations. However, translating technological opportunities into concrete public value for public administrations is still limited. One of the factors hindering this progress is the lack of AI capability within public organisations. The research found that various components of AI capability are essential for successfully developing and using AI technologies, including tangible, intangible, and human-related factors. There is a distinction between the AI capability to develop and the AI capability to implement AI technologies, with more administrations capable of the former but finding difficulties in the latter. A lack of in-house technical expertise to maintain and update the AI systems, legal challenges in deploying developed AI systems, and the capability to introduce changes in the organisation to ensure the system remains operational and used by relevant end-users are among the most critical limiting factors for long-term use of AI by public administrations. The research underlines the strong complementarity between historical eGovernment developments and the capability to deploy AI technologies. The study suggests that funding alone may not be enough to acquire AI capability, and public administrations need to focus on both the capability to develop and implement AI technologies. The research emphasizes that human skillsets, both technical and non-technical, are essential for the successful implementation of AI in public administration.},
author = {van Noordt, Colin and Tangi, Luca},
doi = {10.1016/j.giq.2023.101860},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - van Noordt, Tangi - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {AI-capability,Artificial intelligence,Digital government,Digital government transformation,Emerging technologies,Public sector innovation},
language = {English},
month = {oct},
number = {4},
pages = {101860},
title = {{The dynamics of AI capability and its influence on public value creation of AI within public administration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23000606},
volume = {40},
year = {2023}
}
@article{Dunleavy2023,
abstract = {This article examines the model of digital era governance (DEG) in the light of the latest-wave of data-driven technologies, such as data science methodologies and artificial intelligence (labelled here DSAI). It identifies four key top-level macro-themes through which digital changes in response to these developments may be investigated. First, the capability to store and analyse large quantities of digital data obviates the need for data ‘compression' that characterises Weberian-model bureaucracies, and facilitates data de-compression in data-intensive information regimes, where the capabilities of public agencies and civil society are both enhanced. Second, the increasing capability of robotic devices have expanded the range of tasks that machines extending or substituting workers' capabilities can perform, with implications for a reshaping of state organisation. Third, DSAI technologies allow new options for partitioning state functions in ways that can maximise organisational productivity, in an ‘intelligent centre, devolved delivery' model within vertical policy sectors. Fourth, within each tier of government, DSAI technologies offer new possibilities for ‘administrative holism' - the horizontal allocation of power and functions between organisations, through state integration, common capacity and needs-based joining-up of services. Together, these four themes comprise a third wave of DEG changes, suggesting important administrative choices to be made regarding information regimes, state organisation, functional allocation and outsourcing arrangements, as well as a long-term research agenda for public administration, requiring extensive and detailed analysis.},
author = {Dunleavy, Patrick and Margetts, Helen},
doi = {10.1177/09520767231198737},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Dunleavy, Margetts - Public Policy and Administration.pdf:pdf},
issn = {0952-0767},
journal = {Public Policy and Administration},
keywords = {administrative organization and structures,artificial intelligence,data science,governance,new public management,policy making and public management},
language = {English},
month = {sep},
title = {{Data science, artificial intelligence and the third wave of digital era governance}},
url = {http://journals.sagepub.com/doi/10.1177/09520767231198737},
year = {2023}
}
@article{Alon-Barkat2023,
abstract = {<p>Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants' adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities' reliance on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of selective adherence. We suggest this is driven by bureaucrats' enhanced awareness of discrimination and algorithmic biases in the aftermath of the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.</p>},
author = {Alon-Barkat, Saar and Busuioc, Madalina},
doi = {10.1093/jopart/muac007},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Alon-Barkat, Busuioc - Journal of Public Administration Research and Theory.pdf:pdf},
issn = {1053-1858},
journal = {Journal of Public Administration Research and Theory},
language = {English},
month = {jan},
number = {1},
pages = {153--169},
title = {{Human–AI Interactions in Public Sector Decision Making: “Automation Bias” and “Selective Adherence” to Algorithmic Advice}},
url = {https://academic.oup.com/jpart/article/33/1/153/6524536},
volume = {33},
year = {2023}
}
@article{Straub2023,
abstract = {Recent advances in artificial intelligence (AI), especially in
generative language modelling, hold the promise of transforming
government. Given the advanced capabilities of new AI systems, it is
critical that these are embedded using standard operational procedures,
clear epistemic criteria, and behave in alignment with the normative
expectations of society. Scholars in multiple domains have subsequently
begun to conceptualize the different forms that AI applications may
take, highlighting both their potential benefits and pitfalls. However,
the literature remains fragmented, with researchers in social science
disciplines like public administration and political science, and the
fast-moving fields of AI, ML, and robotics, all developing concepts in
relative isolation. Although there are calls to formalize the emerging
study of AI in government, a balanced account that captures the full
depth of theoretical perspectives needed to understand the consequences
of embedding AI into a public sector context is lacking. Here, we unify
efforts across social and technical disciplines by first conducting an
integrative literature review to identify and cluster 69 key terms that
frequently co-occur in the multidisciplinary study of AI. We then build
on the results of this bibliometric analysis to propose three new
multifaceted concepts for understanding and analysing AI-based systems
for government (AI-GOV) in a more unified way: (1) operational fitness,
(2) epistemic alignment, and (3) normative divergence. Finally, we put
these concepts to work by using them as dimensions in a conceptual
typology of AI-GOV and connecting each with emerging AI technical
measurement standards to encourage operationalization, foster
cross-disciplinary dialogue, and stimulate debate among those aiming to
rethink government with AI.},
author = {Straub, Vincent J. and Morgan, Deborah and Bright, Jonathan and Margetts, Helen},
doi = {10.1016/j.giq.2023.101881},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2023 - Straub et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Government; Public administration; Artificial inte},
language = {English},
month = {oct},
number = {4},
pages = {101881},
title = {{Artificial intelligence in government: Concepts, standards, and a unified framework}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X23000813},
volume = {40},
year = {2023}
}
@article{Wirtz2022,
abstract = {This study addresses the growing challenge of governing artificial intelligence (AI) arising from the risks that it increasingly poses to the public sector and society. Based on an in-depth literature analysis, we first identify AI risks and guidelines and classify them into six categories, including technological, data, and analytical risks and guidelines, informational and communicational risks and guidelines, economic risks and guidelines, social risks and guidelines, ethical risks and guidelines, as well as legal and regulatory risks and guidelines. These risks and guidelines are then elaborated and transferred into a four-layered conceptual framework for AI governance. The framework interrelates AI risks and AI guidelines by means of a risk management and guidance process, resulting in an AI governance layer depicting the process for implementation of customised risk mitigation guidelines. The framework constitutes a comprehensive reference point for developing and implementing AI governance strategies and measures in the public sector. {\textcopyright} 2022 Elsevier Inc.},
annote = {Cited by: 38},
author = {Wirtz, Bernd W and Weyerer, Jan C and Kehl, Ines},
doi = {10.1016/j.giq.2022.101685},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Wirtz, Weyerer, Kehl - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Framework,Governance,Guidelines,Regulation,Risks},
language = {English},
number = {4},
title = {{Governance of artificial intelligence: A risk and guideline-based integrative framework}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126090396&doi=10.1016%2Fj.giq.2022.101685&partnerID=40&md5=ba7bab1e031c65b0fd444ce43f61599f},
volume = {39},
year = {2022}
}
@article{Ahn2022,
abstract = {Government employees play a critical role in adopting and using new technologies in government, and their attitude and willingness to use them matter in creating a sustainable and meaningful digital transformation. This study explores how the perception of government employees shapes the willingness to support the use of AI technologies in government. Based on a survey data on current government employees in the U.S., our analysis reveals that the willingness to implement and use AI technologies in government was contingent upon a series of positive and negative perceptions about the new technologies, long-term outlook on the role of AI technologies in society, and the familiarity and experience in using some form of AI applications in the past. In particular, the perception of AI enhancing the efficiency and effectiveness of the work and a positive and longer-term outlook on AI's future about human labor (as an assistant or a competitor), the perception of the technology's ultimate harm or benefit (does it harm or benefit humanity), its ability to eventually make ethical and moral judgments influenced the willingness to support AI technologies in government. A substantial proportion of the government employees in the survey sample responded that they had experienced using some form of AI applications in their work and this familiarity had a strong positive influence on their support for AI. Our findings point to the importance of training the government employees in AI technologies to improve their understanding and perception about the new technologies as well as their potentials in government that will foster a culture of innovation toward sustainable and impactful digital transformation. {\textcopyright} 2021 Elsevier Inc.},
annote = {Cited by: 73},
author = {Ahn, Michael J. and Chen, Yu-Che},
doi = {10.1016/j.giq.2021.101664},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Ahn, Chen - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Frontier technology,Perception Adoption},
language = {English},
month = {apr},
number = {2},
pages = {101664},
title = {{Digital transformation toward AI-augmented public administration: The perception of government employees and the willingness to use AI in government}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X21001003},
volume = {39},
year = {2022}
}
@article{Bodo2022,
abstract = {Emerging technologies permeate and potentially disrupt a wide spectrum of our social, economic, and political relations. Various state institutions, including education, law enforcement, and healthcare, increasingly rely on technical components, such as automated decision-making systems, e-government systems, and other digital tools to provide cheap, efficient public services, and supposedly fair, transparent, disinterested, and accountable public administration. The increased interest in various blockchain-based solutions from central bank digital currencies, via tokenized educational credentials, and distributed ledger-based land registries to self-sovereign identities is the latest, still mostly unwritten chapter in a long history of standardized, objectified, automated, technocratic, and technologized public administration. The rapid, (often) unplanned, and uncontrolled technologization of public services (as happened in the hasty adoption of distance-learning and teleconferencing systems during Corona Virus Disease (COVID) lockdowns) raises complex questions about the use of novel technological components, which may or may not be ultimately adequate for the task for which they are used. The question whether we can trust the technical infrastructures the public sector uses when providing public services is a central concern in an age where trust in government is declining: If the government's artificial intelligence system that detects welfare fraud fails, the public's confidence in the government is ultimately hit. In this paper, we provide a critical assessment of how the use of potentially untrustworthy (private) technological systems including blockchain-based systems in the public sector may affect trust in government. We then propose several policy options to protect the trust in government even if some of their technological components prove fundamentally untrustworthy.},
annote = {Cited by: 13},
author = {Bod{\'{o}}, Bal{\'{a}}zs and Janssen, Heleen},
doi = {10.1093/polsoc/puac019},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley//2022 - Bod{\'{o}}, Janssen - Policy and Society.pdf:pdf},
issn = {1449-4035},
journal = {Policy and Society},
keywords = {blockchain,emerging technologies,public policy,risk-based policy,trust},
language = {English},
month = {jul},
number = {3},
pages = {414--429},
title = {{Maintaining trust in a technologized public sector}},
url = {https://academic.oup.com/policyandsociety/article/41/3/414/6586682},
volume = {41},
year = {2022}
}
@article{Criado2022,
abstract = {Artificial Intelligence (AI) policies and strategies have been designed and adopted in the public sector during the last few years, with Chief Information Officers (CIOs) playing a key role. Using socio-cognitive and institutional approaches on Information Technologies (ITs) in (public) organizations, we consider that the assumptions, expectations, and knowledge (technological frames) of those in charge (CIOs) of designing AI strategies are guiding the future of these emerging systems in the public sector. In this study, we focus on the technological frames of CIOs in the largest Spanish local governments. Based on a survey administered to CIOs leading IT departments, this article presents original data about their technological frames on AI. Our results: (1) provide insights about how CIOs tend to focus on the technological features of AI implementation while often overlook some of the social, political, and ethical challenges in the public sector; (2) expand the theory on AI by enabling the construction of propositions and testable hypotheses for future research in the field. Therefore, the comparative study of technological frames will be key to successfully design and implement AI policies and strategies in the public sector and to tackle future challenges and opportunities. {\textcopyright} 2022 The Authors},
annote = {Cited by: 24},
author = {Criado, J Ignacio and {O.de Zarate-Alcarazo}, Lucia},
doi = {10.1016/j.giq.2022.101688},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Criado, O.de Zarate-Alcarazo - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial Intelligence,Chief Information Officers,Exploratory research,Governance,Public administration,Technological frames},
language = {English},
number = {3},
title = {{Technological frames, CIOs, and Artificial Intelligence in public administration: A socio-cognitive exploratory study in Spanish local governments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126864088&doi=10.1016%2Fj.giq.2022.101688&partnerID=40&md5=a69857fd60b8092c99df31f6439403b3},
volume = {39},
year = {2022}
}
@article{Hong2022,
abstract = {This study explores the determinants of digital innovation in the public sector. Focusing specifically on new digital technologies, such as big data, artificial intelligence, Internet of things, and augmented reality, we explained the wide variation in how Korean local governments used these technologies to transform their services. We found support for four theoretical mechanisms. First, our findings support the existence of demand-pull innovation in the public sector: public organizations respond to citizen demands or needs for innovation. Second, we also find support for an electoral incentive hypothesis, which posits that local governments' motivation for digital innovation is influenced by local politicians' electoral incentives. Third, our results show the existence of isomorphic pressure as a driver for public sector innovation: public organizations emulate their neighbors in adopting innovative practices. Fourth, the results support the upper echelons theory, as younger policymakers are more active innovators. {\textcopyright} 2022 Elsevier Inc.},
annote = {Cited by: 25},
author = {Hong, Sounman and Kim, Sun Hyoung and Kwon, Myungjung},
doi = {10.1016/j.giq.2022.101723},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Hong, Kim, Kwon - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Digital innovation,Electoral competitiveness,Public sector innovation,Upper echelons theory},
language = {English},
number = {4},
title = {{Determinants of digital innovation in the public sector}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133403917&doi=10.1016%2Fj.giq.2022.101723&partnerID=40&md5=f4f02fdfa1824d074697e0abbbbf63a5},
volume = {39},
year = {2022}
}
@article{Yesmagambetov2022,
abstract = {The issue of public procurement effectiveness is becoming increasingly relevant in the context of the observed budget deficit in Kazakhstan. In this article, business processes related to ensuring the best combination of low price and quality in public procurement as the main indicators of procurement efficiency are studied and described in more depth. Considering the problems of public procurement efficiency, many researchers analyze the supplier identification stage. However, in the procurement of works, the execution phase is equally, if not more, important for efficiency. Analysis of the work execution process in Kazakhstan revealed problems related to quality control of the work performed and the construction materials used, as well as limited competition in their procurement. The high degree of the human factor's presence in the quality assurance process and the low availability of information about the demand for goods creates the risk of purchasing poor-quality goods at a high price. While the effectiveness of using big data in the decision-making process is universally proven, information in the public procurement system is not accumulated properly. In this regard, to ensure the best combination of price and quality of work, the authors propose a model of public procurement of works using digital tools. {\textcopyright} 2022 Uspekhi Khimii, ZIOC RAS, Russian Academy of Sciences.},
annote = {Cited by: 0},
author = {Yesmagambetov, Daulet and Kussainova, Larisa and Junusbekova, Gulsara},
doi = {10.13165/VPA-22-21-4-04},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Yesmagambetov, Kussainova, Junusbekova - Public Policy and Administration.pdf:pdf},
issn = {16482603},
journal = {Public Policy and Administration},
keywords = {competition,digitalization,e-procurement,procurement efficiency,public administration,public procurement,quality of work},
language = {English},
number = {4},
pages = {395 -- 406},
title = {{DIGITAL TOOLS FOR IMPROVING THE EFFICIENCY OF PUBLIC PROCUREMENT OF WORKS IN THE REPUBLIC OF KAZAKHSTAN; [SKAITMENINES PRIEMONES VIE{\v{S}}UJU PIRKIMU EFEKTYVUMUI GERINTI KAZACHSTANO RESPUBLIKOJE]}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149005773&doi=10.13165%2FVPA-22-21-4-04&partnerID=40&md5=02e8baaf6bb3bc4c8802d8a5dd21c78f},
volume = {21},
year = {2022}
}
@article{Zhang2022,
abstract = {The outbreak of COVID-19 has greatly threatened global public health and produced social problems, which includes relative online collective actions. Based on the life cycle law, focusing on the life cycle process of COVID-19 online collective actions, we carried out both macro-level analysis (big data mining) and micro-level behaviors (Agent-Based Modeling) on pandemic-related online collective actions. We collected 138 related online events with macro-level big data characteristics, and used Agent-Based Modeling to capture micro-level individual behaviors of netizens. We set two kinds of movable agents, Hots (events) and Netizens (individuals), which behave smartly and autonomously. Based on multiple simulations and parametric traversal, we obtained the optimal parameter solution. Under the optimal solutions, we repeated simulations by ten times, and took the mean values as robust outcomes. Simulation outcomes well match the real big data of life cycle trends, and validity and robustness can be achieved. According to multiple criteria (spans, peaks, ratios, and distributions), the fitness between simulations and real big data has been substantially supported. Therefore, our Agent-Based Modeling well grasps the micro-level mechanisms of real-world individuals (netizens), based on which we can predict individual behaviors of netizens and big data trends of specific online events. Based on our model, it is feasible to model, calculate, and even predict evolutionary dynamics and life cycles trends of online collective actions. It facilitates public administrations and social governance. {\textcopyright} 2021, The Author(s).},
annote = {Cited by: 2},
author = {Zhang, Gang and Li, Hao and He, Rong and Lu, Peng},
doi = {10.1007/s40747-021-00595-4},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Zhang et al. - Complex and Intelligent Systems.pdf:pdf},
issn = {21994536},
journal = {Complex and Intelligent Systems},
keywords = {Agent-Based Modeling (ABM),Attention shift and attention allocation,COVID-19,Online collective actions,Substitution effects},
language = {English},
number = {2},
pages = {1369 -- 1387},
title = {{Agent-based modeling and life cycle dynamics of COVID-19-related online collective actions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134068532&doi=10.1007%2Fs40747-021-00595-4&partnerID=40&md5=121f28c4910c0a553519156e9c12c154},
volume = {8},
year = {2022}
}
@article{Newman2022,
abstract = {Bureaucracies are often criticized for their inflexibility, budget-maximizing wastefulness, and excessive rules and procedures. Rapid advances in technology, including the expansion of digital government, the use of artificial intelligence, and the ability to collect and analyze big data, promise to make public sector organizations leaner, more efficient, and more responsive to citizens' needs. While these technological changes have prompted some observers to forecast the end of bureaucracy, data from many countries show that bureaucratic public organizations are not disappearing. In this article, we argue that this paradox can be explained by revisiting some of the foundational work of sociologist Max Weber, who envisioned public administration itself as a bureaucratic machine. Advanced computing technologies, like artificial intelligence, are reinforcing bureaucratic tendencies in the public sector, not eliminating them. While advances in technology may transform the way public sector organizations operate, they can also serve to strengthen bureaucracy's core purpose. {\textcopyright} 2021 Elsevier Ltd},
annote = {Cited by: 31},
author = {Newman, Joshua and Mintrom, Michael and O'Neill, Deirdre},
doi = {10.1016/j.futures.2021.102886},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Newman, Mintrom, O'Neill - Futures.pdf:pdf},
issn = {00163287},
journal = {Futures},
keywords = {Artificial intelligence,Bureaucracy,Bureaucratic transformation,Digital technologies,Max Weber},
language = {English},
month = {feb},
pages = {102886},
title = {{Digital technologies, artificial intelligence, and bureaucratic transformation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328721001956},
volume = {136},
year = {2022}
}
@article{Carlsson2022,
abstract = {Artificial intelligence (AI) and digitalisation have become an integral part of public governance. While digital technology is expected to enhance neutrality and accuracy in decision-making, it raises concerns about the status of public values and democratic principles. Guided by the theoretical concepts of input, throughput and output democracy, this article analyses how democratic principles have been interpreted and defended in EU policy formulations relating to digital technology over the last decade. The emergence of AI policy has changed the conditions for democratic input and throughput legitimacy, which is an expression of a shift in power and influence between public and private sectors. Democratic input values in AI production are promoted by ethical guidelines directed towards the industry, while democratic throughput, e.g., accountability and transparency, receive less attention in EU AI policy. This indicates future political implications for the ability of citizens to influence technological change and pass judgement on accountable actors. {\textcopyright} 2022 The Authors},
annote = {Cited by: 11},
author = {Carlsson, Vanja and R{\"{o}}nnblom, Malin},
doi = {10.1016/j.techsoc.2022.102145},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Carlsson, R{\"{o}}nnblom - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {AI ethics,AI policy,Democracy,European union,Public sector,The political},
language = {English},
month = {nov},
pages = {102145},
title = {{From politics to ethics: Transformations in EU policies on digital technology}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0160791X2200286X},
volume = {71},
year = {2022}
}
@article{Cetera2022,
abstract = {Effective programming of research and development (R&D) support, adjusted to the actual potential of beneficiaries, requires the use of modern analytical tools. An efficient R&D support system requires up-to-date data on technological trends, ongoing (and planning) research, market needs and developing innovation. The most popular programming methods were based on the analysis of data with a 4 to 5-year time delay until recently. Having described the method of refining information from unstructured data, we explore how to make it possible not only to solve the issue of up-to-date data but to identify of the latest trends in R&D activities. The analytical tools we describe were already fully functional in 2018 and are constantly being improved. The article presents the potential of one tool that can be applied in public support institutions. Methods of identifying and diagnosing technology trends are presented within the case study of the electric car technology trend. The presented case study shows the effectiveness of the method we developed for identifying and diagnosing areas requiring support from public funds. Public institutions, including public institutions supporting R&D and innovation processes, can apply tools that allow an increase in the quality of public support programmes offered, but also beneficial for the quality of strategic resources management within the institution itself. The comparison of the predictions made by the described tools with the classifications made by experts, the former are more accurate and precise. Moreover, the results of the analyses performed by the presented model are not influenced by distorting factors—fads, trends, political pressures, or processes with an unidentified, non-substantive background. It should be emphasized that the accuracy of the whole model is 0.84. The described tools and methods are already directly applicable in many areas related to the support of R&D activity worldwide. The article presents a solution that effectively enables the management of more precise programmes supporting innovative activities used for the first time in Poland. It is also one of the first uses of these methods by public administration in the world. Our approach not only strengthens improved adjustment of the support offered for R&D activity, but also makes it possible to apply and improve management methods in public institutions. {\textcopyright} 2022, The Author(s).},
annote = {Cited by: 2},
author = {Cetera, Wies{\l}aw and Gogo{\l}ek, W{\l}odzimierz and {\.{Z}}o{\l}nierski, Aleksander and Jaruga, Dariusz},
doi = {10.1186/s40537-022-00610-6},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Cetera et al. - Journal of Big Data.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {Big Data,Business statistics,Data management,Information refining,Information technologies management,Innovation,Research and development management,Research and development support programming},
language = {English},
number = {1},
title = {{Potential for the use of large unstructured data resources by public innovation support institutions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128957082&doi=10.1186%2Fs40537-022-00610-6&partnerID=40&md5=e83541274fd8d5c2c2577ced2015ad4b},
volume = {9},
year = {2022}
}
@article{Bignami2022,
author = {Bignami, Francesca},
doi = {10.1093/ajcl/avac012},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Bignami - The American Journal of Comparative Law.pdf:pdf},
issn = {0002-919X},
journal = {The American Journal of Comparative Law},
language = {English},
month = {oct},
number = {Supplement_1},
pages = {i312--i346},
title = {{Artificial Intelligence Accountability of Public Administration}},
url = {https://academic.oup.com/ajcl/article/70/Supplement_1/i312/6596541},
volume = {70},
year = {2022}
}
@article{Wanckel2022,
abstract = {Public sector organizations at all levels of government increasingly rely on Big Data Algorithmic Systems (BDAS) to support decision-making along the entire policy cycle. But while our knowledge on the use of big data continues to grow for government agencies implementing and delivering public services, empirical research on applications for anticipatory policy design is still in its infancy. Based on the concept of policy analytical capacity (PAC), this case study examines the application of BDAS for early crisis detection within the German Federal Government-that is, the German Federal Foreign Office (FFO) and the Federal Ministry of Defence (FMoD). It uses the nested model of PAC to reflect on systemic, organizational, and individual capacity-building from a neoinstitutional perspective and allow for the consideration of embedded institutional contexts. Results from semi-structured interviews indicate that governments seeking to exploit BDAS in policymaking depend on their institutional environment (e.g., through research and data governance infrastructure). However, specific capacity-building strategies may differ according to the departments' institutional framework, with the FMoD relying heavily on subordinate agencies and the FFO creating network-like structures with external researchers. Government capacity-building at the individual and organizational level is similarly affected by long-established institutional structures, roles, and practices within the organization and beyond, making it important to analyze these three levels simultaneously instead of separately.},
author = {Wanckel, Camilla},
doi = {10.1016/j.giq.2022.101705},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Wanckel - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence (AI),Big data algorithm system (BDAS),Central government organizations,Early crisis detection,Neo-institutionalism,Policy analytical capacity (PAC),Policymaking},
language = {English},
month = {oct},
number = {4},
pages = {101705},
title = {{An ounce of prevention is worth a pound of cure – Building capacities for the use of big data algorithm systems (BDAS) in early crisis detection}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X22000387},
volume = {39},
year = {2022}
}
@article{Jeong2022,
abstract = {South Korea introduced the artificial intelligence impact assessment and was the first case of introducing the artificial intelligence impact assessment as national-level legislation. Artificial intelligence impact assessments will be helpful in deciding whether to introduce artificial intelligence by comparing costs and benefits. However, South Korea's approach had limitations. First, an impact assessment was introduced only in the public sector. Second, artificial intelligence impact assessments were voluntary. Third, the subject of artificial intelligence impact assessments was limited to society. Fourth, it is necessary to establish a relationship with other impact assessments. Fifth, specific details were incomplete.},
author = {Jeong, Jonggu},
doi = {10.3390/laws11050073},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Jeong - LAWS.pdf:pdf},
journal = {LAWS},
keywords = {AI,AI impact assessment,South Korea,intelligent information service},
language = {English},
month = {oct},
number = {5},
title = {{Introduction of the First AI Impact Assessment and Future Tasks: South Korea Discussion}},
volume = {11},
year = {2022}
}
@article{Kaushal2022,
abstract = {<p> A united front from all the stakeholders including public, administration and academia alike is required to counter the growing threat of climate change. The recent rise of social media as the new public address system, makes it an ideal source of information to assess public discussions and responses in real time. We mine c.1.7 m posts from 55 climate related subreddits on social media platform Reddit since its inception. Using USE, a state-of-the-art sentence encoder, and K-means clustering algorithm, we develop a machine learning based approach to identify, store, process and classify the posts automatically, and at a scale. In the broad and multifaceted theme of climate change, our approach narrows down the focus to 10 critical underlying themes comprising the public discussions on social media over time. Furthermore, we employ a full order partial correlation analysis to assess the relationship between the different identified themes. We show that in line with Paris Agreement, while the <italic>climate science</italic> community has been successful in influencing the discussions on both the causes and effects of climate change, the <italic>public administration</italic> has failed to appropriately communicate the causes of climate change and has been able to influence only the discussions on the effects of it. Hence, our study shows a clear gap in the public communication by the administration, wherein counter-intuitively less emphasis has been given on the drivers of climate change. This information can be particularly beneficial to policymakers and climate activists in decision making as they try to close the gap between public and academia. </p>},
author = {Kaushal, Akshay and Acharjee, Animesh and Mandal, Anandadeep},
doi = {10.1038/s41598-022-22034-1},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Kaushal, Acharjee, Mandal - Scientific Reports.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
language = {English},
month = {nov},
number = {1},
pages = {19033},
title = {{Machine learning based attribution mapping of climate related discussions on social media}},
url = {https://www.nature.com/articles/s41598-022-22034-1},
volume = {12},
year = {2022}
}
@article{Cho2022,
abstract = {Purpose The revitalization of big data has gained attention in the public sector. However, such open government data (OGD) is facing major challenges with respect to data quality and limited use. To solve this problem, this study analyzes the factors driving the use of OGD from the perspective of data providers in the public sector. Design/methodology/approach Using the analytic hierarchy process and analytic network process methodologies, the importance of the factors driving the use of big data in the public sector was ranked. In addition, the different characteristics of tasks among the departments in a public agency were compared based on expert interviews. Findings The factors driving OGD use are not only political environment or the technological environment. The importance of the institutional culture within the organization increases with the motivation of the data provider. The priorities of the OGD factors also depend on the objectives of the department involved. Originality/value This study provides implications for improving the publication of open data by analyzing the priorities of the factors driving its use from the perspective of big data providers. It focuses on different perceptions of the factors valued by public officials in charge of data in institutions. The results suggest the need to explore officials' perceptions of value creation in big data fields.},
author = {Cho, Ji Yeon and Lee, Bong Gyou},
doi = {10.1108/ITP-04-2019-0169},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Cho, Lee - Information Technology & People.pdf:pdf},
issn = {0959-3845},
journal = {Information Technology & People},
keywords = {Analytic hierarchy process,Analytic network process,Big data,Data value,Open government data,Public sector},
language = {English},
month = {mar},
number = {2},
pages = {467--493},
title = {{Creating value using public big data: comparison of driving factors from the provider's perspective}},
url = {https://www.emerald.com/insight/content/doi/10.1108/ITP-04-2019-0169/full/html},
volume = {35},
year = {2022}
}
@article{Buttow2022,
abstract = {Algorithmic technologies and artificial intelligence are centred on data and generate new business models, known as the data-driven economy. In the European Union context, the development of such new business is accompanied by a regulatory and political framework. An important aspect of this regulatory framework regards the legal conditions that enable the data collection, availability, sharing, use and reuse. Within the larger context, this article analyses the development of the European Union regulatory framework governing the availability, sharing and reuse of public sector data, also referred to as Public Sector Information policy. Anchored in the analytical tools provided by Discursive Institutionalism and Critical Data Studies and after studying the evolution of this policy over 25 years, this article argues that economic considerations have been overwhelmingly decisive in the European Union Public Sector Information policy and much less attention has been paid to fundamental rights and democracy issues. It also shows how European Union Public Sector Information policy contributes to the data infrastructure, enabling a thriving data-driven economy. In doing so, this article argues that the possible problematic effects of this new data-driven economy are not only affordances of the technology itself but are also the result of political and regulatory choices. More globally, the article stresses the need for policymakers to inscribe each of the policies and regulations affecting the digital transformation in the framework of fundamental rights and democracy.},
author = {{Valli Buttow}, Clarissa and Weerts, Sophie},
doi = {10.1177/20539517221124587},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Valli Buttow, Weerts - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Public sector information,critical data studies,data economy,discursive institutionalism,open government data,regulation},
language = {English},
month = {jul},
number = {2},
pages = {205395172211245},
title = {{Public sector information in the European Union policy: The misbalance between economy and individuals}},
url = {http://journals.sagepub.com/doi/10.1177/20539517221124587},
volume = {9},
year = {2022}
}
@article{Sovrano2022,
abstract = {We are recently witnessing a radical shift towards digitisation in many aspects of our daily life, including law, public administration and governance. This has sometimes been done with the aim of reducing costs and human errors by improving data analysis and management, but not without raising major technological challenges. One of these challenges is certainly the need to cope with relatively small amounts of data, without sacrificing performance. Indeed, cutting-edge approaches to (natural) language processing and understanding are often data-hungry, especially those based on deep learning. With this paper we seek to address the problem of data scarcity in automatic Legalese (or legal English) processing and understanding. What we propose is an ensemble of shallow and deep learning techniques called SyntagmTuner, designed to combine the accuracy of deep learning with the ability of shallow learning to work with little data. Our contribution is based on the assumption that Legalese differs from its spoken language in the way the meaning is encoded by the structure of the text and the co-occurrence of words. As result, we show with SyntagmTuner how we can perform important tasks for e-governance, as multi-label classification of the United Nations General Assembly (UNGA) Resolutions or legal question answering, with data-sets of roughly 100 samples or even less.},
author = {Sovrano, Francesco and Palmirani, Monica and Vitali, Fabio},
doi = {10.1016/j.giq.2022.101715},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Sovrano, Palmirani, Vitali - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Data scarcity,Deep learning,Law,Syntagmatic relations,TF-IDF},
language = {English},
month = {jul},
number = {3},
pages = {101715},
title = {{Combining shallow and deep learning approaches against data scarcity in legal domains}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X2200048X},
volume = {39},
year = {2022}
}
@article{Jorgensen2022,
abstract = {Decision support systems, which incorporate artificial intelligence and big data, are receiving significant attention in the public sector. Decision support systems are sociocultural artefacts that are subject to a mix of technical and political choices, and critical investigation of these choices and the rationales they reflect are paramount since they are inscribed into and may cause harm, violate fundamental rights and reproduce negative social patterns. Applying and merging the concepts of sense-making and translation, this article investigates the rationales, translations and critical reflections that shape the development of a decision support system to support social workers assessing referrals concerning child neglect. It presents findings from a qualitative case study conducted in 2019–2020 at the Citizen Centre Children and Young People, Copenhagen Municipality, Denmark. The analysis shows how key actors through processes of translation construct, negotiate and readjust problem definitions, roles, interests, responsibilities and ideas of ambiguity and accountability. Although technological solutionism is present in these processes, it is not the only rationale invested. Rather, technological and data-driven rationales are adjusted to and merged with rationales of efficiency, return on investment and child welfare. Through continuous renegotiation of roles, responsibilities and problems according to these rationales, the key actors attempt to orchestrate ways of managing the complexity facing child welfare services by projecting images of future potentials of the decision support system that are yet to be realised.},
author = {J{\o}rgensen, Andreas M{\o}ller and Nissen, Maria Appel},
doi = {10.1177/20539517221125163},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - J{\o}rgensen, Nissen - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Algorithms,artificial intelligence,big data,child protection,decision support system,risk assessment},
language = {English},
month = {jul},
number = {2},
pages = {205395172211251},
title = {{Making sense of decision support systems: Rationales, translations and potentials for critical reflections on the reality of child protection}},
url = {http://journals.sagepub.com/doi/10.1177/20539517221125163},
volume = {9},
year = {2022}
}
@article{Fest2022,
abstract = {Recent years have seen a massive growth in ethical and legal frameworks
to govern data science practices. Yet one of the core questions
associated with ethical and legal frameworks is the extent to which they
are implemented in practice. A particularly interesting case in this
context comes to public officials, for whom higher standards typically
exist. We are thus trying to understand how ethical and legal frameworks
influence the everyday practices on data and algorithms of public sector
data professionals. The following paper looks at two cases: public
sector data professionals (1) at municipalities in the Netherlands and
(2) at the Netherlands Police. We compare these two cases based on an
analytical research framework we develop in this article to help
understanding of everyday professional practices. We conclude that there
is a wide gap between legal and ethical governance rules and the
everyday practices.},
author = {Fest, Isabelle and Wieringa, Maranke and Wagner, Ben},
doi = {10.1016/j.patter.2022.100604},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Fest, Wieringa, Wagner - Patterns.pdf:pdf},
issn = {26663899},
journal = {Patterns},
language = {English},
month = {oct},
number = {10},
pages = {100604},
title = {{Paper vs. practice: How legal and ethical frameworks influence public sector data professionals in the Netherlands}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S266638992200229X},
volume = {3},
year = {2022}
}
@article{Johnson2022,
abstract = {Advances in big data and artificial intelligence (AI), including machine learning (ML) and other cognitive computing technologies (CCT), have facilitated the development of human resource management (HRM) applications promising greater efficiency, economy, and effectiveness for public administration (Maciejewski, 2017) and better alignment with the modern, constantly evolving employment landscape. It is not surprising then that these advanced technologies are featured in proposals to elevate the government's human capital. This article discusses current and emerging AI applications that stand to impact most (if not all) HRM functions and their prospects for elevating public human capital. In particular, this article (a) reviews the current state of the field with regards to AI and HRM, (b) discusses AI's current and potential impact upon the core functional areas of HRM, (c) identifies the main challenges AI poses to such concerns as public values, equity, and traditional merit system principles, and (d) concludes by identifying research needs for public HRM scholarship and practice that highlight the growing role and influence of AI applications in the workplace.},
author = {Johnson, Brad A. M. and Coggburn, Jerrell D. and Llorens, Jared J.},
doi = {10.1177/00910260221126498},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Johnson, Coggburn, Llorens - Public Personnel Management.pdf:pdf},
issn = {0091-0260},
journal = {Public Personnel Management},
keywords = {artificial intelligence (AI),public human capital,public human resource management},
language = {English},
month = {dec},
number = {4},
pages = {538--562},
title = {{Artificial Intelligence and Public Human Resource Management: Questions for Research and Practice}},
url = {http://journals.sagepub.com/doi/10.1177/00910260221126498},
volume = {51},
year = {2022}
}
@article{Broomfield2022,
abstract = {The administrative reform of the datafied public administration places great emphasis on the classification, control, and prediction of citizen behavior and therefore has the potential to significantly impact citizen–state relations. There is a growing body of literature on data-oriented activism which aims to resist and counteract existing harmful data practices. However, little is known about the processes, policies, and political-economic structures that make datafication possible. There is a distinct research gap on situated and context-specific empirical research, which critically interrogates the premises, interests, and agendas of data-driven public administration and how stakeholders can impact them. This paper therefore studies the conditions of participation in public administration datafication. It asks the overall research question of how citizens are problematized and included in policy and practitioner discourse in the datafication of public administration. The paper takes Norway as its case and applies Cardullo and Kitchin's scaffold of smart citizen participation at the system level. It makes use of a unique empirical insight into the field, consisting of a survey, interviews, and an extensive document analysis. Unexpectedly, we find that citizens and civil society are rarely engaged in this administrative reform. Instead, we identify a paternalistic, top-down, technocratic approach where the context, values, and agendas of datafication are obscured from the citizen.},
author = {Broomfield, Heather and Reutter, Lisa},
doi = {10.1177/20539517221089302},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Broomfield, Reutter - Big Data & Society.pdf:pdf},
issn = {2053-9517},
journal = {Big Data & Society},
keywords = {Norway,Public administration,artificial intelligence,citizen participation,civil society,datafication},
language = {English},
month = {jan},
number = {1},
pages = {205395172210893},
title = {{In search of the citizen in the datafication of public administration}},
url = {http://journals.sagepub.com/doi/10.1177/20539517221089302},
volume = {9},
year = {2022}
}
@article{James2022,
abstract = {In recent years, a discourse of ‘ethical artificial intelligence' has emerged and gained international traction in response to widely publicised AI failures. In Australia, the discourse around ethical AI does not accord with the reality of AI deployment in the public sector. Drawing on institutional ethnographic approaches, this paper describes the misalignments between how technology is described in government documentation, and how it is deployed in social service delivery. We argue that the propagation of ethical principles legitimates established new public management strategies, and pre-empts questions regarding the efficacy of AI development; instead positioning implementation as inevitable and, provided an ethical framework is adopted, laudable. The ethical AI discourse acknowledges, and ostensibly seeks to move past, widely reported administrative failures involving new technologies. In actuality, this discourse works to make AI implementation a reality, ethical or not.},
author = {James, Alexandra and Whelan, Andrew},
doi = {10.1177/0261018320985463},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - James, Whelan - Critical Social Policy.pdf:pdf},
issn = {0261-0183},
journal = {Critical Social Policy},
keywords = {artificial intelligence,digitised welfare delivery,ethical artificial intelligence,new public management,public sector technology},
language = {English},
month = {feb},
number = {1},
pages = {22--42},
title = {{‘Ethical' artificial intelligence in the welfare state: Discourse and discrepancy in Australian social services}},
url = {http://journals.sagepub.com/doi/10.1177/0261018320985463},
volume = {42},
year = {2022}
}
@article{Coulthart2022,
abstract = {Investigating how the public sector adopts technologies to process and
analyze very large datasets is crucial for understanding governance in
the digital age. The authors of this article examine a large government
agency, the United States Border Patrol (USBP), an organization that is
in the early phases of building big data capabilities. They argue the
wide-scale adoption of big data analytics will require trial-and-error
processes coordinated by organizational leadership in partnership with
front-line employees who make the technology relevant to their needs in
the field. Absent engagement from both levels, organizations like USBP
that face significant barriers to adoption (e.g., limited data science
expertise) will struggle to leverage data at scale. The authors also
extend the literature on big data in the public sector and provide a
rich description of how factors, such as organizational leadership and
resources, impact the innovation process.},
author = {Coulthart, Stephen and Riccucci, Ryan},
doi = {10.1111/puar.13431},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Coulthart, Riccucci - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {mar},
number = {2},
pages = {280--289},
title = {{Putting Big Data to Work in Government: The Case of the United States Border Patrol}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13431},
volume = {82},
year = {2022}
}
@article{Wilson2022,
abstract = {Ethics, explainability, responsibility, and accountability are important concepts for questioning the societal impacts of artificial intelligence and machine learning (AI), but are insufficient to guide the public sector in regulating and implementing AI. Recent frameworks for AI governance help to operationalize these by identifying the processes and layers of governance in which they must be considered, but do not provide public sector workers with guidance on how they should be pursued or understood. This analysis explores how the concept of sustainable AI can help to fill this gap. It does so by reviewing how the concept has been used by the research community and aligning research on sustainable development with research on public sector AI. Doing so identifies the utility of boundary conditions that have been asserted for social sustainability according to the Framework for Strategic Sustainable Development, and which are here integrated with prominent concepts from the discourse on AI and society. This results in a conceptual model that integrates five boundary conditions to assist public sector decision-making about how to govern AI: Diversity, Capacity for learning, Capacity for selforganization Common meaning, and Trust. These are presented together with practical approaches for their presentation, and guiding questions to aid public sector workers in making the decisions that are required by other operational frameworks for ethical AI.},
author = {Wilson, Christopher and van der Velden, Maja},
doi = {10.1016/j.techsoc.2022.101926},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Wilson, van der Velden - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {AI governance,Artificial intelligence,Public administration,Social sustainability,Sustainability},
language = {English},
month = {feb},
pages = {101926},
title = {{Sustainable AI: An integrated model to guide public sector decision-making}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0160791X22000677},
volume = {68},
year = {2022}
}
@article{Gesk2022,
abstract = {Interest in implementing artificial intelligence (AI)-based software in the public sector is growing. First implementations and research in individual public services have already been carried out; however, a better understanding of citizens' acceptance of this technology is missing in the public sector, as insights from the private sector cannot be transferred directly. For this purpose, we conduct policy-capturing experiments to analyze AI's acceptance in six representative scenarios. Based on behavioral reasoning theory, we gather evidence from 329 participants. The results show that AI solutions in general public services are preferred over those provided by humans, but specific services are still a human domain. Further analyses show that the major drivers toward acceptance are the reasons against AI. The results contribute to understanding of when and why AI is accepted in public services. Public administration can use the results to identify AI-based software to invest in and communicate their usage to perceive such investments' high acceptance rates.},
author = {Gesk, Tanja Sophie and Leyer, Michael},
doi = {10.1016/j.giq.2022.101704},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Gesk, Leyer - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Acceptance,Artificial intelligence,Behavioral reasoning theory,Public services},
language = {English},
month = {jul},
number = {3},
pages = {101704},
title = {{Artificial intelligence in public services: When and why citizens accept its usage}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X22000375},
volume = {39},
year = {2022}
}
@article{Alshahrani2022,
abstract = {Artificial Intelligence (AI) has been suggested to have transformative potential for public sector organizations through enabling increased productivity and novel ways to deliver public services. In order to materialize the transformative potential of AI, public sector organizations need to successfully assimilate AI in their operational activities. However, AI assimilation in the public sector appears to be fragmented and lagging the private sector, and the phenomena has really limited attention from academic research community. To address this gap, we adopt the case study approach to explore three Saudi-Arabian public sector organizations and analyze the results using the attention-based view of the organization (ABV) as the theoretical lens. This study elucidates the challenges related AI assimilation in public sector in terms of how organizational attention is focused situated and distributed during the assimilation process. Five key challenges emerged from the cases studied, namely (i) misalignment between AI and management decision-making, (ii) tensions with linguistics and national culture, (iii) developing and implementing AI infrastructure, (iv) data integrity and sharing, and (v) ethical and governance concerns. The findings reveal a re-enforcing relationship between the situated attention and structural distribution of attention that can accelerate the successful assimilation of AI in public sector organizations.},
author = {Alshahrani, Albandari and Dennehy, Denis and M{\"{a}}ntym{\"{a}}ki, Matti},
doi = {10.1016/j.giq.2021.101617},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Alshahrani, Dennehy, M{\"{a}}ntym{\"{a}}ki - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Attention-based view,Decision making,Public sector},
language = {English},
month = {oct},
number = {4},
pages = {101617},
title = {{An attention-based view of AI assimilation in public sector organizations: The case of Saudi Arabia}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X21000538},
volume = {39},
year = {2022}
}
@article{VanNoordt2022a,
abstract = {There is great interest to use artificial intelligence (AI) technologies to improve government processes and public services. However, the adoption of technologies has often been challenging for public administrations. In this article, the adoption of AI in governmental organizations has been researched as a form of information and communication technologies (ICT)–enabled governance innovation in the public sector. Based on findings from three cases of AI adoption in public sector organizations, this article shows strong similarities between the antecedents identified in previous academic literature and the factors contributing to the use of AI in government. The adoption of AI in government does not solely rely on having high-quality data but is facilitated by numerous environmental, organizational, and other factors that are strictly intertwined among each other. To address the specific nature of AI in government and the complexity of its adoption in the public sector, we thus propose a framework to provide a comprehensive overview of the key factors contributing to the successful adoption of AI systems, going beyond the narrow focus on data, processing power, and algorithm development often highlighted in the mainstream AI literature and policy discourse.},
author = {van Noordt, Colin and Misuraca, Gianluca},
doi = {10.1177/0894439320980449},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - van Noordt, Misuraca - Social Science Computer Review.pdf:pdf},
issn = {0894-4393},
journal = {Social Science Computer Review},
keywords = {AI-enabled innovation,adoption,artificial intelligence,digital transformation,public sector innovation},
language = {English},
month = {apr},
number = {2},
pages = {426--444},
title = {{Exploratory Insights on Artificial Intelligence for Government in Europe}},
url = {http://journals.sagepub.com/doi/10.1177/0894439320980449},
volume = {40},
year = {2022}
}
@article{Campion2022,
abstract = {Despite the current popularity of artificial intelligence (AI) and a steady increase in publications over time, few studies have investigated AI in public contexts. As a result, assumptions about the drivers, challenges, and impacts of AI in government are far from conclusive. By using a case study that involves a large research university in England and two different county councils in a multiyear collaborative project around AI, we study the challenges that interorganizational collaborations face in adopting AI tools and implementing organizational routines to address them. Our findings reveal the most important challenges facing such collaborations: a resistance to sharing data due to privacy and security concerns, insufficient understanding of the required and available data, a lack of alignment between project interests and expectations around data sharing, and a lack of engagement across organizational hierarchy. Organizational routines capable of overcoming such challenges include working on-site, presenting the benefits of data sharing, reframing problems, designating joint appointments and boundary spanners, and connecting participants in the collaboration at all levels around project design and purpose.},
author = {Campion, Averill and Gasco-Hernandez, Mila and {Jankin Mikhaylov}, Slava and Esteve, Marc},
doi = {10.1177/0894439320979953},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - Campion et al. - Social Science Computer Review.pdf:pdf},
issn = {0894-4393},
journal = {Social Science Computer Review},
keywords = {adoption of AI,challenges of AI,interorganizational collaboration,organizational routines,public sector},
language = {English},
month = {apr},
number = {2},
pages = {462--477},
title = {{Overcoming the Challenges of Collaboratively Adopting Artificial Intelligence in the Public Sector}},
url = {http://journals.sagepub.com/doi/10.1177/0894439320979953},
volume = {40},
year = {2022}
}
@article{VanNoordt2022,
abstract = {Artificial Intelligence is increasingly being used by public sector organisations. Previous research highlighted that the use of AI technologies in government could improve policy making processes, public service delivery and the internal management of public administrations. In this article, we explore to which extent the use of AI in the public sector impacts these core governance functions. Findings from the review of a sample of 250 cases across the European Union, show that AI is used mainly to support improving public service delivery, followed by enhancing internal management and only in a limited number assist directly or indirectly policy decision-making. The analysis suggests that different types of AI technologies and applications are used in different governance functions, highlighting the need to further in-depth investigation to better understand the role and impact of use in what is being defined the governance ``of, with and by AI''.},
author = {van Noordt, Colin and Misuraca, Gianluca},
doi = {10.1016/j.giq.2022.101714},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2022 - van Noordt, Misuraca - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Policy making,Public administration,Public sector management,Public services},
language = {English},
month = {jul},
number = {3},
pages = {101714},
title = {{Artificial intelligence for the public sector: results of landscaping the use of AI in government across the European Union}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X22000478},
volume = {39},
year = {2022}
}
@article{Conejero2021,
abstract = {Education and employment are key aspects of a country's well-being. Governments expend valuable resources on designing education plans and employment programs. These two aspects are usually analysed separately, although, as they are closely related, considering them together might improve their efficacy. The problem lies, at least in part, in the fact that different public entities manage their own data with their own isolated systems, and do not develop joint educational and employment policies. In order to facilitate working towards this goal, in this manuscript, we make use of Data Engineering, Data Visualization, and Intelligent Data Analytics methods to create a decision support system for the Government of Extremadura. Extremadura is a European Union Objective 1 region in Spain with high rates of unemployment and secondary school drop-out. Data Engineering is used to create a Data Warehouse that unifies the different data sources into a central repository for quick access and control. This allows dealing with the challenge of transforming, processing, storing and accessing the data. Data Visualization techniques are applied to create an interactive dashboard that assists users in analysing and interpreting the data in the Data Warehouse repository. Thus, charts, diagrams, and maps are created specifically to help technical or political decision-makers. Finally, Intelligent Data Analytics techniques are used to incorporate Association Rules into the visualization dashboard. Its goal is to identify associations, relationships, and patterns in data that, at least in plain sight, are not readable or interpretable by humans. It does this by inferring knowledge that humans cannot pick out by themselves. As a result, a complete system was defined and implemented to support public administrations in their decision-making and definition of precise evidence-based policies in the areas of education and employment. In particular, it allows the definition of unified strategies to reduce the unemployment rate. {\textcopyright} 2020 Elsevier Ltd},
annote = {Cited by: 10},
author = {Conejero, Jose Mar{\'{i}}a and Preciado, Juan Carlos and Fern{\'{a}}ndez-Garc{\'{i}}a, Antonio Jes{\'{u}}s and Prieto, Alvaro E. and Rodr{\'{i}}guez-Echeverr{\'{i}}a, Roberto},
doi = {10.1016/j.eswa.2020.114509},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Conejero et al. - Expert Systems with Applications.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Association rules,Data mining,Decision-making tool,Education-employment,Intelligent systems,Machine learning},
language = {English},
month = {may},
pages = {114509},
title = {{Towards the use of Data Engineering, Advanced Visualization techniques and Association Rules to support knowledge discovery for public policies}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417420311532},
volume = {170},
year = {2021}
}
@article{Merhi2021,
abstract = {This study aims to fill a gap in the literature by identifying, defining, and evaluating the critical success factors that impact the implementation of data intelligence in the public sector. Fourteen factors were identified, and then divided into three categories: organization, process, and technology. We used the analytical hierarchy process, a quantitative method of decision-making, to evaluate the importance of the factors presented in the study using data collected from nine experts. The results showed that technology, as a category, is the most important. The analysis also indicated that project management, information systems & data, and data quality are the most important factors among all fourteen critical success factors. We discuss the implications of the analysis for practitioners and researchers in the paper. {\textcopyright} 2021},
annote = {Cited by: 21},
author = {Merhi, Mohammad I.},
doi = {10.1016/j.techfore.2021.121180},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Merhi - Technological Forecasting and Social Change.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {AHP,Data analytics,Data intelligence,Public sector,Success factors,Systems implementation},
language = {English},
month = {dec},
pages = {121180},
title = {{Evaluating the critical success factors of data intelligence implementation in the public sector using analytical hierarchy process}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162521006132},
volume = {173},
year = {2021}
}
@article{Chen2021a,
abstract = {Background: The use of digital health technologies was an integral part to China's early response to coronavirus disease 2019 (COVID-19). Existing literatures have analyzed and discussed implemented digital health innovations from the perspective of technologies, whereas how policy mechanisms contributed to the formulation of the digital health landscape for COVID-19 was overlooked. This study aimed to examine the contexts and key mechanisms in China's rapid mobilization of digital health interventions in response to COVID-19, and to document and share lessons learned. Methods: Policy documents were identified and retrieved from government portals and recognized media outlets. Data on digital health interventions were collected through three consecutive surveys administered between 23 January 2020 and 31 March 2020 by China Academy of Information and Communication Technology (CAICT) affiliated to the Ministry of Industry and Information Technology (MIIT). Participants were member companies of the Internet Health alliance established by MIIT and the National Health Commission (NHC) in June 2016. Self-report digital interventions focusing on social and economic recovery were excluded. Two hundred and sixty-six unique digital health interventions meeting our criteria were extracted from 175 narratives on digital health interventions submitted by 116 participating companies. Thematic analysis was conducted to describe the scope and priority of policies advocating for the use of digital health technologies and the implementation pattern of digital health interventions. Data limitations precluded an evaluation of the impact of digital health interventions over a longer time frame. Results: Between January and March 2020, national policy directives promoting the use of digital technologies for the containment of COVID-19 collectively advocated for use cases in emergency planning and preparedness, public health response, and clinical services. Interventions to strengthen clinical services were mentioned more than the other two themes (n = 15, 62.5% (15/24)). Using digital technologies for public health response was mentioned much less than clinical services (n = 5, 20.8% (5/24)). Emergency planning and preparedness was least mentioned (n = 4, 16.7% (4/24)). Interventions in support of clinical services disproportionately favored healthcare facilities in less resource-constraint settings. Digital health interventions shared the same pattern of distribution. More digital health technologies were implemented in clinical services (n = 103, 38.7% (103/266)) than that in public health response (n = 91, 34.2% (91/266)). Emergency planning and preparedness had the least self-reported digital health interventions (n = 72, 27.1% (72/266)). We further identified case studies under each theme in which the wide use of digital health technologies highlighted contextual factors and key enabling mechanisms. Conclusions: The contextual factors and key enabling mechanisms through the use of policy instruments to promote digital health interventions for COVID-19 in China include pathway of policy directives influencing the private sector using a decentralized system, the booming digital health landscape before COVID-19, agility of the public sector in introducing regulatory flexibilities and incentives to mobilize the private sector. {\textcopyright} 2021},
annote = {Cited by: 14},
author = {Chen, Mengji and Xu, Shan and Husain, Lewis and Galea, Gauden},
doi = {10.1016/j.imed.2021.03.001},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Chen et al. - Intelligent Medicine.pdf:pdf},
issn = {26671026},
journal = {Intelligent Medicine},
keywords = {Artificial intelligence,Big data,Coronavirus disease 2019,Digital health,Telemedicine},
language = {English},
month = {may},
number = {1},
pages = {29--36},
title = {{Digital health interventions for COVID-19 in China: a retrospective analysis}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2667102621000024},
volume = {1},
year = {2021}
}
@article{Shah2021,
abstract = {The public sector, private firms, business community, and civil society are generating data that is high in volume, veracity, velocity and comes from a diversity of sources. This kind of data is known as big data. Public Administrations (PAs) pursue big data as “new oil” and implement data-centric policies to transform data into knowledge, to promote good governance, transparency, innovative digital services, and citizens' engagement in public policy. From the above, the Government Big Data Ecosystem (GBDE) emerges. Managing big data throughout its lifecycle becomes a challenging task for governmental organizations. Despite the vast interest in this ecosystem, appropriate big data management is still a challenge. This study intends to fill the above-mentioned gap by proposing a data lifecycle framework for data-driven governments. Through a Systematic Literature Review, we identified and analysed 76 data lifecycles models to propose a data lifecycle framework for data-driven governments (DaliF). In this way, we contribute to the ongoing discussion around big data management, which attracts researchers' and practitioners' interest. {\textcopyright} 2021, The Author(s).},
annote = {Cited by: 21},
author = {Shah, Syed Iftikhar Hussain and Peristeras, Vassilios and Magnisalis, Ioannis},
doi = {10.1186/s40537-021-00481-3},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Shah, Peristeras, Magnisalis - Journal of Big Data.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {Big data,Data lifecycle,Data management,Data-driven government,Government Big Data Ecosystem},
language = {English},
number = {1},
title = {{DaLiF: a data lifecycle framework for data-driven governments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107949250&doi=10.1186%2Fs40537-021-00481-3&partnerID=40&md5=7e2b6c38f966b0ec182fc8db046b6f01},
volume = {8},
year = {2021}
}
@article{Aerts2021,
abstract = {Rising rates of NCDs threaten fragile healthcare systems in low- and middle-income countries. Fortunately, new digital technology provides tools to more effectively address the growing dual burden of disease. Two-thirds of the world's population subscribed to mobile services by the end of 2018, while the falling price of connectivity and the 5G networks rollout promise to accelerate the use of digital technology. Properly leveraged, we can employ digital solutions and applications to transform health systems from reactive to proactive and even preventive, helping people stay healthy. With artificial intelligence (AI), health systems can be made more predictive by detecting risk factors and helping health professionals respond faster to prevent disease. Yet this rapid pace of growth has also complicated the digital health landscape. Myriad digital health apps compete and overlap in the public and private sectors, and significant gaps in the collection and analysis of digital data threaten to leave some behind. Established in 2010, the Broadband Commission for Sustainable Development is led by ITU and UNESCO and advocates for the transformational impact of broadband technologies for development. Its working group on digital and AI in health, co-chaired by the Novartis Foundation and at different times Nokia, Intel and Microsoft, identifies best practices for countries to realize the potential of digital technology in health and care. Interviewing more than 100 key stakeholders and reviewing over 200 documents, the Working Group set out to identify common challenges that countries face in implementing digital health solutions, and to develop a framework that countries can use to build systems for supporting digital health solutions. Common challenges include a lack of coordination leading to fragmented digital health solutions; lack of systems and workforce capacity to manage data and digital technology, and inadequate financing to support digital health. The working group proposes six building blocks for digital health systems: formulate and execute a national digital health strategy; create policy and regulatory frameworks that support innovation while protecting security and privacy; ensure access to digital infrastructure; ensure interoperability of digital health system components; establish effective partnerships; and sustain adequate financing. {\textcopyright} 2021},
annote = {Cited by: 24},
author = {Aerts, Ann and Bogdan-Martin, Doreen},
doi = {10.1016/j.ijmedinf.2021.104456},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Aerts, Bogdan-Martin - International Journal of Medical Informatics.pdf:pdf},
issn = {13865056},
journal = {International Journal of Medical Informatics},
keywords = {Digital technology,Health systems,Intersectoral collaboration,Noncommunicable diseases,Sustainable Development Goals},
language = {English},
month = {jun},
pages = {104456},
title = {{Leveraging data and AI to deliver on the promise of digital health}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1386505621000824},
volume = {150},
year = {2021}
}
@article{Rosecky2021,
abstract = {Nowadays, the European municipal waste management policy based on the circular economy paradigm demands the closing of material and financial loops at all territorial levels of public administration. The effective planning of treatment capacities (especially sorting plants, recycling, and energy recovery facilities) and municipal waste management policy requires an accurate prognosis of municipal waste generation, and therefore, the knowledge of behavioral, socio-economic, and demographic factors influencing the waste management (and recycling) behavior of households, and other municipal waste producers. To enable public bodies at different territorial levels to undertake an effective action resulting in circular economy we evaluated various factors influencing the generation of municipal waste fractions at regional, micro-regional and municipal level in the Czech Republic. Principal components were used as input for traditional models (multivariable linear regression, generalized linear model) as well as tree-based machine learning models (regression trees, random forest, gradient boosted regression trees). Study results suggest that the linear regression model usually offers a good trade-off between model accuracy and interpretability. When the most important goal of the prediction is supposed to be accuracy, the random forest is generally the best choice. The quality of developed models depends mostly on the chosen territorial level and municipal waste fraction. The performance of these models deteriorates significantly for lower territorial levels because of worse data quality and bigger variability. Only the age structure seems to be important across territorial levels and municipal waste fractions. Nevertheless, also other factors are of high significance in explaining the generation of municipal waste fractions at different territorial levels (e.g. number of economic subjects, expenditures, population density and the level of education). Therefore, there is not one single effective public policy dealing with circular economy strategy that fits all territorial levels. Public representatives should focus on policies effective at specific territorial level. However, performance of the models is poor for lower territorial levels (municipality and micro-regions). Thus, results for municipalities and micro-regions are weak and should be treated as such. {\textcopyright} 2021 Elsevier Ltd},
annote = {Cited by: 39},
author = {Roseck{\'{y}}, Martin and {\v{S}}ompl{\'{a}}k, Radovan and Slav{\'{i}}k, Jan and Kalina, Jiř{\'{i}} and Bulkov{\'{a}}, Gabriela and Bedn{\'{a}}ř, Josef},
doi = {10.1016/j.jenvman.2021.112584},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Roseck{\'{y}} et al. - Journal of Environmental Management.pdf:pdf},
issn = {03014797},
journal = {Journal of Environmental Management},
keywords = {Machine learning,Municipal waste generation,Public policy,Regression modelling,Socio-economic factors,Territorial levels},
language = {English},
title = {{Predictive modelling as a tool for effective municipal waste management policy at different territorial levels}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105836019&doi=10.1016%2Fj.jenvman.2021.112584&partnerID=40&md5=c8d07d817d38ecd149aca24836cb81d4},
volume = {291},
year = {2021}
}
@article{Chen2021,
abstract = {Public sectors are utilizing AI-based self-service technology (SST) at an accelerating rate, given its potential for improving work efficiency and user experience, reducing service costs, and relieving human workloads. However, there is a limited understanding of the factors influencing citizens' user experience when services supported by AI-based SST are provided. Thus, with insights from the Consumer Value Theory, this paper aims to explore the factors that are important to AI-based SST user experience and the conditional role of trust in government. The on-site survey of 379 citizens in a public service center in China indicates that user experience positively relates to personalization and aesthetics and negatively associates with perceived time spent on the AI-based self-service machines. In addition, the results suggest that citizens with more trust in government are more likely to have a pleasant experience coming from AI-based SST's personalization and aesthetics. Public managers should ensure that the AI-based SST is aesthetically appealing and should be able to personalize the delivery of the right contents to the right person at the right time. Furthermore, they should always prioritize cultivating more trust from citizens to achieve a more positive user experience. {\textcopyright} 2020 Elsevier Inc.},
annote = {Cited by: 92},
author = {Chen, Tao and Guo, Wenshan and Gao, Xian and Liang, Zhehao},
doi = {10.1016/j.giq.2020.101520},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Chen et al. - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Artificial intelligence,Self-service technology,Trust in government,User experience},
language = {English},
month = {oct},
number = {4},
pages = {101520},
title = {{AI-based self-service technology in public service delivery: User experience and influencing factors}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X20302999},
volume = {38},
year = {2021}
}
@article{Cong2021,
abstract = {Current debates over digital contact tracing mainly focus on the tools and experiences in the West. China's health code, while often seen as one of the earliest and most widely adopted apps since the outbreak of COVID-19, has not been studied specifically. This article provides a detailed analysis of the health code, draws comparison with the contact tracing apps developed by Google and Apple, and seeks to understand the specifications and contradictions internal to the health code's development and deployment in China. Looking at both technical features and the mode and process of its adoption, the article argues that the health code is strictly speaking not a contact tracing tool, but a technology of population control which is integrated in traditional forms of control and facilitates the enhancement of such control. As a technology of ruling the population, rather than the virus as such, the health code also reveals crucial problems in the modernization and informatization of the state governance and public administration. A critique on the health code solely informed by privacy and personal data protection runs the risk of being co-opted by the government and technology companies deploying such tools to expand their surveillance and regulatory power. Copyright {\textcopyright} 2021 Cong.},
annote = {Cited by: 29},
author = {Cong, Wanshu},
doi = {10.3389/fpos.2021.627959},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Cong - Frontiers in Political Science.pdf:pdf},
issn = {26733145},
journal = {Frontiers in Political Science},
keywords = {big data,contact tracing,digital platform,health emergency,privacy,surveillance},
language = {English},
title = {{From Pandemic Control to Data-Driven Governance: The Case of China's Health Code}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118887215&doi=10.3389%2Ffpos.2021.627959&partnerID=40&md5=7f33ab4bc6e1a8f866c51a9640ce3ce4},
volume = {3},
year = {2021}
}
@article{Scannapieco2021,
abstract = {The paper highlights how each step of a data science pipeline can be performed in a “responsible” way, taking into account privacy, ethics, and quality issues. Several examples from the Italian public sector contribute to clarifying how data collections and data analyses can be carried out under a responsible view. {\textcopyright} 2021 The Authors},
annote = {Cited by: 0},
author = {Scannapieco, Monica and Virgillito, Antonino},
doi = {10.1016/j.patter.2021.100393},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Scannapieco, Virgillito - Patterns(2).pdf:pdf},
issn = {26663899},
journal = {Patterns},
keywords = {Artificial intelligence,Self-service technology,Trust in government,User experience},
language = {English},
month = {dec},
number = {12},
pages = {100393},
title = {{How to be responsible in all the steps of a data science pipeline: The case of the Italian public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2666389921002609},
volume = {2},
year = {2021}
}
@article{Cerrillo-Martinez2021,
abstract = {Public transparency is becoming increasingly complex due to the volume of data generated by government, the plurality of uses given to public data, their dispersal over different organizations, bodies and units and the diversity of mecha­nisms through which they are channelled. All this requires government agencies not only to improve data management but also to adopt procedures and structures that facilitate decision-making regarding data's use and quality. In this context, this study defines data governance as the set of principles, values and standards that guide interaction in decision-making among stakeholders who create, manage and use data. This study uses the analysis of three data governance cases to identify the defining characteristics of data governance (data governance's design, the institutional position on data governance in the organizational structure, the stakeholders involved in data governance, the interaction channels provided and the functions attributed to them). Based on these elements, three models of data governance promoted by government agencies are observed. In the light of the data governance models analysed, the final reflection identifies how data governance can contribute to improve public transparency.},
author = {Cerrillo-Mart{\'{i}}nez, Agust{\'{i}} and Casades{\'{u}}s-de-Mingo, Anah{\'{i}}},
doi = {10.3145/epi.2021.jul.02},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Cerrillo-Mart{\'{i}}nez, Casades{\'{u}}s-de-Mingo - El Profesional de la informaci{\'{o}}n.pdf:pdf},
issn = {16992407},
journal = {El Profesional de la informaci{\'{o}}n},
keywords = {Accountability,Big data,Case studies,Compliance,Data,Data governance,Data management,Data re-use,Legal frameworks,Local administration,Open data,Open government,Policies,Public administration,Public policy,Public sector,Transparency},
language = {English},
month = {jul},
number = {4},
title = {{Data governance for public transparency}},
url = {https://revista.profesionaldelainformacion.com/index.php/EPI/article/view/86362},
volume = {30},
year = {2021}
}
@article{Adamczyk2021,
abstract = {What is the impact of automation on public sector employment? Using machine learning and natural language processing algorithms, this study estimates which occupations and agencies of the Brazilian Federal Government are most susceptible to automation. We contribute to the literature by introducing Bartik Occupational Tasks (BOT), an objective method used to estimate automation susceptibility that avoids subjective or ad hoc classifications. We show that approximately 20% of Brazilian public sector employees work in jobs with a high potential of automation in the coming decades. Government occupations with lower schooling and lower salary levels are most susceptible to future automation.},
author = {Adamczyk, Willian Boschetti and Monasterio, Leonardo and Fochezatto, Adelar},
doi = {10.1016/j.techsoc.2021.101722},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Adamczyk, Monasterio, Fochezatto - Technology in Society.pdf:pdf},
issn = {0160791X},
journal = {Technology in Society},
keywords = {Automation,machine learning,public sector},
language = {English},
month = {nov},
pages = {101722},
title = {{Automation in the future of public sector employment: the case of Brazilian Federal Government}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0160791X21001974},
volume = {67},
year = {2021}
}
@article{Kempeneer2021,
abstract = {In a sense, the 2008 financial crisis was a crisis of theory. Regulators, banks, and financial markets all had encompassing theoretical models about how the economy worked, but they all failed to predict the looming crisis. As such, regulators increasingly turn to big data to understand banks' health. Despite the prominence of big data in society, its use in the public sector remains grossly understudied. This paper explores the regulatory use of big data in the case of the EU-wide banking stress test, a key regulatory indicator. The paper draws on interviews with supervisors at the European Central Bank (ECB), European Banking Authority (EBA) and National Bank of Belgium (NBB), as well as with consultants and risk directors in Belgian banks, to explain how big data-driven regulation affects the relationship between regulators and regulated entities. It draws particular attention to the epistemological component of using large data sets in decision-making: a big data state of mind. The article more specifically shows how the underlying epistemology, rather than simply the bigness of datasets, affects the relationship between regulators and regulated entities, and the regulatory process at large. The paper concludes that regulators' big data state of mind calls for new practical and legal guidelines regarding the validity of data-driven knowledge claims. Moreover, it shows how accountability based on descriptive transparency no longer makes sense in the `age of the algorithm', suggesting a shift towards relational transparency and joint knowledge production.},
author = {Kempeneer, Shirley},
doi = {10.1016/j.giq.2021.101578},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Kempeneer - Government Information Quarterly.pdf:pdf},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Accountable AI,Banking stress test,Big data,Epistemology,Financial regulation,Transparency},
language = {English},
month = {jul},
number = {3},
pages = {101578},
title = {{A big data state of mind: Epistemological challenges to accountability and transparency in data-driven regulation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0740624X21000149},
volume = {38},
year = {2021}
}
@article{Gallego2021,
abstract = {Is it possible to predict malfeasance in public procurement? With the proliferation of e-procurement systems in the public sector, anti-corruption agencies and watchdog organizations have access to valuable sources of information with which to identify transactions that are likely to become troublesome and why. In this article, we discuss the promises and challenges of using machine learning models to predict inefficiency and corruption in public procurement. We illustrate this approach with a dataset with more than two million public procurement contracts in Colombia. We trained machine learning models to predict which of them will result in corruption investigations, a breach of contract, or implementation inefficiencies. We then discuss how our models can help practitioners better understand the drivers of corruption and inefficiency in public procurement. Our approach will be useful to governments interested in exploiting large administrative datasets to improve the provision of public goods, and it highlights some of the tradeoffs and challenges that they might face throughout this process. (C) 2020 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.},
author = {Gallego, Jorge and Rivero, Gonzalo and Mart{\'{i}}nez, Juan},
doi = {10.1016/j.ijforecast.2020.06.006},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Gallego, Rivero, Mart{\'{i}}nez - International Journal of Forecasting.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Corruption,Forecasting,Inefficiency,Machine learning,Public procurement},
language = {English},
month = {jan},
number = {1},
pages = {360--377},
title = {{Preventing rather than punishing: An early warning model of malfeasance in public procurement}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207020300935},
volume = {37},
year = {2021}
}
@article{Hartmann2021,
abstract = {Algorithms are increasingly used in different domains of public policy. They help humans to profile unemployed, support administrations to detect tax fraud and give recidivism risk scores that judges or criminal justice managers take into account when they make bail decisions. In recent years, critics have increasingly pointed to ethical challenges of these tools and emphasized problems of discrimination, opaqueness or accountability, and computer scientists have proposed technical solutions to these issues. In contrast to these important debates, the literature on how these tools are implemented in the actual everyday decision-making process has remained cursory. This is problematic because the consequences of ADM systems are at least as dependent on the implementation in an actual decision-making context as on their technical features. In this study, we show how the introduction of risk assessment tools in the criminal justice sector on the local level in the USA has deeply transformed the decision-making process. We argue that this is mainly due to the fact that the evidence generated by the algorithm introduces a notion of statistical prediction to a situation which was dominated by fundamental uncertainty about the outcome before. While this expectation is supported by the case study evidence, the possibility to shift blame to the algorithm does seem much less important to the criminal justice actors.},
author = {Hartmann, Kathrin and Wenzelburger, Georg},
doi = {10.1007/s11077-020-09414-y},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Hartmann, Wenzelburger - Policy Sciences.pdf:pdf},
issn = {0032-2687},
journal = {Policy Sciences},
keywords = {Artificial intelligence,Big data,Public administration,Public policy,criminal justice},
language = {English},
month = {jun},
number = {2},
pages = {269--287},
title = {{Uncertainty, risk and the use of algorithms in policy decisions: a case study on criminal justice in the USA}},
url = {https://link.springer.com/10.1007/s11077-020-09414-y},
volume = {54},
year = {2021}
}
@article{Asatiani2021,
abstract = {The paper presents an approach for implementing inscrutable (i.e., nonexplainable) artificial intelligence (AI) such as neural networks in an accountable and safe manner in organizational settings. Drawing on an exploratory case study and the recently proposed concept of envelopment, it describes a case of an organization successfully “enveloping” its AI solutions to balance the performance benefits of flexible AI models with the risks that inscrutable models can entail. The authors present several envelopment methods—establishing clear boundaries within which the AI is to interact with its surroundings, choosing and curating the training data well, and appropriately managing input and output sources—alongside their influence on the choice of AI models within the organization. This work makes two key contributions: It introduces the concept of sociotechnical envelopment by demonstrating the ways in which an organization's successful AI envelopment depends on the interaction of social and technical factors, thus extending the literature's focus beyond mere technical issues. Secondly, the empirical examples illustrate how operationalizing a sociotechnical envelopment enables an organization to manage the trade-off between low explainability and high performance presented by inscrutable models. These contributions pave the way for more responsible, accountable AI implementations in organizations, whereby humans can gain better control of even inscrutable machine-learning models.},
author = {Asatiani, Aleksandre and Malo, Pekka and Nagb{\o}l, Per R{\aa}dberg and Penttinen, Esko and Rinta-Kahila, Tapani and Salovaara, Antti},
doi = {10.17705/1jais.00664},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Asatiani et al. - Journal of the Association for Information Systems.pdf:pdf},
issn = {15369323},
journal = {Journal of the Association for Information Systems},
keywords = {Artificial Intelligence,Envelopment,Explainable AI,Machine Learning,Public Sector,Sociotechnical Systems,XAI},
language = {English},
number = {2},
pages = {325--352},
title = {{Sociotechnical Envelopment of Artificial Intelligence: An Approach to Organizational Deployment of Inscrutable Artificial Intelligence Systems}},
url = {https://aisel.aisnet.org/jais/vol22/iss2/8/},
volume = {22},
year = {2021}
}
@article{Zekic-Susac2021,
abstract = {The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities. ? 2021 Elsevier B.V. All rights reserved.},
author = {Zeki{\'{c}}-Su{\v{s}}ac, Marijana and Has, Adela and Kne{\v{z}}evi{\'{c}}, Marinela},
doi = {10.1016/j.neucom.2020.01.124},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Zeki{\'{c}}-Su{\v{s}}ac, Has, Kne{\v{z}}evi{\'{c}} - Neurocomputing.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Energy cost,Machine learning,Neural networks,Public building,Regression trees,Variable reduction},
language = {English},
month = {jun},
pages = {223--233},
title = {{Predicting energy cost of public buildings by artificial neural networks, CART, and random forest}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231221001430},
volume = {439},
year = {2021}
}
@article{Wang2021,
abstract = {Despite significant theoretical and empirical attention on public value creation in the public sector, the relationship between artificial intelligence (AI) use and value creation from the citizen perspective remains poorly understood. We ground our study in Moore's public value management to examine the relationship between AI use and value creation. We conceptually categorize public service value into public value and private value. We use procedural justice and trust in government as indicators of public value and, based on motivation theory, we use perceived usefulness and perceived enjoyment as indicators of private value. A field survey of 492 AI voice robot users in China was conducted to test our model. The results indicated that the effective use of AI voice robots was significantly associated with private value and procedural justice. However, the relationship between the effective use of AI and trust in government was not found to be significant. Surprisingly, the respondents indicated that private value had a greater effect on overall value creation than public value. This contrasts with the common idea that value creation from the government perspective suggests that social objectives requiring public value are more important to citizens. The results also show that gender and citizens with different experiences show different AI usage behaviors.},
author = {Wang, Changlin and Teo, Thompson S.H. and Janssen, Marijn},
doi = {10.1016/j.ijinfomgt.2021.102401},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Wang, Teo, Janssen - International Journal of Information Management.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Artificial intelligence,Private value,Public value,Value creation,Voice robot},
language = {English},
month = {dec},
pages = {102401},
title = {{Public and private value creation using artificial intelligence: An empirical study of AI voice robot users in Chinese public sector}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401221000943},
volume = {61},
year = {2021}
}
@article{Zekic-Susac2021a,
abstract = {Energy efficiency of public sector is an important issue in the context of smart cities due to the fact that buildings are the largest energy consumers, especially public buildings such as educational, health, government and other public institutions that have a large usage frequency. However, recent developments of machine learning within Big Data environment have not been exploited enough in this domain. This paper aims to answer the question of how to incorporate Big Data platform and machine learning into an intelligent system for managing energy efficiency of public sector as a substantial part of the smart city concept. Deep neural networks, Rpart regression tree and Random forest with variable reduction procedures were used to create prediction models of specific energy consumption of Croatian public sector buildings. The most accurate model was produced by Random forest method, and a comparison of important predictors extracted by all three methods has been conducted. The models could be implemented in the suggested intelligent system named MERIDA which integrates Big Data collection and predictive models of energy consumption for each energy source in public buildings, and enables their synergy into a managing platform for improving energy efficiency of the public sector within Big Data environment. The paper also discusses technological requirements for developing such a platform that could be used by public administration to plan reconstruction measures of public buildings, to reduce energy consumption and cost, as well as to connect such smart public buildings as part of smart cities. Such digital transformation of energy management can increase energy efficiency of public administration, its higher quality of service and healthier environment.},
author = {Zeki{\'{c}}-Su{\v{s}}ac, Marijana and Mitrovi{\'{c}}, Sa{\v{s}}a and Has, Adela},
doi = {10.1016/j.ijinfomgt.2020.102074},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Zeki{\'{c}}-Su{\v{s}}ac, Mitrovi{\'{c}}, Has - International Journal of Information Management.pdf:pdf},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Planning models Energy efficiency Machine learning},
language = {English},
month = {jun},
pages = {102074},
title = {{Machine learning based system for managing energy efficiency of public sector as an approach towards smart cities}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0268401219302968},
volume = {58},
year = {2021}
}
@article{Busuioc2021,
abstract = {Artificial intelligence (AI) algorithms govern in subtle yet fundamental
ways the way we live and are transforming our societies. The promise of
efficient, low-cost, or ``neutral'' solutions harnessing the potential
of big data has led public bodies to adopt algorithmic systems in the
provision of public services. As AI algorithms have permeated
high-stakes aspects of our public existence-from hiring and education
decisions to the governmental use of enforcement powers (policing) or
liberty-restricting decisions (bail and sentencing)-this necessarily
raises important accountability questions: What accountability
challenges do AI algorithmic systems bring with them, and how can we
safeguard accountability in algorithmic decision-making? Drawing on a
decidedly public administration perspective, and given the current
challenges that have thus far become manifest in the field, we
critically reflect on and map out in a conceptually guided manner the
implications of these systems, and the limitations they pose, for public
accountability.},
author = {Busuioc, Madalina},
doi = {10.1111/puar.13293},
file = {:C\:/Users/mauri/OneDrive/Referencias/Mendeley/2021 - Busuioc - Public Administration Review.pdf:pdf},
issn = {0033-3352},
journal = {Public Administration Review},
language = {English},
month = {sep},
number = {5},
pages = {825--836},
title = {{Accountable Artificial Intelligence: Holding Algorithms to Account}},
url = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13293},
volume = {81},
year = {2021}
}
