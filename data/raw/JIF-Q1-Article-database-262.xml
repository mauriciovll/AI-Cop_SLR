<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Scutella, Maryanne</author><author>Plewa, Carolin</author><author>Reaiche, Carmen</author></authors></contributors><titles><title>Virtual agents in the public service: examining citizens' value-in-use</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>73-88</pages><volume>26</volume><issue>1</issue><keywords><keyword>virtual agent; value-in-use; value co-creation; e-government</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/14719037.2022.2044504</electronic-resource-num><language>English</language><urls/><abstract>The importance of today's public sector delivering citizen-centric
services enabled by technology is well recognized. To deliver such
services, the public sector is turning to artificial intelligence, and
in particular virtual agents (VA). This research examines how citizens
gain value from interacting with VAs in a public sector setting. Through
empirical research, utilizing transcripts from citizens' interactions
with a VA, four dimensions of value-in-use were identified. This adds to
the theoretical body of knowledge on value co-creation in public service
settings and provides practical insights into how citizens use VAs and
possible avenues for future investment and improvements.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Dongkun</author><author>Peng, Jieyang</author><author>Tao, Xiaoming</author><author>Duan, Yiping</author></authors></contributors><titles><title>Boosting urban prediction tasks with domain-sharing knowledge via
meta-learning</title><secondary-title>INFORMATION FUSION</secondary-title></titles><periodical><full-title>INFORMATION FUSION</full-title></periodical><volume>107</volume><keywords><keyword>Data mining; Traffic prediction; Meta learning; Graph neural network</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.inffus.2024.102324</electronic-resource-num><language>English</language><urls/><abstract>Urban prediction tasks refer to predicting urban indicators ( e.g. ,
traffic, temperature, etc.) using urban big data, which is crucial for
understanding the urban patterns, and further benefits the urban public
administration. An empirical study indicates that there are correlated
patterns among urban prediction tasks from various domains, which
suggests the existence of domain -sharing knowledge. Aggregating such
domain -sharing knowledge would significantly benefit urban prediction
tasks. However, as a widely used learning paradigm for knowledge
aggregation, existing meta -learning methods, especially gradient -based
methods, can only work for singledomain tasks. To solve the problem, we
propose Cross -Domain Meta -Learning (CDML), a flexible framework for
aggregating domain -sharing knowledge from cross -domain urban
prediction tasks. Specifically, the core architecture of CDML is the
model fusion block that includes (1) meta -model, shared by cross
-domain tasks for capturing domain -sharing knowledge; (2) domain
-specific model, shared only by the same -domain tasks for preserving
domain -specific knowledge; and (3) knowledge fusion unit, for combining
both the domainsharing/specific knowledge for good generalization.
Moreover, we develop asynchronous meta -training and adaption strategy
strategies to further guarantee cross -domain generalization. The
extensive experimental results validate the effectiveness of the
proposed framework with the superior ability of boosting existing urban
prediction models, quick adaption, and the potential for simplifying
models.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gallego, Jorge</author><author>Rivero, Gonzalo</author><author>Martinez, Juan</author></authors></contributors><titles><title>Preventing rather than punishing: An early warning model of malfeasance
in public procurement</title><secondary-title>INTERNATIONAL JOURNAL OF FORECASTING</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF FORECASTING</full-title></periodical><pages>360-377</pages><volume>37</volume><issue>1</issue><keywords><keyword>Public procurement; Corruption; Inefficiency; Machine learning;
Forecasting</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijforecast.2020.06.006</electronic-resource-num><language>English</language><urls/><abstract>Is it possible to predict malfeasance in public procurement? With the
proliferation of e-procurement systems in the public sector,
anti-corruption agencies and watchdog organizations have access to
valuable sources of information with which to identify transactions that
are likely to become troublesome and why. In this article, we discuss
the promises and challenges of using machine learning models to predict
inefficiency and corruption in public procurement. We illustrate this
approach with a dataset with more than two million public procurement
contracts in Colombia. We trained machine learning models to predict
which of them will result in corruption investigations, a breach of
contract, or implementation inefficiencies. We then discuss how our
models can help practitioners better understand the drivers of
corruption and inefficiency in public procurement. Our approach will be
useful to governments interested in exploiting large administrative
datasets to improve the provision of public goods, and it highlights
some of the tradeoffs and challenges that they might face throughout
this process. (C) 2020 International Institute of Forecasters. Published
by Elsevier B.V. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Neumann, Oliver</author><author>Guirguis, Katharina</author><author>Steiner, Reto</author></authors></contributors><titles><title>Exploring artificial intelligence adoption in public organizations: a
comparative case study</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>114-141</pages><volume>26</volume><issue>1</issue><keywords><keyword>Artificial intelligence; AI; public organizations; public
administration; technology adoption; TOE framework</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/14719037.2022.2048685</electronic-resource-num><language>English</language><urls/><abstract>Despite the enormous potential of artificial intelligence (AI), many
public organizations struggle to adopt this technology. Simultaneously,
empirical research on what determines successful AI adoption in public
settings remains scarce. Using the technology organization environment
(TOE) framework, we address this gap with a comparative case study of
eight Swiss public organizations. Our findings suggest that the
importance of technological and organizational factors varies depending
on the organization's stage in the adoption process, whereas
environmental factors are generally less critical. Accordingly, this
study advances our theoretical understanding of the specificities of AI
adoption in public organizations throughout the different adoption
stages.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zekic-Susac, Marijana</author><author>Has, Adela</author><author>Knezevic, Marinela</author></authors></contributors><titles><title>Predicting energy cost of public buildings by artificial neural
networks, CART, and random forest</title><secondary-title>NEUROCOMPUTING</secondary-title></titles><periodical><full-title>NEUROCOMPUTING</full-title></periodical><pages>223-233</pages><volume>439</volume><keywords><keyword>Energy cost; Machine learning; Neural networks; Public building;
Regression trees; Variable reduction</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.neucom.2020.01.124</electronic-resource-num><language>English</language><urls/><abstract>The paper deals with modeling the cost of energy consumed in public
buildings by leveraging three machine learning methods: artificial
neural networks, CART, and random forest regression trees. Energy
consumption is one of the major issues in global and national policies,
therefore scientific efforts in creating prediction models of energy
consumption and cost are highly important. One of the largest energy
consumers in every state is its public sector, consisting of
educational, health, public administration, military, and other types of
public buildings. Recent technologies based on sensor networks and Big
data platforms enable collection of large amounts of data that could be
used to analyze energy consumption and cost. A real data from Croatian
public sector is used in this paper including a large number of
constructional, energetic, occupational, climate and other attributes.
The algorithms for data pre-processing and modeling by optimizing
parameters are suggested. Three strategies were tested: (1) with all
available variables, (2) with a filter-based variable selection, and (3)
with a wrapper-based variable selection which integrates Boruta
algorithm and random forest. Prediction models of energy cost are
created using two approaches: (a) comparative usage of artificial neural
networks and two types of regression trees, CART and random forest, and
(b) integration of RF-Boruta variable selection and machine learning
methods for prediction. A cross-validation procedure was used to
optimize the artificial neural network and regression tree topology, as
well to select the most appropriate activation function. Along with
creating a prediction model, the aim of the paper was also to extract
the relevant predictors of energy cost in public buildings which are
important in planning the construction or renovation of buildings. The
results have shown that the second approach which integrates machine
learning with Boruta method, where the random forest algorithm is used
for both variable reduction and prediction modeling, has produced a
higher accuracy of prediction than the individual usage of three machine
learning methods. Such findings confirm the potential of hybrid machine
learning methods which are suggested in previous research, but in favor
of random forest method over CART and artificial neural networks.
Regarding the variable selection, the model has extracted heating and
occupational data as the most important, followed by constructional,
cooling, electricity, and lighting attributes. The model could be
implemented in public buildings information systems and their IoT
networks within the concept of smart buildings and smart cities. ? 2021
Elsevier B.V. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Maragno, Giulia</author><author>Tangi, Luca</author><author>Gastaldi, Luca</author><author>Benedetti, Michele</author></authors></contributors><titles><title>Exploring the factors, affordances and constraints outlining the
implementation of Artificial Intelligence in public sector organizations</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>73</volume><keywords><keyword>Artificial Intelligence; Public Sector Organizations; TOE framework;
Technology Affordances and Constraints</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2023.102686</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) is viewed as having great potential for the
public sector to improve the management of internal activities and the
delivery of public services. However, realizing its potential depends on
the proper implementation of the technology, which is characterized by
unique factors, that afford or constrain its use. What these factors are
and how they affect AI implementation is still poorly understood, and
scholars call for studies to add empirical evidence to the existing
knowledge. This study relies on a case study methodology and, by
adopting an abductive approach, applies a double theoretical
perspective: the Technology-OrganizationEnvironment (TOE) framework and
the Technology Affordances and Constraints Theory (TACT). Drawing on
these combined lenses, we develop a conceptual framework that extends
previous studies by showing how AI implementation is the result of a
combination of contextual factors that are deeply interrelated and,
specifically, how AI-related factors bring new affordances and
constraints to the application domain.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sundberg, Leif</author><author>Holmstrom, Jonny</author></authors></contributors><titles><title>Fusing domain knowledge with machine learning: A public sector
perspective</title><secondary-title>JOURNAL OF STRATEGIC INFORMATION SYSTEMS</secondary-title></titles><periodical><full-title>JOURNAL OF STRATEGIC INFORMATION SYSTEMS</full-title></periodical><volume>33</volume><issue>3</issue><keywords><keyword>Knowledge production; Artificial Intelligence; Machine Learning; Natural
Language Processing; Public Sector</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.jsis.2024.101848</electronic-resource-num><language>English</language><urls/><abstract>Machine learning (ML) offers widely-recognized, but complex,
opportunities for both public and private sector organizations to
generate value from data. A key requirement is that organizations must
find ways to develop new knowledge by merging crucial `domain knowledge
` of experts in relevant fields with `machine knowledge `, i.e., data
that can be used to inform predictive models. In this paper, we argue
that understanding the process of generating such knowledge is essential
to strategically develop ML. In efforts to contribute to such
understanding, we examine the generation of new knowledge from domain
knowledge through ML via an exploratory study of two cases in the
Swedish public sector. The findings reveal the roles of three mechanisms
- dubbed consolidation, algorithmic mediation, and naturalization - in
tying domain knowledge to machine knowledge. The study contributes a
theory of knowledge production related to organizational use of ML, with
important implications for its strategic governance, particularly in the
public sector.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Alon-Barkat, Saar</author><author>Busuioc, Madalina</author></authors></contributors><titles><title>Human-AI Interactions in Public Sector Decision Making: ``Automation
Bias'' and ``Selective Adherence'' to Algorithmic Advice</title><secondary-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</full-title></periodical><pages>153-169</pages><volume>33</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1093/jopart/muac007</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence algorithms are increasingly adopted as
decisional aides by public bodies, with the promise of overcoming biases
of human decision-makers. At the same time, they may introduce new
biases in the human-algorithm interaction. Drawing on psychology and
public administration literatures, we investigate two key biases:
overreliance on algorithmic advice even in the face of ``warning
signals'' from other sources (automation bias), and selective adoption
of algorithmic advice when this corresponds to stereotypes (selective
adherence). We assess these via three experimental studies conducted in
the Netherlands: In study 1 (N = 605), we test automation bias by
exploring participants' adherence to an algorithmic prediction compared
to an equivalent human-expert prediction. We do not find evidence for
automation bias. In study 2 (N = 904), we replicate these findings, and
also test selective adherence. We find a stronger propensity for
adherence when the advice is aligned with group stereotypes, with no
significant differences between algorithmic and human-expert advice. In
study 3 (N = 1,345), we replicate our design with a sample of civil
servants. This study was conducted shortly after a major scandal
involving public authorities' reliance on an algorithm with
discriminatory outcomes (the ``childcare benefits scandal''). The
scandal is itself illustrative of our theory and patterns diagnosed
empirically in our experiment, yet in our study 3, while supporting our
prior findings as to automation bias, we do not find patterns of
selective adherence. We suggest this is driven by bureaucrats' enhanced
awareness of discrimination and algorithmic biases in the aftermath of
the scandal. We discuss the implications of our findings for public
sector decision making in the age of automation. Overall, our study
speaks to potential negative effects of automation of the administrative
state for already vulnerable and disadvantaged citizens.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hjaltalin, Illugi Torfason</author><author>Sigurdarson, Hallur Thor</author></authors></contributors><titles><title>The strategic use of AI in the public sector: A public values analysis
of national AI strategies</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Artificial intelligence; Public value; E -government; Strategy;
Technology application; National strategy; Discourse analysis</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101914</electronic-resource-num><language>English</language><urls/><abstract>Governments worldwide are strategically investing in artificial
intelligence (AI) to improve public services and streamline internal
operations. In this context, national AI strategies play a pivotal role.
This study uses combined qualitative research methods analyzing 28
national AI strategies (i.e., the texts). Our aim is to delve into how
governments define and position AI applications within the public
sector. Specifically, the study explores how the texts convey AI's
application in this context employing a public value(s) perspective. Its
discursive analytical approach coupled with a comprehensive take on
public value theory (Moore, 1995) engenders novel insights into national
discourses on AI in the public sector. Against this background we draw
on public administration and policy research in our analysis of three
dominant discourses that we identify in the texts, i.e. empowerment
through information, enhanced administrative practices, and improved
service delivery. We find that the discourses involve different
positions in relation to governments' use of AI and depend on particular
actors and types of public service. Commonly, they concern government
objectives to tackle critical societal issues through AI, such as in the
areas of health and social care and employment. In particular, the
discourse of enhanced administrative practices commonly positioned AI as
a tool to optimize internal processes, resource allocation, and
organizational management. On the other hand, the discourse of improved
service delivery similarly placed public services front and center,
while the discourse of empowerment through information framed AI as
being able to enhance citizens' service experiences. Interestingly,
discourses emphasizing the policymaking function, i.e., AI applied to
the development of public policy,-receives limited attention. Our
findings underscore strategic prioritizations. While efficiency and
service delivery dominate the discourse, citizen engagement remains
underemphasized. We argue that policymakers must strike a balance,
ensuring AI aligns with broader societal outcomes while addressing
democratic imperatives.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wanckel, Camilla</author></authors></contributors><titles><title>An ounce of prevention is worth a pound of cure - Building capacities
for the use of big data algorithm systems (BDAS) in early crisis
detection</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>4</issue><keywords><keyword>Big data algorithm system (BDAS); Artificial intelligence (AI); Early
crisis detection; Policymaking Policy analytical capacity (PAC); Central
government organizations; Neo-institutionalism</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101705</electronic-resource-num><language>English</language><urls/><abstract>Public sector organizations at all levels of government increasingly
rely on Big Data Algorithmic Systems (BDAS) to support decision-making
along the entire policy cycle. But while our knowledge on the use of big
data continues to grow for government agencies implementing and
delivering public services, empirical research on applications for
anticipatory policy design is still in its infancy. Based on the concept
of policy analytical capacity (PAC), this case study examines the
application of BDAS for early crisis detection within the German Federal
Government-that is, the German Federal Foreign Office (FFO) and the
Federal Ministry of Defence (FMoD). It uses the nested model of PAC to
reflect on systemic, organizational, and individual capacity-building
from a neoinstitutional perspective and allow for the consideration of
embedded institutional contexts. Results from semi-structured interviews
indicate that governments seeking to exploit BDAS in policymaking depend
on their institutional environment (e.g., through research and data
governance infrastructure). However, specific capacity-building
strategies may differ according to the departments' institutional
framework, with the FMoD relying heavily on subordinate agencies and the
FFO creating network-like structures with external researchers.
Government capacity-building at the individual and organizational level
is similarly affected by long-established institutional structures,
roles, and practices within the organization and beyond, making it
important to analyze these three levels simultaneously instead of
separately.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fernandez-Sande, Manuel</author><author>Rodriguez-Pallares, Miriam</author></authors></contributors><titles><title>Big data in radio broadcasting companies: applications and evolution</title><secondary-title>PROFESIONAL DE LA INFORMACION</secondary-title></titles><periodical><full-title>PROFESIONAL DE LA INFORMACION</full-title></periodical><volume>31</volume><issue>5</issue><keywords><keyword>Radio; Radio broadcasting companies; Big data; Business intelligence;
Media management; Data management; Audio platforms; Podcasting;
Podcasts; Audio communication; Prisa Radio; Atresmedia Radio; COPE
Group; RNE</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.3145/epi.2022.sep.16</electronic-resource-num><language>English</language><urls/><abstract>The radio broadcasting industry is facing a process of profound digital
transformation throughout which, over the last 20 years, the strategies
to preserve the traditional business model have prevailed. The
consolidation of platformization and datafication in the economic
management of the media requires adaptation of the radio broadcasting
sector's structures, management models, and corporate culture. Through
an exhaustive bibliographic review, nonparticipant observation, and
in-depth interviews conducted with heads of the systems, sales and
marketing, content, and digital and innovation departments of the three
leading Spanish companies (Prisa Radio, Grupo COPE, and Atresmedia
Radio) and the state public broadcaster (RNE), we seek to identify the
functional areas of the radio broadcasting company in which big data
(BD) has a greater potential for application, trying to establish the
differences in its utilization in the analogue and digital business
model. The results revealed that the degree of BD implementation in the
Spanish radio broadcasting industry was significantly different between
the private sector -which within the last 2 or 3 years has begun to
introduce, very incipiently, big data management, applied primarily to
the analysis of digital audiences, these users' consumer behavior, and
business management- and the public sector, which so far has not adopted
these technologies on a systematic basis.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gesk, Tanja Sophie</author><author>Leyer, Michael</author></authors></contributors><titles><title>Artificial intelligence in public services: When and why citizens accept
its usage</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Artificial intelligence; Public services; Acceptance; Behavioral
reasoning theory</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101704</electronic-resource-num><language>English</language><urls/><abstract>Interest in implementing artificial intelligence (AI)-based software in
the public sector is growing. First implementations and research in
individual public services have already been carried out; however, a
better understanding of citizens' acceptance of this technology is
missing in the public sector, as insights from the private sector cannot
be transferred directly. For this purpose, we conduct policy-capturing
experiments to analyze AI's acceptance in six representative scenarios.
Based on behavioral reasoning theory, we gather evidence from 329
participants. The results show that AI solutions in general public
services are preferred over those provided by humans, but specific
services are still a human domain. Further analyses show that the major
drivers toward acceptance are the reasons against AI. The results
contribute to understanding of when and why AI is accepted in public
services. Public administration can use the results to identify AI-based
software to invest in and communicate their usage to perceive such
investments' high acceptance rates.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Enriquez-Sarano, Louis</author></authors></contributors><titles><title>DATA-RICH AND KNOWLEDGE-POOR: HOW PRIVACY LAW PRIVATIZED MEDICAL DATA
AND WHAT TO DO ABOUT IT</title><secondary-title>COLUMBIA LAW REVIEW</secondary-title></titles><periodical><full-title>COLUMBIA LAW REVIEW</full-title></periodical><pages>2319-2357</pages><volume>120</volume><issue>8</issue><keywords/><dates><year>2020</year></dates><language>English</language><urls/><abstract>The Health Information Technology for Economic and Clinical Health Act
(HITECH) successfully encouraged widespread adoption of electronic
health records (EHR). Their suitability for ``big data'' analysis make
EHR data immensely valuable for secondary research, which could help
scientists develop new drugs, medical devices, and public-health
knowledge. Thus far, EHR data have not been widely available to academic
medical scientists in quantities sufficient to support big data
analysis. Instead, the data are aggregated, analyzed, and sold by
insurance companies, EHR vendors, and other medical informatics firms.
This Note argues that the advent of the EHR data market is a direct
result of HITECH's interaction with the Health Insurance Portability and
Accountability Act of 1996 (HIPAA) (together, the ``Privacy Regime'').
The Privacy Regime (1) establishes the necessary preconditions for the
EHR data market; (2) funnels EHR data towards a few large firms; and (3)
prevents others, including academic scientists, from acquiring data in
similarly large quantities.
The Privacy Regime has radically changed medical research regulation.
Traditional clinical trials and retrospective studies are governed by
the familiar safeguards of medical ethics including IRB review, peer
review, and publication. But under the Privacy Regime, private-sector
EHR-based studies are not subject to any ethical review. This result
subverts the fundamental principles of medical ethics and inhibits
socially valuable public-sector research. This Note proposes reforming
the Privacy Regime to subject all medical research to ethical review and
to incentivize private firms to share EHR data with academic
researchers.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Corrales-Garay, Diego</author><author>Ortiz-de-Urbina-Criado, Marta</author><author>Mora-Valentin, Eva-Maria</author></authors></contributors><titles><title>Knowledge areas, themes and future research on open data: A co-word
analysis</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><pages>77-87</pages><volume>36</volume><issue>1</issue><keywords><keyword>Open data; Bibliometric analysis; Co-word analysis; Science map;
Knowledge areas; Most-studied themes; Future trends</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.10.008</electronic-resource-num><language>English</language><urls/><abstract>This paper aims to contribute to a better understanding of the
literature on open data in three ways. The first is to develop a
descriptive analysis of journals and authors to identify the knowledge
areas in which open data are applied. The second is to analyse the
conceptual structure of the field using a bibliometric technique. The
co-word analysis enabled us to create a map of the main themes that have
been studied, identifying their importance and relevance. These themes
were analysed and grouped. The third is to propose future research
trends. According to our results, the main knowledge areas are
Engineering, Health, Public Administration, Management and Education.
The main themes are big data, open-linked data and data reuse. Finally,
several research questions are proposed according to knowledge area and
theme.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Changlin</author><author>Teo, Thompson S H</author><author>Janssen, Marijn</author></authors></contributors><titles><title>Public and private value creation using artificial intelligence: An
empirical study of AI voice robot users in Chinese public sector</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>61</volume><keywords><keyword>Value creation; Public value; Private value; Artificial intelligence;
Voice robot</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2021.102401</electronic-resource-num><language>English</language><urls/><abstract>Despite significant theoretical and empirical attention on public value
creation in the public sector, the relationship between artificial
intelligence (AI) use and value creation from the citizen perspective
remains poorly understood. We ground our study in Moore's public value
management to examine the relationship between AI use and value
creation. We conceptually categorize public service value into public
value and private value. We use procedural justice and trust in
government as indicators of public value and, based on motivation
theory, we use perceived usefulness and perceived enjoyment as
indicators of private value. A field survey of 492 AI voice robot users
in China was conducted to test our model. The results indicated that the
effective use of AI voice robots was significantly associated with
private value and procedural justice. However, the relationship between
the effective use of AI and trust in government was not found to be
significant. Surprisingly, the respondents indicated that private value
had a greater effect on overall value creation than public value. This
contrasts with the common idea that value creation from the government
perspective suggests that social objectives requiring public value are
more important to citizens. The results also show that gender and
citizens with different experiences show different AI usage behaviors.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Orgeira-Crespo, Pedro</author><author>Miguez-Alvarez, Carla</author><author>Cuevas-Alonso, Miguel</author><author>Doval-Ruiz, Maria Isabel</author></authors></contributors><titles><title>Decision Algorithm for the Automatic Determination of the Use of
Non-Inclusive Terms in Academic Texts</title><secondary-title>PUBLICATIONS</secondary-title></titles><periodical><full-title>PUBLICATIONS</full-title></periodical><volume>8</volume><issue>3</issue><keywords><keyword>inclusive language; Spanish language; natural language processing;
classification algorithm; machine learning</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.3390/publications8030041</electronic-resource-num><language>English</language><urls/><abstract>The use of inclusive language, among many other gender equality
initiatives in society, has garnered great attention in recent years.
Gender equality offices in universities and public administration cannot
cope with the task of manually checking the use of non-inclusive
language in the documentation that those institutions generate. In this
research, an automated solution for the detection of non-inclusive uses
of the Spanish language in doctoral theses generated in Spanish
universities is introduced using machine learning techniques. A large
dataset has been used to train, validate, and analyze the use of
inclusive language; the result is an algorithm that detects, within any
Spanish text document, non-inclusive uses of the language with error,
false positive, and false negative ratios slightly over 10%, and
precision, recall, and F-measure percentages over 86%. Results also
show the evolution with time of the ratio of non-inclusive usages per
document, having a pronounced reduction in the last years under study.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aoki, Naomi</author></authors></contributors><titles><title>An experimental study of public trust in AI chatbots in the public
sector</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>37</volume><issue>4</issue><keywords><keyword>Artificial intelligence; Chatbot; Public trust; Human-machine
relationship; Public service; Street-level bureaucracy; Administrative
discretion</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.giq.2020.101490</electronic-resource-num><language>English</language><urls/><abstract>This study investigates the public's initial trust in so-called
``artificial intelligence'' (AI) chatbots about to be introduced into
use in the public sector. While the societal impacts of AI are widely
speculated about, empirical testing remains rare. To narrow this gap,
this study builds on theories of operators' trust in machines in
industrial settings and proposes that initial public trust in chatbot
responses depends on (i) the area of enquiry, since expectations about a
chatbot's performance vary with the topic, and (ii) the purposes that
governments communicate to the public for introducing the use of
chatbots. Analyses based on an experimental online survey in Japan
generated results indicating that, if a government were to announce its
intention to use ``AI'' chatbots to answer public enquiries, the
public's initial trust in their responses would be lower in the area of
parental support than in the area of waste separation, with a moderate
effect size. Communicating purposes that would directly benefit
citizens, such as achieving uniformity in response quality and
timeliness in responding, would enhance public trust in chatbots.
Although the effect sizes are small, communicating these purposes might
be still worthwhile, as it would be an inexpensive measure for a
government to take.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Criado, J Ignacio</author><author>Sandoval-Almazan, Rodrigo</author><author>Gil-Garcia, J.
Ramon</author></authors></contributors><titles><title>Artificial intelligence and public administration: Understanding actors,
governance, and policy from micro, meso, and macro perspectives</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>;
analytical framework</keyword><keyword>Artificial intelligence; public administration; public policy; theory</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1177/09520767241272921</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has become one of the most prominent topics
in public policy and administration studies over the last years. Despite
the attention to AI in this field isn't entirely new, the universality
of these group of technologies has radically increased the attention of
scholars around the globe. This expansion of AI in the public sector
entails the exploration of renovated foundations of analysis, not only
to understand the novelty of these technologies, but also to connect
these processes of adoption and implementation with other debates in
public policy and administration. To do so, in this article we debate
the need of an analytical framework of AI in the public sector based on
the three levels of public administration: macro, meso, and micro. Also,
we review the state-of-the-art in the field using the articles presented
in the special issue on Artificial Intelligence and Public
Administration: Actors, Governance, and Policy. Form here, we propose
studying AI using a combination of macro, meso, and micro levels of
public administration. We assume this will help to broadly apprehend how
and why people, policies, and institutions interrelate with AI in public
sector settings, and which effects can be expected from these processes
in public administration.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rosecky, Martin</author><author>Somplak, Radovan</author><author>Slavik, Jan</author><author>Kalina Jiri
and Bulkova, Gabriela</author><author>Bednar, Josef</author></authors></contributors><titles><title>Predictive modelling as a tool for effective municipal waste management
policy at different territorial levels</title><secondary-title>JOURNAL OF ENVIRONMENTAL MANAGEMENT</secondary-title></titles><periodical><full-title>JOURNAL OF ENVIRONMENTAL MANAGEMENT</full-title></periodical><volume>291</volume><keywords><keyword>Municipal waste generation; Territorial levels; Regression modelling;
Machine learning; Socio-economic factors; Public policy</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.jenvman.2021.112584</electronic-resource-num><language>English</language><urls/><abstract>Nowadays, the European municipal waste management policy based on the
circular economy paradigm demands the closing of material and financial
loops at all territorial levels of public administration. The effective
planning of treatment capacities (especially sorting plants, recycling,
and energy recovery facilities) and municipal waste management policy
requires an accurate prognosis of municipal waste generation, and
therefore, the knowledge of behavioral, socio-economic, and demographic
factors influencing the waste management (and recycling) behavior of
households, and other municipal waste producers. To enable public bodies
at different territorial levels to undertake an effective action
resulting in circular economy we evaluated various factors influencing
the generation of municipal waste fractions at regional, micro-regional
and municipal level in the Czech Republic. Principal components were
used as input for traditional models (multivariable linear regression,
generalized linear model) as well as tree-based machine learning models
(regression trees, random forest, gradient boosted regression trees).
Study results suggest that the linear regression model usually offers a
good trade-off between model accuracy and interpretability. When the
most important goal of the prediction is supposed to be accuracy, the
random forest is generally the best choice. The quality of developed
models depends mostly on the chosen territorial level and municipal
waste fraction. The performance of these models deteriorates
significantly for lower territorial levels because of worse data quality
and bigger variability. Only the age structure seems to be important
across territorial levels and municipal waste fractions. Nevertheless,
also other factors are of high significance in explaining the generation
of municipal waste fractions at different territorial levels (e.g.
number of economic subjects, expenditures, population density and the
level of education). Therefore, there is not one single effective public
policy dealing with circular economy strategy that fits all territorial
levels. Public representatives should focus on policies effective at
specific territorial level. However, performance of the models is poor
for lower territorial levels (municipality and micro-regions). Thus,
results for municipalities and microregions are weak and should be
treated as such.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Doring, Matthias</author><author>Mikkelsen, Kim Sass</author><author>Madsen, Jonas Krogh</author><author>Haug, Kristian Bloch</author></authors></contributors><titles><title>Creating a workforce of fatigued cynics? A randomized controlled trial
of implementing an algorithmic decision-making support tool</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Cynicism towards change; Change fatigue; Algorithmic decision -support
tool; Randomized controlled trial</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101911</electronic-resource-num><language>English</language><urls/><abstract>In recent decades, public service provision has become increasingly
digitalized. However, while digitalization and artificial intelligence
holds many promises, there is surprisingly little causal evidence on how
it affects the employees who provide such services in the frontline.
Based on cognitive and social psychological theories, we argue that IT
projects can increase employees' cynicism towards change and change
fatigue. In liaison with a Danish unemployment insurance fund, we test
our hypotheses in a pre-registered randomized controlled trial that
introduced an algorithmic decision-making support tool to underpin the
counselling of newly unemployed clients. We do not find evidence that
implementation of this tool resulted in negative employee outcomes.
However, exploratory analyses indicate that this conclusion may mask
smaller or heterogenous effects depending on employees' years of service
with the insurance fund. We end the paper by discussing the implications
of organizational change in the public sector.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bodo, Balazs</author><author>Janssen, Heleen</author></authors></contributors><titles><title>Maintaining trust in a technologized public sector</title><secondary-title>POLICY AND SOCIETY</secondary-title></titles><periodical><full-title>POLICY AND SOCIETY</full-title></periodical><pages>414-429</pages><volume>41</volume><issue>3</issue><keywords><keyword>trust; public policy; emerging technologies; blockchain; risk-based
policy</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1093/polsoc/puac019</electronic-resource-num><language>English</language><urls/><abstract>Emerging technologies permeate and potentially disrupt a wide spectrum
of our social, economic, and political relations. Various state
institutions, including education, law enforcement, and healthcare,
increasingly rely on technical components, such as automated
decision-making systems, e-government systems, and other digital tools
to provide cheap, efficient public services, and supposedly fair,
transparent, disinterested, and accountable public administration. The
increased interest in various blockchain-based solutions from central
bank digital currencies, via tokenized educational credentials, and
distributed ledger-based land registries to self-sovereign identities is
the latest, still mostly unwritten chapter in a long history of
standardized, objectified, automated, technocratic, and technologized
public administration. The rapid, (often) unplanned, and uncontrolled
technologization of public services (as happened in the hasty adoption
of distance-learning and teleconferencing systems during Corona Virus
Disease (COVID) lockdowns) raises complex questions about the use of
novel technological components, which may or may not be ultimately
adequate for the task for which they are used. The question whether we
can trust the technical infrastructures the public sector uses when
providing public services is a central concern in an age where trust in
government is declining: If the government's artificial intelligence
system that detects welfare fraud fails, the public's confidence in the
government is ultimately hit. In this paper, we provide a critical
assessment of how the use of potentially untrustworthy (private)
technological systems including blockchain-based systems in the public
sector may affect trust in government. We then propose several policy
options to protect the trust in government even if some of their
technological components prove fundamentally untrustworthy.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Frost, Neli</author></authors></contributors><titles><title>The Impoverished Publicness of Algorithmic Decision Making</title><secondary-title>OXFORD JOURNAL OF LEGAL STUDIES</secondary-title></titles><periodical><full-title>OXFORD JOURNAL OF LEGAL STUDIES</full-title></periodical><keywords><keyword>public decision making; artificial intelligence; machine learning;
public administration; administrative law; law &amp; technology</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1093/ojls/gqae027</electronic-resource-num><language>English</language><urls/><abstract>The increasing use of machine learning (ML) in public administration
requires that we think carefully about the political and legal
constraints imposed on public decision making. These developments
confront us with the following interrelated questions: can algorithmic
public decisions be truly `public'? And, to what extent does the use of
ML models compromise the `publicness' of such decisions? This article is
part of a broader inquiry into the myriad ways in which digital and AI
technologies transform the fabric of our democratic existence by
mutating the `public'. Focusing on the site of public administration,
the article develops a conception of publicness that is grounded in a
view of public administrations as communities of practice. These
communities operate through dialogical, critical and synergetic
interactions that allow them to track-as faithfully as possible-the
public's heterogeneous view of its interests, and reify these interests
in decision making. Building on this theorisation, the article suggests
that the use of ML models in public decision making inevitably generates
an impoverished publicness, and thus undermines the potential of public
administrations to operate as a locus of democratic construction. The
article thus advocates for a reconsideration of the ways in which
administrative law problematises and addresses the harms of algorithmic
decision making.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van Noordt, Colin</author><author>Misuraca, Gianluca</author></authors></contributors><titles><title>Artificial intelligence for the public sector: results of landscaping
the use of AI in government across the European Union</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Artificial intelligence; Public administration; Public services; Policy
making; Public sector management</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101714</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence is increasingly being used by public sector
organisations. Previous research highlighted that the use of AI
technologies in government could improve policy making processes, public
service delivery and the internal management of public administrations.
In this article, we explore to which extent the use of AI in the public
sector impacts these core governance functions. Findings from the review
of a sample of 250 cases across the European Union, show that AI is used
mainly to support improving public service delivery, followed by
enhancing internal management and only in a limited number assist
directly or indirectly policy decision-making. The analysis suggests
that different types of AI technologies and applications are used in
different governance functions, highlighting the need to further
in-depth investigation to better understand the role and impact of use
in what is being defined the governance ``of, with and by AI''.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dunleavy, Patrick</author><author>Margetts, Helen</author></authors></contributors><titles><title>Data science, artificial intelligence and the third wave of digital era
governance</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>administrative organization and structures; governance; new public
management; policy-making and public management; artificial
intelligence; data science</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231198737</electronic-resource-num><language>English</language><urls/><abstract>This article examines the model of digital era governance (DEG) in the
light of the latest-wave of data-driven technologies, such as data
science methodologies and artificial intelligence (labelled here DSAI).
It identifies four key top-level macro-themes through which digital
changes in response to these developments may be investigated. First,
the capability to store and analyse large quantities of digital data
obviates the need for data `compression' that characterises
Weberian-model bureaucracies, and facilitates data de-compression in
data-intensive information regimes, where the capabilities of public
agencies and civil society are both enhanced. Second, the increasing
capability of robotic devices have expanded the range of tasks that
machines extending or substituting workers' capabilities can perform,
with implications for a reshaping of state organisation. Third, DSAI
technologies allow new options for partitioning state functions in ways
that can maximise organisational productivity, in an `intelligent
centre, devolved delivery' model within vertical policy sectors. Fourth,
within each tier of government, DSAI technologies offer new
possibilities for `administrative holism' - the horizontal allocation of
power and functions between organisations, through state integration,
common capacity and needs-based joining-up of services. Together, these
four themes comprise a third wave of DEG changes, suggesting important
administrative choices to be made regarding information regimes, state
organisation, functional allocation and outsourcing arrangements, as
well as a long-term research agenda for public administration, requiring
extensive and detailed analysis.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Robles, Pedro</author><author>Mallinson, Daniel J</author></authors></contributors><titles><title>Artificial intelligence technology, public trust, and effective
governance</title><secondary-title>REVIEW OF POLICY RESEARCH</secondary-title></titles><periodical><full-title>REVIEW OF POLICY RESEARCH</full-title></periodical><keywords><keyword>AI governance; AI policy; artificial intelligence framework; information
technology governance; public sector; public values</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1111/ropr.12555</electronic-resource-num><language>English</language><urls/><abstract>Advancement in information technology continues to evolve especially in
the field of artificial intelligence (AI). Research studies have been
conducted to evaluate the perceptions of Americans on the development
and utilization of AI technology and if it is appropriate to use AI in
public administrative duties. The research revealed that society is
fragmented regarding the acceptance of AI, and whether AI decisions
could have long-term effects on the labor industry, legal system, and
national security. The 2018 AI Public Opinion Survey revealed
significant concerns among the American public regarding AI, yet also a
recognition of its promise. The goal of this article is to further
develop a governance framework for AI that considers the importance of
public trust in AI policy. First, it discusses the necessity of public
trust for the effective governance of emergent technology. Then, it
evaluates public opinion on AI technology that specifically pertains to
governance. The article concludes with a discussion of why public trust
is central to good AI governance.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cho, Ji Yeon</author><author>Lee, Bong Gyou</author></authors></contributors><titles><title>Creating value using public big data: comparison of driving factors from
the provider's perspective</title><secondary-title>INFORMATION TECHNOLOGY &amp; PEOPLE</secondary-title></titles><periodical><full-title>INFORMATION TECHNOLOGY &amp; PEOPLE</full-title></periodical><pages>467-493</pages><volume>35</volume><issue>2</issue><keywords><keyword>Big data; Open government data; Data value; Public sector; Analytic
hierarchy process; Analytic network process</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1108/ITP-04-2019-0169</electronic-resource-num><language>English</language><urls/><abstract>Purpose The revitalization of big data has gained attention in the
public sector. However, such open government data (OGD) is facing major
challenges with respect to data quality and limited use. To solve this
problem, this study analyzes the factors driving the use of OGD from the
perspective of data providers in the public sector.
Design/methodology/approach Using the analytic hierarchy process and
analytic network process methodologies, the importance of the factors
driving the use of big data in the public sector was ranked. In
addition, the different characteristics of tasks among the departments
in a public agency were compared based on expert interviews. Findings
The factors driving OGD use are not only political environment or the
technological environment. The importance of the institutional culture
within the organization increases with the motivation of the data
provider. The priorities of the OGD factors also depend on the
objectives of the department involved. Originality/value This study
provides implications for improving the publication of open data by
analyzing the priorities of the factors driving its use from the
perspective of big data providers. It focuses on different perceptions
of the factors valued by public officials in charge of data in
institutions. The results suggest the need to explore officials'
perceptions of value creation in big data fields.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nitzberg, Mark</author><author>Zysman, John</author></authors></contributors><titles><title>Algorithms, data, and platforms: the diverse challenges of governing AI</title><secondary-title>JOURNAL OF EUROPEAN PUBLIC POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF EUROPEAN PUBLIC POLICY</full-title></periodical><pages>1753-1778</pages><volume>29</volume><issue>11, SI</issue><keywords><keyword>Artificial intelligence; AI governance; AI regulation; digital platform;
general purpose of technology; global digital governance and regulation</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1080/13501763.2022.2096668</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) poses a set of interwoven challenges. A new
general purpose technology likened to steam power or electricity, AI
must first be clearly defined before considering its global governance.
In this context, a useful definition is technology that uses advanced
computation to perform at human cognitive capacity in some task area.
Like electricity, AI cannot be governed in isolation, but in the context
of a broader digital technology toolbox. Establishing national and
community priorities on how to reap AI's benefits, while managing its
social and economic risks, will be an evolving debate. A fundamental
driver of the development and deployment of AI tools, of the algorithms
and data, are the dominant Digital Platform Firms (DPFs). Unless
specifically regulated, DPF's set de facto rules for use of data and
algorithms. That can shift the borderline between public and private,
and result in priorities that differ from those of the public sector or
civil society. Governance of AI and the toolbox is a critical component
of national success in the coming decades, as governments recognize
opportunities and geopolitical risks posed by the suite of technologies.
However, AI pries open a Pandora's box of questions that sweep across
the economy and society engaging diverse communities. Rather than strive
towards global agreement on a single set of market and social rules, one
must consider how to pursue objectives of interoperability amongst
nations with quite different political economies. Even such limited
agreements are complicated following the Russian invasion of Ukraine.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Straub, Vincent J</author><author>Morgan, Deborah</author><author>Bright, Jonathan</author><author>Margetts, Helen</author></authors></contributors><titles><title>Artificial intelligence in government: Concepts, standards, and a
unified framework</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>40</volume><issue>4</issue><keywords><keyword>Government; Public administration; Artificial intelligence; Machine
learning; Review; Typology; Standards</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.giq.2023.101881</electronic-resource-num><language>English</language><urls/><abstract>Recent advances in artificial intelligence (AI), especially in
generative language modelling, hold the promise of transforming
government. Given the advanced capabilities of new AI systems, it is
critical that these are embedded using standard operational procedures,
clear epistemic criteria, and behave in alignment with the normative
expectations of society. Scholars in multiple domains have subsequently
begun to conceptualize the different forms that AI applications may
take, highlighting both their potential benefits and pitfalls. However,
the literature remains fragmented, with researchers in social science
disciplines like public administration and political science, and the
fast-moving fields of AI, ML, and robotics, all developing concepts in
relative isolation. Although there are calls to formalize the emerging
study of AI in government, a balanced account that captures the full
depth of theoretical perspectives needed to understand the consequences
of embedding AI into a public sector context is lacking. Here, we unify
efforts across social and technical disciplines by first conducting an
integrative literature review to identify and cluster 69 key terms that
frequently co-occur in the multidisciplinary study of AI. We then build
on the results of this bibliometric analysis to propose three new
multifaceted concepts for understanding and analysing AI-based systems
for government (AI-GOV) in a more unified way: (1) operational fitness,
(2) epistemic alignment, and (3) normative divergence. Finally, we put
these concepts to work by using them as dimensions in a conceptual
typology of AI-GOV and connecting each with emerging AI technical
measurement standards to encourage operationalization, foster
cross-disciplinary dialogue, and stimulate debate among those aiming to
rethink government with AI.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kuziemski, Maciej</author><author>Misuraca, Gianluca</author></authors></contributors><titles><title>AI governance in the public sector: Three tales from the frontiers of
automated decision-making in democratic settings</title><secondary-title>TELECOMMUNICATIONS POLICY</secondary-title></titles><periodical><full-title>TELECOMMUNICATIONS POLICY</full-title></periodical><volume>44</volume><issue>6</issue><keywords><keyword>Artificial intelligence; Public sector innovation; Automated decision
making; Algorithmic accountability</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.telpol.2020.101976</electronic-resource-num><language>English</language><urls/><abstract>The rush to understand new socio-economic contexts created by the wide
adoption of AI is justified by its far-ranging consequences, spanning
almost every walk of life. Yet, the public sector's predicament is a
tragic double bind: its obligations to protect citizens from potential
algorithmic harms are at odds with the temptation to increase its own
efficiency - or in other words - to govern algorithms, while governing
by algorithms. Whether such dual role is even possible, has been a
matter of debate, the challenge stemming from algorithms' intrinsic
properties, that make them distinct from other digital solutions, long
embraced by the governments, create externalities that rule-based
programming lacks. As the pressures to deploy automated decision making
systems in the public sector become prevalent, this paper aims to
examine how the use of AI in the public sector in relation to existing
data governance regimes and national regulatory practices can be
intensifying existing power asymmetries. To this end, investigating the
legal and policy instruments associated with the use of AI for
strenghtening the immigration process control system in Canada;
``optimising'' the employment services'' in Poland, and
personalising the digital service experience in Finland, the paper
advocates for the need of a common framework to evaluate the potential
impact of the use of AI in the public sector. In this regard, it
discusses the specific effects of automated decision support systems on
public services and the growing expectations for governments to play a
more prevalent role in the digital society and to ensure that the
potential of technology is harnessed, while negative effects are
controlled and possibly avoided. This is of particular importance in
light of the current COVID-19 emergency crisis where AI and the
underpinning regulatory framework of data ecosystems, have become
crucial policy issues as more and more innovations are based on large
scale data collections from digital devices, and the real-time
accessibility of information and services, contact and relationships
between institutions and citizens could strengthen - or undermine -
trust in governance systems and democracy.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Newman, Joshua</author><author>Mintrom, Michael</author></authors></contributors><titles><title>Mapping the discourse on evidence-based policy, artificial intelligence,
and the ethical practice of policy analysis</title><secondary-title>JOURNAL OF EUROPEAN PUBLIC POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF EUROPEAN PUBLIC POLICY</full-title></periodical><pages>1839-1859</pages><volume>30</volume><issue>9</issue><keywords><keyword>Policy analysis; evidence-based policy; artificial intelligence; public
service delivery; frame reflection; ethics</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/13501763.2023.2193223</electronic-resource-num><language>English</language><urls/><abstract>Scholarship on evidence-based policy, a subset of the policy analysis
literature, largely assumes information is produced and consumed by
humans. However, due to the expansion of artificial intelligence in the
public sector, debates no longer capture the full range concerns. Here,
we derive a typology of arguments on evidence-based policy that performs
two functions: taken separately, the categories serve as directions in
which debates may proceed, in light of advances in technology; taken
together, the categories act as a set of frames through which the use of
evidence in policy making might be understood. Using a case of welfare
fraud detection in the Netherlands, we show how the acknowledgement of
divergent frames can enable a holistic analysis of evidence use in
policy making that considers the ethical issues inherent in automated
data processing. We argue that such an analysis will enhance the
real-world relevance of the evidence-based policy paradigm.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Asatiani, Aleksandre</author><author>Malo, Pekka</author><author>Nagbol, Per Radberg</author><author>Penttinen, Esko</author><author>Rinta-Kahila, Tapani</author><author>Salovaara, Antti</author></authors></contributors><titles><title>Sociotechnical Envelopment of Artificial Intelligence: An Approach to
Organizational Deployment of Inscrutable Artificial Intelligence Systems</title><secondary-title>JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS</secondary-title></titles><periodical><full-title>JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS</full-title></periodical><pages>325-352</pages><volume>22</volume><issue>2</issue><keywords><keyword>Artificial Intelligence; Explainable AI; XAI; Envelopment;
Sociotechnical Systems; Machine Learning; Public Sector</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.17705/1jais.00664</electronic-resource-num><language>English</language><urls/><abstract>The paper presents an approach for implementing inscrutable (i.e.,
nonexplainable) artificial intelligence (AI) such as neural networks in
an accountable and safe manner in organizational settings. Drawing on an
exploratory case study and the recently proposed concept of envelopment,
it describes a case of an organization successfully ``enveloping'' its
AI solutions to balance the performance benefits of flexible AI models
with the risks that inscrutable models can entail. The authors present
several envelopment methods-establishing clear boundaries within which
the AI is to interact with its surroundings, choosing and curating the
training data well, and appropriately managing input and output
sources-alongside their influence on the choice of AI models within the
organization. This work makes two key contributions: It introduces the
concept of sociotechnical envelopment by demonstrating the ways in which
an organization's successful AI envelopment depends on the interaction
of social and technical factors, thus extending the literature's focus
beyond mere technical issues. Secondly, the empirical examples
illustrate how operationalizing a sociotechnical envelopment enables an
organization to manage the trade-off between low explainability and high
performance presented by inscrutable models. These contributions pave
the way for more responsible, accountable AI implementations in
organizations, whereby humans can gain better control of even
inscrutable machine-learning models.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Go, Heounmo</author><author>Park, Sanghyun</author></authors></contributors><titles><title>A study on deep learning model based on global-local structure for crowd
flow prediction</title><secondary-title>SCIENTIFIC REPORTS</secondary-title></titles><periodical><full-title>SCIENTIFIC REPORTS</full-title></periodical><volume>14</volume><issue>1</issue><keywords><keyword>Crowd flow prediction; Deep learning; Spatio-temporal data mining</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1038/s41598-024-63310-6</electronic-resource-num><language>English</language><urls/><abstract>Crowd flow prediction has been studied for a variety of purposes,
ranging from the private sector such as location selection of stores
according to the characteristics of commercial districts and
customer-tailored marketing to the public sector for social
infrastructure design such as transportation networks. Its importance is
even greater in light of the spread of contagious diseases such as
COVID-19. In many cases, crowd flow can be divided into subgroups by
common characteristics such as gender, age, location type, etc. If we
use such hierarchical structure of the data effectively, we can improve
prediction accuracy of crowd flow for subgroups. But the existing
prediction models do not consider such hierarchical structure of the
data. In this study, we propose a deep learning model based on
global-local structure of the crowd flow data, which utilizes the
overall(global) and subdivided by the types of sites(local) crowd flow
data simultaneously to predict the crowd flow of each subgroup. The
experiment result shows that the proposed model improves the prediction
accuracy of each sub-divided subgroup by 5.2% (Table 5 Cat #9)-45.95%
(Table 11 Cat #5), depending on the data set. This result comes from
the comparison with the related works under the same condition that use
target category data to predict each subgroup. In addition, when we
refine the global data composition by considering the correlation
between subgroups and excluding low correlated subgroups, the prediction
accuracy is further improved by 5.6-48.65%.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ignacio Criado, J</author><author>de Zarate-Alcarazo, Lucia O</author></authors></contributors><titles><title>Technological frames, CIOs, and Artificial Intelligence in public
administration: A socio-cognitive exploratory study in Spanish local
governments</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Technological frames; Artificial Intelligence; Chief Information
Officers; Public administration; Governance; Exploratory research</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101688</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) policies and strategies have been designed
and adopted in the public sector during the last few years, with Chief
Information Officers (CIOs) playing a key role. Using socio-cognitive
and institutional approaches on Information Technologies (ITs) in
(public) organizations, we consider that the assumptions, expectations,
and knowledge (technological frames) of those in charge (CIOs) of
designing AI strategies are guiding the future of these emerging systems
in the public sector. In this study, we focus on the technological
frames of CIOs in the largest Spanish local governments. Based on a
survey administered to CIOs leading IT departments, this article
presents original data about their technological frames on AI. Our
results: (1) provide insights about how CIOs tend to focus on the
technological features of AI implementation while often overlook some of
the social, political, and ethical challenges in the public sector; (2)
expand the theory on AI by enabling the construction of propositions and
testable hypotheses for future research in the field. Therefore, the
comparative study of technological frames will be key to successfully
design and implement AI policies and strategies in the public sector and
to tackle future challenges and opportunities.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sanchez-Graells, Albert</author></authors></contributors><titles><title>Responsibly Buying Artificial Intelligence: A `Regulatory Hallucination'</title><secondary-title>CURRENT LEGAL PROBLEMS</secondary-title></titles><periodical><full-title>CURRENT LEGAL PROBLEMS</full-title></periodical><keywords><keyword>public procurement; artificial intelligence; regulation; commercial
determination; regulatory tunnelling</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1093/clp/cuae003</electronic-resource-num><language>English</language><urls/><abstract>As part of its `pro-innovation' approach to artificial intelligence
(AI), the UK has left public sector AI procurement and deployment to
`regulation by contract' based on thin guidance. Borrowing from the
description of AI `hallucinations' as plausible but incorrect answers
given with high confidence by AI systems, I argue that this is a
`regulatory hallucination': an incorrect answer to the challenge of
regulating the procurement and use of AI by the public sector. The
pretence that public buyers can `confidently and responsibly procure AI
technologies' can generate individual harms and broader negative social
effects as the public sector ramps up AI adoption and accumulates a
potentially significant stock of AI deployments across all areas of
public sector activity. I sketch an alternative strategy to boost the
effectiveness of the goals of AI regulation and the protection of
individual rights and collective interests through the creation of an
independent authority.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Yi</author><author>Wu, Mengjia</author><author>Tian, George Yijun</author><author>Zhang Guangquan
and Lu, Jie</author></authors></contributors><titles><title>Ethics and privacy of artificial intelligence: Understandings from
bibliometrics</title><secondary-title>KNOWLEDGE-BASED SYSTEMS</secondary-title></titles><periodical><full-title>KNOWLEDGE-BASED SYSTEMS</full-title></periodical><volume>222</volume><keywords><keyword>Artificial intelligence; Ethics; Privacy; Bibliometrics; Topic analysis</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.knosys.2021.106994</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) and its broad applications are disruptively
transforming the daily lives of human beings and a discussion of the
ethical and privacy issues surrounding AI is a topic of growing
interest, not only among academics but also the general public This
review identifies the key entities (i.e., leading research institutions
and their affiliated countries/regions, core research journals, and
communities) that contribute to the research on the ethical and privacy
issues in relation to AI and their intersections using co-occurrence
analysis. Topic analyses profile the topical landscape of AI ethics
using a topical hierarchical tree and the changing interest of society
in AI ethics over time through scientific evolutionary pathways. We also
paired 15 selected AI techniques with 17 major ethical issues and
identify emerging ethical issues from a core set of the most recent
articles published in Nature, Science, and Proceedings of the National
Science Academy of the United States. These insights bridging the
knowledge base of AI techniques and ethical issues in the literature,
are of interest to the AI community and audiences in science policy,
technology management, and public administration. (C) 2021 Elsevier B.V.
All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jorgensen, Andreas Moller</author><author>Nissen, Maria Appel</author></authors></contributors><titles><title>Making sense of decision support systems: Rationales, translations and
potentials for critical reflections on the reality of child protection</title><secondary-title>BIG DATA &amp; SOCIETY</secondary-title></titles><periodical><full-title>BIG DATA &amp; SOCIETY</full-title></periodical><volume>9</volume><issue>2</issue><keywords><keyword>Algorithms; big data; artificial intelligence; child protection; risk
assessment; decision support system</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/20539517221125163</electronic-resource-num><language>English</language><urls/><abstract>Decision support systems, which incorporate artificial intelligence and
big data, are receiving significant attention in the public sector.
Decision support systems are sociocultural artefacts that are subject to
a mix of technical and political choices, and critical investigation of
these choices and the rationales they reflect are paramount since they
are inscribed into and may cause harm, violate fundamental rights and
reproduce negative social patterns. Applying and merging the concepts of
sense-making and translation, this article investigates the rationales,
translations and critical reflections that shape the development of a
decision support system to support social workers assessing referrals
concerning child neglect. It presents findings from a qualitative case
study conducted in 2019-2020 at the Citizen Centre Children and Young
People, Copenhagen Municipality, Denmark. The analysis shows how key
actors through processes of translation construct, negotiate and
readjust problem definitions, roles, interests, responsibilities and
ideas of ambiguity and accountability. Although technological
solutionism is present in these processes, it is not the only rationale
invested. Rather, technological and data-driven rationales are adjusted
to and merged with rationales of efficiency, return on investment and
child welfare. Through continuous renegotiation of roles,
responsibilities and problems according to these rationales, the key
actors attempt to orchestrate ways of managing the complexity facing
child welfare services by projecting images of future potentials of the
decision support system that are yet to be realised.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Johnson, Brad A M</author><author>Coggburn, Jerrell D</author><author>Llorens, Jared J</author></authors></contributors><titles><title>Artificial Intelligence and Public Human Resource Management: Questions
for Research and Practice</title><secondary-title>PUBLIC PERSONNEL MANAGEMENT</secondary-title></titles><periodical><full-title>PUBLIC PERSONNEL MANAGEMENT</full-title></periodical><pages>538-562</pages><volume>51</volume><issue>4</issue><keywords><keyword>artificial intelligence (AI); public human resource management; public
human capital</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/00910260221126498</electronic-resource-num><language>English</language><urls/><abstract>Advances in big data and artificial intelligence (AI), including machine
learning (ML) and other cognitive computing technologies (CCT), have
facilitated the development of human resource management (HRM)
applications promising greater efficiency, economy, and effectiveness
for public administration (Maciejewski, 2017) and better alignment with
the modern, constantly evolving employment landscape. It is not
surprising then that these advanced technologies are featured in
proposals to elevate the government's human capital. This article
discusses current and emerging AI applications that stand to impact most
(if not all) HRM functions and their prospects for elevating public
human capital. In particular, this article (a) reviews the current state
of the field with regards to AI and HRM, (b) discusses AI's current and
potential impact upon the core functional areas of HRM, (c) identifies
the main challenges AI poses to such concerns as public values, equity,
and traditional merit system principles, and (d) concludes by
identifying research needs for public HRM scholarship and practice that
highlight the growing role and influence of AI applications in the
workplace.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Engstrom, David Freeman</author><author>Ho, Daniel E</author></authors></contributors><titles><title>Algorithmic Accountability in the Administrative State</title><secondary-title>YALE JOURNAL ON REGULATION</secondary-title></titles><periodical><full-title>YALE JOURNAL ON REGULATION</full-title></periodical><pages>800-854</pages><volume>37</volume><issue>3, SI</issue><keywords/><dates><year>2020</year></dates><language>English</language><urls/><abstract>How will artificial intelligence (Al) transform government? Stemming
from a major study commissioned by the Administrative Conference of the
United States (ACUS), we highlight the promise and trajectory of
algorithmic tools used by federal agencies to perform the work of
governance. Moving past the abstract mappings of transparency measures
and regulatory mechanisms that pervade the current algorithmic
accountability literature, our analysis centers around a detailed
technical account of a pair of current applications that exemplifi; AI's
move to the center of the redistributive and coercive power of the
state: the Social Security Administration's use of AI tools to
adjudicate disability benefits cases and the Securities and Exchange
Commission's use of AI tools to target enforcement efforts under federal
securities law. We argue that the next generation of work will need to
push past a narrow focus on constitutional law and instead engage with
the broader terrain of administrative law, which is far more likely to
modulate use of algorithmic governance tools going forward. We
demonstrate the shortcomings of conventional ex ante and ex post review
under current administrative law doctrines and then consider how those
doctrines might adapt in response. Finally, we ask how else to build a
sensible accountability structure around public sector use of
algorithmic governance tools while maintaining incentives and
opportunities for salutary innovation. Reviewing some commonly offered
solutions, we propose a further and novel approach to oversight centered
on prospective benchmarking. By requiring agencies to reserve a random
set of cases for manual decision making, benchmarking offers a concrete
and accessible test of the validity and legality of machine outputs,
enabling agencies, courts, and the public to learn about, validate, and
correct errors in algorithmic decision making.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Papyshev, Gleb</author><author>Yarime, Masaru</author></authors></contributors><titles><title>The state's role in governing artificial intelligence: development,
control, and promotion through national strategies</title><secondary-title>POLICY DESIGN AND PRACTICE</secondary-title></titles><periodical><full-title>POLICY DESIGN AND PRACTICE</full-title></periodical><pages>79-102</pages><volume>6</volume><issue>1, SI</issue><keywords><keyword>Artificial intelligence; national AI strategy; state's role; qualitative
content analysis; Latent Dirichlet Allocation topic modeling</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/25741292.2022.2162252</electronic-resource-num><language>English</language><urls/><abstract>Numerous governments worldwide have issued national artificial
intelligence (AI) strategies in the last five years to deal with the
opportunities and challenges posed by this technology. However, a
systematic understanding of the roles and functions that the governments
are taking is lacking in the academic literature. Therefore, this
research uses qualitative content analysis and Latent Dirichlet
Allocation (LDA) topic modeling methodologies to investigate the texts
of 31 strategies from across the globe. The findings of the qualitative
content analysis highlight thirteen functions of the state, which
include human capital, ethics, R&amp;D, regulation, data, private sector
support, public sector applications, diffusion and awareness, digital
infrastructure, national security, national challenges, international
cooperation, and financial support. We combine these functions into
three general themes, representing the state's role: development,
control, and promotion. LDA topic modeling results are also reflective
of these themes. Each general theme is present in every national
strategy's text, but the proportion they occupy in the text is
different. The combined typology based on two methods reveals that the
countries from the post-soviet bloc and East Asia prioritize the theme
``development,'' highlighting the high level of the state's
involvement in AI innovation. The countries from the EU focus on
``control,'' which reflects the union's hard stance on AI regulation,
whereas countries like the UK, the US, and Ireland emphasize a more
hands-off governance arrangement with the leading role of the private
sector by prioritizing ``promotion.''</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van Noordt, Colin</author><author>Misuraca, Gianluca</author></authors></contributors><titles><title>Exploratory Insights on Artificial Intelligence for Government in Europe</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><pages>426-444</pages><volume>40</volume><issue>2</issue><keywords><keyword>artificial intelligence; public sector innovation; adoption; AI-enabled
innovation; digital transformation</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/0894439320980449</electronic-resource-num><language>English</language><urls/><abstract>There is great interest to use artificial intelligence (AI) technologies
to improve government processes and public services. However, the
adoption of technologies has often been challenging for public
administrations. In this article, the adoption of AI in governmental
organizations has been researched as a form of information and
communication technologies (ICT)-enabled governance innovation in the
public sector. Based on findings from three cases of AI adoption in
public sector organizations, this article shows strong similarities
between the antecedents identified in previous academic literature and
the factors contributing to the use of AI in government. The adoption of
AI in government does not solely rely on having high-quality data but is
facilitated by numerous environmental, organizational, and other factors
that are strictly intertwined among each other. To address the specific
nature of AI in government and the complexity of its adoption in the
public sector, we thus propose a framework to provide a comprehensive
overview of the key factors contributing to the successful adoption of
AI systems, going beyond the narrow focus on data, processing power, and
algorithm development often highlighted in the mainstream AI literature
and policy discourse.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Islam, Md. Monirul</author><author>Tareque, Mohammad</author></authors></contributors><titles><title>Public sector innovation outcome-driven sustainable development in
Bangladesh: applying the dynamic autoregressive distributed lag
simulations and Kernel-based regularised least square machine learning
algorithm approaches</title><secondary-title>JOURNAL OF PUBLIC POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC POLICY</full-title></periodical><pages>326-357</pages><volume>43</volume><issue>2</issue><keywords><keyword>Bangladesh; governance; ICT; public sector innovation outcome; renewable
energy; trademark innovation</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1017/S0143814X22000368</electronic-resource-num><language>English</language><urls/><abstract>This research investigates the role of public sector innovation
outcomes, e.g. trademark innovation, information and communication
technology (ICT), renewable energy, and governance, in the sustainable
development of Bangladesh during 1980-2019. Utilising the dynamic
autoregressive distributed lag (DARDL) simulation approach, this study
divulges a favourable long-term influencing profile of public sector
innovation outcomes, i.e. trademark innovation, ICT, and renewable
energy on sustainable development, while governance has a heterogeneous
impact. Besides, the findings from the DARDL simulations area plots
display 10% counterfactual shocks to the public sector innovation
outcomes on sustainable development. Furthermore, the Kernel-based
regularised least square machine learning algorithm approach used in the
study examines the marginal effects of the public sector innovation
outcomes on sustainable development for robust findings. Therefore, the
policy suggestions are solely concerned with the public sector's
adoption of more innovation dynamics through appropriate policy
formulation.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Exmeyer, Patrick C</author><author>Hall, Jeremy L</author></authors></contributors><titles><title>High time for a higher-level look at high-technology: Plotting a course
for managing government information in an age of governance</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>429-434</pages><volume>83</volume><issue>2</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1111/puar.13513</electronic-resource-num><language>English</language><urls/><abstract>For years, scholarly interest in the intersection of government and
technology has overwhelmingly focused on the end-product of technology
capabilities. Recent advancements in computational power have
facilitated breathtaking growth of data analytics, artificial
intelligence (AI), and process automation, sparking considerable
attention by scholars and practitioners alike. However, insight
concerning the technology hardware assets powering emergent applications
in the public sector remains glaringly absent amidst this rapidly
expanding area of research. We position that gaining a greater
understanding of the scope of technology utility in governance requires
exploration of not only the applications or interfaces produced by
technology hardware, but rather the aim of promoting both modernity and
processing capacity of the hardware driving technology in government.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van Noordt, Colin</author><author>Tangi, Luca</author></authors></contributors><titles><title>The dynamics of AI capability and its influence on public value creation
of AI within public administration</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>40</volume><issue>4</issue><keywords><keyword>Artificial intelligence; AI-capability; Digital government
transformation; Public sector innovation; Digital government; Emerging
technologies</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.giq.2023.101860</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) technologies in public administration are
gaining increasing attention due to the potential benefits they can
provide in improving governmental operations. However, translating
technological opportunities into concrete public value for public
administrations is still limited. One of the factors hindering this
progress is the lack of AI capability within public organisations. The
research found that various components of AI capability are essential
for successfully developing and using AI technologies, including
tangible, intangible, and human-related factors. There is a distinction
between the AI capability to develop and the AI capability to implement
AI technologies, with more administrations capable of the former but
finding difficulties in the latter. A lack of in-house technical
expertise to maintain and update the AI systems, legal challenges in
deploying developed AI systems, and the capability to introduce changes
in the organisation to ensure the system remains operational and used by
relevant end-users are among the most critical limiting factors for
long-term use of AI by public administrations. The research underlines
the strong complementarity between historical eGovernment developments
and the capability to deploy AI technologies. The study suggests that
funding alone may not be enough to acquire AI capability, and public
administrations need to focus on both the capability to develop and
implement AI technologies. The research emphasizes that human skillsets,
both technical and non-technical, are essential for the successful
implementation of AI in public administration.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cobbe, Jennifer</author><author>Singh, Jatinder</author></authors></contributors><titles><title>Reviewable Automated Decision-Making</title><secondary-title>COMPUTER LAW &amp; SECURITY REVIEW</secondary-title></titles><periodical><full-title>COMPUTER LAW &amp; SECURITY REVIEW</full-title></periodical><volume>39</volume><keywords><keyword>automated decision-making; accountable systems; reviewability</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.clsr.2020.105475</electronic-resource-num><language>English</language><urls/><abstract>In this paper we introduce the concept of `reviewability' as an
alternative approach to im-proving the accountability of automated
decision-making that involves machine learning systems. In doing so, we
draw on an understanding of automated decision-making as a
socio-technical process, involving both human (organisational) and
technical components, beginning before a decision is made and extending
beyond the decision itself. Although explanations for automated
decisions may be useful in some contexts, they focus more narrowly on
the model and therefore do not provide the information about that
process as a whole that is necessary for many aspects of accountability,
regulatory oversight, and assessments for legal compliance. Drawing on
previous work on the application of administrative law and judicial
review mechanisms to automated decision-making in the public sector, we
argue that breaking down the automated decision-making process into its
technical and organisational components allows us to consider how
appropriate record-keeping and logging mechanisms implemented at each
stage of that process would allow for the process as a whole to be
reviewed. Although significant research is needed to explore how it can
be implemented, we argue that a reviewability framework potentially
offers for a more useful and more holistic form of accountability for
automated decision-making than approaches focused more narrowly on
explanations. (C) 2020 Jennifer Cobbe and Jatinder Singh. Published by
Elsevier Ltd. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kowalski, Radoslaw</author><author>Esteve, Marc</author><author>Mikhaylov, Slava Jankin</author></authors></contributors><titles><title>Improving public services by mining citizen feedback: An application of
natural language processing</title><secondary-title>PUBLIC ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION</full-title></periodical><pages>1011-1026</pages><volume>98</volume><issue>4</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1111/padm.12656</electronic-resource-num><language>English</language><urls/><abstract>Research on user satisfaction has increased substantially in recent
years. To date, most studies have tested the significance of predefined
factors thought to influence user satisfaction, with no scalable means
of verifying the validity of their assumptions. Digital technology has
created new methods of collecting user feedback where service users post
comments. As topic models can analyse large volumes of feedback, they
have been proposed as a feasible approach to aggregating user opinions.
This novel approach has been applied to process reviews of primary care
practices in England. Findings from an analysis of more than 200,000
reviews show that the quality of interactions with staff and
bureaucratic exigencies are the key drivers of user satisfaction. In
addition, patient satisfaction is strongly influenced by factors that
are not measured by state-of-the-art patient surveys. These results
highlight the potential benefits of text mining and machine learning for
public administration.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rezapour, Mostafa</author><author>Elmshaeuser, Scott K</author></authors></contributors><titles><title>Artificial intelligence-based analytics for impacts of COVID-19 and
online learning on college students' mental health</title><secondary-title>PLOS ONE</secondary-title></titles><periodical><full-title>PLOS ONE</full-title></periodical><volume>17</volume><issue>11</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1371/journal.pone.0276767</electronic-resource-num><language>English</language><urls/><abstract>COVID-19, the disease caused by the novel coronavirus (SARS-CoV-2),
first emerged in Wuhan, China late in December 2019. Not long after, the
virus spread worldwide and was declared a pandemic by the World Health
Organization in March 2020. This caused many changes around the world
and in the United States, including an educational shift towards online
learning. In this paper, we seek to understand how the COVID-19 pandemic
and the increase in online learning impact college students' emotional
wellbeing. We use several machine learning and statistical models to
analyze data collected by the Faculty of Public Administration at the
University of Ljubljana, Slovenia in conjunction with an international
consortium of universities, other higher education institutions, and
students' associations. Our results indicate that features related to
students' academic life have the largest impact on their emotional
wellbeing. Other important factors include students' satisfaction with
their university's and government's handling of the pandemic as well as
students' financial security.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Whicher, Anna</author><author>Crick, Tom</author></authors></contributors><titles><title>Co-design, evaluation and the Northern Ireland Innovation Lab</title><secondary-title>PUBLIC MONEY &amp; MANAGEMENT</secondary-title></titles><periodical><full-title>PUBLIC MONEY &amp; MANAGEMENT</full-title></periodical><pages>290-299</pages><volume>39</volume><issue>4</issue><keywords><keyword>Co-design; co-production; evaluation; Northern Ireland; policy labs;
public services</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1080/09540962.2019.1592920</electronic-resource-num><language>English</language><urls/><abstract>Around the world there are more than 100 policy labs-multi-disciplinary
government teams developing public services and policies using
innovation methods to engage citizens and stakeholders. These policy
labs use a range of innovation methods and approaches, including
co-production, co-creation, co-design, behavioural insights, systems
thinking, ethnography, data science, nudge theory and lean processes.
Although the methods may vary, one element is consistent: policy labs
actively, creatively and collaboratively engage the public and a wide
range of stakeholders in jointly developing solutions. The Northern
Ireland Public Sector Innovation Lab (iLab) is part of a growing UK and
international community of policy labs using co-design to engage with
users for value co-creation, aiming to improve public governance by
creating a safe space to generate ideas, test prototypes and refine
concepts with beneficiaries. Drawing on iLab's experience, this paper
explores three questions: What are the main determinants of effective
co-design? What are the unintended consequences of co-design? And what
lessons can be learned from iLab and shared with other policy labs?
IMPACT There is a need to reinstate the legitimacy of public
policy-making and public service development through more effective
citizen engagement. To experiment with more creative and user-centred
approaches, governments are establishing Policy Labs to engage citizens
at multiple stages of the development process. The Northern Ireland
Public Sector Innovation Lab (iLab) is part of a growing UK and
international community of Policy Labs using co-design to engage with
users for value co-creation, aiming to improve public governance by
creating a safe space to generate ideas, test prototypes and refine
concepts with beneficiaries.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Vogl, Thomas M</author><author>Seidelin, Cathrine</author><author>Ganesh, Bharath</author><author>Bright, Jonathan</author></authors></contributors><titles><title>Smart Technology and the Emergence of Algorithmic Bureaucracy:
Artificial Intelligence in UK Local Authorities</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>946-961</pages><volume>80</volume><issue>6</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1111/puar.13286</electronic-resource-num><language>English</language><urls/><abstract>In recent years, local authorities in the UK have begun to adopt a
variety of ``smart'' technological changes to enhance service
delivery. These changes are having profound impacts on the structure of
public administration. Focusing on the particular case of artificial
intelligence, specifically autonomous agents and predictive analytics, a
combination of desk research, a survey questionnaire, and interviews
were used to better understand the extent and nature of these changes in
local government. Findings suggest that local authorities are beginning
to adopt smart technologies and that these technologies are having an
unanticipated impact on how public administrators and computational
algorithms become imbricated in the delivery of public services. This
imbrication is described as algorithmic bureaucracy, and it provides a
framework within which to explore how these technologies transform both
the socio-technical relationship between workers and their tools, as
well as the ways that work is organized in the public sector.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Costa, Goncal</author><author>Arroyo, Oriol</author><author>Rueda, Pablo</author><author>Briones, Alan</author></authors></contributors><titles><title>A ventilation early warning system (VEWS) for diaphanous workspaces
considering COVID-19 and future pandemics scenarios</title><secondary-title>HELIYON</secondary-title></titles><periodical><full-title>HELIYON</full-title></periodical><volume>9</volume><issue>3</issue><keywords><keyword>Smart building; Building digital twin; COVID-19; IoT; Simulation; BIM;
Facilities management</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.heliyon.2023.e14640</electronic-resource-num><language>English</language><urls/><abstract>The COVID-19 pandemic has generated new needs due to the associated
health risks and, more specifically, its rapid infection rate.
Prevention measures to avoid contagions in indoor spaces, especially in
office and public buildings (e.g., hospitals, public administration,
educational cen-tres, etc.), have led to the need for adequate
ventilation to dilute the possible concentration of the virus. This
article presents our contribution to this new challenge, namely the
Ventilation Early Warning System (VEWS) which has aims to adapt the
operation of the current Heating, Venti-lating and Air Conditioning
(HVAC) systems to the ventilation needs of diaphanous workspaces, based
on a Smart Campus Digital Twin (SCDT) framework approach, while
maintaining sus-tainability. Different technologies such as the Internet
of Things (IoT), Building Information Modelling (BIM) and Artificial
Intelligence (AI) algorithms are combined to collect and integrate
monitoring data (historical records, real-time information, and
location-related patterns) to carry out forecasting simulations in this
digital twin. The generated outputs serve to assist facility managers in
their building governance, considering the appropriate application of
health mea-sures to reduce the risk of coronavirus contagion in
combination with sustainability criteria. The article also provides the
results of the implementation of the VEWS in a university workspace as a
case study. Its application has made it possible to detect and warn of
inadequate ventilation situations for the daily flow of people in the
different controlled zones.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dickinson, Helen</author><author>Yates, Sophie</author></authors></contributors><titles><title>From external provision to technological outsourcing: lessons for public
sector automation from the outsourcing literature</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>243-261</pages><volume>25</volume><issue>2</issue><keywords><keyword>Automation; artificial intelligence; robotics; outsourcing</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/14719037.2021.1972681</electronic-resource-num><language>English</language><urls/><abstract>Automation is not new, but the possibilities for automation have been
significantly expanded in recent years through advancements in
artificial intelligence. Such technologies may drive some improvements,
although they are not without risk and we lack a solid evidence base to
suggest the implications of these changes. Framing AI supported
automation as `technological outsourcing', we draw on the
well-established outsourcing literature to derive lessons about the
possible implications of public sector automation and outline some
principles that agencies can use to assist in their decision-making
about whether to invest in automation of particular processes.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hong, Sounman</author><author>Kim, Sun Hyoung</author><author>Kwon, Myungjung</author></authors></contributors><titles><title>Determinants of digital innovation in the public sector</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>4</issue><keywords><keyword>Digital innovation; Public sector innovation; Electoral competitiveness;
Artificial intelligence; Upper echelons theory</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101723</electronic-resource-num><language>English</language><urls/><abstract>This study explores the determinants of digital innovation in the public
sector. Focusing specifically on new digital technologies, such as big
data, artificial intelligence, Internet of things, and augmented
reality, we explained the wide variation in how Korean local governments
used these technologies to transform their services. We found support
for four theoretical mechanisms. First, our findings support the
existence of demand-pull innovation in the public sector: public
organizations respond to citizen demands or needs for innovation.
Second, we also find support for an electoral incentive hypothesis,
which posits that local governments' motivation for digital innovation
is influenced by local politicians' electoral incentives. Third, our
results show the existence of isomorphic pressure as a driver for public
sector innovation: public organizations emulate their neighbors in
adopting innovative practices. Fourth, the results support the upper
echelons theory, as younger policymakers are more active innovators.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wu, Xiaohui</author></authors></contributors><titles><title>Analysis of Environmental Governance Expense Prediction Reform With the
Background of Artificial Intelligence</title><secondary-title>JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING</secondary-title></titles><periodical><full-title>JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING</full-title></periodical><pages>1-19</pages><volume>34</volume><issue>5</issue><keywords><keyword>Artificial Intelligence; environmental Governance; Environmental
Management; Environmental Regulatory Governance (ERG)</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.4018/JOEUC.287874</electronic-resource-num><language>English</language><urls/><abstract>In this paper, artificial intelligence-assisted rule-based confidence
metric (AI-CRBM) framework has been introduced for analyzing
environmental governance expense prediction reform. A metric method is
to assess a level of collective environmental governance representing
general, government, and corporate aspects. The equilibrium approach is
used to calculate improvements in the source of environmental management
based on cost, and it is tailored to test the public sector-corporation
for environmental shared governance. The overall concept of cost
prediction or estimation of environmental governance is achieved by the
rule-based confidence method. The framework compares the expected cost
to the environment of governance to determine the efficiency of the cost
prediction process.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fattah, Ikhsan A</author></authors></contributors><titles><title>Decision making performance of business analytics capabilities: the role
of big data literacy and analytics competency</title><secondary-title>BUSINESS PROCESS MANAGEMENT JOURNAL</secondary-title></titles><periodical><full-title>BUSINESS PROCESS MANAGEMENT JOURNAL</full-title></periodical><keywords><keyword>Decision making performance; Business analytics capabilities; Big data
literacy; Analytics competency; Public sector institutions</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1108/BPMJ-11-2023-0894</electronic-resource-num><language>English</language><urls/><abstract>PurposeThis study investigates the relationships between data governance
(DG), business analytics capabilities (BAC), and decision-making
performance (DMP), with a focus on the mediating effects of big data
literacy (BDL) and data analytics competency
(DAC).Design/methodology/approachThe study was conducted with 178
experienced managers in public service organizations, using a
quantitative approach. Structural equation modeling (SEM) and mediation
tests were employed to analyze the data.FindingsThe findings reveal that
DG and BDL are critical antecedents for developing analytical
capabilities. Big data literacy mediates the relationship between DG and
BAC, while BAC mediates the relationship between DG and DMP.
Furthermore, DAC mediates the relationship between BA capabilities and
DMP, explaining most of the effect of BAC on DMP.Practical
implicationsThese results highlight the importance of DG in fostering
BDL and analytical skills for improved decision-making in
organizations.Originality/valueBy prioritizing DG practices that promote
BDL and analytical capabilities, organizations can leverage business
analytics to enhance decision-making.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Anastasopoulos, L Jason</author><author>Whitford, Andrew B</author></authors></contributors><titles><title>Machine Learning for Public Administration Research, With Application to
Organizational Reputation</title><secondary-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</full-title></periodical><pages>491-510</pages><volume>29</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1093/jopart/muy060</electronic-resource-num><language>English</language><urls/><abstract>Machine learning (ML) methods have gained a great deal of popularity in
recent years among public administration scholars and practitioners.
These techniques open the door to the analysis of text, image and other
types of data that allow us to test foundational theories of public
administration and to develop new theories. Despite the excitement
surrounding ML methods, clarity regarding their proper use and potential
pitfalls is lacking. This article attempts to fill this gap in the
literature through providing an ML ``guide to practice'' for public
administration scholars and practitioners. Here, we take a foundational
view of ML and describe how these methods can enrich public
administration research and practice through their ability develop new
measures, tap into new sources of data and conduct statistical inference
and causal inference in a principled manner. We then turn our attention
to the pitfalls of using these methods such as unvalidated measures and
lack of interpretability. Finally, we demonstrate how ML techniques can
help us learn about organizational reputation in federal agencies
through an illustrated example using tweets from 13 executive federal
agencies. All R code, analyses, and data described in this article can
be found in the Supplementary Appendix.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Selten, Friso</author><author>Klievink, Bram</author></authors></contributors><titles><title>Organizing public sector AI adoption: Navigating between separation and
integration</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Artificial intelligence; Public sector; Management; Adoption;
Ambidexterity; Structural separation; Contextual integration</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2023.101885</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has the potential to improve public
governance, but the use of AI in public organizations remains limited.
In this qualitative study, we explore how public organizations
strategically manage the adoption of AI. Managing AI adoption in the
public sector is complex because of the inherent tension between public
organizations' identity, characterized by formal and rigid structures,
and the demands of AI innovation that require experimentation and
flexibility. Our findings show that public organizations navigate this
tension either by creating separate departments for data science teams,
or by integrating data science teams into already existing operational
departments. The case studies reveal that separation improves the
technical expertise and capabilities of the organization, whereas
integration improves the alignment between AI and primary processes. The
findings also show that both approaches are characterized by different
AI adoption barriers. We empirically identify the processes and routines
public organizations develop to overcome these barriers.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cerrillo-Martinez, Agusti</author><author>Casadesus-de-Mingo, Anahi</author></authors></contributors><titles><title>Data governance for public transparency</title><secondary-title>PROFESIONAL DE LA INFORMACION</secondary-title></titles><periodical><full-title>PROFESIONAL DE LA INFORMACION</full-title></periodical><volume>30</volume><issue>4</issue><keywords><keyword>Data; Data governance; Transparency; Public administration; Local
administration; Big data; Public sector; Public policy; Accountability;
Data management; Data re-use; Open government; Open data; Legal
frameworks; Policies; Compliance; Case studies</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.3145/epi.2021.jul.02</electronic-resource-num><language>English</language><urls/><abstract>Public transparency is becoming increasingly complex due to the volume
of data generated by government, the plurality of uses given to public
data, their dispersal over different organizations, bodies and units and
the diversity of mechanisms through which they are channelled. All this
requires government agencies not only to improve data management but
also to adopt procedures and structures that facilitate decision-making
regarding data's use and quality. In this context, this study defines
data governance as the set of principles, values and standards that
guide interaction in decision-making among stakeholders who create,
manage and use data. This study uses the analysis of three data
governance cases to identify the defining characteristics of data
governance (data governance's design, the institutional position on data
governance in the organizational structure, the stakeholders involved in
data governance, the interaction channels provided and the functions
attributed to them). Based on these elements, three models of data
governance promoted by government agencies are observed. In the light of
the data governance models analysed, the final reflection identifies how
data governance can contribute to improve public transparency.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kankanamge, Nayomi</author><author>Yigitcanlar, Tan</author><author>Goonetilleke, Ashantha</author></authors></contributors><titles><title>Public perceptions on artificial intelligence driven disaster
management: Evidence from Sydney, Melbourne and Brisbane</title><secondary-title>TELEMATICS AND INFORMATICS</secondary-title></titles><periodical><full-title>TELEMATICS AND INFORMATICS</full-title></periodical><volume>65</volume><keywords><keyword>artificial intelligence (AI); Disaster management; Disaster
preparedness; Disaster response; Disaster recovery; Public perception</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.tele.2021.101729</electronic-resource-num><language>English</language><urls/><abstract>In recent years, artificial intelligence (AI) is being increasingly
utilised in disaster management activities. The public is engaged with
AI in various ways in these activities. For instance, crowdsourcing
applications developed for disaster management to handle the tasks of
collecting data through social media platforms, and increasing disaster
awareness through serious gaming applications. Nonetheless, there are
limited empirical investigations and understanding on public perceptions
concerning AI for disaster management. Bridging this knowledge gap is
the justification for this paper. The methodological approach adopted
involved: Initially, collecting data through an online survey from
residents (n = 605) of three major Australian cities; Then, analysis of
the data using statistical modelling. The analysis results revealed
that: (a) Younger generations have a greater appreciation of
opportunities created by AI-driven applications for disaster management;
(b) People with tertiary education have a greater understanding of the
benefits of AI in managing the pre- and post-disaster phases, and; (c)
Public sector administrative and safety workers, who play a vital role
in managing disasters, place a greater value on the contributions by AI
in disaster management. The study advocates relevant authorities to
consider public perceptions in their efforts in integrating AI in
disaster management.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Engstrom, David Freeman</author><author>Haim, Amit</author></authors></contributors><titles><title>Regulating Government AI and the Challenge of Sociotechnical Design</title><secondary-title>ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE</secondary-title></titles><periodical><full-title>ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE</full-title></periodical><pages>277-298</pages><volume>19</volume><keywords><keyword>artificial intelligence; government; public administration; regulation;
institutional design</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1146/annurev-lawsocsci-120522-091626</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) is transforming how governments work, from
distribution of public benefits, to identifying enforcement targets, to
meting out sanctions. But given AI's twin capacity to cause and cure
error, bias, and inequity, there is little consensus about how to
regulate its use. This review advances debate by lifting up research at
the intersection of computer science, organizational behavior, and law.
First, pushing past the usual catalogs of algorithmic harms and
benefits, we argue that what makes government AI most concerning is its
steady advance into discretion-laden policy spaces where we have long
tolerated less-than-full legal accountability. The challenge is how, but
also whether, to fortify existing public law paradigms without
hamstringing government or stymieing useful innovation. Second, we argue
that sound regulation must connect emerging knowledge about internal
agency practices in designing and implementing AI systems to
longer-standing lessons about the limits of external legal constraints
in inducing organizations to adopt desired practices. Meaningful
accountability requires a more robust understanding of organizational
behavior and law as AI permeates bureaucratic routines.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zekic-Susac, Marijana</author><author>Mitrovic, Sasa</author><author>Has, Adela</author></authors></contributors><titles><title>Machine learning based system for managing energy efficiency of public
sector as an approach towards smart cities</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>58</volume><keywords><keyword>Planning models; Energy efficiency; Machine learning; Public sector;
Smart cities</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2020.102074</electronic-resource-num><language>English</language><urls/><abstract>Energy efficiency of public sector is an important issue in the context
of smart cities due to the fact that buildings are the largest energy
consumers, especially public buildings such as educational, health,
government and other public institutions that have a large usage
frequency. However, recent developments of machine learning within Big
Data environment have not been exploited enough in this domain. This
paper aims to answer the question of how to incorporate Big Data
platform and machine learning into an intelligent system for managing
energy efficiency of public sector as a substantial part of the smart
city concept. Deep neural networks, Rpart regression tree and Random
forest with variable reduction procedures were used to create prediction
models of specific energy consumption of Croatian public sector
buildings. The most accurate model was produced by Random forest method,
and a comparison of important predictors extracted by all three methods
has been conducted. The models could be implemented in the suggested
intelligent system named MERIDA which integrates Big Data collection and
predictive models of energy consumption for each energy source in public
buildings, and enables their synergy into a managing platform for
improving energy efficiency of the public sector within Big Data
environment. The paper also discusses technological requirements for
developing such a platform that could be used by public administration
to plan reconstruction measures of public buildings, to reduce energy
consumption and cost, as well as to connect such smart public buildings
as part of smart cities. Such digital transformation of energy
management can increase energy efficiency of public administration, its
higher quality of service and healthier environment.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Guenduez, Ali A</author><author>Mettler, Tobias</author><author>Schedler, Kuno</author></authors></contributors><titles><title>Technological frames in public administration: What do public managers
think of big data?</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>37</volume><issue>1</issue><keywords><keyword>Big data; Technological frame; Public manager; Public administration; Q
methodology</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.giq.2019.101406</electronic-resource-num><language>English</language><urls/><abstract>Being among the largest creators and gatherers of data in many
countries, public administrations are looking for ways to harness big
data technology. However, the de facto uses of big data in the public
sector remain very limited. Despite numerous studies aiming to clarify
the term big data, for many public managers, it remains unclear what
this technology does and does not offer public administration. Using the
concept of technological frames, we explore the assumptions,
expectations, and understandings that public managers possess in order
to interpret and make sense of big data. We identify nine big data
frames, ranging from inward-oriented technoenthusiasts to
outward-oriented techno-skeptics, each of which characterizes public
managers' specific viewpoints relating to the introduction of big data
in public administrations. Our findings highlight inconsistencies
between different perceptions and reveal widespread skepticism among
public managers, helping better understand why the de facto uses of big
data in the public sector remain very limited.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Li, Yiran</author><author>Fan, Yingying</author><author>Nie, Lin</author></authors></contributors><titles><title>Making governance agile: Exploring the role of artificial intelligence
in China's local governance</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>Artificial intelligence; agile governance; government as a platform;
public value</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231188229</electronic-resource-num><language>English</language><urls/><abstract>As the key to digital transformation, artificial intelligence is
believed to help achieve the goal of government as a platform and the
agile development of digital services. Yet we know little about its
potential role in local governance, especially the advances that
AI-supported services for the public sector in local governance have
ventured and the public value they have created. Combining the digital
transformation concepts and public value theory, we fill the gap by
examining artificial intelligence (AI) deployment in the public sector
of a pilot city of digital transformation in China. Using a mixed-method
approach, we show how AI configurations facilitate public value creation
in the digital era and identify four dimensions of AI deployment in the
public sector: data integration, policy innovation, smart application,
and collaboration. Our case analysis on these four dimensions
demonstrates two roles that AI technology plays in local
governance-''AI cage'' and ``AI colleague.'' The former builds the
technology infrastructure and platform in each stage of service
delivery, regulating the behaviors of frontline workers, while the
latter helps frontline workers make decisions, thus improving the
agility of public service provision.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Medaglia, Rony</author><author>Gil-Garcia, J Ramon</author><author>Pardo, Theresa A</author></authors></contributors><titles><title>Artificial Intelligence in Government: Taking Stock and Moving Forward</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><pages>123-140</pages><volume>41</volume><issue>1</issue><keywords><keyword>artificial intelligence; government; public sector</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/08944393211034087</electronic-resource-num><language>English</language><urls/><abstract>The use of artificial intelligence (AI) applications in government is
receiving increasing attention from global research and practice
communities. This article, introducing a Special Issue on Artificial
Intelligence in Government published in the Social Science Computer
Review, presents an overview of some of the main policy initiatives
across the world in relation to AI in government and discusses the state
of the art of existing research. Based on an analysis of current trends
in research and practice, we highlight four areas to be the focus of
future research on AI in government: governance of AI, trustworthy AI,
impact assessment methodologies, and data governance.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Abbas, Syed Wasim</author><author>Hamid, Muhammad</author><author>Alkanhel, Reem</author><author>Abdallah, Hanaa A</author></authors></contributors><titles><title>Official Statistics and Big Data Processing with Artificial
Intelligence: Capacity Indicators for Public Sector Organizations</title><secondary-title>SYSTEMS</secondary-title></titles><periodical><full-title>SYSTEMS</full-title></periodical><volume>11</volume><issue>8</issue><keywords><keyword>artificial intelligence; big data; convex logistic principal component
analysis; capacity indicator; sensor-based systems</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.3390/systems11080424</electronic-resource-num><language>English</language><urls/><abstract>Efficient monitoring and achievement of the Sustainable Development
Goals (SDGs) has increased the need for a variety of data and
statistics. The massive increase in data gathering through social
networks, traditional business systems, and Internet of Things
(IoT)-based sensor devices raises real questions regarding the capacity
of national statistical systems (NSS) for utilizing big data sources.
Further, in this current era, big data is captured through sensor-based
systems in public sector organizations. To gauge the capacity of public
sector institutions in this regard, this work provides an indicator to
monitor the processing capacity of the public sector organizations
within the country (Pakistan). Some of the indicators related to
measuring the capacity of the NSS were captured through a census-based
survey. At the same time, convex logistic principal component analysis
was used to develop scores and relative capacity indicators. The
findings show that most organizations hesitate to disseminate data due
to concerns about data privacy and that public sector organizations' IT
personnel are unable to deal with big data sources to generate official
statistics. Artificial intelligence (AI) techniques can be used to
overcome these challenges, such as automating data processing, improving
data privacy and security, and enhancing the capabilities of IT human
resources. This research helps to design capacity-building initiatives
for public sector organizations in weak dimensions, focusing on
leveraging AI to enhance the production of quality and reliable
statistics.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Enqvist, Lena</author></authors></contributors><titles><title>Rule-based versus AI-driven benefits allocation: GDPR and AIA legal
implications and challenges for automation in public social security
administration</title><secondary-title>INFORMATION &amp; COMMUNICATIONS TECHNOLOGY LAW</secondary-title></titles><periodical><full-title>INFORMATION &amp; COMMUNICATIONS TECHNOLOGY LAW</full-title></periodical><pages>222-246</pages><volume>33</volume><issue>2</issue><keywords><keyword>Automated decision-making; GDPR; Artificial Intelligence Act; social
security administration; public administration</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/13600834.2024.2349835</electronic-resource-num><language>English</language><urls/><abstract>This article focuses on the legal implications of the growing reliance
on automated systems in public administrations, using the example of
social security benefits administration. It specifically addresses the
deployment of automated systems for decisions on benefits eligibility
within the frameworks of the General Data Protection Regulation (GDPR)
and the Artificial Intelligence Act (AIA). It compares how these two
legal frameworks, each targeting different regulatory objects (personal
data versus AI systems) and employing different protective measures,
apply for two common system types: rule-based systems utilised for
making fully automated decisions on eligibility, and machine learning AI
systems utilised for assisting case administrators in their
decision-making. It concludes on the combined impact that the GDPR and
the AIA will have on each of these types of systems, as well as on
differences in how these instruments determines the basic legality of
utilising such systems within social security administration.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Vydra, Simon</author><author>Klievink, Bram</author></authors></contributors><titles><title>Techno-optimism and policy-pessimism in the public sector big data
debate</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>36</volume><issue>4</issue><keywords><keyword>Big data; Analytics; Government; Public administration; Policy-making;
Decision-making; Science-policy interface; Network governance</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2019.05.010</electronic-resource-num><language>English</language><urls/><abstract>Despite great potential, high hopes and big promises, the actual impact
of big data on the public sector is not always as transformative as the
literature would suggest. In this paper, we ascribe this predicament to
an overly strong emphasis the current literature places on
technical-rational factors at the expense of political decision-making
factors. We express these two different emphases as two archetypical
narratives and use those to illustrate that some political
decision-making factors should be taken seriously by critiquing some of
the core lechno-optimise tenets from a more `policy-pessimist' angle. In
the conclusion we have these two narratives meet `eye-to-eye',
facilitating a more systematized interrogation of big data promises and
shortcomings in further research, paying appropriate attention to both
technical-rational and political decision-making factors. We finish by
offering a realist rejoinder of these two narratives, allowing for more
context-specific scrutiny and balancing both technical-rational and
political decision-making concerns, resulting in more realistic
expectations about using big data for policy-making in practice.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Madan, Rohit</author><author>Ashok, Mona</author></authors></contributors><titles><title>Making Sense of AI Benefits: A Mixed-method Study in Canadian Public
Administration</title><secondary-title>INFORMATION SYSTEMS FRONTIERS</secondary-title></titles><periodical><full-title>INFORMATION SYSTEMS FRONTIERS</full-title></periodical><keywords><keyword>Artificial Intelligence; Public administration; Sensemaking;
Institutional theory; Institutional pressures</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1007/s10796-024-10475-0</electronic-resource-num><language>English</language><urls/><abstract>Public administrators receive conflicting signals on the transformative
benefits of Artificial Intelligence (AI) and the counternarratives of
AI's ethical impacts on society and democracy. Against this backdrop,
this paper explores the factors that affect the sensemaking of AI
benefits in Canadian public administration. A mixed-method research
design using PLS-SEM (n = 272) and interviews (n = 38) tests and
explains the effect of institutional and consultant pressures on the
perceived benefits of AI use. The quantitative study shows only service
coercive pressures have a significant effect on perceived benefits of AI
use and consultant pressures are significant in generating all
institutional pressures. The qualitative study explains the results and
highlights the underlying mechanisms. The key conclusion is that in the
earlier stages of AI adoption, demand pull is the main driver rather
than technology push. A processual sensemaking model is developed
extending the theory on institutions and sensemaking. And several
managerial implications are discussed.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cheong, So-Min</author><author>Sankaran, Kris</author><author>Bastani, Hamsa</author></authors></contributors><titles><title>Artificial intelligence for climate change adaptation</title><secondary-title>WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY</secondary-title></titles><periodical><full-title>WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY</full-title></periodical><volume>12</volume><issue>5</issue><keywords><keyword>AI; climate change adaptation; machine learning</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1002/widm.1459</electronic-resource-num><language>English</language><urls/><abstract>Although artificial intelligence (AI; inclusive of machine learning) is
gaining traction supporting climate change projections and impacts,
limited work has used AI to address climate change adaptation. We
identify this gap and highlight the value of AI especially in supporting
complex adaptation choices and implementation. We illustrate how AI can
effectively leverage precise, real-time information in data-scarce
settings. We focus on supervised learning, transfer learning,
reinforcement learning, and multimodal learning to illustrate how
innovative AI methods can enable better-informed choices, tailor
adaptation measures to heterogenous groups and generate effective
synergies and trade-offs. This article is categorized under: Application
Areas &gt; Government and Public Sector</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sun, Tara Qian</author><author>Medaglia, Rony</author></authors></contributors><titles><title>Mapping the challenges of Artificial Intelligence in the public sector:
Evidence from public healthcare</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><pages>368-383</pages><volume>36</volume><issue>2</issue><keywords><keyword>Artificial Intelligence; Public sector; Healthcare; Challenges; Framing;
China</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.09.008</electronic-resource-num><language>English</language><urls/><abstract>The nascent adoption of Artificial Intelligence (AI) in the public
sector is being assessed in contradictory ways. But while there is
increasing speculation about both its dangers and its benefits, there is
very little empirical research to substantiate them. This study aims at
mapping the challenges in the adoption of AI in the public sector as
perceived by key stakeholders. Drawing on the theoretical lens of
framing, we analyse a case of adoption of the AI system IBM Watson in
public healthcare in China, to map how three groups of stakeholders
(government policy-makers, hospital managers/doctors, and Information
Technology (IT) firm managers) perceive the challenges of AI adoption in
the public sector. Findings show that different stakeholders have
diverse, and sometimes contradictory, framings of the challenges. We
contribute to research by providing an empirical basis to claims of AI
challenges in the public sector, and to practice by providing four sets
of guidelines for the governance of AI adoption in the public sector.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Keppeler, Florian</author></authors></contributors><titles><title>No Thanks, Dear AI! Understanding the Effects of Disclosure and
Deployment of Artificial Intelligence in Public Sector Recruitment</title><secondary-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</secondary-title></titles><periodical><full-title>JOURNAL OF PUBLIC ADMINISTRATION RESEARCH AND THEORY</full-title></periodical><pages>39-52</pages><volume>34</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1093/jopart/muad009</electronic-resource-num><language>English</language><urls/><abstract>Applications based on artificial intelligence (AI) play an increasing
role in the public sector and invoke political discussions. Research
gaps exist regarding the disclosure effects-reactions to disclosure of
the use of AI applications-and the deployment effect-efficiency gains in
data savvy tasks. This study analyzes disclosure effects and explores
the deployment of an AI application in a preregistered field experiment
(n = 2,000) co-designed with a public organization in the context of
employer-driven recruitment. The linear regression results show that
disclosing the use of the AI application leads to significantly less
interest in an offer among job candidates. The explorative analysis of
the deployment of the AI application indicates that the person-job fit
determined by the leaders can be predicted by the AI application. Based
on the literature on algorithm aversion and digital discretion, this
study provides a theoretical and empirical disentanglement of the
disclosure effect and the deployment effect to inform future evaluations
of AI applications in the public sector. It contributes to the
understanding of how AI applications can shape public policy and
management decisions, and discusses the potential benefits and downsides
of disclosing and deploying AI applications in the public sector and in
employer-driven recruitment.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Busuioc, Madalina</author></authors></contributors><titles><title>Accountable Artificial Intelligence: Holding Algorithms to Account</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>825-836</pages><volume>81</volume><issue>5</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1111/puar.13293</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) algorithms govern in subtle yet fundamental
ways the way we live and are transforming our societies. The promise of
efficient, low-cost, or ``neutral'' solutions harnessing the potential
of big data has led public bodies to adopt algorithmic systems in the
provision of public services. As AI algorithms have permeated
high-stakes aspects of our public existence-from hiring and education
decisions to the governmental use of enforcement powers (policing) or
liberty-restricting decisions (bail and sentencing)-this necessarily
raises important accountability questions: What accountability
challenges do AI algorithmic systems bring with them, and how can we
safeguard accountability in algorithmic decision-making? Drawing on a
decidedly public administration perspective, and given the current
challenges that have thus far become manifest in the field, we
critically reflect on and map out in a conceptually guided manner the
implications of these systems, and the limitations they pose, for public
accountability.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Alshahrani, Albandari</author><author>Dennehy, Denis</author><author>Mantymaki, Matti</author></authors></contributors><titles><title>An attention-based view of AI assimilation in public sector
organizations: The case of Saudi Arabia</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>4</issue><keywords><keyword>Artificial intelligence; Decision making; Attention-based view; Public
sector</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2021.101617</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has been suggested to have transformative
potential for public sector organizations through enabling increased
productivity and novel ways to deliver public services. In order to
materialize the transformative potential of AI, public sector
organizations need to successfully assimilate AI in their operational
activities. However, AI assimilation in the public sector appears to be
fragmented and lagging the private sector, and the phenomena has really
limited attention from academic research community. To address this gap,
we adopt the case study approach to explore three Saudi-Arabian public
sector organizations and analyze the results using the attention-based
view of the organization (ABV) as the theoretical lens. This study
elucidates the challenges related AI assimilation in public sector in
terms of how organizational attention is focused situated and
distributed during the assimilation process. Five key challenges emerged
from the cases studied, namely (i) misalignment between AI and
management decision-making, (ii) tensions with linguistics and national
culture, (iii) developing and implementing AI infrastructure, (iv) data
integrity and sharing, and (v) ethical and governance concerns. The
findings reveal a re-enforcing relationship between the situated
attention and structural distribution of attention that can accelerate
the successful assimilation of AI in public sector organizations.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bignami, Francesca</author></authors></contributors><titles><title>Artificial Intelligence Accountability of Public
Administration&lt;SUP&gt;&lt;/SUP&gt;</title><secondary-title>AMERICAN JOURNAL OF COMPARATIVE LAW</secondary-title></titles><periodical><full-title>AMERICAN JOURNAL OF COMPARATIVE LAW</full-title></periodical><pages>i312-i346</pages><volume>70</volume><issue>SUPP 1, 1, SI</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1093/ajcl/avac012</electronic-resource-num><language>English</language><urls/></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Buttow, Clarissa Valli</author><author>Weerts, Sophie</author></authors></contributors><titles><title>Public sector information in the European Union policy: The misbalance
between economy and individuals</title><secondary-title>BIG DATA &amp; SOCIETY</secondary-title></titles><periodical><full-title>BIG DATA &amp; SOCIETY</full-title></periodical><volume>9</volume><issue>2</issue><keywords><keyword>Public sector information; open government data; data economy;
regulation; discursive institutionalism; critical data studies</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/20539517221124587</electronic-resource-num><language>English</language><urls/><abstract>Algorithmic technologies and artificial intelligence are centred on data
and generate new business models, known as the data-driven economy. In
the European Union context, the development of such new business is
accompanied by a regulatory and political framework. An important aspect
of this regulatory framework regards the legal conditions that enable
the data collection, availability, sharing, use and reuse. Within the
larger context, this article analyses the development of the European
Union regulatory framework governing the availability, sharing and reuse
of public sector data, also referred to as Public Sector Information
policy. Anchored in the analytical tools provided by Discursive
Institutionalism and Critical Data Studies and after studying the
evolution of this policy over 25 years, this article argues that
economic considerations have been overwhelmingly decisive in the
European Union Public Sector Information policy and much less attention
has been paid to fundamental rights and democracy issues. It also shows
how European Union Public Sector Information policy contributes to the
data infrastructure, enabling a thriving data-driven economy. In doing
so, this article argues that the possible problematic effects of this
new data-driven economy are not only affordances of the technology
itself but are also the result of political and regulatory choices. More
globally, the article stresses the need for policymakers to inscribe
each of the policies and regulations affecting the digital
transformation in the framework of fundamental rights and democracy.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ingrams, Alex</author></authors></contributors><titles><title>Public Values in the Age of Big Data: A Public Information Perspective</title><secondary-title>POLICY AND INTERNET</secondary-title></titles><periodical><full-title>POLICY AND INTERNET</full-title></periodical><pages>128-148</pages><volume>11</volume><issue>2</issue><keywords><keyword>big data; democracy; public information; public values; public policy;
technocracy</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1002/poi3.193</electronic-resource-num><language>English</language><urls/><abstract>Public administration scholars have so far largely viewed big data as a
kind of technocratic transformation. However, through citizens' digital
records, use of service apps, social media, digital sensors, and other
digital footprints, big data also gives policymakers insights into
citizen choices and is therefore potentially supportive of public values
such as participation and openness. Focusing on two underexplored
countries, Germany and the Netherlands, this article develops a public
values framework for big data that considers citizen values alongside
technocratic ones. It takes the particular case of public information
agencies such as ombudsmen and courts of audit, examining the functions
they play and whether they have the capacity to address tensions arising
between technocratic and citizen values. The study finds that, while
capacity does exist, it is heavily tilted toward technocratic values,
with no capacity to address participative values. Finally, five
propositions are advanced, which describe where the tensions lie and
therefore where the attention of public information agencies should best
be focused.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ruvalcaba-Gomez, Edgar A</author></authors></contributors><titles><title>Systematic and axiological capacities in artificial intelligence applied
in the public sector</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>Artificial intelligence; public sector; exploratory factor analysis;
capabilities</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231170321</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) as a technological development is being
implemented in the public sector with the intention of improving service
delivery, as well as to help solve complex problems. However, there is a
wide range of capabilities that AI can perform and that public officials
perceive and implement in different ways. This paper aims to describe
and analyze some categories into which AI capabilities in the public
sector are divided. Using an Exploratory Factor Analysis (EFA), our
results show that the capabilities of AI from the perspective of public
officials can be classified into two aspects: systematic factors and
axiological factors. Systematic factors are related to the analysis and
behavior of data, including monitoring, analyzing, interacting,
remembering, and anticipation. Axiological factors refer to the impacts
of values, ethics, and decisions, including acting, feeling, moralizing,
creating, and deciding capacities. This categorization of AI
capabilities in the public sector sheds light on the perception of
public officials about the implementation of this technological
development.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wirtz, Bernd W</author><author>Weyerer, Jan C</author><author>Kehl, Ines</author></authors></contributors><titles><title>Governance of artificial intelligence: A risk and guideline-based
integrative framework</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>4</issue><keywords><keyword>Artificial intelligence; Risks; Guidelines; Governance; Regulation;
Framework</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101685</electronic-resource-num><language>English</language><urls/><abstract>This study addresses the growing challenge of governing artificial
intelligence (AI) arising from the risks that it increasingly poses to
the public sector and society. Based on an in-depth literature analysis,
we first identify AI risks and guidelines and classify them into six
categories, including technological, data, and analytical risks and
guidelines, informational and communicational risks and guidelines,
economic risks and guidelines, social risks and guidelines, ethical
risks and guidelines, as well as legal and regulatory risks and
guidelines. These risks and guidelines are then elaborated and
transferred into a four-layered conceptual framework for AI governance.
The framework interrelates AI risks and AI guidelines by means of a risk
management and guidance process, resulting in an AI governance layer
depicting the process for implementation of customised risk mitigation
guidelines. The framework constitutes a comprehensive reference point
for developing and implementing AI governance strategies and measures in
the public sector.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jeong, Jonggu</author></authors></contributors><titles><title>Introduction of the First AI Impact Assessment and Future Tasks: South
Korea Discussion</title><secondary-title>LAWS</secondary-title></titles><periodical><full-title>LAWS</full-title></periodical><volume>11</volume><issue>5</issue><keywords><keyword>AI; AI impact assessment; intelligent information service; South Korea</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.3390/laws11050073</electronic-resource-num><language>English</language><urls/><abstract>South Korea introduced the artificial intelligence impact assessment and
was the first case of introducing the artificial intelligence impact
assessment as national-level legislation. Artificial intelligence impact
assessments will be helpful in deciding whether to introduce artificial
intelligence by comparing costs and benefits. However, South Korea's
approach had limitations. First, an impact assessment was introduced
only in the public sector. Second, artificial intelligence impact
assessments were voluntary. Third, the subject of artificial
intelligence impact assessments was limited to society. Fourth, it is
necessary to establish a relationship with other impact assessments.
Fifth, specific details were incomplete.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sovrano, Francesco</author><author>Palmirani, Monica</author><author>Vitali, Fabio</author></authors></contributors><titles><title>Combining shallow and deep learning approaches against data scarcity in
legal domains</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>39</volume><issue>3</issue><keywords><keyword>Data scarcity; Deep learning; TF-IDF; Syntagmatic relations; Law</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2022.101715</electronic-resource-num><language>English</language><urls/><abstract>We are recently witnessing a radical shift towards digitisation in many
aspects of our daily life, including law, public administration and
governance. This has sometimes been done with the aim of reducing costs
and human errors by improving data analysis and management, but not
without raising major technological challenges. One of these challenges
is certainly the need to cope with relatively small amounts of data,
without sacrificing performance. Indeed, cutting-edge approaches to
(natural) language processing and understanding are often data-hungry,
especially those based on deep learning. With this paper we seek to
address the problem of data scarcity in automatic Legalese (or legal
English) processing and understanding. What we propose is an ensemble of
shallow and deep learning techniques called SyntagmTuner, designed to
combine the accuracy of deep learning with the ability of shallow
learning to work with little data. Our contribution is based on the
assumption that Legalese differs from its spoken language in the way the
meaning is encoded by the structure of the text and the co-occurrence of
words. As result, we show with SyntagmTuner how we can perform important
tasks for e-governance, as multi-label classification of the United
Nations General Assembly (UNGA) Resolutions or legal question answering,
with data-sets of roughly 100 samples or even less.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Tao</author><author>Li, Siqi</author><author>Zeng, Zhongping</author><author>Liang, Zhehao</author><author>Chen, Yuxi</author><author>Guo, Wenshan</author></authors></contributors><titles><title>An empirical investigation of users' switching intention to public
service robots: From the perspective of PPM framework</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>2</issue><keywords><keyword>Public service robot; Artificial intelligence; Push -pull -mooring
framework; Switching behavior</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101933</electronic-resource-num><language>English</language><urls/><abstract>In recent years, the application of artificial intelligence (AI)
technology has become increasingly common in the public sector. Users
have been switching their experiences in handling businesses from
interactions with human staff to those with robots. Prior studies have
focused on investigating the key factors that influence users' adoption
of public service robots; however, only a few have considered users'
switching behaviors from traditional human services to robotic ones.
This study employs a push-pull-mooring (PPM) framework derived from the
human migration field to understand the factors that affect users'
switching intentions in the context of public service robot
applications. The research model was tested with 419 valid responses
among users who had experienced both human services and public service
robots in Chinese government service halls. The structural equation
modeling (SEM) method was applied to quantitatively analyze the data.
This study sheds new light on the key determinants of users' switching
intentions toward public service robots from the perspectives of push,
pull, and mooring effects. The results can help practitioners and
managers understand users' intentions for such switches and make
scientific decisions to encourage citizens' positive responses to
service robots.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>van der Voort, H G</author><author>Klievink, A J</author><author>Arnaboldi, M</author><author>Meijer, A. J</author></authors></contributors><titles><title>Rationality and politics of algorithms. Will the promise of big data
survive the dynamics of public decision making?</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><pages>27-38</pages><volume>36</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.10.011</electronic-resource-num><language>English</language><urls/><abstract>Big data promises to transform public decision-making for the better by
making it more responsive to actual needs and policy effects. However,
much recent work on big data in public decision-making assumes a
rational view of decision-making, which has been much criticized in the
public administration debate. In this paper, we apply this view, and a
more political one, to the context of big data and offer a qualitative
study. We question the impact of big data on decision-making, realizing
that big data including its new methods and functions must inevitably
encounter existing political and managerial institutions. By studying
two illustrative cases of big data use processes, we explore how these
two worlds meet. Specifically, we look at the interaction between data
analysts and decision makers. In this we distinguish between a rational
view and a political view, and between an information logic and a
decision logic. We find that big data provides ample opportunities for
both analysts and decision makers to do a better job, but this doesn't
necessarily imply better decision-making, because big data also provides
opportunities for actors to pursue their own interests. Big data enables
both data analysts and decision makers to act as autonomous agents
rather than as links in a functional chain. Therefore, big data's impact
cannot be interpreted only in terms of its functional promise; it must
also be acknowledged as a phenomenon set to impact our policymaking
institutions, including their legitimacy.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schuelke-Leech, Beth-Anne</author><author>Jordan, Sara R</author><author>Barry, Betsy</author></authors></contributors><titles><title>Regulating Autonomy: An Assessment of Policy Language for Highly
Automated Vehicles Palabras clave</title><secondary-title>REVIEW OF POLICY RESEARCH</secondary-title></titles><periodical><full-title>REVIEW OF POLICY RESEARCH</full-title></periodical><pages>547-579</pages><volume>36</volume><issue>4</issue><keywords><keyword>highly automated vehicles; autonomous vehicles; driverless cars;
responsibility; policy making; big data analysis</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1111/ropr.12332</electronic-resource-num><language>English</language><urls/><abstract>Self-driving cars (also known as driverless cars, autonomous vehicles,
and highly automated vehicles [HAVs]) will change the regulatory,
political, and ethical frameworks surrounding motor vehicles. At the
highest levels of automation, HAVs are operated by independent machine
agents, making decisions without the direct intervention of humans. The
current transportation system assumes human intervention though,
including legal and moral responsibilities of human operators. Has the
development of these artificial intelligence (AI) and autonomous system
(AS) technologies outpaced the ethical and political conversations? This
paper examines discussions of HAVs, driver responsibility, and
technology failure to highlight the differences between how the
policy-making institutions in the United States (Congress and the Public
Administration) and technology and transportation experts are or are not
speaking about responsibility in the context of autonomous systems
technologies. We report findings from a big data analysis of
corpus-level documents to find that enthusiasm for HAVs has outpaced
other discussions of the technology.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dwivedi, Yogesh K</author><author>Hughes, Laurie</author><author>Ismagilova, Elvira</author><author>Aarts, Gert</author><author>Coombs, Crispin</author><author>Crick, Tom</author><author>Duan, Yanqing</author><author>Dwivedi, Rohita</author><author>Edwards, John</author><author>Eirug, Aled</author><author>Galanos, Vassilis</author><author>Ilavarasan, P Vigneswara</author><author>Janssen, Marijn</author><author>Jones, Paul</author><author>Kar, Arpan Kumar</author><author>Kizgin, Hatice</author><author>Kronemann, Bianca</author><author>Lal, Banita</author><author>Lucini, Biagio</author><author>Medaglia, Rony</author><author>Le Meunier-FitzHugh, Kenneth</author><author>Le Meunier-FitzHugh, Leslie Caroline</author><author>Misra, Santosh</author><author>Mogaji, Emmanuel</author><author>Sharma, Sujeet Kumar</author><author>Singh, Jang Bahadur</author><author>Raghavan, Vishnupriya</author><author>Raman, Ramakrishnan</author><author>Rana, Nripendra P</author><author>Samothrakis, Spyridon</author><author>Spencer, Jak</author><author>Tamilmani, Kuttimani</author><author>Tubadji, Annie</author><author>Walton, Paul</author><author>Williams, Michael D</author></authors></contributors><titles><title>Artificial Intelligence (AI): Multidisciplinary perspectives on emerging
challenges, opportunities, and agenda for research, practice and policy</title><secondary-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</secondary-title></titles><periodical><full-title>INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT</full-title></periodical><volume>57</volume><keywords><keyword>Artificial intelligence; AI; Cognitive computing; Expert systems;
Machine learning; Research agenda</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijinfomgt.2019.08.002</electronic-resource-num><language>English</language><urls/><abstract>As far back as the industrial revolution, significant development in
technical innovation has succeeded in transforming numerous manual tasks
and processes that had been in existence for decades where humans had
reached the limits of physical capacity. Artificial Intelligence (AI)
offers this same transformative potential for the augmentation and
potential replacement of human tasks and activities within a wide range
of industrial, intellectual and social applications. The pace of change
for this new AI technological age is staggering, with new breakthroughs
in algorithmic machine learning and autonomous decision-making,
engendering new opportunities for continued innovation. The impact of AI
could be significant, with industries ranging from: finance, healthcare,
manufacturing, retail, supply chain, logistics and utilities, all
potentially disrupted by the onset of AI technologies. The study brings
together the collective insight from a number of leading expert
contributors to highlight the significant opportunities, realistic
assessment of impact, challenges and potential research agenda posed by
the rapid emergence of AI within a number of domains: business and
management, government, public sector, and science and technology. This
research offers significant and timely insight to AI technology and its
impact on the future of industry and society in general, whilst
recognising the societal and industrial influence on pace and direction
of AI development.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Adamczyk, Willian Boschetti</author><author>Monasterio, Leonardo</author><author>Fochezatto, Adelar</author></authors></contributors><titles><title>Automation in the future of public sector employment: the case of
Brazilian Federal Government</title><secondary-title>TECHNOLOGY IN SOCIETY</secondary-title></titles><periodical><full-title>TECHNOLOGY IN SOCIETY</full-title></periodical><volume>67</volume><keywords><keyword>Automation; Machine learning; Public sector</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.techsoc.2021.101722</electronic-resource-num><language>English</language><urls/><abstract>What is the impact of automation on public sector employment? Using
machine learning and natural language processing algorithms, this study
estimates which occupations and agencies of the Brazilian Federal
Government are most susceptible to automation. We contribute to the
literature by introducing Bartik Occupational Tasks (BOT), an objective
method used to estimate automation susceptibility that avoids subjective
or ad hoc classifications. We show that approximately 20% of Brazilian
public sector employees work in jobs with a high potential of automation
in the coming decades. Government occupations with lower schooling and
lower salary levels are most susceptible to future automation.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wilson, Christopher</author><author>van der Velden, Maja</author></authors></contributors><titles><title>Sustainable AI: An integrated model to guide public sector
decision-making</title><secondary-title>TECHNOLOGY IN SOCIETY</secondary-title></titles><periodical><full-title>TECHNOLOGY IN SOCIETY</full-title></periodical><volume>68</volume><keywords><keyword>Artificial intelligence; Public administration; Sustainability; Social
sustainability; AI governance</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.techsoc.2022.101926</electronic-resource-num><language>English</language><urls/><abstract>Ethics, explainability, responsibility, and accountability are important
concepts for questioning the societal impacts of artificial intelligence
and machine learning (AI), but are insufficient to guide the public
sector in regulating and implementing AI. Recent frameworks for AI
governance help to operationalize these by identifying the processes and
layers of governance in which they must be considered, but do not
provide public sector workers with guidance on how they should be
pursued or understood. This analysis explores how the concept of
sustainable AI can help to fill this gap. It does so by reviewing how
the concept has been used by the research community and aligning
research on sustainable development with research on public sector AI.
Doing so identifies the utility of boundary conditions that have been
asserted for social sustainability according to the Framework for
Strategic Sustainable Development, and which are here integrated with
prominent concepts from the discourse on AI and society. This results in
a conceptual model that integrates five boundary conditions to assist
public sector decision-making about how to govern AI: Diversity,
Capacity for learning, Capacity for selforganization Common meaning, and
Trust. These are presented together with practical approaches for their
presentation, and guiding questions to aid public sector workers in
making the decisions that are required by other operational frameworks
for ethical AI.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hartmann, Kathrin</author><author>Wenzelburger, Georg</author></authors></contributors><titles><title>Uncertainty, risk and the use of algorithms in policy decisions: a case
study on criminal justice in the USA</title><secondary-title>POLICY SCIENCES</secondary-title></titles><periodical><full-title>POLICY SCIENCES</full-title></periodical><pages>269-287</pages><volume>54</volume><issue>2</issue><keywords><keyword>Artificial intelligence; Big data; Public policy; Public administration;
Criminal justice</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1007/s11077-020-09414-y</electronic-resource-num><language>English</language><urls/><abstract>Algorithms are increasingly used in different domains of public policy.
They help humans to profile unemployed, support administrations to
detect tax fraud and give recidivism risk scores that judges or criminal
justice managers take into account when they make bail decisions. In
recent years, critics have increasingly pointed to ethical challenges of
these tools and emphasized problems of discrimination, opaqueness or
accountability, and computer scientists have proposed technical
solutions to these issues. In contrast to these important debates, the
literature on how these tools are implemented in the actual everyday
decision-making process has remained cursory. This is problematic
because the consequences of ADM systems are at least as dependent on the
implementation in an actual decision-making context as on their
technical features. In this study, we show how the introduction of risk
assessment tools in the criminal justice sector on the local level in
the USA has deeply transformed the decision-making process. We argue
that this is mainly due to the fact that the evidence generated by the
algorithm introduces a notion of statistical prediction to a situation
which was dominated by fundamental uncertainty about the outcome before.
While this expectation is supported by the case study evidence, the
possibility to shift blame to the algorithm does seem much less
important to the criminal justice actors.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Butt, Sameera</author><author>Mahmood, Asif</author><author>Saleem, Saima</author></authors></contributors><titles><title>The role of institutional factors and cognitive absorption on students'
satisfaction and performance in online learning during COVID 19</title><secondary-title>PLOS ONE</secondary-title></titles><periodical><full-title>PLOS ONE</full-title></periodical><volume>17</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1371/journal.pone.0269609</electronic-resource-num><language>English</language><urls/><abstract>With the rise of the Covid-19 pandemic, there has been a severe negative
impact on all aspects of life, whether it be a job, business, health,
education, etc. As a result, institutions, schools, colleges and
universities are being shut down globally to control the spread of
Covid-19. Due to this reason, the mode of education has a dramatic shift
from on-campus to online learning with virtual teaching using digital
technologies. This sudden shift has elevated the stress level among the
students because they were not mentally prepared for it, and hence their
academic performance has been adversely affected. So, there needs to
figure out the underlying process to make online learning more
productive. Thus, to obtain this objective, the present study has
integrated the modified Technology Acceptance Model (TAM), Task
Technology Fit Model (TTF), DeLone and McLean Model of Information
Systems Success (DMISM) and Unified Theory of Acceptance and Use of
Technology (UTAUT) model. A sample of 404 students was obtained, where
202 students were from the top ten public sector universities, and 202
were from the top ten private sector universities of Punjab. Structural
Equation Modelling (SEM) was used to analyze the hypothesized framework
using AMOS. The results reveal that institutional factors positively
impact students' performance mediated by user satisfaction and task
technology fit. Similarly, institutional factors affect performance
through mediation by user satisfaction and actual usage in sequence.
Cognitive absorption was used as a moderator between institutional
factors and user satisfaction. In the end, theoretical and practical
inferences have also been discussed.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kaushal, Akshay</author><author>Acharjee, Animesh</author><author>Mandal, Anandadeep</author></authors></contributors><titles><title>Machine learning based attribution mapping of climate related
discussions on social media</title><secondary-title>SCIENTIFIC REPORTS</secondary-title></titles><periodical><full-title>SCIENTIFIC REPORTS</full-title></periodical><volume>12</volume><issue>1</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1038/s41598-022-22034-1</electronic-resource-num><language>English</language><urls/><abstract>A united front from all the stakeholders including public,
administration and academia alike is required to counter the growing
threat of climate change. The recent rise of social media as the new
public address system, makes it an ideal source of information to assess
public discussions and responses in real time. We mine c.1.7 m posts
from 55 climate related subreddits on social media platform Reddit since
its inception. Using USE, a state-of-the-art sentence encoder, and
K-means clustering algorithm, we develop a machine learning based
approach to identify, store, process and classify the posts
automatically, and at a scale. In the broad and multifaceted theme of
climate change, our approach narrows down the focus to 10 critical
underlying themes comprising the public discussions on social media over
time. Furthermore, we employ a full order partial correlation analysis
to assess the relationship between the different identified themes. We
show that in line with Paris Agreement, while the climate science
community has been successful in influencing the discussions on both the
causes and effects of climate change, the public administration has
failed to appropriately communicate the causes of climate change and has
been able to influence only the discussions on the effects of it. Hence,
our study shows a clear gap in the public communication by the
administration, wherein counter-intuitively less emphasis has been given
on the drivers of climate change. This information can be particularly
beneficial to policymakers and climate activists in decision making as
they try to close the gap between public and academia.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zahid, Reeba</author><author>Altaf, Ayesha</author><author>Ahmad, Tauqir</author><author>Iqbal, Faiza</author><author>Vera, Yini Airet Miro</author><author>Flores, Miguel Angel Lopez</author><author>Ashraf, Imran</author></authors></contributors><titles><title>Secure Data Management Life Cycle for Government Big-Data Ecosystem:
Design and Development Perspective</title><secondary-title>SYSTEMS</secondary-title></titles><periodical><full-title>SYSTEMS</full-title></periodical><volume>11</volume><issue>8</issue><keywords><keyword>big data; data life cycle; GBDE; secure data life cycle</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.3390/systems11080380</electronic-resource-num><language>English</language><urls/><abstract>The rapid generation of data from various sources by the public sector,
private corporations, business associations, and local communities is
referred to as big data. This large and complex dataset is often
regarded as the `new oil' by public administrations (PAs), and
data-driven approaches are employed to transform it into valuable
insights that can improve governance, transparency, digital services,
and public engagement. The government's big-data ecosystem (GBDE) is a
result of this initiative. Effective data management is the first step
towards large-scale data analysis, which yields insights that benefit
your work and your customers. However, managing big data throughout its
life cycle is a daunting challenge for public agencies. Despite its
widespread use, big data management is still a significant obstacle. To
address this issue, this study proposes a hybrid approach to secure the
data management life cycle for GBDE. Specifically, we use a combination
of the ECC algorithm with AES 128 BITS encryption to ensure that the
data remain confidential and secure. We identified and analyzed various
data life cycle models through a systematic literature review to create
a data management life cycle for data-driven governments. This approach
enhances the security and privacy of data management and addresses the
challenges faced by public agencies.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mergel, Ines</author><author>Dickinson, Helen</author><author>Stenvall, Jari</author><author>Gasco, Mila</author></authors></contributors><titles><title>Implementing AI in the public sector</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><keywords><keyword>Artificial intelligence (AI); implementation of technology; digital
transformation</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/14719037.2023.2231950</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has advanced as one of the most prominent
technological innovations to push the conversation about the digital
transformation of the public sector forward. This special issue focuses
on actual implementation approaches or challenges that public managers
are facing while they fulfil new policy that asks for the implementation
of AI in public administrations. In addition to assessing the
contributions of papers in this issue, we also provide a research agenda
on how future research can fill some of the methodological, theoretical,
and application gaps in the public management literature.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Androutsopoulou, Aggeliki</author><author>Karacapilidis, Nikos</author><author>Loukis Euripidis
and Charalabidis, Yannis</author></authors></contributors><titles><title>Transforming the communication between citizens and government through
AI-guided chatbots</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><pages>358-367</pages><volume>36</volume><issue>2</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.giq.2018.10.001</electronic-resource-num><language>English</language><urls/><abstract>Driven by `success stories' reported by private sector firms, government
agencies have also started adopting various Artificial Intelligence (AI)
technologies in diverse domains (e.g. health, taxation, and education);
however, extensive research is required in order to exploit the full
potential of AI in the public sector, and leverage various AI
technologies to address important problems/needs. This paper makes a
contribution in this direction: it presents a novel approach, as well as
the architecture of an ICT platform supporting it, for the advanced
exploitation of a specific AI technology, namely chatbots, in the public
sector in order to address a crucial issue: the improvement of
communication between government and citizens (which has for long time
been problematic). The proposed approach builds on natural language
processing, machine learning and data mining technologies, and leverages
existing data of various forms (such as documents containing legislation
and directives, structured data from government agencies' operational
systems, social media data, etc.), in order to develop a new digital
channel of communication between citizens and government. Making use of
appropriately structured and semantically annotated data, this channel
enables `richer' and more expressive interaction of citizens with
government in everyday language, facilitating and advancing both
information seeking and conducting of transactions. Compared to existing
digital channels, the proposed approach is appropriate for a wider range
of citizens' interactions, with higher levels of complexity, ambiguity
and uncertainty. In close co-operation with three Greek government
agencies (the Ministry of Finance, a social security organization, and a
big local government organization), this approach has been validated
through a series of application scenarios.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wirtz, Bernd W</author><author>Mueller, Wilhelm M</author></authors></contributors><titles><title>An integrated artificial intelligence framework for public management</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>1076-1100</pages><volume>21</volume><issue>7</issue><keywords><keyword>Artificial intelligence; framework; conceptual study; public
administration; public business model</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1080/14719037.2018.1549268</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) extends the limits of current performance
in data processing and analysis many times over. Since this states a
great improvement in managing public data, this conceptual study
discusses the use of AI in public management structures in connection
with their risks and side effects. The exercise of state power and
public influence through intelligent machines make ethical and political
guidelines essential for their operation, constituting the cornerstones
of the AI framework model developed here. The organizational structure
and technical specification are additional aspects of the AI that
determine design and functionality of the framework model in practical
application.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Giest, Sarah N</author><author>Klievink, Bram</author></authors></contributors><titles><title>More than a digital system: how AI is changing the role of bureaucrats
in different organizational contexts</title><secondary-title>PUBLIC MANAGEMENT REVIEW</secondary-title></titles><periodical><full-title>PUBLIC MANAGEMENT REVIEW</full-title></periodical><pages>379-398</pages><volume>26</volume><issue>2</issue><keywords><keyword>Public decision-making; artificial intelligence; digital welfare system;
bureaucrats; public sector innovation</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1080/14719037.2022.2095001</electronic-resource-num><language>English</language><urls/><abstract>The paper highlights the effects of AI implementation on public sector
innovation. This is explored by asking how AI-driven technologies in
public decision-making in different organizational contexts impacts
innovation in the role definition of bureaucrats. We focus on
organizational as well as agency- and individual-level factors in two
cases: The Dutch Childcare Allowance case and the US Integrated Data
Automated System. We observe administrative process innovation in both
cases where organizational structures and tasks of bureaucrats are
transformed, and in the US case we also find conceptual innovation in
that welfare fraud is addressed by replacing bureaucrats all together.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pencheva, Irina</author><author>Esteve, Marc</author><author>Mikhaylov, Slava Jankin</author></authors></contributors><titles><title>Big Data and AI - A transformational shift for government: So, what next
for research?</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><pages>24-44</pages><volume>35</volume><issue>1</issue><keywords><keyword>Big Data; literature review; policy process</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1177/0952076718780537</electronic-resource-num><language>English</language><urls/><abstract>Big Data and artificial intelligence will have a profound
transformational impact on governments around the world. Thus, it is
important for scholars to provide a useful analysis on the topic to
public managers and policymakers. This study offers an in-depth review
of the Policy and Administration literature on the role of Big Data and
advanced analytics in the public sector. It provides an overview of the
key themes in the research field, namely the application and benefits of
Big Data throughout the policy process, and challenges to its adoption
and the resulting implications for the public sector. It is argued that
research on the subject is still nascent and more should be done to
ensure that the theory adds real value to practitioners. A critical
assessment of the strengths and limitations of the existing literature
is developed, and a future research agenda to address these gaps and
enrich our understanding of the topic is proposed.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Stone, Merlin</author><author>Aravopoulou, Eleni</author><author>Ekinci, Yuksel</author><author>Evans, Geraint</author><author>Hobbs, Matt</author><author>Labib, Ashraf</author><author>Laughlin, Paul</author><author>Machtynger, Jon</author><author>Machtynger, Liz</author></authors></contributors><titles><title>Artificial intelligence (AI) in strategic marketing decision-making: a
research agenda</title><secondary-title>BOTTOM LINE</secondary-title></titles><periodical><full-title>BOTTOM LINE</full-title></periodical><pages>183-200</pages><volume>33</volume><issue>2</issue><keywords><keyword>Strategy; Planning; Marketing; Artificial intelligence; Decision-making;
Operations</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1108/BL-03-2020-0022</electronic-resource-num><language>English</language><urls/><abstract>Purpose
The purpose of this paper is to review literature about the applications
of artificial intelligence (AI) in strategic situations and identify the
research that is needed in the area of applying AI to strategic
marketing decisions.
Design/methodology/approach
The approach was to carry out a literature review and to consult with
marketing experts who were invited to contribute to the paper.
Findings
There is little research into applying AI to strategic marketing
decision-making. This research is needed, as the frontier of AI
application to decision-making is moving in many management areas from
operational to strategic. Given the competitive nature of such decisions
and the insights from applying AI to defence and similar areas, it is
time to focus on applying AI to strategic marketing decisions.
Research limitations/implications
The application of AI to strategic marketing decision-making is known to
be taking place, but as it is commercially sensitive, data is not
available to the authors.
Practical implications
There are strong implications for all businesses, particularly large
businesses in competitive industries, where failure to deploy AI in the
face of competition from firms, who have deployed AI to improve their
decision-making could be dangerous.
Social implications
The public sector is a very important marketing decision maker. Although
in most cases it does not operate competitively, it must make decisions
about making different services available to different citizens and
identify the risks of not providing services to certain citizens; so,
this paper is relevant to the public sector.
Originality/value
To the best of the authors' knowledge, this is one of the first papers
to probe deployment of AI in strategic marketing decision-making.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>James, Alexandra</author><author>Whelan, Andrew</author></authors></contributors><titles><title>`Ethical' artificial intelligence in the welfare state: Discourse and
discrepancy in Australian social services</title><secondary-title>CRITICAL SOCIAL POLICY</secondary-title></titles><periodical><full-title>CRITICAL SOCIAL POLICY</full-title></periodical><pages>22-42</pages><volume>42</volume><issue>1</issue><keywords><keyword>artificial intelligence; ethical artificial intelligence; digitised
welfare delivery; public sector technology; new public management</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/0261018320985463</electronic-resource-num><language>English</language><urls/><abstract>In recent years, a discourse of `ethical artificial intelligence' has
emerged and gained international traction in response to widely
publicised AI failures. In Australia, the discourse around ethical AI
does not accord with the reality of AI deployment in the public sector.
Drawing on institutional ethnographic approaches, this paper describes
the misalignments between how technology is described in government
documentation, and how it is deployed in social service delivery. We
argue that the propagation of ethical principles legitimates established
new public management strategies, and pre-empts questions regarding the
efficacy of AI development; instead positioning implementation as
inevitable and, provided an ethical framework is adopted, laudable. The
ethical AI discourse acknowledges, and ostensibly seeks to move past,
widely reported administrative failures involving new technologies. In
actuality, this discourse works to make AI implementation a reality,
ethical or not.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Berman, Alexander</author><author>Licht, Karl de Fine</author><author>Carlsson, Vanja</author></authors></contributors><titles><title>Trustworthy AI in the public sector: An empirical analysis of a Swedish
labor market decision-support system</title><secondary-title>TECHNOLOGY IN SOCIETY</secondary-title></titles><periodical><full-title>TECHNOLOGY IN SOCIETY</full-title></periodical><volume>76</volume><keywords><keyword>Decision -support systems; Trustworthy AI; Artificial Intelligence;
Public employment services; Public sector</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techsoc.2024.102471</electronic-resource-num><language>English</language><urls/><abstract>This paper investigates the deployment of Artificial Intelligence (AI)
in the Swedish Public Employment Service (PES), focusing on the concept
of trustworthy AI in public decision -making. Despite Sweden's advanced
digitalization efforts and the widespread application of AI in the
public sector, our study reveals significant gaps between theoretical
ambitions and practical outcomes, particularly in the context of AI's
trustworthiness. We employ a robust theoretical framework comprising
Institutional Theory, the Resource -Based View (RBV), and Ambidexterity
Theory, to analyze the challenges and discrepancies in AI implementation
within PES. Our analysis shows that while AI promises enhanced decision
-making efficiency, the reality is marred by issues of transparency,
interpretability, and stakeholder engagement. The opacity of the neural
network used by the agency to assess jobseekers' need for support and
the lack of comprehensive technical understanding among PES management
contribute to the challenges in achieving transparent and interpretable
AI systems. Economic pressures for efficiency often overshadow the need
for ethical considerations and stakeholder involvement, leading to
decisions that may not be in the best interest of jobseekers. We propose
recommendations for enhancing AI's trustworthiness in public services,
emphasizing the importance of stakeholder engagement, particularly
involving jobseekers in the decision -making process. Our study
advocates for a more nuanced balance between the use of advanced AI
technologies and the leveraging of internal resources such as skilled
personnel and organizational knowledge. We also highlight the need for
improved AI literacy among both management and personnel to effectively
navigate AI's integration into public decision -making processes. Our
findings contribute to the ongoing debate on trustworthy AI, offering a
detailed case study that bridges the gap between theoretical exploration
and practical application. By scrutinizing the AI implementation in the
Swedish PES, we provide valuable insights and guidelines for other
public sector organizations grappling with the integration of AI into
their decision -making processes.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>McDonald III, Bruce D</author><author>Hall, Jeremy L</author><author>O'Flynn, Janine</author><author>Thiel, Sandra</author></authors></contributors><titles><title>The future of public administration research: An editor's perspective</title><secondary-title>PUBLIC ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION</full-title></periodical><pages>59-71</pages><volume>100</volume><issue>1, SI</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1111/padm.12829</electronic-resource-num><language>English</language><urls/><abstract>Research in the field of public administration has changed and advanced
significantly in recent years. These advancements concern both how we
engage in research-such as the methods we apply, the interdisciplinary
nature of the theories we use, and the research questions we ask.
Increasingly, we are witnessing a shift in public-sector values away
from efficiency and effectiveness and toward a paradigm that highlights
equity. In this article, we reflect on these changes from our position
as editors-in-chief of some of the leading journals in the field. In
addition to describing the progress of this discipline, we explore
emerging windows of opportunity for new research. One such window is
research on ways to incorporate interdisciplinary perspectives and
methods. We also see the need for work in such areas as social equity,
comparative administration, artificial intelligence, and climate change.
Finally, we argue for a more proactive approach in disseminating
research to those involved in the day-to-day decision-making processes
of public organizations.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Botta, Federico</author><author>Lovelace, Robin</author><author>Gilbert, Laura</author><author>Turrell, Arthur</author></authors></contributors><titles><title>Packaging code and data for reproducible research: A case study of
journey time statistics</title><secondary-title>ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE</secondary-title></titles><periodical><full-title>ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE</full-title></periodical><keywords><keyword>Data science for public good; government data; open source</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1177/23998083241267331</electronic-resource-num><language>English</language><urls/><abstract>The effective and ethical use of data to inform decision-making offers
huge value to the public sector, especially when delivered by
transparent, reproducible, and robust data processing workflows. One way
that governments are unlocking this value is through making their data
publicly available, allowing more people and organisations to derive
insights. However, open data is not enough in many cases: publicly
available datasets need to be accessible in an analysis-ready form from
popular data science tools, such as R and Python, for them to realise
their full potential. This paper explores ways to maximise the impact of
open data with reference to a case study of packaging code to facilitate
reproducible analysis. We present the jtstats project, which consists of
a main Python package, and a smaller R version, for importing,
processing, and visualising large and complex datasets representing
journey times, for many transport modes and trip purposes at multiple
geographic levels, released by the UK Department for Transport (DfT).
jtstats shows how domain specific packages can enable reproducible
research within the public sector and beyond, saving duplicated effort
and reducing the risks of errors from repeated analyses. We hope that
the jtstats project inspires others, particularly those in the public
sector, to add value to their data sets by making them more accessible.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Andrews, Leighton</author></authors></contributors><titles><title>Public administration, public leadership and the construction of public
value in the age of the algorithm and ``big data'</title><secondary-title>PUBLIC ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION</full-title></periodical><pages>296-310</pages><volume>97</volume><issue>2, SI</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1111/padm.12534</electronic-resource-num><language>English</language><urls/><abstract>Public administration scholarship has to a significant degree neglected
technological change. The age of the algorithm and big data' is throwing
up new challenges for public leadership, which are already being
confronted by public leaders in different jurisdictions. Algorithms may
be perceived as presenting new kinds of wicked problems' for public
authorities. The article offers a tentative overview of the kind of
algorithmic challenges facing public leaders in an environment where the
discursive context is shaped by corporate technology companies. Public
value theory is assessed as an analytical framework to examine how
public leaders are seeking to address the ethical and public value
issues affecting governance and regulation, drawing on recent UK
experience in particular. The article suggests that this is a fruitful
area for future research.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Coulthart, Stephen</author><author>Riccucci, Ryan</author></authors></contributors><titles><title>Putting Big Data to Work in Government: The Case of the United States
Border Patrol</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><pages>280-289</pages><volume>82</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1111/puar.13431</electronic-resource-num><language>English</language><urls/><abstract>Investigating how the public sector adopts technologies to process and
analyze very large datasets is crucial for understanding governance in
the digital age. The authors of this article examine a large government
agency, the United States Border Patrol (USBP), an organization that is
in the early phases of building big data capabilities. They argue the
wide-scale adoption of big data analytics will require trial-and-error
processes coordinated by organizational leadership in partnership with
front-line employees who make the technology relevant to their needs in
the field. Absent engagement from both levels, organizations like USBP
that face significant barriers to adoption (e.g., limited data science
expertise) will struggle to leverage data at scale. The authors also
extend the literature on big data in the public sector and provide a
rich description of how factors, such as organizational leadership and
resources, impact the innovation process.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Coglianese, Cary</author><author>Lai, Alicia</author></authors></contributors><titles><title>ALGORITHM VS. ALGORITHM</title><secondary-title>DUKE LAW JOURNAL</secondary-title></titles><periodical><full-title>DUKE LAW JOURNAL</full-title></periodical><pages>1281-1340</pages><volume>71</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><language>English</language><urls/><abstract>Critics raise alarm bells about governmental use of digital algorithms,
charging that they are too complex, inscrutable, and prone to bias. A
realistic assessment of digital algorithms, though, must acknowledge
that government is already driven by algorithms of arguably greater
complexity and potential for abuse: the algorithms implicit in human
decision-making. The human brain operates algorithmically through
complex neural networks. And when humans make collective decisions, they
operate via algorithms too-those reflected in legislative, judicial, and
administrative processes. Yet these human algorithms undeniably fail and
are far from transparent. On an individual level, human decision-making
suffers from memory limitations, fatigue, cognitive biases, and racial
prejudices, among other problems. On an organizational level, humans
succumb to groupthink and free riding, along with other collective
dysfunctionalities. As a result, human decisions will in some cases
prove far more problematic than their digital counterparts. Digital
algorithms, such as machine learning, can improve governmental
performance by facilitating outcomes that are more accurate, timely, and
consistent. Still, when deciding whether to deploy digital algorithms to
perform tasks currently completed by humans, public officials should
proceed with care on a case-by-case basis. They should consider both
whether a particular use would satisfy the basic preconditions for
successful machine learning and whether it would in fact lead to
demonstrable improvements over the status quo. The question about the
future of public administration is not whether digital algorithms are
perfect. Rather, it is a question about what will work better: human
algorithms or digital ones.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Krepl, Vladimir</author><author>Fandi, Ghaeth</author><author>Rehabi, Mohammad</author><author>Ghanem, Safwan</author><author>Jrad, Fayez</author><author>Mueller, Zdenek</author><author>Smutka, Lubos</author><author>Kyncl, Jan</author><author>Urbanus, Melkior</author><author>Fandie, Soliman</author><author>Cabelkova, Inna</author><author>Tlusty, Josef</author></authors></contributors><titles><title>Effective criteria in the public-private partnership in developing
countries to apply the sustainable development goals: GAN-based decision
support system for the renewable electrical system, case study Syria</title><secondary-title>HELIYON</secondary-title></titles><periodical><full-title>HELIYON</full-title></periodical><volume>9</volume><issue>11</issue><keywords><keyword>Effective criteria; Private-public partnership; Electrical system;
Sustainable energy; Generative adversarial neural networks; Sustainable
development goals</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.heliyon.2023.e21422</electronic-resource-num><language>English</language><urls/><abstract>The cost of generating electricity in developing countries surpasses the
government's ability to sustain it, necessitating the involvement of the
private sector in this service provision through public-private
partnerships (PPPs) contracts. In Syria, the electricity system has been
highly susceptible to damage as a result of the ongoing crisis, leading
to frequent and prolonged blackouts. This research focuses on addressing
the need for a comprehensive system that aids decision-making for PPPs
contracts in the country. By employing a combination of studies,
reports, and interviews with domain experts, significant general and
exclusive factors that guide decision-makers in PPPs contracts are
identified and organized into questionnaires. These questionnaires are
then filled out by professionals engaged in PPPs contracts. The
collected data is analyzed and validated using SPSS software. However,
due to insufficient data collected, generative adversarial neural
networks (GAN) are utilized to enhance the research data. Additionally,
Expert Choice and the analytic hierarchy process are employed to
calculate weights for each factor. Remarkably, the calculated weights
for both general and exclusive factors align with real-life strategies.
General factors primarily address the financial and commercial
considerations associated with PPPs, while exclusive factors primarily
focus on the operational aspects of the electrical power system. These
factors are arranged in descending order of effectiveness, enabling
stakeholders to determine whether the private sector should be engaged
in the project or if it should remain within the public sector's
purview. The proposed system has demonstrated its reliability and can
serve as a promising starting point for PPPs contracts.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kempeneer, Shirley</author></authors></contributors><titles><title>A big data state of mind: Epistemological challenges to accountability
and transparency in data-driven regulation</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>38</volume><issue>3</issue><keywords><keyword>Big data; Transparency; Accountable AI; Epistemology; Financial
regulation; Banking stress test</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.giq.2021.101578</electronic-resource-num><language>English</language><urls/><abstract>In a sense, the 2008 financial crisis was a crisis of theory.
Regulators, banks, and financial markets all had encompassing
theoretical models about how the economy worked, but they all failed to
predict the looming crisis. As such, regulators increasingly turn to big
data to understand banks' health. Despite the prominence of big data in
society, its use in the public sector remains grossly understudied. This
paper explores the regulatory use of big data in the case of the EU-wide
banking stress test, a key regulatory indicator. The paper draws on
interviews with supervisors at the European Central Bank (ECB), European
Banking Authority (EBA) and National Bank of Belgium (NBB), as well as
with consultants and risk directors in Belgian banks, to explain how big
data-driven regulation affects the relationship between regulators and
regulated entities. It draws particular attention to the epistemological
component of using large data sets in decision-making: a big data state
of mind. The article more specifically shows how the underlying
epistemology, rather than simply the bigness of datasets, affects the
relationship between regulators and regulated entities, and the
regulatory process at large. The paper concludes that regulators' big
data state of mind calls for new practical and legal guidelines
regarding the validity of data-driven knowledge claims. Moreover, it
shows how accountability based on descriptive transparency no longer
makes sense in the `age of the algorithm', suggesting a shift towards
relational transparency and joint knowledge production.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mokander, Jakob</author><author>Schroeder, Ralph</author></authors></contributors><titles><title>Artificial Intelligence, Rationalization, and the Limits of Control in
the Public Sector: The Case of Tax Policy Optimization</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><keywords><keyword>artificial intelligence; automated decision-making; bureaucratization;
equality; governance; policymaking; rationalization; tax policy; Weber</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1177/08944393241235175</electronic-resource-num><language>English</language><urls/><abstract>In this paper, we first frame the use of artificial intelligence (AI)
systems in the public sector as a continuation and intensification of
long-standing rationalization and bureaucratization processes. Drawing
on Weber, we understand the core of these processes to be the
replacement of traditions with instrumental rationality, that is, the
most calculable and efficient way of achieving any given policy
objective. Second, we demonstrate how much of the criticisms, both among
the public and in scholarship, directed towards AI systems spring from
well-known tensions at the heart of Weberian rationalization. To
illustrate this point, we introduce a thought experiment whereby AI
systems are used to optimize tax policy to advance a specific normative
end: reducing economic inequality. Our analysis shows that building a
machine-like tax system that promotes social and economic equality is
possible. However, our analysis also highlights that AI-driven policy
optimization (i) comes at the exclusion of other competing political
values, (ii) overrides citizens' sense of their (non-instrumental)
obligations to each other, and (iii) undermines the notion of humans as
self-determining beings. Third, we observe that contemporary scholarship
and advocacy directed towards ensuring that AI systems are legal,
ethical, and safe build on and reinforce central assumptions that
underpin the process of rationalization, including the modern idea that
science can sweep away oppressive systems and replace them with a rule
of reason that would rescue humans from moral injustices. That is overly
optimistic: science can only provide the means - it cannot dictate the
ends. Nonetheless, the use of AI in the public sector can also benefit
the institutions and processes of liberal democracies. Most importantly,
AI-driven policy optimization demands that normative ends are made
explicit and formalized, thereby subjecting them to public scrutiny,
deliberation, and debate.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Campion, Averill</author><author>Gasco-Hernandez, Mila</author><author>Mikhaylov Slava Jankin
and Esteve, Marc</author></authors></contributors><titles><title>Overcoming the Challenges of Collaboratively Adopting Artificial
Intelligence in the Public Sector</title><secondary-title>SOCIAL SCIENCE COMPUTER REVIEW</secondary-title></titles><periodical><full-title>SOCIAL SCIENCE COMPUTER REVIEW</full-title></periodical><pages>462-477</pages><volume>40</volume><issue>2</issue><keywords><keyword>adoption of AI; challenges of AI; organizational routines;
interorganizational collaboration; public sector</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/0894439320979953</electronic-resource-num><language>English</language><urls/><abstract>Despite the current popularity of artificial intelligence (AI) and a
steady increase in publications over time, few studies have investigated
AI in public contexts. As a result, assumptions about the drivers,
challenges, and impacts of AI in government are far from conclusive. By
using a case study that involves a large research university in England
and two different county councils in a multiyear collaborative project
around AI, we study the challenges that interorganizational
collaborations face in adopting AI tools and implementing organizational
routines to address them. Our findings reveal the most important
challenges facing such collaborations: a resistance to sharing data due
to privacy and security concerns, insufficient understanding of the
required and available data, a lack of alignment between project
interests and expectations around data sharing, and a lack of engagement
across organizational hierarchy. Organizational routines capable of
overcoming such challenges include working on-site, presenting the
benefits of data sharing, reframing problems, designating joint
appointments and boundary spanners, and connecting participants in the
collaboration at all levels around project design and purpose.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Marty, Robert</author><author>Duhaut, Alice</author></authors></contributors><titles><title>Global poverty estimation using private and public sector big data
sources</title><secondary-title>SCIENTIFIC REPORTS</secondary-title></titles><periodical><full-title>SCIENTIFIC REPORTS</full-title></periodical><volume>14</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1038/s41598-023-49564-6</electronic-resource-num><language>English</language><urls/><abstract>Household surveys give a precise estimate of poverty; however, surveys
are costly and are fielded infrequently. We demonstrate the importance
of jointly using multiple public and private sector data sources to
estimate levels and changes in wealth for a large set of countries. We
train models using 63,854 survey cluster locations across 59 countries,
relying on data from satellites, Facebook Marketing information, and
OpenStreetMaps. The model generalizes previous approaches to a wide set
of countries. On average, across countries, the model explains 55% (min
= 14%; max = 85%) of the variation in levels of wealth at the survey
cluster level and 59% (min = 0%; max = 93%) of the variation at the
district level, and the model explains 4% (min = 0%; max = 17%) and
6% (min = 0%; max = 26%) of the variation of changes in wealth at the
cluster and district levels. Models perform best in lower-income
countries and in countries with higher variance in wealth. Features from
nighttime lights, OpenStreetMaps, and land cover data are most important
in explaining levels of wealth, and features from nighttime lights are
most important in explaining changes in wealth.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Desiere, Sam</author><author>Struyven, Ludo</author></authors></contributors><titles><title>Using Artificial Intelligence to classify Jobseekers: The
Accuracy-Equity Trade-off</title><secondary-title>JOURNAL OF SOCIAL POLICY</secondary-title></titles><periodical><full-title>JOURNAL OF SOCIAL POLICY</full-title></periodical><pages>367-385</pages><volume>50</volume><issue>2</issue><keywords><keyword>profiling; statistical discrimination; public employment services;
artificial intelligence; VDAB</keyword></keywords><dates><year>2021</year></dates><electronic-resource-num>10.1017/S0047279420000203</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) is increasingly popular in the public
sector to improve the cost-efficiency of service delivery. One example
is AI-based profiling models in public employment services (PES), which
predict a jobseeker's probability of finding work and are used to
segment jobseekers in groups. Profiling models hold the potential to
improve identification of jobseekers at-risk of becoming long-term
unemployed, but also induce discrimination. Using a recently developed
AI-based profiling model of the Flemish PES, we assess to what extent
AI-based profiling `discriminates' against jobseekers of foreign origin
compared to traditional rule-based profiling approaches. At a maximum
level of accuracy, jobseekers of foreign origin who ultimately find a
job are 2.6 times more likely to be misclassified as `high-risk'
jobseekers. We argue that it is critical that policymakers and
caseworkers understand the inherent trade-offs of profiling models, and
consider the limitations when integrating these models in daily
operations. We develop a graphical tool to visualize the accuracy-equity
trade-off in order to facilitate policy discussions.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Antony, Jiju</author><author>Sony, Michael</author><author>Gutierrez, Leopoldo</author></authors></contributors><titles><title>An Empirical Study Into the Limitations and Emerging Trends of Six
Sigma: Findings From a Global Survey</title><secondary-title>IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT</secondary-title></titles><periodical><full-title>IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT</full-title></periodical><pages>2088-2101</pages><volume>69</volume><issue>5</issue><keywords><keyword>Six sigma; Market research; Organizations; Big Data; Belts;
Technological innovation; Emerging trends; empirical study; limitations;
Six Sigma</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1109/TEM.2020.2995168</electronic-resource-num><language>English</language><urls/><abstract>The purpose of this article is to identify and evaluate the limitations
and emerging trends of Six Sigma from the perspectives of Six Sigma
experts. The authors developed an online global survey and deployed the
survey to 1250 Six Sigma experts of which 307 experts responded. The
article finds integration of Six Sigma with Big Data to be the topmost
among Asian, South American, and African experts, whereas European and
North American experts felt Six Sigma in Small and Medium Sized
Enterprises and Micro-enterprises would be very beneficial. The
manufacturing sector experts nominated the topmost emerging trend as Six
Sigma in Small and Medium Sized Enterprises and Micro-enterprises to be
very challenging and will be rewarding if implemented properly. In the
service sector, the topmost emerging trend was the integration of Six
Sigma with Big Data. However, public sector experts felt variance
reduction should not be the only goal of Six Sigma implementation. The
that master black belts perceived Six Sigma in Small and Medium Sized
Enterprises and Micro-enterprises would be advantageous, whereas Black
and Green Belts perceived Integration of Six Sigma with Big Data to be
topmost emerging trend.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Haesevoets, Tessa</author><author>Verschuere, Bram</author><author>Van Severen, Ruben</author><author>Roets, Arne</author></authors></contributors><titles><title>How do citizens perceive the use of Artificial Intelligence in public
sector decisions?</title><secondary-title>GOVERNMENT INFORMATION QUARTERLY</secondary-title></titles><periodical><full-title>GOVERNMENT INFORMATION QUARTERLY</full-title></periodical><volume>41</volume><issue>1</issue><keywords><keyword>Artificial Intelligence (AI); Public sector decisions; Hybrid decision
-making; Decisional weight; Roles; Legitimacy; Decision type</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2023.101906</electronic-resource-num><language>English</language><urls/><abstract>Artificial Intelligence (AI) has become increasingly prevalent in almost
every aspect of our lives. At the same time, a debate about its
applications, safety, and privacy is raging. In three studies, we
explored how UK respondents perceive the usage of AI in various public
sector decisions. Our results are fourfold. First, we found that people
prefer AI to have considerably less decisional weight than various human
decision-makers; those being: politicians, citizens, and (human)
experts. Secondly, our findings revealed that people prefer AI to
provide input and advice to these human decision-makers, rather than
letting AI make decisions by itself. Thirdly, although AI is seen as
contributing less to perceived legitimacy than these human
decision-makers, similar to (human) experts, its contribution is seen
more in terms of output legitimacy than in terms of input and throughput
legitimacy. Finally, our results suggest that the involvement of AI is
perceived more suitable for decisions that are low (instead of high)
ideologically-charged. Overall, our findings thus show that people are
rather skeptical towards using AI in the public domain, but this does
not imply that they want to exclude AI entirely from the decision-making
process.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jobin, Anna</author><author>Ienca, Marcello</author><author>Vayena, Effy</author></authors></contributors><titles><title>The global landscape of AI ethics guidelines</title><secondary-title>NATURE MACHINE INTELLIGENCE</secondary-title></titles><periodical><full-title>NATURE MACHINE INTELLIGENCE</full-title></periodical><pages>389-399</pages><volume>1</volume><issue>9</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s42256-019-0088-2</electronic-resource-num><language>English</language><urls/><abstract>In the past five years, private companies, research institutions and
public sector organizations have issued principles and guidelines for
ethical artificial intelligence (AI). However, despite an apparent
agreement that AI should be `ethical', there is debate about both what
constitutes `ethical AI' and which ethical requirements, technical
standards and best practices are needed for its realization. To
investigate whether a global agreement on these questions is emerging,
we mapped and analysed the current corpus of principles and guidelines
on ethical AI. Our results reveal a global convergence emerging around
five ethical principles (transparency, justice and fairness,
non-maleficence, responsibility and privacy), with substantive
divergence in relation to how these principles are interpreted, why they
are deemed important, what issue, domain or actors they pertain to, and
how they should be implemented. Our findings highlight the importance of
integrating guideline-development efforts with substantive ethical
analysis and adequate implementation strategies. As AI technology
develops rapidly, it is widely recognized that ethical guidelines are
required for safe and fair implementation in society. But is it possible
to agree on what is `ethical AI'? A detailed analysis of 84 AI ethics
reports around the world, from national and international organizations,
companies and institutes, explores this question, finding a convergence
around core principles but substantial divergence on practical
implementation.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ingrams, Alex</author></authors></contributors><titles><title>Big Data and Dahl's Challenge of Democratic Governance</title><secondary-title>REVIEW OF POLICY RESEARCH</secondary-title></titles><periodical><full-title>REVIEW OF POLICY RESEARCH</full-title></periodical><pages>357-377</pages><volume>36</volume><issue>3</issue><keywords><keyword>Internet; e-governance; governance; ICTs; Media</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1111/ropr.12331</electronic-resource-num><language>English</language><urls/><abstract>Big data applications have been acclaimed as potentially transformative
for the public sector. But, despite this acclaim, most theory of big
data is narrowly focused around technocratic goals. The conceptual
frameworks that situate big data within democratic governance systems
recognizing the role of citizens are still missing. This paper explores
the democratic governance impacts of big data in three policy areas
using Robert Dahl's dimensions of control and autonomy. Key impacts and
potential tensions are highlighted. There is evidence of impacts on both
dimensions, but the dimensions conflict as well as align in notable ways
and focused policy efforts will be needed to find a balance.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ghorbany, Siavash</author><author>Yousefi, Saied</author><author>Noorzai, Esmatullah</author></authors></contributors><titles><title>Evaluating and optimizing performance of public-private partnership
projects using copula Bayesian network</title><secondary-title>ENGINEERING CONSTRUCTION AND ARCHITECTURAL MANAGEMENT</secondary-title></titles><periodical><full-title>ENGINEERING CONSTRUCTION AND ARCHITECTURAL MANAGEMENT</full-title></periodical><pages>290-323</pages><volume>31</volume><issue>1</issue><keywords><keyword>Project management; Integration; Optimization</keyword></keywords><dates><year>2024</year></dates><electronic-resource-num>10.1108/ECAM-05-2022-0492</electronic-resource-num><language>English</language><urls/><abstract>Purpose Being an efficient mechanism for the value of money,
public-private partnership (PPP) is one of the most prominent approaches
for infrastructure construction. Hence, many controversies about the
performance effectiveness of these delivery systems have been debated.
This research aims to develop a novel performance management perspective
by revealing the causal effect of key performance indicators (KPIs) on
PPP infrastructures. Design/methodology/approach The literature review
was used in this study to extract the PPPs KPIs. Experts' judgment and
interviews, as well as questionnaires, were designed to obtain data.
Copula Bayesian network (CBN) has been selected to achieve the research
purpose. CBN is one of the most potent tools in statistics for analyzing
the causal relationship of different elements and considering their
quantitive impact on each other. By utilizing this technique and using
Python as one of the best programming languages, this research used
machine learning methods, SHAP and XGBoost, to optimize the network.
Findings The sensitivity analysis of the KPIs verified the causation
importance in PPPs performance management. This study determined the
causal structure of KPIs in PPP projects, assessed each indicator's
priority to performance, and found 7 of them as a critical cluster to
optimize the network. These KPIs include innovation for financing,
feasibility study, macro-environment impact, appropriate financing
option, risk identification, allocation, sharing, and transfer, finance
infrastructure, and compliance with the legal and regulatory framework.
Practical implications Identifying the most scenic indicators helps the
private sector to allocate the limited resources more rationally and
concentrate on the most influential parts of the project. It also
provides the KPIs' critical cluster that should be controlled and
monitored closely by PPP project managers. Additionally, the public
sector can evaluate the performance of the private sector more
accurately. Finally, this research provides a comprehensive causal
insight into the PPPs' performance management that can be used to
develop management systems in future research. Originality/value For the
first time, this research proposes a model to determine the causal
structure of KPIs in PPPs and indicate the importance of this insight.
The developed innovative model identifies the KPIs' behavior and takes a
non-linear approach based on CBN and machine learning methods while
providing valuable information for construction and performance managers
to allocate resources more efficiently.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fest, Isabelle</author><author>Wieringa, Maranke</author><author>Wagner, Ben</author></authors></contributors><titles><title>Paper vs. practice: How legal and ethical frameworks influence public
sector data professionals in the Netherlands</title><secondary-title>PATTERNS</secondary-title></titles><periodical><full-title>PATTERNS</full-title></periodical><volume>3</volume><issue>10</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.patter.2022.100604</electronic-resource-num><language>English</language><urls/><abstract>Recent years have seen a massive growth in ethical and legal frameworks
to govern data science practices. Yet one of the core questions
associated with ethical and legal frameworks is the extent to which they
are implemented in practice. A particularly interesting case in this
context comes to public officials, for whom higher standards typically
exist. We are thus trying to understand how ethical and legal frameworks
influence the everyday practices on data and algorithms of public sector
data professionals. The following paper looks at two cases: public
sector data professionals (1) at municipalities in the Netherlands and
(2) at the Netherlands Police. We compare these two cases based on an
analytical research framework we develop in this article to help
understanding of everyday professional practices. We conclude that there
is a wide gap between legal and ethical governance rules and the
everyday practices.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dunleavy, Patrick</author><author>Evans, Mark</author></authors></contributors><titles><title>Australian administrative elites and the challenges of digital-era
change</title><secondary-title>JOURNAL OF CHINESE GOVERNANCE</secondary-title></titles><periodical><full-title>JOURNAL OF CHINESE GOVERNANCE</full-title></periodical><pages>181-200</pages><volume>4</volume><issue>2, SI</issue><keywords><keyword>Bureaucracy; public service officials; digital; artificial intelligence;
service reform</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1080/23812346.2019.1596544</electronic-resource-num><language>English</language><urls/><abstract>Within long-lived public sector bureaucracies, the organizational
cultures developed by administrative elites have strong filtering and
focusing effects on the kinds of technological changes adopted,
especially in the modern era. Normally seen as very slow-moving and hard
to alter, senior officials' attitudes towards digital changes have
recently begun to alter in more substantial ways in Australia. We review
first a considerable reappraisal of the priority given to digital
changes by top public service managers. This cultural shift has followed
on from tech-lead disruptive societal changes affecting most areas of
government now, and from the rise of global-scaled ICT corporations to
become key management exemplars for officials. Second, we look at the
chequered history of political leaders' interventions to speed up
digital change, showing that in the period 2015-19 Australia witnessed
both the initial power and later limits of such involvement. Finally, we
consider Australia's recent experience with big data/ artificial
intelligence (BDAI), a key area of technological change for public
service officials, but one that in a liberal democracy can also easily
spark public resistance to their plans.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mohamed, Azlinah</author><author>Najafabadi, Maryam Khanian</author><author>Wah, Yap Bee</author><author>Zaman, Ezzatul Akmal Kamaru</author><author>Maskat, Ruhaila</author></authors></contributors><titles><title>The state of the art and taxonomy of big data analytics: view from new
big data framework</title><secondary-title>ARTIFICIAL INTELLIGENCE REVIEW</secondary-title></titles><periodical><full-title>ARTIFICIAL INTELLIGENCE REVIEW</full-title></periodical><pages>989-1037</pages><volume>53</volume><issue>2</issue><keywords><keyword>Parallel and distributed computing; Big data tools; Big data analytics
techniques; Domain area</keyword></keywords><dates><year>2020</year></dates><electronic-resource-num>10.1007/s10462-019-09685-9</electronic-resource-num><language>English</language><urls/><abstract>Big data has become a significant research area due to the birth of
enormous data generated from various sources like social media, internet
of things and multimedia applications. Big data has played critical role
in many decision makings and forecasting domains such as recommendation
systems, business analysis, healthcare, web display advertising,
clinicians, transportation, fraud detection and tourism marketing. The
rapid development of various big data tools such as Hadoop, Storm,
Spark, Flink, Kafka and Pig in research and industrial communities has
allowed the huge number of data to be distributed, communicated and
processed. Big data applications use big data analytics techniques to
efficiently analyze large amounts of data. However, choosing the
suitable big data tools based on batch and stream data processing and
analytics techniques for development a big data system are difficult due
to the challenges in processing and applying big data. Practitioners and
researchers who are developing big data systems have inadequate
information about the current technology and requirement concerning the
big data platform. Hence, the strengths and weaknesses of big data
technologies and effective solutions for Big Data challenges are needed
to be discussed. Hence, due to that, this paper presents a review of the
literature that analyzes the use of big data tools and big data
analytics techniques in areas like health and medical care, social
networking and internet, government and public sector, natural resource
management, economic and business sector. The goals of this paper are to
(1) understand the trend of big data-related research and current frames
of big data technologies; (2) identify trends in the use or research of
big data tools based on batch and stream processing and big data
analytics techniques; (3) assist and provide new researchers and
practitioners to place new research activity in this domain
appropriately. The findings of this study will provide insights and
knowledge on the existing big data platforms and their application
domains, the advantages and disadvantages of big data tools, big data
analytics techniques and their use, and new research opportunities in
future development of big data systems.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Broomfield, Heather</author><author>Reutter, Lisa</author></authors></contributors><titles><title>In search of the citizen in the datafication of public administration</title><secondary-title>BIG DATA &amp; SOCIETY</secondary-title></titles><periodical><full-title>BIG DATA &amp; SOCIETY</full-title></periodical><volume>9</volume><issue>1</issue><keywords><keyword>Public administration; datafication; citizen participation; civil
society; Norway; artificial intelligence</keyword></keywords><dates><year>2022</year></dates><electronic-resource-num>10.1177/20539517221089302</electronic-resource-num><language>English</language><urls/><abstract>The administrative reform of the datafied public administration places
great emphasis on the classification, control, and prediction of citizen
behavior and therefore has the potential to significantly impact
citizen-state relations. There is a growing body of literature on
data-oriented activism which aims to resist and counteract existing
harmful data practices. However, little is known about the processes,
policies, and political-economic structures that make datafication
possible. There is a distinct research gap on situated and
context-specific empirical research, which critically interrogates the
premises, interests, and agendas of data-driven public administration
and how stakeholders can impact them. This paper therefore studies the
conditions of participation in public administration datafication. It
asks the overall research question of how citizens are problematized and
included in policy and practitioner discourse in the datafication of
public administration. The paper takes Norway as its case and applies
Cardullo and Kitchin's scaffold of smart citizen participation at the
system level. It makes use of a unique empirical insight into the field,
consisting of a survey, interviews, and an extensive document analysis.
Unexpectedly, we find that citizens and civil society are rarely engaged
in this administrative reform. Instead, we identify a paternalistic,
top-down, technocratic approach where the context, values, and agendas
of datafication are obscured from the citizen.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Yi-Fan</author><author>Chen, Yu-Che</author><author>Chien, Shih-Yi</author></authors></contributors><titles><title>Citizens' intention to follow recommendations from a
government-supported AI-enabled system</title><secondary-title>PUBLIC POLICY AND ADMINISTRATION</secondary-title></titles><periodical><full-title>PUBLIC POLICY AND ADMINISTRATION</full-title></periodical><keywords><keyword>artificial intelligence; transparency; privacy; technology familiarity;
trust</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1177/09520767231176126</electronic-resource-num><language>English</language><urls/><abstract>Artificial intelligence (AI) applications in public services are an
emerging and crucial issue in the modern world. Many countries utilize
AI-enabled systems to serve citizens and deliver public services.
Although AI can bring more efficiency and responsiveness, this
technology raises privacy and social inequality concerns. From the
perspective of behavioral public administration (BPA), citizens' use of
AI-enabled systems depends on their perception of this technology. This
study proposes a conceptual framework connecting citizens' perceptions,
trust, and intention to follow instructions from the
government-supported AI-enabled recommendation system in the pandemic.
Our study launches an online-based experimental survey and analyzes the
data with the partial least square structural equation model (PLS-SEM).
The research findings suggest that algorithmic transparency increases
trust in the recommendations, but privacy concerns decrease the trust
when the system asks for sensitive information. Additionally, citizens
familiar with technologies are more likely to trust the recommendations
in the feature-based communication strategy. Finally, trust in the
recommendations can mediate the impacts of citizens' perceptions of the
AI system. This study clarifies the effects of perceptions, identifies
the role of trust, and explores the communication strategies in
citizens' intention to follow the AI-enabled system recommendations. The
results can deepen AI research in public administration and provide
policy suggestions for the public sector to develop strategies to
increase policy compliance with system recommendations.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nai, Roberto</author><author>Meo, Rosa</author><author>Morina, Gabriele</author><author>Pasteris, Paolo</author></authors></contributors><titles><title>Public tenders, complaints, machine learning and recommender systems: a
case study in public administration</title><secondary-title>COMPUTER LAW &amp; SECURITY REVIEW</secondary-title></titles><periodical><full-title>COMPUTER LAW &amp; SECURITY REVIEW</full-title></periodical><volume>51</volume><keywords><keyword>Public procurement; Legal prediction; Complaint detection; Knowledge
discovery; Natural language processing; Machine learning; Recommender
system</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.clsr.2023.105887</electronic-resource-num><language>English</language><urls/><abstract>With the proliferation of e-procurement systems in the public sector,
valuable and open information sources can be jointly accessed. Our
research aims to explore different legal Open Data; in particular, we
explored the data set of the National Anti-Corruption Authority in Italy
on public procurement and the judges' sentences related to public
procurement, published on the website of the Italian Administrative
Justice from 2007 to 2022. Our first goal was to train machine learning
models capable of automatically recognizing which procurement has led to
disputes and consequently complaints to the Administrative Justice,
identifying the relevant features of procurement that correspond to
certain anomalies. Our second goal was to develop a recommender system
on procurement to return similar procurement to a given one and find
companies for bidders, depending on the procurement requirements.(c)
2023 Roberto Nai, Rosa Meo, Gabriele Morina, Paolo Pasteris. Published
by Elsevier Ltd. This is an open access article under the CC BY license
( http://creativecommons.org/licenses/by/4.0/ )</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hu, Qian</author><author>Zhong, Wei</author></authors></contributors><titles><title>State-level politicization of crisis communication on Twitter during
COVID-19: Conceptualization, measurement, and impacts</title><secondary-title>PUBLIC ADMINISTRATION REVIEW</secondary-title></titles><periodical><full-title>PUBLIC ADMINISTRATION REVIEW</full-title></periodical><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1111/puar.13653</electronic-resource-num><language>English</language><urls/><abstract>The political dimension of crisis communication remains understudied in
public administration. We defined the politicization of government
crisis communication as the employment of politics-oriented
communication strategies in crisis messaging. We further examined the
state-level politicization occurring during COVID-19 and its influence
on public engagement and policy compliance. We applied machine learning
algorithms to analyze 43,642 Twitter messages posted by fifty US state
governors, assessing the extent to which these governors politicized
crisis communication. We compiled data from multiple sources to explore
the influence of communication politicization on public engagement and
compliance behaviors. While most governors showed major concerns
regarding reputation and blame, their level of politicization and
selection of communication strategies varied. Increased levels of
communication politicization discouraged the public's online engagement
and policy compliance. Excessive levels of political consideration could
undermine the legitimacy and effectiveness of government crisis
communication, and thus an examination of their relationship was
essential.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pautz, Hartwig</author></authors></contributors><titles><title>Policy making and artificial intelligence in Scotland</title><secondary-title>CONTEMPORARY SOCIAL SCIENCE</secondary-title></titles><periodical><full-title>CONTEMPORARY SOCIAL SCIENCE</full-title></periodical><pages>618-636</pages><volume>18</volume><issue>5</issue><keywords><keyword>Artificial intelligence; policy making; Scotland; Big Data</keyword></keywords><dates><year>2023</year></dates><electronic-resource-num>10.1080/21582041.2023.2293822</electronic-resource-num><language>English</language><urls/><abstract>The article presents an exploratory qualitative single case study about
whether and how artificial intelligence (AI) is used by the Scottish
Government, about the key concerns relating to its usage, and about
obstacles to, and drivers of AI usage. Besides the academic literature
and published reports, the analysis rests on 12 semi-structured
interviews. Interviewees include Scottish Government employees, experts
from academia and representatives of commercial and non-commercial AI
and Big Data organisations. The article finds that the Scottish
Government has, so far, made little use of AI. Currently, AI is used in
very limited ways in process automation and for gaining `cognitive
insights' with the human in control. There are no `strategic' AI
applications where advanced reasoning and `decision-making by algorithm'
play a role. Data-driven e-policy making is not currently on the cards.
The reasons are the Scottish Government's wariness of AI, a lack of
`digital maturity' (concerning Big Data and digital infrastructure, but
also expertise) in the public sector, and ethical concerns around the
use of AI. Governments need to conduct a debate about the extent of AI
usage to avoid `AI creep' in their institutions and to assure that AI
does not have negative consequences for democracy.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wilson, Christopher</author><author>Broomfield, Heather</author></authors></contributors><titles><title>Learning how to do AI: managing organizational boundaries in an intergovernmental learning forum</title><secondary-title>Public Management Review</secondary-title></titles><periodical><full-title>Public Management Review</full-title></periodical><pages>1938 - 1957</pages><volume>25</volume><issue>10</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/14719037.2022.2055119</electronic-resource-num><notes>Cited by: 7</notes><research-notes>Cited by: 7</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128713952&amp;doi=10.1080%2F14719037.2022.2055119&amp;partnerID=40&amp;md5=5517e797b2ab66a9a31a06f2ac637ce7</url></web-urls></urls><abstract>This analysis applies boundary theory to public manager efforts to overcome AI capacity gaps through a public sector collaborative learning forum. Administrative and interview data identify the types of knowledge managers are able to access, the types of organizational differences that influence learning, and the strategies public managers use to overcome them. Analysis suggests that unstructured learning fora are better suited to the transfer of tacit procedural knowledge than declarative knowledge about AI, and emphasizes the importance of social trust and network structure to overcome knowledge gaps through peer learning.  2022 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Senalp, Fatih Mehmet</author><author>Ceylan, Murat</author></authors></contributors><titles><title>A new approach for super-resolution and classification applications on neonatal thermal images</title><secondary-title>Quantitative InfraRed Thermography Journal</secondary-title></titles><periodical><full-title>Quantitative InfraRed Thermography Journal</full-title></periodical><pages>172 - 189</pages><volume>21</volume><issue>3</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1080/17686733.2023.2179282</electronic-resource-num><notes>Cited by: 5</notes><research-notes>Cited by: 5</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149387420&amp;doi=10.1080%2F17686733.2023.2179282&amp;partnerID=40&amp;md5=08851044f856307c5f95ac29c080fb26</url></web-urls></urls><abstract>Thermal imaging systems are harmless to human health and enable contactless heat measurements. The thermal cameras are used in many public sectors where it is necessary to detect the change of temperature values. However, thermal cameras are costly and produce images with low edge information. This situation prevents the widespread use of thermal cameras. Therefore, in recent years, the researches to advance the quality of thermal images have increased. Within the scope of the studies in this paper, first of all, three different datasets consisting of thermal images in the colourful format of neonates were created. Also, TSRGAN+ deep network model was presented for super-resolution studies. The super-resolution images obtained visually approached ground truth images to a great extent. In addition, these results were compared using the peak signal to noise ratio (PSNR) and the structural similarity index measure (SSIM) image quality metrics. The proposed model showed a superior success in terms of the values of PSNR and SSIM compared to the state-of-the-art models. Here, the PSNR value of the proposed TSRGAN+ model increased by 11.5 dB compared to the TSRGAN network architecture, while the SSIM value increased by around 23%. Finally, the unhealthy-healthy image classification applications were performed on all thermal image sets in order to implement both the task-based evaluation and a real-life application. Thus, a new method is presented to evaluate the results of the super-resolution studies. Here, firstly, a CNN-based classifier was designed and the classification metrics were obtained for all three datasets. Then, transfer learning was applied using state-of-the-art models (ResNet101, Xception) to increase classification success. Here, the most successful results were obtained in applications using the ResNet101 model. Also, the developed model outperformed the TSRGAN, which achieved the second-best result. When all the obtained results are evaluated, it has been observed that the super-resolution models increase the success of unhealthy-healthy classification by about 10% compared to the low resolution images. In other words, the effects of super-resolution techniques on classification applications are clearly seen. In summary, the logical use of the super-resolution research will enable the common use of low-cost thermal cameras in the application fields such as medicine.  2023 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gupta, Meenu</author><author>Chaudhary, Gopal</author><author>Bansal, Dhruvi</author><author>Pandey, Shashwat</author></authors></contributors><titles><title>DTLMV2A real-time deep transfer learning mask classifier for overcrowded spaces</title><secondary-title>Applied Soft Computing</secondary-title></titles><periodical><full-title>Applied Soft Computing</full-title></periodical><volume>127</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.asoc.2022.109313</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134886926&amp;doi=10.1016%2Fj.asoc.2022.109313&amp;partnerID=40&amp;md5=9f3d84027554d2d95b6c0037f607c01a</url></web-urls></urls><abstract>Through the commencement of the COVID-19 pandemic, the whole globe is in disarray and debating on unique approaches to stop this viral transmission. Masks are being worn by people all around the world as one of the preventative measures to avoid contracting this sickness. Although some people are following and adopting this precaution, others are not, despite official recommendations from the administration and public health organisations has been announced. In this paper DTLMV2 (Deep Transfer Learning MobileNetV2 for the objective of classification) is proposed - A face mask identification model that can reliably determine whether an individual is wearing a mask or not is suggested and implemented in this work. The model architecture employs the peruse of MobileNetV2, a lightweight Convolutional Neural Network (CNN) that requires less computing power and can be readily integrated into computer vision and mobile systems. The computer vision with MobileNet is required to formulate a low-cost mask detection system for a group of people in open spaces that can assist in determining whether a person is wearing a mask or not, as well as function as a surveillance system since it is effective on both real-time pictures and videos. The face recognition model obtained 97.01% accuracy on validation data, 98% accuracy on training data and 97.45% accuracy on testing data.  2022 Elsevier B.V.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Saloner, Brendan</author><author>Chang, Hsien-Yen</author><author>Krawczyk, Noa</author><author>Ferris, Lindsey</author><author>Eisenberg, Matthew</author><author>Richards, Thomas</author><author>Lemke, Klaus</author><author>Schneider, Kristin E</author><author>Baier, Michael</author><author>Weiner, Jonathan P</author></authors></contributors><titles><title>Predictive Modeling of Opioid Overdose Using Linked Statewide Medical and Criminal Justice Data</title><secondary-title>JAMA Psychiatry</secondary-title></titles><periodical><full-title>JAMA Psychiatry</full-title></periodical><pages>1155 - 1162</pages><volume>77</volume><issue>11</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1001/jamapsychiatry.2020.1689</electronic-resource-num><notes>Cited by: 30</notes><research-notes>Cited by: 30</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089739259&amp;doi=10.1001%2Fjamapsychiatry.2020.1689&amp;partnerID=40&amp;md5=064a0896e421cd491264f593ab30b35a</url></web-urls></urls><abstract>Importance: Responding to the opioid crisis requires tools to identify individuals at risk of overdose. Given the expansion of illicit opioid deaths, it is essential to consider risk factors across multiple service systems. Objective: To develop a predictive risk model to identify opioid overdose using linked clinical and criminal justice data. Design, Setting, and Participants: A cross-sectional sample was created using 2015 data from 4 Maryland databases: All-payer hospital discharges, the prescription drug monitoring program (PDMP), public-sector specialty behavioral treatment, and criminal justice records for property or drug-associated offenses. Maryland adults aged 18 to 80 years with records in any of 4 databases were included, excluding individuals who died in 2015 or had a non-Maryland zip code. Logistic regression models were estimated separately for risk of fatal and nonfatal opioid overdose in 2016. Model performance was assessed using bootstrapping. Data analysis took place from February 2018 to November 2019. Exposures: Controlled substance prescription fills and hospital, specialty behavioral health, or criminal justice encounters. Main Outcomes and Measures: Fatal opioid overdose defined by the state medical examiner and 1 or more nonfatal overdoses treated in Maryland hospitals during 2016. Results: There were 2294707 total individuals in the sample, of whom 42.3% were male (n = 970019) and 53.0% were younger than 50 years (647083 [28.2%] aged 18-34 years and 568160 [24.8%] aged 35-49 years). In 2016, 1204 individuals (0.05%) in the sample experienced fatal opioid overdose and 8430 (0.37%) experienced nonfatal opioid overdose. In adjusted analysis, the factors mostly strongly associated with fatal overdose were male sex (odds ratio [OR], 2.40 [95% CI, 2.08-2.76]), diagnosis of opioid use disorder in a hospital (OR, 2.93 [95% CI, 2.17-3.80]), release from prison in 2015 (OR, 4.23 [95% CI, 2.10-7.11]), and receiving opioid addiction treatment with medication (OR, 2.81 [95% CI, 2.20-3.86]). Similar associations were found for nonfatal overdose. The area under the curve for fatal overdose was 0.82 for a model with hospital variables, 0.86 for a model with both PDMP and hospital variables, and 0.89 for a model that further added behavioral health and criminal justice variables. For nonfatal overdose, the area under the curve using all variables was 0.85. Conclusions and Relevance: In this analysis, fatal and nonfatal opioid overdose could be accurately predicted with linked administrative databases. Hospital encounter data had higher predictive utility than PDMP data. Model performance was meaningfully improved by adding PDMP records. Predictive models using linked databases can be used to target large-scale public health programs..  2020 American Medical Association. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bolton, Mitzi</author><author>Mintrom, Michael</author></authors></contributors><titles><title>RegTech and creating public value: opportunities and challenges</title><secondary-title>Policy Design and Practice</secondary-title></titles><periodical><full-title>Policy Design and Practice</full-title></periodical><pages>266 - 282</pages><volume>6</volume><issue>3</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/25741292.2023.2213059</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159315954&amp;doi=10.1080%2F25741292.2023.2213059&amp;partnerID=40&amp;md5=f4dcee5821e068d8c6016e567963641f</url></web-urls></urls><abstract>Regulatory technology (RegTech) has its origins in private sector applications of information technology in pursuit of more efficient compliance with government regulations. Initially, the term RegTech referred to either the technical solutions intended to aid financial service providers in managing regulatory issues or to the companies and organizations that develop and deliver such solutions. Increasingly, regulatory experts are stretching the terms coverage to include efforts by governments to harness technical solutions in pursuit of more efficient targeting and conduct of regulatory monitoring and enforcement. Whether deployed within the private or public sectors, RegTech holds significant potential to improve regulatory compliance, reduce compliance costs, and improve the speed and accuracy with which known harms can be addressed and emerging risks can be identified. Here, we focus on the potential for RegTech to support the creation of public value. We suggest public value is most likely to be realized when governments (1) keep focused on regulatory purpose and effective design and (2) build effective collaboration with RegTech providers and regulated entities.  2023 The Author(s). Published by Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fazekas, Mihly</author><author>King, Lawrence Peter</author></authors></contributors><titles><title>Perils of development funding? The tale of EU Funds and grand corruption in Central and Eastern Europe</title><secondary-title>Regulation and Governance</secondary-title></titles><periodical><full-title>Regulation and Governance</full-title></periodical><pages>405 - 430</pages><volume>13</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1111/rego.12184</electronic-resource-num><notes>Cited by: 29</notes><research-notes>Cited by: 29</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041900170&amp;doi=10.1111%2Frego.12184&amp;partnerID=40&amp;md5=8a093c7130a286513dde84a0dd35eaa8</url></web-urls></urls><abstract>Given the unprecedented scale of intergovernmental development funding and the importance of institutional quality for human well-being, it is imperative to precisely understand the impact of development funds on corruption. In Europe, European Union (EU) Funds provide a boost to public spending in recipient member states while introducing additional corruption controls. We investigate whether EU Funds increase high-level corruption in the Czech Republic and Hungary in 20092012. We analyze newly collected data from over 100,000 public procurement contracts to develop objective corruption risk indicators and link them to agency level data in the public sector. Propensity score matching estimations suggest that EU funds increase corruption risk by up to 34 percent. The negative effects are largely attributable to overly formalistic compliance and EU Funds overriding domestic accountability mechanisms in public organizations entirely dependent on external funds. The policy implications are profound: governments should reduce barriers to market entry by lowering red tape and prevent excessive concentration of funds.  2018 John Wiley &amp; Sons Australia, Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Koloniaris, Stavros</author><author>Kousiouris, George</author><author>Anagnostopoulos, Dimosthenis</author><author>Nikolaidou, Mara</author><author>Tserpes, Konstantinos</author></authors></contributors><titles><title>Survey-based investigation, feature extraction and classification of Greek municipalities maturity for open source adoption and migration prospects</title><secondary-title>Journal of Systems and Software</secondary-title></titles><periodical><full-title>Journal of Systems and Software</full-title></periodical><volume>158</volume><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.jss.2019.110431</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072785004&amp;doi=10.1016%2Fj.jss.2019.110431&amp;partnerID=40&amp;md5=cca537c4a58be9a2bda5ab66a1ae4b2f</url></web-urls></urls><abstract>While FOSS solutions have attracted a significant amount of attention, alongside with necessary and growing IT related expenditure for the digitalization of public administration, authorities face the question of whether migration to such solutions is feasible and/or worthwhile. The purpose of the presented work is to analyze existing domain research and extract key features, grouped in three major areas (namely Readiness, Ease of Use and Gain from migration), that should be investigated prior to a migration attempt. Following and building upon an extensive survey on Greek municipalities, the latter are categorized via the k-means non-supervised machine learning method to 3 levels of maturity regarding candidate participation in relevant projects. A combined scoring approach, based on similar features of the target FOSS solution as well as the aforementioned municipality categorization, is presented in order to detect a priori good candidate combinations (municipality and software) for minimizing a migration project risk. The method is validated through the aforementioned survey on municipalities with confirmed FOSS usage, indicating that selection in the proposed organized manner can aid in harvesting FOSS benefits. Furthermore, it is compared against a popular maturity model method (BPMMM) in order to comment on the applicability and classification process.  2019</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Engstrom, David Freeman</author><author>Ho, Daniel E</author></authors></contributors><titles><title>Algorithmic accountability in the administrative state</title><secondary-title>Yale Journal on Regulation</secondary-title></titles><periodical><full-title>Yale Journal on Regulation</full-title></periodical><pages>800 - 854</pages><volume>37</volume><issue>3</issue><keywords/><dates><year>2020</year></dates><notes>Cited by: 35</notes><research-notes>Cited by: 35</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096213987&amp;partnerID=40&amp;md5=f24bf27a1c8c3a193349764eb0bd350f</url></web-urls></urls><abstract>How will artificial intelligence (AI) transform government? Stemming from a major study commissioned by the Administrative Conference of the United States (ACUS), we highlight the promise and trajectory of algorithmic tools used by federal agencies to perform the work of governance. Moving past the abstract mappings of transparency measures and regulatory mechanisms that pervade the current algorithmic accountability literature, our analysis centers around a detailed technical account of a pair of current applications that exemplify AI's move to the center of the redistributive and coercive power of the state: the Social Security Administration's use of AI tools to adjudicate disability benefits cases and the Securities and Exchange Commission's use of AI tools to target enforcement efforts under federal securities law. We argue that the next generation of work will need to push past a narrow focus on constitutional law and instead engage with the broader terrain of administrative law, which is far more likely to modulate use of algorithmic governance tools going forward. We demonstrate the shortcomings of conventional ex ante and ex post review under current administrative law doctrines and then consider how those doctrines might adapt in response. Finally, we ask how else to build a sensible accountability structure around public sector use of algorithmic governance tools while maintaining incentives and opportunities for salutary innovation. Reviewing some commonly offered solutions, we propose a further and novel approach to oversight centered on prospective benchmarking. By requiring agencies to reserve a random set of cases for manual decision making, benchmarking offers a concrete and accessible test of the validity and legality of machine outputs, enabling agencies, courts, and the public to learn about, validate, and correct errors in algorithmic decision making.  2020 Yale Journal on Regulation. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aerts, Ann</author><author>Bogdan-Martin, Doreen</author></authors></contributors><titles><title>Leveraging data and AI to deliver on the promise of digital health</title><secondary-title>International Journal of Medical Informatics</secondary-title></titles><periodical><full-title>International Journal of Medical Informatics</full-title></periodical><volume>150</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.ijmedinf.2021.104456</electronic-resource-num><notes>Cited by: 24</notes><research-notes>Cited by: 24</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104593451&amp;doi=10.1016%2Fj.ijmedinf.2021.104456&amp;partnerID=40&amp;md5=5f038d694972617af3b3d92f70ca9ad9</url></web-urls></urls><abstract>Rising rates of NCDs threaten fragile healthcare systems in low- and middle-income countries. Fortunately, new digital technology provides tools to more effectively address the growing dual burden of disease. Two-thirds of the world's population subscribed to mobile services by the end of 2018, while the falling price of connectivity and the 5G networks rollout promise to accelerate the use of digital technology. Properly leveraged, we can employ digital solutions and applications to transform health systems from reactive to proactive and even preventive, helping people stay healthy. With artificial intelligence (AI), health systems can be made more predictive by detecting risk factors and helping health professionals respond faster to prevent disease. Yet this rapid pace of growth has also complicated the digital health landscape. Myriad digital health apps compete and overlap in the public and private sectors, and significant gaps in the collection and analysis of digital data threaten to leave some behind. Established in 2010, the Broadband Commission for Sustainable Development is led by ITU and UNESCO and advocates for the transformational impact of broadband technologies for development. Its working group on digital and AI in health, co-chaired by the Novartis Foundation and at different times Nokia, Intel and Microsoft, identifies best practices for countries to realize the potential of digital technology in health and care. Interviewing more than 100 key stakeholders and reviewing over 200 documents, the Working Group set out to identify common challenges that countries face in implementing digital health solutions, and to develop a framework that countries can use to build systems for supporting digital health solutions. Common challenges include a lack of coordination leading to fragmented digital health solutions; lack of systems and workforce capacity to manage data and digital technology, and inadequate financing to support digital health. The working group proposes six building blocks for digital health systems: formulate and execute a national digital health strategy; create policy and regulatory frameworks that support innovation while protecting security and privacy; ensure access to digital infrastructure; ensure interoperability of digital health system components; establish effective partnerships; and sustain adequate financing.  2021</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Conejero, Jose Mara</author><author>Preciado, Juan Carlos</author><author>Fernndez-Garca, Antonio Jess</author><author>Prieto, Alvaro E</author><author>Rodrguez-Echeverra, Roberto</author></authors></contributors><titles><title>Towards the use of Data Engineering, Advanced Visualization techniques and Association Rules to support knowledge discovery for public policies</title><secondary-title>Expert Systems with Applications</secondary-title></titles><periodical><full-title>Expert Systems with Applications</full-title></periodical><volume>170</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.eswa.2020.114509</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099203384&amp;doi=10.1016%2Fj.eswa.2020.114509&amp;partnerID=40&amp;md5=4128dc687f091e1ea31b108141d34243</url></web-urls></urls><abstract>Education and employment are key aspects of a country's well-being. Governments expend valuable resources on designing education plans and employment programs. These two aspects are usually analysed separately, although, as they are closely related, considering them together might improve their efficacy. The problem lies, at least in part, in the fact that different public entities manage their own data with their own isolated systems, and do not develop joint educational and employment policies. In order to facilitate working towards this goal, in this manuscript, we make use of Data Engineering, Data Visualization, and Intelligent Data Analytics methods to create a decision support system for the Government of Extremadura. Extremadura is a European Union Objective 1 region in Spain with high rates of unemployment and secondary school drop-out. Data Engineering is used to create a Data Warehouse that unifies the different data sources into a central repository for quick access and control. This allows dealing with the challenge of transforming, processing, storing and accessing the data. Data Visualization techniques are applied to create an interactive dashboard that assists users in analysing and interpreting the data in the Data Warehouse repository. Thus, charts, diagrams, and maps are created specifically to help technical or political decision-makers. Finally, Intelligent Data Analytics techniques are used to incorporate Association Rules into the visualization dashboard. Its goal is to identify associations, relationships, and patterns in data that, at least in plain sight, are not readable or interpretable by humans. It does this by inferring knowledge that humans cannot pick out by themselves. As a result, a complete system was defined and implemented to support public administrations in their decision-making and definition of precise evidence-based policies in the areas of education and employment. In particular, it allows the definition of unified strategies to reduce the unemployment rate.  2020 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Abubakar, Muhammad</author><author>Che, Yanbo</author><author>Faheem, Muhammad</author><author>Bhutta, Muhammad Shoaib</author><author>Mudasar, Abdul Qadeer</author></authors></contributors><titles><title>Intelligent Modeling and Optimization of Solar Plant Production Integration in the Smart Grid Using Machine Learning Models</title><secondary-title>Advanced Energy and Sustainability Research</secondary-title></titles><periodical><full-title>Advanced Energy and Sustainability Research</full-title></periodical><volume>5</volume><issue>4</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1002/aesr.202300160</electronic-resource-num><notes>Cited by: 5</notes><research-notes>Cited by: 5</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182808271&amp;doi=10.1002%2Faesr.202300160&amp;partnerID=40&amp;md5=b355c04ec90d1f822c2043962d051941</url></web-urls></urls><abstract>To address the rising energy demands in industrial and public sectors, integrating zero-carbon emission energy sources into the power grid is crucial. Smart grids, equipped with advanced sensing, computing, and communication technologies, offer an efficient way to incorporate renewable energy resources and manage power systems effectively. However, improving solar energy efficiency, which currently contributes around 3.6% to global electricity, is a challenge in smart grid infrastructures. This research tackles this issue by deploying machine learning models, specifically recurrent neural network (RNN), long short-term memory (LSTM), and gate recurrent unit (GRU), to predict measurements that could enhance solar power generation in smart grids. The objective is to boost both performance and accuracy of solar power generation in the smart grid. The study conducts experimental analyses and performance evaluations of these models in smart grid environments, considering factors like power output, irradiance, and performance ratio. The results, presented through graphical visualizations, show notable improvements, particularly with the LSTM model, which achieves a 97% accuracy, outperforming the RNN and GRU models. This outcome highlights the LSTM model's effectiveness in accurately predicting measurements, thereby advancing solar power generation efficiency in the smart grid framework.  2024 The Authors. Advanced Energy and Sustainability Research published by Wiley-VCH GmbH.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Intezari, Ali</author><author>Gressel, Simone</author></authors></contributors><titles><title>Information and reformation in KM systems: big data and strategic decision-making</title><secondary-title>Journal of Knowledge Management</secondary-title></titles><periodical><full-title>Journal of Knowledge Management</full-title></periodical><pages>71 - 91</pages><volume>21</volume><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1108/JKM-07-2015-0293</electronic-resource-num><notes>Cited by: 104</notes><research-notes>Cited by: 104</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014758737&amp;doi=10.1108%2FJKM-07-2015-0293&amp;partnerID=40&amp;md5=9376ebd8aa0b4ea702a11c0d9f2d33d9</url></web-urls></urls><abstract>Purpose: The purpose of this paper is to provide a theoretical framework of how knowledge management (KM) systems can facilitate the incorporation of big data into strategic decisions. Advanced analytics are becoming increasingly critical in making strategic decisions in any organization from the private to public sectors and from for-profit companies to not-for-profit organizations. Despite the growing importance of capturing, sharing and implementing peoples knowledge in organizations, it is still unclear how big data and the need for advanced analytics can inform and, if necessary, reform the design and implementation of KM systems. Design/methodology/approach: To address this gap, a combined approach has been applied. The KM and data analysis systems implemented by companies were analyzed, and the analysis was complemented by a review of the extant literature. Findings: Four types of data-based decisions and a set of ground rules are identified toward enabling KM systems to handle big data and advanced analytics. Practical implications: The paper proposes a practical framework that takes into account the diverse combinations of data-based decisions. Suggestions are provided about how KM systems can be reformed to facilitate the incorporation of big data and advanced analytics into organizations strategic decision-making. Originality/value: This is the first typology of data-based decision-making considering advanced analytics.  2017,  Emerald Publishing Limited.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Smith, Catherine</author><author>Vajdic, Claire M</author><author>Stephenson, Niamh</author></authors></contributors><titles><title>Techno-legal expertise and the datafication of the state: Big data, accountability and the value of a social license with institutional roots</title><secondary-title>Futures</secondary-title></titles><periodical><full-title>Futures</full-title></periodical><volume>154</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.futures.2023.103263</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174354062&amp;doi=10.1016%2Fj.futures.2023.103263&amp;partnerID=40&amp;md5=8fa384c6c2cea48a44b7d9e36b18027d</url></web-urls></urls><abstract>As governments around the world become increasingly datafied, debates are emerging about the best ways to attend to the complex socio-political implications of big data and the datafication of the state. Drawing on semi-structured interviews with senior executives and data experts within Australian government agencies, high-level privacy experts, and other experts in public sector data integration, this article examines how a sociotechnical imaginary about data-driven, democratic government acts within and alongside routinely bureaucratised forms of techno-legal risk management to inform the work of Australia's data integration experts. Notably, these techno-legal experts recognised the limitations of techno-legal data management, and mobilised notions of the social license when seeking to (re)orient the trajectories of data integration towards the democratic, data-driven government they envisage. Contributing to debates about the datafication of the state, we argue that while a social license will not be a panacea to all the complexities of datafication, a social license with institutional roots is essential to deepen accountability towards publics, and to help ensure that datafication can be co-produced by, and reflective of, the sociotechnical futures envisaged by a broader range of publics.  2023 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Al-Ruithe, Majid</author><author>Benkhelifa, Elhadj</author></authors></contributors><titles><title>Determining the enabling factors for implementing cloud data governance in the Saudi public sector by structural equation modelling</title><secondary-title>Future Generation Computer Systems</secondary-title></titles><periodical><full-title>Future Generation Computer Systems</full-title></periodical><pages>1061 - 1076</pages><volume>107</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.future.2017.12.057</electronic-resource-num><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040984891&amp;doi=10.1016%2Fj.future.2017.12.057&amp;partnerID=40&amp;md5=4605d7f9ba5bdaab23dd40e69c3d96f3</url></web-urls></urls><abstract>Businesses have grown more sophisticated in their use of data, which drives new demands that require different ways to handle this data. Data management solutions on their own are becoming very expensive and unable to cope with the reality of everlasting data complexity. Forward-thinking organisations believe that the only way to solve the data problem will be the implementation of effective data governance. Attempts to govern data failed before, as they were driven by information technology (IT), and affected by rigid processes and fragmented activities carried out on a system-by-system basis. Until very recently, governance remained mostly informal, with very ambiguous and generic regulations in silos around specific enterprise repositories, lacking structure and the wider support of the organisation. Despite its highly recognised importance, the area of data governance is still underdeveloped and under-researched. In the cloud computing context, the cloud brings new issues of data governance, where the loss of governance is one of the top risks of cloud computing. Thus, before adopting the cloud, the organisations should develop a cloud data governance programme. It is important, therefore, to understand the enabling factors for successful implementation of cloud data governance in organisations. However, as every organisation has its own constraints and requirements, the phrase no one size fits all applies in this case. This study focuses on the case of the public sector in the Kingdom of Saudi Arabia. Therefore, the aim of this research is to identify the enabling factors in adopting and implementing cloud data governance in the Saudi public sector. The study's sample covered the largest and most important Saudi public sector organisations, with questionnaires distributed to relevant employees. The results of the study were based on 206 respondents, and structural equation modelling (SEM) was used to evaluate these results.  2018 Elsevier B.V.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aggarwal, Ajay</author><author>Court, Laurence Edward</author><author>Hoskin, Peter</author><author>Jacques, Isabella</author><author>Kroiss, Mariana</author><author>Laskar, Sarbani</author><author>Lievens, Yolande</author><author>Mallick, Indranil</author><author>Abdul Malik, Rozita</author><author>Miles, Elizabeth</author><author>Mohamad, Issa</author><author>Murphy, Claire</author><author>Nankivell, Matthew</author><author>Parkes, Jeannette</author><author>Parmar, Mahesh</author><author>Roach, Carol</author><author>Simonds, Hannah</author><author>Torode, Julie</author><author>Vanderstraeten, Barbara</author><author>Langley, Ruth</author></authors></contributors><titles><title>ARCHERY: a prospective observational study of artificial intelligence-based radiotherapy treatment planning for cervical, head and neck and prostate cancer - study protocol</title><secondary-title>BMJ Open</secondary-title></titles><periodical><full-title>BMJ Open</full-title></periodical><volume>13</volume><issue>12</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1136/bmjopen-2023-077253</electronic-resource-num><notes>Cited by: 4</notes><research-notes>Cited by: 4</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179808654&amp;doi=10.1136%2Fbmjopen-2023-077253&amp;partnerID=40&amp;md5=6afd1c0c8fc4ce9db271e81fc66fdb41</url></web-urls></urls><abstract>Introduction Fifty per cent of patients with cancer require radiotherapy during their disease course, however, only 10%-40% of patients in low-income and middle-income countries (LMICs) have access to it. A shortfall in specialised workforce has been identified as the most significant barrier to expanding radiotherapy capacity. Artificial intelligence (AI)-based software has been developed to automate both the delineation of anatomical target structures and the definition of the position, size and shape of the radiation beams. Proposed advantages include improved treatment accuracy, as well as a reduction in the time (from weeks to minutes) and human resources needed to deliver radiotherapy. Methods ARCHERY is a non-randomised prospective study to evaluate the quality and economic impact of AI-based automated radiotherapy treatment planning for cervical, head and neck, and prostate cancers, which are endemic in LMICs, and for which radiotherapy is the primary curative treatment modality. The sample size of 990 patients (330 for each cancer type) has been calculated based on an estimated 95% treatment plan acceptability rate. Time and cost savings will be analysed as secondary outcome measures using the time-driven activity-based costing model. The 48-month study will take place in six public sector cancer hospitals in India (n=2), Jordan (n=1), Malaysia (n=1) and South Africa (n=2) to support implementation of the software in LMICs. Ethics and dissemination The study has received ethical approval from University College London (UCL) and each of the six study sites. If the study objectives are met, the AI-based software will be offered as a not-for-profit web service to public sector state hospitals in LMICs to support expansion of high quality radiotherapy capacity, improving access to and affordability of this key modality of cancer cure and control. Public and policy engagement plans will involve patients as key partners.   2023 BMJ. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bonci, Andrea</author><author>Clini, Paolo</author><author>Martin, Rafael</author><author>Pirani, Massimiliano</author><author>Quattrini, Ramona</author><author>Raikov, Alexander</author></authors></contributors><titles><title>Collaborative intelligence cyber-physical system for the valorization and re-use of cultural heritage</title><secondary-title>Journal of Information Technology in Construction</secondary-title></titles><periodical><full-title>Journal of Information Technology in Construction</full-title></periodical><pages>305 - 323</pages><volume>23</volume><issue>1</issue><keywords/><dates><year>2018</year></dates><notes>Cited by: 7</notes><research-notes>Cited by: 7</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060091336&amp;partnerID=40&amp;md5=43b22a313731fabe7b0ab641577170b4</url></web-urls></urls><abstract>This paper is a proposition of methodological and technological approaches that try to constitute a framework that introduces modern artificial intelligence (AI) technologies for decision-making in the adaptive reuse of cultural heritage (CH) processes. The research aims to accelerate and improve the quality of adaptive CH re-use. The complexity of the problem derives from some causes of different nature: lack of attention to this problem from the public administration and private investors; decision-making processes complicated by the need to connect with experts, located in different countries. Most professionals, related to the CH management, cannot access detailed data about already existing successful initiatives. The specific objective and goal of the research is the creation of an AI framework and eco-system for supporting the development and implementation of innovative business and governance models to fill up the investment gap in the adaptive re-use practices. The paper shortly describes the first steps for creating a platform designed and developed to assist and advice public entities, networked experts, private entrepreneurs and citizens in actions aiming at the valorisation of the historic and CH asset and its integration in different groups of countries to boost growth, job opportunities and social benefits, under overall sustainability constraints. The technical solutions here adopted are based on convergent methodology and networked expertise (e-expertise) technology, open data models and active knowledge extraction and processing, machine learning, collective intelligence, recommendation systems and predictive analytics, CH adaptive re-use, innovation business, and models and case-based reasoning methods. Examples of case studies giving the inception for the project components are given.  2018 The author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Beccali, Marco</author><author>Ciulla, Giuseppina</author><author>Lo Brano, Valerio</author><author>Galatioto, Alessandra</author><author>Bonomolo, Marina</author></authors></contributors><titles><title>Artificial neural network decision support tool for assessment of the energy performance and the refurbishment actions for the non-residential building stock in Southern Italy</title><secondary-title>Energy</secondary-title></titles><periodical><full-title>Energy</full-title></periodical><pages>1201 - 1218</pages><volume>137</volume><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1016/j.energy.2017.05.200</electronic-resource-num><notes>Cited by: 78</notes><research-notes>Cited by: 78</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020622964&amp;doi=10.1016%2Fj.energy.2017.05.200&amp;partnerID=40&amp;md5=e564d4b49f6e31721ba652253de94206</url></web-urls></urls><abstract>The public buildings sector represents one of the most intensive items of EU energy consumption; the application of retrofit solutions in existing buildings is a crucial way to reduce its impact. To facilitate the knowledge of the energy performance of existing non-residential buildings and the choice of the more adequate actions, Public Administrations (PA) should have the availability of proper tools. Within the Italian project POI 2007-13, a database and a decision support tool, for easy use, even to a non-technical user, have been developed. A large set of data, obtained from the energy audits of 151 existing public buildings located in four regions of South Italy have been analysed, elaborated, and organised in a database. This was used to identify the best architectures of two ANNs and to train them. The first ANN provides the actual energy performance of any building; the second ANN assesses key economic indicators. A decision support tool, based on the use of these ANNs is conceived for a fast prediction of the energy performance of buildings and for a first selection of energy retrofit actions that can be applied.  2017 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Liu, Mengxuan</author><author>Yang, Chunxia</author><author>Fan, Zhaoxiang</author><author>Yuan, Chao</author></authors></contributors><titles><title>Prediction approach on pedestrian outdoor activity preference under factors of public open space integrated microclimate</title><secondary-title>Building and Environment</secondary-title></titles><periodical><full-title>Building and Environment</full-title></periodical><volume>244</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.buildenv.2023.110761</electronic-resource-num><notes>Cited by: 5</notes><research-notes>Cited by: 5</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168804750&amp;doi=10.1016%2Fj.buildenv.2023.110761&amp;partnerID=40&amp;md5=eb3c1b851beac1b94a33c237ff92ceb3</url></web-urls></urls><abstract>This study conducted measurements of microclimates and investigations of spatial environments and human activities in six typical waterfront public spaces in Shanghai. The aim was to explore the synergistic influence mechanism of public open space (POS) integrated microclimate (POSIM) on pedestrians activities to predict the utilization of public space. The measurement period was during the spring and early summer when outdoor activities were more diversified. 121 observation points were set up in urban waterfront public spaces, and an outdoor activity characteristic database of 25,583 people was established. In addition, multiple linear regression and nonlinear neural network models were introduced to analyze data from different types of activities to calculate the fitness of the models and the influence weights of the variables. The results indicated that the neural network had stronger predictive ability for the spatial integration of microclimate demands of different activities. The prediction degree for strolling and sitting activities was the highest, with R2 (goodness of fit) of 0.704 and 0.844, respectively, while the prediction degree for viewing and sports activities was lower (R2 &lt; 0.5). This study integrated the synergistic influence of urban waterfront public open spaces and microclimates factors on pedestrian outdoor activities to predict the preference patterns of different activities for spatial types. Focus on the requirements of space occupants, this study analyzed the public space environment from the bottom up and provided reference and inspiration for subsequent design optimization of urban waterfront areas.  2023 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Smidt, Esther</author><author>Mei Cheong, Cecilia Yin</author><author>Dachroeden, Emily</author><author>Kochem, Timothy</author></authors></contributors><titles><title>The meaning of quality in online/blended courses to American and Malaysian administrators, faculty, and students</title><secondary-title>International Journal of Distance Education Technologies</secondary-title></titles><periodical><full-title>International Journal of Distance Education Technologies</full-title></periodical><pages>45 - 58</pages><volume>17</volume><issue>2</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.4018/IJDET.2019040103</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073902485&amp;doi=10.4018%2FIJDET.2019040103&amp;partnerID=40&amp;md5=a208fd3d30da328350c87ccd66998a56</url></web-urls></urls><abstract>This article compares two studies, investigating administrator, faculty, and student perceptions of quality in online/blended courses conducted in two different contexts, namely (1) two midsize public universities in the United States, and (2) a college in a public university in Malaysia. The research question explored in both studies was: What is the meaning of quality in an online/blended course to administrators, faculty, and students? Survey data from the three constituents in both contexts were obtained. Qualitative data analysis revealed the top 7-8 quality features of each context as ranked by number of references. The results revealed similarities and differences in the rankings of the quality features between constituents and between contexts. Similarities suggested that different constituents had different priorities with regards to quality features while differences appeared to be based on where each institution was on their distance education trajectory. These findings should be considered and reflected on in online course design, teaching strategies, and student support. Copyright  2019, IGI Global.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Li, Chaoran</author><author>Han, Xianjie</author><author>Zhang, Qiang</author><author>Li, Menghan</author><author>Rao, Zhonghao</author><author>Liao, Wei</author><author>Liu, Xiaori</author><author>Liu, Xinjian</author><author>Li, Gang</author></authors></contributors><titles><title>State-of-health and remaining-useful-life estimations of lithium-ion battery based on temporal convolutional network-long short-term memory</title><secondary-title>Journal of Energy Storage</secondary-title></titles><periodical><full-title>Journal of Energy Storage</full-title></periodical><volume>74</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.est.2023.109498</electronic-resource-num><notes>Cited by: 12</notes><research-notes>Cited by: 12</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175293019&amp;doi=10.1016%2Fj.est.2023.109498&amp;partnerID=40&amp;md5=40076172fc24f5d07aa4227559568cf5</url></web-urls></urls><abstract>Accurate estimations in state of health (SOH) and remaining useful life (RUL) are significant for safe and efficient operation of batteries. With the development of big data and deep learning technology, the neural network method has been widely used for SOH and RUL estimations because of its excellent nonlinear mapping performance, adaptive performance and self-learning performance. In this paper, a novel hybrid model based on temporal convolutional network-long short-term memory (TCN-LSTM) for SOH and RUL estimations is proposed. The hyperparameters of each layer in the model are optimized using Bayesian optimization algorithm. Three different models, including convolutional neural network-long short-term memory (CNN-LSTM) model, temporal convolutional network (TCN) model and long short-term memory (LSTM) model, are adopted as comparisons to evaluate the performance of the proposed model. All the models are tested using two public battery datasets from National Aeronautics and Space Administration (NASA dataset) and Oxford University (OX dataset). In SOH task, the TCN-LSTM model achieves an accuracy improvement of &gt;16 % and 14 % in NASA and OX datasets, respectively. In RUL task, the accuracies of the TCN-LSTM model and the CNN-LSTM model are superior to other models in NASA dataset; while the LSTM model and the CNN-LSTM model have better performance in OX dataset.  2023 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Butz, Nikolaus T</author><author>Stupnisky, Robert H</author></authors></contributors><titles><title>Improving student relatedness through an online discussion intervention: The application of self-determination theory in synchronous hybrid programs</title><secondary-title>Computers and Education</secondary-title></titles><periodical><full-title>Computers and Education</full-title></periodical><pages>117 - 138</pages><volume>114</volume><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1016/j.compedu.2017.06.006</electronic-resource-num><notes>Cited by: 69</notes><research-notes>Cited by: 69</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021754839&amp;doi=10.1016%2Fj.compedu.2017.06.006&amp;partnerID=40&amp;md5=365661b2555b9a5e75e8eb1ef58a41d7</url></web-urls></urls><abstract>Students' feelings of relatedness (i.e., feeling connected to others) are crucial for success in any learning environment; however, online courses often limit relatedness development, either by removing spontaneous interaction (e.g., asynchronous delivery) or by introducing seemingly incompatible online and on-campus factions (e.g., synchronous hybrid delivery). It was hypothesized that the strengths of one delivery mode could offset the weaknesses of the other. The purpose of this study was to implement and evaluate an online discussion board intervention designed to scaffold relatedness development. Deci and Ryan's (1985) self-determination theory was adopted as the theoretical framework. Participants were 83 graduate students enrolled in synchronous hybrid Masters of Business Administration (MBA), Masters of Public Administration (MPA), and Masters of Aviation (MS-Avit) programs offered at a large midwestern research university. This study used a convergent parallel mixed methods approach (QUAN + qual = triangulation). The methods involved a pretest-posttest experimental design in which students were randomly assigned to either the experimental group, wherein they participated in the intervention, or the control group, wherein they attended classes without any auxiliary interactions. The results indicated that students who participated in the intervention improved their self-efficacy for developing relatedness with individuals who attended online. The qualitative analysis generated three key themes: relatedness beliefs, program delivery, and student-interface interaction. This study holds practical implications for online learning in that it explicated how a threaded discussion can be used to scaffold relatedness development. The theoretical implications of this study involved the substantiation of three key elements of SDT: the basic needs, the types of motivation, and the importance of contextual support.  2017 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Weerakkody, Vishanth</author><author>Sivarajah, Uthayasankar</author><author>Mahroof, Kamran</author><author>Maruyama, Takao</author><author>Lu, Shan</author></authors></contributors><titles><title>Influencing subjective well-being for business and sustainable development using big data and predictive regression analysis</title><secondary-title>Journal of Business Research</secondary-title></titles><periodical><full-title>Journal of Business Research</full-title></periodical><pages>520 - 538</pages><volume>131</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.jbusres.2020.07.038</electronic-resource-num><notes>Cited by: 19</notes><research-notes>Cited by: 19</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089564063&amp;doi=10.1016%2Fj.jbusres.2020.07.038&amp;partnerID=40&amp;md5=feb64727f9771758129f823cea8e12fa</url></web-urls></urls><abstract>Business leaders and policymakers within service economies are placing greater emphasis on well-being, given the role of workers in such settings. Whilst people's well-being can lead to economic growth, it can also have the opposite effect if overlooked. Therefore, enhancing subjective well-being (SWB) is pertinent for all organisations for the sustainable development of an economy. While health conditions were previously deemed the most reliable predictors, the availability of data on people's personal lifestyles now offers a new dimension into well-being for organisations. Using open data available from the national Annual Population Survey in the UK, which measures SWB, this research uncovered that among several independent variables to predict varying levels of people's perceived well-being, long-term health conditions, one's marital status, and age played a key role in SWB. The proposed model provides the key indicators of measuring SWB for organisations using big data.  2020</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zaidi, Syed Mohammad Asad</author><author>Mahfooz, Amna</author><author>Latif, Abdullah</author><author>Nawaz, Nainan</author><author>Fatima, Razia</author><author>Rehman, Fazal Ur</author><author>Reza, Tahira Ezra</author><author>Emmanuel, Faran</author></authors></contributors><titles><title>Geographical targeting of active case finding for tuberculosis in Pakistan using hotspots identified by artificial intelligence software (SPOT-TB): Study protocol for a pragmatic stepped wedge cluster randomised control trial</title><secondary-title>BMJ Open Respiratory Research</secondary-title></titles><periodical><full-title>BMJ Open Respiratory Research</full-title></periodical><volume>11</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1136/bmjresp-2023-002079</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198594547&amp;doi=10.1136%2Fbmjresp-2023-002079&amp;partnerID=40&amp;md5=82c9056d570e3a948b6c2a38666c07c2</url></web-urls></urls><abstract>Introduction Pakistan has significantly strengthened its capacity for active case finding (ACF) for tuberculosis (TB) that is being implemented at scale in the country. However, yields of ACF have been lower than expected, raising concerns on its effectiveness in the programmatic setting. Distribution of TB in communities is likely to be spatially heterogeneous and targeting of ACF in areas with higher TB prevalence may help improve yields. The primary aim of SPOT-TB is to investigate whether a policy change to use a geographically targeted approach towards ACF supported by an artificial intelligence (AI) software, MATCH-AI, can improve yields in Pakistan. Methods and analysis SPOT-TB will use a pragmatic, stepped wedge cluster randomised design. A total of 30 mobile X-ray units and their field teams will be randomised to receive the intervention. Site selection for ACF in the intervention areas will be guided primarily through the use of MATCH-AI software that models subdistrict TB prevalence and identifies potential disease hotspots. Control areas will use existing approaches towards site selection that are based on staff knowledge, experience and analysis of historical data. The primary outcome measure is the difference in bacteriologically confirmed incident TB detected in the intervention relative to control areas. All remaining ACF-related procedures and algorithms will remain unaffected by this trial. Ethics and dissemination Ethical approval has been obtained from the Health Services Academy, Islamabad, Pakistan (7-82/IERC-HSA/2022-52) and from the Common Management Unit for TB, HIV and Malaria, Ministry of Health Services, Regulation and Coordination, Islamabad, Pakistan (26-IRB-CMU-2023). Findings from this study will be disseminated through publications in peer-reviewed journals and stakeholder meetings in Pakistan with the implementing partners and public-sector officials. Findings will also be presented at local and international medical and public health conferences.   Author(s) (or their employer(s)) 2024.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rocca, Laura</author><author>Giacomini, Davide</author><author>Zola, Paola</author></authors></contributors><titles><title>Environmental disclosure and sentiment analysis: state of the art and opportunities for public-sector organisations</title><secondary-title>Meditari Accountancy Research</secondary-title></titles><periodical><full-title>Meditari Accountancy Research</full-title></periodical><pages>617 - 646</pages><volume>29</volume><issue>3</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1108/MEDAR-09-2019-0563</electronic-resource-num><notes>Cited by: 18</notes><research-notes>Cited by: 18</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089603646&amp;doi=10.1108%2FMEDAR-09-2019-0563&amp;partnerID=40&amp;md5=2893337cbc86223283a88a0ddac02f9d</url></web-urls></urls><abstract>Purpose: Because of the expansion of the internet and Web 2.0 phenomenon, new challenges are emerging in the disclosure practises adopted by organisations in the public-sector. This study aims to examine local governments (LGOs) use of social media (SM) in disclosing environmental actions/plans/information as a new way to improve accountability to citizens to obtain organisational legitimacy and the related sentiment of citizens judgements. Design/methodology/approach: This paper analyses the content of 39 Italian LGOs public pages on Facebook. After the distinction between five classes of environmental issues (air, water, energy, waste and territory), an initial study is performed to detect possible sub-topics applying latent Dirichlet allocation. Having a list of posts related to specific environmental themes, the researchers computed the sentiment of citizens comments. To measure sentiment, two different approaches were implemented: one based on a lexicon dictionary and the other based on convolutional neural networks. Findings: Facebook is used by LGOs to disclose environmental issues, focussing on their main interest in obtaining organisational legitimacy, and the analysis shows an increasing impact of Web 2.0 in the direct interaction of LGOs with citizens. On the other hand, there is a clear divergence of interest on environmental topics between LGOs and citizens in a dialogic accountability framework. Practical implications: Sentiment analysis (SA) could be used by politicians, but also by managers/entrepreneurs in the business sector, to analyse stakeholders judgements of their communications/actions and plans on corporate social responsibility. This tool gives a result on time (i.e. not months or years after, as for the reporting system). It is cheaper than a survey and allows a first photograph of stakeholders sentiment. It can also be a useful tool for supporting, developing and improving environmental reporting. Originality/value: To the best of the authors knowledge, this paper is one of the first to apply SA to environmental disclosure via SM in the public sphere. The study links modern techniques in natural language processing and machine learning with the important aspects of environmental communication between LGOs and citizens.  2020, Laura Rocca, Davide Giacomini and Paola Zola.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kale, Alex</author><author>Guo, Ziyang</author><author>Qiao, Xiao Li</author><author>Heer, Jeffrey</author><author>Hullman, Jessica</author></authors></contributors><titles><title>EVM: Incorporating Model Checking into Exploratory Visual Analysis</title><secondary-title>IEEE Transactions on Visualization and Computer Graphics</secondary-title></titles><periodical><full-title>IEEE Transactions on Visualization and Computer Graphics</full-title></periodical><pages>208 - 218</pages><volume>30</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1109/TVCG.2023.3326516</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171891883&amp;doi=10.1109%2FTVCG.2023.3326516&amp;partnerID=40&amp;md5=c09ad2f4cc5dc61e8dfcc4477f6c3645</url></web-urls></urls><abstract>Visual analytics (VA) tools support data exploration by helping analysts quickly and iteratively generate views of data which reveal interesting patterns. However, these tools seldom enable explicit checks of the resulting interpretations of data - e.g., whether patterns can be accounted for by a model that implies a particular structure in the relationships between variables. We present EVM, a data exploration tool that enables users to express and check provisional interpretations of data in the form of statistical models. EVM integrates support for visualization-based model checks by rendering distributions of model predictions alongside user-generated views of data. In a user study with data scientists practicing in the private and public sector, we evaluate how model checks influence analysts' thinking during data exploration. Our analysis characterizes how participants use model checks to scrutinize expectations about data generating process and surfaces further opportunities to scaffold model exploration in VA tools.  1995-2012 IEEE.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cazzola, Walter</author><author>Favalli, Luca</author></authors></contributors><titles><title>Software modernization powered by dynamic language product lines</title><secondary-title>Journal of Systems and Software</secondary-title></titles><periodical><full-title>Journal of Systems and Software</full-title></periodical><volume>218</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.jss.2024.112188</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203019716&amp;doi=10.1016%2Fj.jss.2024.112188&amp;partnerID=40&amp;md5=c80e8bf2b0bf97dd6ef001ca3cd7263c</url></web-urls></urls><abstract>Legacy software poses a critical challenge for organizations due to the costs of maintaining and modernizing outdated systems, as well as the scarcity of experts in aging programming languages. The issue extends beyond commercial applications, affecting public administration, as exemplified by the urgent need for COBOL programmers during the COVID-19 pandemic. In response, this work introduces a modernization approach based on dynamic language product lines, a subset of dynamic software product lines. This approach leverages open language implementations and dynamically generated micro-languages for the incremental migration of legacy systems to modern technologies. The language can be reconfigured at runtime to adapt to the execution of either legacy or modern code, and to generate a compatibility layer between the data types handled by the two languages. Through this process, the costs of modernizing legacy systems can be spread across several iterations, as developers can replace legacy code incrementally, with legacy and modern code coexisting until a complete refactoring is possible. By moving the overhead of making legacy and modern features work together in a hybrid system from the system implementation to the language implementation, the quality of the system itself does not degrade due to the introduction of glue code. To demonstrate the practical applicability of this approach, we present a case study on a COBOL system migration to Java. Using the Neverlang language workbench to create modular and reconfigurable language implementations, both the COBOL interpreter and the application evolve to spread the development effort across several iterations. Through this study, this work presents a viable solution for organizations dealing with the complexity of modernizing legacy software to contemporary technologies. The contributions of this work are (i) a language-oriented, incremental refactoring process for legacy systems, (ii) a concrete application of open language implementations, and (iii) a general template for the implementation of interoperability between languages in hybrid systems.  2024 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Iftekhar, Md Sayed</author><author>Pannell, David J</author></authors></contributors><titles><title>Developing an integrated investment decision-support framework for water-sensitive urban design projects</title><secondary-title>Journal of Hydrology</secondary-title></titles><periodical><full-title>Journal of Hydrology</full-title></periodical><volume>607</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.jhydrol.2022.127532</electronic-resource-num><notes>Cited by: 19</notes><research-notes>Cited by: 19</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124243775&amp;doi=10.1016%2Fj.jhydrol.2022.127532&amp;partnerID=40&amp;md5=a55456a58db65f462d244ce82e81a108</url></web-urls></urls><abstract>Traditional centralized water-management systems have tended to fall short in delivering environmental and amenity benefits in urban areas. Water-sensitive urban design (WSUD) projects have been proposed as an alternative due to their ability to generate multiple benefits, including improving water quality, water supply, aesthetics, urban cooling, spaces for recreation, and habitat for biodiversity. However, in most cities, investment in such systems has been relatively low, in part due to the difficulty of monetizing the multifunctional benefits of WSUD projects and including them in comprehensive economic analyses. We describe the development, testing and application of INFFEWS (Investment Framework For the Economics of Water Sensitive cities), an economic decision-support system for investment in WSUD projects. INFFEWS is based on a Benefit: Cost Analysis (BCA) framework and is consistent with standard BCA. A prominent feature of the framework is its strong emphasis on quantifying the monetary-equivalent values of intangible (non-market) benefits from WSUD projects. Development of the tools and their supporting materials has involved extensive consultation with intended users, review of existing tools, and primary research over eight years (20132020). The frameworks can be applied to business-case development and decision making at multiple levels in public-sector and private-sector organisations.  2022 Elsevier B.V.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhu, Nengjun</author><author>Cao, Jian</author><author>Lu, Xinjiang</author><author>Liu, Chuanren</author><author>Liu, Hao</author><author>Li, Yanyan</author><author>Luo, Xiangfeng</author><author>Xiong, Hui</author></authors></contributors><titles><title>Predicting a Person's Next Activity Region with a Dynamic Region-Relation-Aware Graph Neural Network</title><secondary-title>ACM Transactions on Knowledge Discovery from Data</secondary-title></titles><periodical><full-title>ACM Transactions on Knowledge Discovery from Data</full-title></periodical><volume>16</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1145/3529091</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141153746&amp;doi=10.1145%2F3529091&amp;partnerID=40&amp;md5=c388b553c9cc5c4f81e760559d32194f</url></web-urls></urls><abstract>The understanding of people's inter-regional mobility behaviors, such as predicting the next activity region (AR) or uncovering the intentions for regional mobility, is of great value to public administration or business interests. While there are numerous studies on human mobility, these studies are mainly from a statistical view or study movement behaviors within a region. The work on individual-level inter-regional mobility behavior is limited. To this end, in this article, we propose a dynamic region-relation-aware graph neural network (DRRGNN) for exploring individual mobility behaviors over ARs. Specifically, we aim at developing models that can answer three questions: (1) Which regions are the ARs? (2) Which region will be the next AR, and (3) Why do people make this regional mobility? To achieve these tasks, we first propose a method to find out people's ARs. Then, the designed model integrates a dynamic graph convolution network (DGCN) and a recurrent neural network (RNN) to depict the evolution of relations between ARs and mine the regional mobility patterns. In the learning process, the model further considers peoples' profiles and visited point-of-interest (POIs). Finally, extensive experiments on two real-world datasets show that the proposed model can significantly improve accuracy for both the next AR prediction and mobility intention prediction.  2022 Association for Computing Machinery.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Carlo, Dino Di</author><author>Ozcan, Aydogan</author><author>Eryilmaz, Merve</author><author>Goncharov, Artem</author><author>Han, Gyeo-Re</author><author>Joung, Hyou-Arm</author><author>Ballard, Zachary S</author><author>Ghosh, Rajesh</author><author>Zhang, Yijie</author></authors></contributors><titles><title>A Paper-Based Multiplexed Serological Test to Monitor Immunity against SARS-COV2 Using Machine Learning</title><secondary-title>ACS Nano</secondary-title></titles><periodical><full-title>ACS Nano</full-title></periodical><pages>16819 - 16831</pages><volume>18</volume><issue>26</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1021/acsnano.4c02434</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196734059&amp;doi=10.1021%2Facsnano.4c02434&amp;partnerID=40&amp;md5=ebe528e0a5c3c658c1b0d3673e96cbd4</url></web-urls></urls><abstract>The rapid spread of SARS-CoV-2 caused the COVID-19 pandemic and accelerated vaccine development to prevent the spread of the virus and control the disease. Given the sustained high infectivity and evolution of SARS-CoV-2, there is an ongoing interest in developing COVID-19 serology tests to monitor population-level immunity. To address this critical need, we designed a paper-based multiplexed vertical flow assay (xVFA) using five structural proteins of SARS-CoV-2, detecting IgG and IgM antibodies to monitor changes in COVID-19 immunity levels. Our platform not only tracked longitudinal immunity levels but also categorized COVID-19 immunity into three groups: protected, unprotected, and infected, based on the levels of IgG and IgM antibodies. We operated two xVFAs in parallel to detect IgG and IgM antibodies using a total of 40 L of human serum sample in &lt;20 min per test. After the assay images of the paper-based sensor panel were captured using a mobile phone-based custom-designed optical reader and then processed by a neural network-based serodiagnostic algorithm. The serodiagnostic algorithm was trained with 120 measurements/tests and 30 serum samples from 7 randomly selected individuals and was blindly tested with 31 serum samples from 8 different individuals, collected before vaccination as well as after vaccination or infection, achieving an accuracy of 89.5%. The competitive performance of the xVFA, along with its portability, cost-effectiveness, and rapid operation, makes it a promising computational point-of-care (POC) serology test for monitoring COVID-19 immunity, aiding in timely decisions on the administration of booster vaccines and general public health policies to protect vulnerable populations.  2024 The Authors. Published by American Chemical Society.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Oikonomidi, Theodora</author><author>Ravaud, Philippe</author><author>James, Arthur</author><author>Cosson, Emmanuel</author><author>Montori, Victor</author><author>Tran, Viet-Thi</author></authors></contributors><titles><title>An International, Mixed-Methods Study of the Perceived Intrusiveness of Remote Digital Diabetes Monitoring</title><secondary-title>Mayo Clinic Proceedings</secondary-title></titles><periodical><full-title>Mayo Clinic Proceedings</full-title></periodical><pages>1236 - 1247</pages><volume>96</volume><issue>5</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.mayocp.2020.07.040</electronic-resource-num><notes>Cited by: 6</notes><research-notes>Cited by: 6</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100654780&amp;doi=10.1016%2Fj.mayocp.2020.07.040&amp;partnerID=40&amp;md5=ec08abed41da6b68250b4286fce92f11</url></web-urls></urls><abstract>Objective: To assess the relationship between remote digital monitoring (RDM) modalities for diabetes and intrusiveness in patients lives. Patients and Methods: Online vignette-based survey (February 1 through July 1, 2019). Adults with diabetes (type 1, 2, or subtypes such as latent autoimmune diabetes of adulthood) assessed three randomly selected vignettes among 36 that combined different modalities for monitoring tools (three options: glucose- and physical activity [PA]monitoring only, or glucose- and PA-monitoring with occasional or regular food monitoring), duration/feedback loops (six options: monitoring for a week before all vs before specific consultations with feedback given in consultation, vs monitoring permanently, with real-time feedback by one's physician vs by anoter caregiver, vs monitoring permanently, with real-time, artificial intelligence-generated treatment feedback vs treatment and lifestyle feedback), and data handling (two options: by the public vs private sector). We compared intrusiveness (assessed on a 5-point scale) across vignettes and used linear mixed models to identify intrusiveness determinants. We collected qualitative data to identify aspects that drove participants perception of intrusiveness. Results: Overall, 1010 participants from 30 countries provided 2860 vignette-assessments (52% were type 1 diabetes). The monitoring modalities associated with increased intrusiveness were food monitoring compared with glucose- and PA-monitoring alone (=0.34; 95% CI, 0.26 to 0.42; P&lt;.001) and permanent monitoring with real-time physician-generated feedback compared with monitoring for a week with feedback in consultation (=0.25; 95% CI, 0.16 to 0.34, P&lt;.001). Public-sector data handling was associated with decreased intrusiveness as compared with private-sector (=0.15; 95% CI, 0.22 to 0.09; P&lt;.001). Four drivers of intrusiveness emerged from the qualitative analysis: practical/psychosocial burden (eg, RDM attracting attention in public), control, data safety/misuse, and dehumanization of care. Conclusion: RDM is intrusive when it includes food monitoring, real-time human feedback, and private-sector data handling.  2020 Mayo Foundation for Medical Education and Research</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Shah, Naimatullah</author><author>Irani, Zahir</author><author>Sharif, Amir M</author></authors></contributors><titles><title>Big data in an HR context: Exploring organizational change readiness, employee attitudes and behaviors</title><secondary-title>Journal of Business Research</secondary-title></titles><periodical><full-title>Journal of Business Research</full-title></periodical><pages>366 - 378</pages><volume>70</volume><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1016/j.jbusres.2016.08.010</electronic-resource-num><notes>Cited by: 149</notes><research-notes>Cited by: 149</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504360&amp;doi=10.1016%2Fj.jbusres.2016.08.010&amp;partnerID=40&amp;md5=dc42efedbb49dcfed21f5826778fa7f6</url></web-urls></urls><abstract>This research highlights a contextual application for big data within a HR case study setting. This is achieved through the development of a normative conceptual model that seeks to envelop employee behaviors and attitudes in the context of organizational change readiness. This empirical application considers a data sample from a large public sector organization and through applying Structural Equation Modelling (SEM) identifies salary, job promotion, organizational loyalty and organizational identity influences on employee job satisfaction (suggesting and mediating employee readiness for organizational change). However in considering this specific context, the authors highlight how, where and why such a normative approach to employee factors may be limited and thus, proposes through a framework which brings together big data principles, implementation approaches and management commitment requirements can be applied and harnessed more effectively in order to assess employee attitudes and behaviors as part of wider HR predictive analytics (HRPA) approaches. The researchers conclude with a discussion on these research elements and a set of practical, conceptual and management implications of the findings along with recommendations for future research in the area.  2016 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>McLennan, Stuart</author><author>Rachut, Sarah</author><author>Lange, Johannes</author><author>Fiske, Amelia</author><author>Heckmann, Dirk</author><author>Buyx, Alena</author></authors></contributors><titles><title>Practices and Attitudes of Bavarian Stakeholders Regarding the Secondary Use of Health Data for Research Purposes During the COVID-19 Pandemic: Qualitative Interview Study</title><secondary-title>Journal of Medical Internet Research</secondary-title></titles><periodical><full-title>Journal of Medical Internet Research</full-title></periodical><volume>24</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.2196/38754</electronic-resource-num><notes>Cited by: 8</notes><research-notes>Cited by: 8</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132962569&amp;doi=10.2196%2F38754&amp;partnerID=40&amp;md5=b15eaab45ad285923110ee2b2b5e77c8</url></web-urls></urls><abstract>Background: The COVID-19 pandemic is a threat to global health and requires collaborative health research efforts across organizations and countries to address it. Although routinely collected digital health data are a valuable source of information for researchers, benefiting from these data requires accessing and sharing the data. Health care organizations focusing on individual risk minimization threaten to undermine COVID-19 research efforts, and it has been argued that there is an ethical obligation to use the European Union's General Data Protection Regulation (GDPR) scientific research exemption during the COVID-19 pandemic to support collaborative health research. Objective: This study aims to explore the practices and attitudes of stakeholders in the German federal state of Bavaria regarding the secondary use of health data for research purposes during the COVID-19 pandemic, with a specific focus on the GDPR scientific research exemption. Methods: Individual semistructured qualitative interviews were conducted between December 2020 and January 2021 with a purposive sample of 17 stakeholders from 3 different groups in Bavaria: researchers involved in COVID-19 research (n=5, 29%), data protection officers (n=6, 35%), and research ethics committee representatives (n=6, 35%). The transcripts were analyzed using conventional content analysis. Results: Participants identified systemic challenges in conducting collaborative secondary-use health data research in Bavaria; secondary health data research generally only happens when patient consent has been obtained, or the data have been fully anonymized. The GDPR research exemption has not played a significant role during the pandemic and is currently seldom and restrictively used. Participants identified 3 key groups of barriers that led to difficulties: the wider ecosystem at many Bavarian health care organizations, legal uncertainty that leads to risk-adverse approaches, and ethical positions that patient consent ought to be obtained whenever possible to respect patient autonomy. To improve health data research in Bavaria and across Germany, participants wanted greater legal certainty regarding the use of pseudonymized data for research purposes without the patient's consent. Conclusions: The current balance between enabling the positive goals of health data research and avoiding associated data protection risks is heavily skewed toward avoiding risks; so much so that it makes reaching the goals of health data research extremely difficult. This is important, as it is widely recognized that there is an ethical imperative to use health data to improve care. The current approach also creates a problematic conflict with the ambitions of Germany, and the federal state of Bavaria, to be a leader in artificial intelligence. A recent development in the field of German public administration known as norm screening.  Stuart McLennan, Sarah Rachut, Johannes Lange, Amelia Fiske, Dirk Heckmann, Alena Buyx.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Newman, Joshua</author><author>Mintrom, Michael</author><author>O'Neill, Deirdre</author></authors></contributors><titles><title>Digital technologies, artificial intelligence, and bureaucratic transformation</title><secondary-title>Futures</secondary-title></titles><periodical><full-title>Futures</full-title></periodical><volume>136</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.futures.2021.102886</electronic-resource-num><notes>Cited by: 31</notes><research-notes>Cited by: 31</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121440551&amp;doi=10.1016%2Fj.futures.2021.102886&amp;partnerID=40&amp;md5=809a6c70d03aea995a20150e6db9a690</url></web-urls></urls><abstract>Bureaucracies are often criticized for their inflexibility, budget-maximizing wastefulness, and excessive rules and procedures. Rapid advances in technology, including the expansion of digital government, the use of artificial intelligence, and the ability to collect and analyze big data, promise to make public sector organizations leaner, more efficient, and more responsive to citizens' needs. While these technological changes have prompted some observers to forecast the end of bureaucracy, data from many countries show that bureaucratic public organizations are not disappearing. In this article, we argue that this paradox can be explained by revisiting some of the foundational work of sociologist Max Weber, who envisioned public administration itself as a bureaucratic machine. Advanced computing technologies, like artificial intelligence, are reinforcing bureaucratic tendencies in the public sector, not eliminating them. While advances in technology may transform the way public sector organizations operate, they can also serve to strengthen bureaucracy's core purpose.  2021 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Yuan, Liang</author><author>Lu, Weisheng</author><author>Yang, Bing</author><author>Peng, Ziyu</author></authors></contributors><titles><title>Strength of Strong Ties: Empirical Evidence from the Construction Waste Hauling Business in Hong Kong</title><secondary-title>Journal of Management in Engineering</secondary-title></titles><periodical><full-title>Journal of Management in Engineering</full-title></periodical><volume>40</volume><issue>6</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1061/JMENEA.MEENG-6111</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200461182&amp;doi=10.1061%2FJMENEA.MEENG-6111&amp;partnerID=40&amp;md5=c0ace876be7456d7c032e75dbc56f7ee</url></web-urls></urls><abstract>The so-called strength of weak ties (SWT) theory asserts that weak relationships are more instrumental than strong ones in job searching and sharing. Yet, some posit the opposite: job opportunities tend to be shared through strong ties in some business areas. Nevertheless, little empirical research has been conducted to substantiate the hypotheses and unravel the rationales behind them. This paper attempts to contribute empirical evidence to this management field by focusing on the construction waste hauling business in Hong Kong. Four null hypotheses about the relationships between haulers' tie strength and job opportunity sharing (defined as waste hauling order sharing) are proposed, and then a big data set containing 11.7 million waste hauling records is analyzed to test the hypotheses. The analysis shows that, in general, the stronger the tie strength of two haulers, the higher the quantity of job opportunities they share. Among all ties a hauler owns, the greater the proportion of strong ties, the higher the quantity and quality (e.g., shorter distance and less underloading) of job opportunities will be shared. However, these positive effects will be diminished when the strength or proportion exceeds a certain point. These empirical findings not only highlight the strength of strong ties, providing an empirical supplement for the long-standing SWT theory, but also exemplify an exploration of applying SWT theory in the construction management field. Moreover, this study provides practical implications for construction waste hauling businesses to improve efficiency and the public sector to pursue social optimality in construction waste management.  2024 American Society of Civil Engineers.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Malomo, Fola</author><author>Sena, Vania</author></authors></contributors><titles><title>Data Intelligence for Local Government? Assessing the Benefits and Barriers to Use of Big Data in the Public Sector</title><secondary-title>Policy and Internet</secondary-title></titles><periodical><full-title>Policy and Internet</full-title></periodical><pages>7 - 27</pages><volume>9</volume><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1002/poi3.141</electronic-resource-num><notes>Cited by: 61</notes><research-notes>Cited by: 61</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006761764&amp;doi=10.1002%2Fpoi3.141&amp;partnerID=40&amp;md5=49fb93eee68dec97f0075e3bdff31997</url></web-urls></urls><abstract>The concept of Big Data has become very popular over the last decade, with large technology companies successfully building their business models around its exploitation. The public sector in the United Kingdom has tried to follow suit and local governments in particular have tried to introduce new models of service delivery based on the routine extraction of information from their own Big Data. These attempts have been hailed as the beginning of a new era for the public sector where service delivery and commissioning are shaped by data intelligence on local needs and by evidence on the outcomes. In this article we assess this claim and the extent to which it captures the way local governments in the United Kingdom use intelligence from Big Data in light of the structural barriers they face when trying to exploit their data. We also present a case study on the development and deployment of an integrated data model for children services in a large county council in the South-East of England.  2016 Policy Studies Organization</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mor, Surender</author><author>Gupta, Geetu</author></authors></contributors><titles><title>Artificial intelligence and technical efficiency: The case of Indian commercial banks</title><secondary-title>Strategic Change</secondary-title></titles><periodical><full-title>Strategic Change</full-title></periodical><pages>235 - 245</pages><volume>30</volume><issue>3</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1002/jsc.2406</electronic-resource-num><notes>Cited by: 23</notes><research-notes>Cited by: 23</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105317764&amp;doi=10.1002%2Fjsc.2406&amp;partnerID=40&amp;md5=cea99d80ba5bd170c1f3bcfce0caac77</url></web-urls></urls><abstract>The deployment of artificial intelligence (AI) in chatbots, virtual assistants, and ATMs reduces technical inefficiency in Indian commercial banks. The impact of (AI) on the technical efficiency of 47 examined commercial banks in India has reduced technical inefficiency to 11%, primarily due to internal factors or decision making. The verdict endorses the speeding up of (AI) deployment besides raising the level of assets, reducing the nonperforming assets, especially banks functioning in the public sector.  2021 John Wiley &amp; Sons, Ltd.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Gang</author><author>Li, Hao</author><author>He, Rong</author><author>Lu, Peng</author></authors></contributors><titles><title>Agent-based modeling and life cycle dynamics of COVID-19-related online collective actions</title><secondary-title>Complex and Intelligent Systems</secondary-title></titles><periodical><full-title>Complex and Intelligent Systems</full-title></periodical><pages>1369 - 1387</pages><volume>8</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1007/s40747-021-00595-4</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134068532&amp;doi=10.1007%2Fs40747-021-00595-4&amp;partnerID=40&amp;md5=121f28c4910c0a553519156e9c12c154</url></web-urls></urls><abstract>The outbreak of COVID-19 has greatly threatened global public health and produced social problems, which includes relative online collective actions. Based on the life cycle law, focusing on the life cycle process of COVID-19 online collective actions, we carried out both macro-level analysis (big data mining) and micro-level behaviors (Agent-Based Modeling) on pandemic-related online collective actions. We collected 138 related online events with macro-level big data characteristics, and used Agent-Based Modeling to capture micro-level individual behaviors of netizens. We set two kinds of movable agents, Hots (events) and Netizens (individuals), which behave smartly and autonomously. Based on multiple simulations and parametric traversal, we obtained the optimal parameter solution. Under the optimal solutions, we repeated simulations by ten times, and took the mean values as robust outcomes. Simulation outcomes well match the real big data of life cycle trends, and validity and robustness can be achieved. According to multiple criteria (spans, peaks, ratios, and distributions), the fitness between simulations and real big data has been substantially supported. Therefore, our Agent-Based Modeling well grasps the micro-level mechanisms of real-world individuals (netizens), based on which we can predict individual behaviors of netizens and big data trends of specific online events. Based on our model, it is feasible to model, calculate, and even predict evolutionary dynamics and life cycles trends of online collective actions. It facilitates public administrations and social governance.  2021, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Haddadin, Sami</author><author>Parusel, Sven</author><author>Johannsmeier, Lars</author><author>Golz, Saskia</author><author>Gabl, Simon</author><author>Walch, Florian</author><author>Sabaghian, Mohamadreza</author><author>Jahne, Christoph</author><author>Hausperger, Lukas</author><author>Haddadin, Simon</author></authors></contributors><titles><title>The Franka Emika Robot: A Reference Platform for Robotics Research and Education</title><secondary-title>IEEE Robotics and Automation Magazine</secondary-title></titles><periodical><full-title>IEEE Robotics and Automation Magazine</full-title></periodical><pages>46 - 64</pages><volume>29</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1109/MRA.2021.3138382</electronic-resource-num><notes>Cited by: 65</notes><research-notes>Cited by: 65</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125327947&amp;doi=10.1109%2FMRA.2021.3138382&amp;partnerID=40&amp;md5=d58d21c64b4d3dde34a3a0b47ae84a6a</url></web-urls></urls><abstract>The importance of robots for industry, research, education, and society as a whole is steadily increasing as reflected by the number of available systems and installed robots, not only in industry but also in the public sector and households. Software-only robotics researchers usually rely on commercially available robots which, in the case of manipulators, are primarily designed for industrial purposes and are often far from their needs. This article is a hands-on tutorial on the Franka Emika robot, the first series of industrial artificial intelligence (AI)-ready tactile robot platforms. Beyond industrial use, the systems can be seamlessly expanded to fulfill the demands of research and education across all robotics and AI disciplines. To satisfy the needs of such a wide variety of fields, it provides three different interfaces: Desk, a high-level app-based user interface for easy and fast task programming; Robot Integrated Development Environment (RIDE), a command-based programming environment used to create high-performance robot skills that enables programming custom apps and integrating external sensors; and the Franka control interface (FCI), a 1-kHz low-level torque and position control interface that exploits the also-Available Langrangian dynamics robot model. We take a close look at implementations with all interfaces, ranging from simple solutions, apps, and controllers to robot-learning examples illustrating how to exploit all the advantages of this platform in ongoing robotics research and education.   1994-2011 IEEE.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Choi, Youngseok</author><author>Lee, Habin</author><author>Irani, Zahir</author></authors></contributors><titles><title>Big data-driven fuzzy cognitive map for prioritising IT service procurement in the public sector</title><secondary-title>Annals of Operations Research</secondary-title></titles><periodical><full-title>Annals of Operations Research</full-title></periodical><pages>75 - 104</pages><volume>270</volume><issue>1-2</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1007/s10479-016-2281-6</electronic-resource-num><notes>Cited by: 54</notes><research-notes>Cited by: 54</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982292325&amp;doi=10.1007%2Fs10479-016-2281-6&amp;partnerID=40&amp;md5=1677c94bef289f0e0a4a40409a88a2c5</url></web-urls></urls><abstract>The prevalence of big data is starting to spread across the public and private sectors however, an impediment to its widespread adoption orientates around a lack of appropriate big data analytics (BDA) and resulting skills to exploit the full potential of big data availability. In this paper, we propose a novel BDA to contribute towards this void, using a fuzzy cognitive map (FCM) approach that will enhance decision-making thus prioritising IT service procurement in the public sector. This is achieved through the development of decision models that capture the strengths of both data analytics and the established intuitive qualitative approach. By taking advantages of both data analytics and FCM, the proposed approach captures the strength of data-driven decision-making and intuitive model-driven decision modelling. This approach is then validated through a decision-making case regarding IT service procurement in public sector, which is the fundamental step of IT infrastructure supply for publics in a regional government in the Russia federation. The analysis result for the given decision-making problem is then evaluated by decision makers and e-government expertise to confirm the applicability of the proposed BDA. In doing so, demonstrating the value of this approach in contributing towards robust public decision-making regarding IT service procurement.  2016, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dogra, Varun</author><author>Alharithi, Fahd S</author><author>lvarez, Roberto Marcelo</author><author>Singh, Aman</author><author>Qahtani, Abdulrahman M</author></authors></contributors><titles><title>NLP-Based Application for Analyzing Private and Public Banks Stocks Reaction to News Events in the Indian Stock Exchange</title><secondary-title>Systems</secondary-title></titles><periodical><full-title>Systems</full-title></periodical><volume>10</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.3390/systems10060233</electronic-resource-num><notes>Cited by: 7</notes><research-notes>Cited by: 7</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144738435&amp;doi=10.3390%2Fsystems10060233&amp;partnerID=40&amp;md5=5befcd0bf849b8e249e427e79f4cc676</url></web-urls></urls><abstract>This is an effort to analyze the reaction of stock prices of Indian public and private banks listed in NSE and BSE to the announcement of seven best case news events. Several recent studies have analyzed the correlation between stock prices and news announcements; however, there is no evidence on how private and public sector Indian bank stocks react to important news events independently. We examine these features by concentrating on a sample of banking and government news events. We classify these news events to create a group of negative and a group of positive tone of announcements (sentiments). The statistical results show that the negative banking news announcements had a one-month impact on private banks, with statistically significant negative mean CARs. However, with highly statistically substantial negative mean CARs, the influence of the negative banking news announcements on public banks was observed for two months after the news was published. Furthermore, the influence of the positive banking news on private banks persisted a month after the news was published. Positive banking news events had an influence on public banks for five days after they were published. The study concludes that public bank stocks react more to negative news announcements than positive news announcements in the same manner as the sentimental polarity of the news announcements as compared to private bank stocks. First, we retrieved the news articles published in prominent online financial news portals between 2017 and 2020, and the seven major news events were extracted and classified using multi-class text classification. The Random Forest classifier produced a significant accuracy of 94% with pre-trained embeddings of DistilBERT, a neural network model, which outperformed the traditional feature representation technique, TF-IDF. The training data for the classifier were balanced using the SMOTE sampling technique.  2022 by the authors.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Klievink, Bram</author><author>Romijn, Bart-Jan</author><author>Cunningham, Scott</author><author>de Bruijn, Hans</author></authors></contributors><titles><title>Big data in the public sector: Uncertainties and readiness</title><secondary-title>Information Systems Frontiers</secondary-title></titles><periodical><full-title>Information Systems Frontiers</full-title></periodical><pages>267 - 283</pages><volume>19</volume><issue>2</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1007/s10796-016-9686-2</electronic-resource-num><notes>Cited by: 157</notes><research-notes>Cited by: 157</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982126226&amp;doi=10.1007%2Fs10796-016-9686-2&amp;partnerID=40&amp;md5=84822de6a52d6dd0aeaa989cce50369e</url></web-urls></urls><abstract>Big data is being implemented with success in the private sector and science. Yet the public sector seems to be falling behind, despite the potential value of big data for government. Government organizations do recognize the opportunities of big data but seem uncertain about whether they are ready for the introduction of big data, and if they are adequately equipped to use big data. This paper addresses those uncertainties. It presents an assessment framework for evaluating public organizations big data readiness. Doing so demystifies the concept of big data, as it is expressed in terms of specific and measureable organizational characteristics. The framework was tested by applying it to organizations in the Dutch public sector. The results suggest that organizations may be technically capable of using big data, but they will not significantly gain from these activities if the applications do not fit their organizations and main statutory tasks. The framework proved helpful in pointing out areas where public sector organizations could improve, providing guidance on how government can become more big data ready in the future.  2016, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jain, Shrey</author><author>Jauhar, Sunil Kumar</author><author>Piyush</author></authors></contributors><titles><title>A machine-learning-based framework for contractor selection and order allocation in public construction projects considering sustainability, risk, and safety</title><secondary-title>Annals of Operations Research</secondary-title></titles><periodical><full-title>Annals of Operations Research</full-title></periodical><pages>225 - 267</pages><volume>338</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1007/s10479-024-05898-6</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186946153&amp;doi=10.1007%2Fs10479-024-05898-6&amp;partnerID=40&amp;md5=0bdc4eca8c34bdb5e8580b2647f680f5</url></web-urls></urls><abstract>Effective contractor selection is crucial for successful execution of construction projects. In contrast to the conventional lowest-bid approach prevalent in the public sector, this study focuses on developing a framework that minimizes time and cost overruns by considering diverse criteria for contractor selection. A variety of machine learning models, including multi-linear regression, random forest, Support Vector Machine, and Artificial Neural Network, have been employed, with multi-linear regression proving to be the most effective, achieving the lowest Mean Squared Error of 0.00003366. To determine the final order allocation, a multi-objective mathematical model was utilized to optimize conflicting criteria, such as time and cost overruns, sustainability, risk, and safety aspects related to shortlisted contractors. The findings highlight the significance of specific selection criteria, such as turnover, experience in similar projects, qualification of staff, technology utilization, client satisfaction, accident records, available bid capacity, and socioeconomic factors. This study emphasizes a three-phase decision-making framework for contractor selection and order allocation, particularly in public construction projects, with a focus on sustainability. By adopting this approach, government agencies can enhance infrastructure projects and minimize overruns through optimization and analytical tools, which aligns with the Gati-Shakti scheme of the Indian government. It is recommended that clients embrace a holistic approach to contractor selection, considering both technical and non-technical factors, to ensure successful project outcomes.  The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Laux, Johann</author><author>Wachter, Sandra</author><author>Mittelstadt, Brent</author></authors></contributors><titles><title>Trustworthy artificial intelligence and the European Union AI act: On the conflation of trustworthiness and acceptability of risk</title><secondary-title>Regulation and Governance</secondary-title></titles><periodical><full-title>Regulation and Governance</full-title></periodical><pages>3 - 32</pages><volume>18</volume><issue>1</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1111/rego.12512</electronic-resource-num><notes>Cited by: 35</notes><research-notes>Cited by: 35</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147512970&amp;doi=10.1111%2Frego.12512&amp;partnerID=40&amp;md5=e27b299e9fa111f48f13c78bbc6b8045</url></web-urls></urls><abstract>In its AI Act, the European Union chose to understand trustworthiness of AI in terms of the acceptability of its risks. Based on a narrative systematic literature review on institutional trust and AI in the public sector, this article argues that the EU adopted a simplistic conceptualization of trust and is overselling its regulatory ambition. The paper begins by reconstructing the conflation of trustworthiness with acceptability in the AI Act. It continues by developing a prescriptive set of variables for reviewing trust research in the context of AI. The paper then uses those variables for a narrative review of prior research on trust and trustworthiness in AI in the public sector. Finally, it relates the findings of the review to the EU's AI policy. Its prospects to successfully engineer citizen's trust are uncertain. There remains a threat of misalignment between levels of actual trust and the trustworthiness of applied AI.  2023 The Authors. Regulation &amp; Governance published by John Wiley &amp; Sons Australia, Ltd.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Somohano-Rodrguez, Francisco M</author><author>Madrid-Guijarro, Antonia</author></authors></contributors><titles><title>Do industry 4.0 technologies improve Cantabrian manufacturing smes performance? The role played by industry competition</title><secondary-title>Technology in Society</secondary-title></titles><periodical><full-title>Technology in Society</full-title></periodical><volume>70</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.techsoc.2022.102019</electronic-resource-num><notes>Cited by: 18</notes><research-notes>Cited by: 18</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132526925&amp;doi=10.1016%2Fj.techsoc.2022.102019&amp;partnerID=40&amp;md5=287df8be64a7266a808d70bd20cabedb</url></web-urls></urls><abstract>This paper studies whether investments in Industry 4.0 improve performance and give SMEs (Small and Medium-Sized Enterprises) an opportunity to get ahead. We base our research on the competitive context by considering the number of firms in specific industries and the inverted-U framework. We analyze the effects of investing in five digital enablers (Big Data, Cloud Computing, Cybersecurity, Advanced Robotics, and the Internet of Things) on firm revenues, labor performance, and profitability in terms of neck-and-neck and leader-laggard competition models. Results from 274 SMEs for the period 20052018 show that these effects depend on the technology implemented. Big Data contributes to competitive advantages, while investing in Advanced Robots is negative for sales growth. We do not have conclusive results about Cybersecurity, Cloud Computing, and the Internet of Things. These findings have relevant implications for both managers and public administrations, as they demonstrate that investing in Industry 4.0 improves productivity in the case of some of the enablers.  2022</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Montaghi, Alessandro</author><author>Bregaglio, Simone</author><author>Bajocco, Sofia</author></authors></contributors><titles><title>An open-source cloud-based procedure for MODIS remote sensing products: The nasawebservicepython package</title><secondary-title>Ecological Informatics</secondary-title></titles><periodical><full-title>Ecological Informatics</full-title></periodical><volume>79</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.ecoinf.2023.102433</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181043991&amp;doi=10.1016%2Fj.ecoinf.2023.102433&amp;partnerID=40&amp;md5=7e19104fa4d0b43ef52805dd28ca3371</url></web-urls></urls><abstract>Living in the era of big data demands an increase in the application and development of solutions for data ingestion in agroecological research, both in the private and public sectors. Among available data sources, satellite imagery is a viable solution to acquire large amounts of data at cheaper costs. Although cloud-based commercially distributed services are flourishing, open-source software able to assist practitioners and researchers in downloading and pre-processing satellite imagery is strongly demanded by the remote sensing community. This is especially true when looking at applications developed in Python, a programming language that quickly gained popularity in agroecological science. In this letter, we introduce nasawebservice version 1.0.0, a Python Package designed to automatically collect remotely sensed data from the NASA MODIS/VIIRS Land Products web service. The nasawebservice package contains a set of classes and methods to facilitate download operations for practitioners and researchers and to implement user-friendly data ingestion pipelines in local and cloud environments. The main advantage of nasawebservice is the reduction of pre-processing operations to use satellite images due to getting the data in JSON format, with consequent saving of computational time for large data download and analytic operational pipelines.  2023</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Millward-Hopkins, Joel</author></authors></contributors><titles><title>Back to the future: Old values for a new (more equal) world</title><secondary-title>Futures</secondary-title></titles><periodical><full-title>Futures</full-title></periodical><volume>128</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.futures.2021.102727</electronic-resource-num><notes>Cited by: 9</notes><research-notes>Cited by: 9</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102029946&amp;doi=10.1016%2Fj.futures.2021.102727&amp;partnerID=40&amp;md5=6e7f7f7c75d2191eb64098c8d7962589</url></web-urls></urls><abstract>Inequality has become a defining feature of our time and concerns are growing that artificial intelligence, human-enhancement and global ecological breakdown could cause levels to spiral upwards. Although public disapproval of current inequalities is widespread, studies also show that people don't desire equality, but prefer fair, still significant inequalities. Here, I argue these preferences are rooted in ideals of meritocracy and intuitive notions of free will; values that'll become increasingly tenuous in a future of human enhancement, where they could legitimise mass inequalities. Maintaining an illusion of free will is often argued to be needed to disincentivise immoral behaviour, but it also creates a vicious feedback: It provides social legitimacy to substantial inequalities, which exacerbate precisely those immoral behaviours that the illusion is intended to mitigate. However, meritocratic values, and their foundational notion of individual agency, are neither natural nor inevitable  they're mediated by social practices. To see what egalitarian practices may look like, I review the rich anthropology literature on egalitarian societies. This highlights an irony, in that the meritocratic ideals proposed by contemporary politicians as a remedy to entrenched inequalities are the same values seen as the origin of inequality in existing egalitarian societies around the world.  2021 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Desouza, Kevin C</author><author>Jacob, Benoy</author></authors></contributors><titles><title>Big Data in the Public Sector: Lessons for Practitioners and Scholars</title><secondary-title>Administration and Society</secondary-title></titles><periodical><full-title>Administration and Society</full-title></periodical><pages>1043 - 1064</pages><volume>49</volume><issue>7</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1177/0095399714555751</electronic-resource-num><notes>Cited by: 121</notes><research-notes>Cited by: 121</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022022132&amp;doi=10.1177%2F0095399714555751&amp;partnerID=40&amp;md5=212306507a9b50076c14acabdcbc3f6a</url></web-urls></urls><abstract>In this essay, we consider the role of Big Data in the public sector. Motivating our work is the recognition that Big Data is still in its infancy and many important questions regarding the true value of Big Data remain unanswered. The question we consider is as follows: What are the limits, or potential, of Big Data in the public sector? By reviewing the literature and summarizing insights from a series of interviews from public sector Chief Information Officers (CIOs), we offer a scholarly foundation for both practitioners and researchers interested in understanding Big Data in the public sector.  2014,  The Author(s) 2014.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Tan, Jie</author><author>Doing, Georgia</author><author>Lewis, Kimberley A</author><author>Price, Courtney E</author><author>Chen, Kathleen M</author><author>Cady, Kyle C</author><author>Perchuk, Barret</author><author>Laub, Michael T</author><author>Hogan, Deborah A</author><author>Greene, Casey S</author></authors></contributors><titles><title>Unsupervised Extraction of Stable Expression Signatures from Public Compendia with an Ensemble of Neural Networks</title><secondary-title>Cell Systems</secondary-title></titles><periodical><full-title>Cell Systems</full-title></periodical><pages>63 - 71.e6</pages><volume>5</volume><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1016/j.cels.2017.06.003</electronic-resource-num><notes>Cited by: 56</notes><research-notes>Cited by: 56</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023158178&amp;doi=10.1016%2Fj.cels.2017.06.003&amp;partnerID=40&amp;md5=85c6081f6274fbf45c24bd8178407531</url></web-urls></urls><abstract>Cross-experiment comparisons in public data compendia are challenged by unmatched conditions and technical noise. The ADAGE method, which performs unsupervised integration with denoising autoencoder neural networks, can identify biological patterns, but because ADAGE models, like many neural networks, are over-parameterized, different ADAGE models perform equally well. To enhance model robustness and better build signatures consistent with biological pathways, we developed an ensemble ADAGE (eADAGE) that integrated stable signatures across models. We applied eADAGE to a compendium of Pseudomonas aeruginosa gene expression profiling experiments performed in 78 media. eADAGE revealed a phosphate starvation response controlled by PhoB in media with moderate phosphate and predicted that a second stimulus provided by the sensor kinase, KinB, is required for this PhoB activation. We validated this relationship using both targeted and unbiased genetic approaches. eADAGE, which captures stable biological patterns, enables cross-experiment comparisons that can highlight measured but undiscovered relationships.  2017 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rogge, Nicky</author><author>Agasisti, Tommaso</author><author>De Witte, Kristof</author></authors></contributors><titles><title>Big data and the measurement of public organizations performance and efficiency: The state-of-the-art</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>263 - 281</pages><volume>32</volume><issue>4</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1177/0952076716687355</electronic-resource-num><notes>Cited by: 75</notes><research-notes>Cited by: 75</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030151796&amp;doi=10.1177%2F0952076716687355&amp;partnerID=40&amp;md5=69687fa620d2fe4b68d500e49d436674</url></web-urls></urls><abstract>The increasing availability of statistical data raises opportunities for big data and learning analytics. Here, we review the academic literature and research relating to the use of big data analytics in the public sector, and its contribution to public organizations performance and efficiency. We outline the advantages as well as the limitations of using big data in public sector organizations and identify research gaps in recent studies and interesting areas for future research.  2017,  The Author(s) 2017.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nollenberger, Karl</author></authors></contributors><titles><title>On-Campus versus Hybrid Courses in a Master of Public Administration Program</title><secondary-title>Journal of Public Affairs Education</secondary-title></titles><periodical><full-title>Journal of Public Affairs Education</full-title></periodical><pages>625 - 636</pages><volume>23</volume><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1080/15236803.2017.12002273</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066337290&amp;doi=10.1080%2F15236803.2017.12002273&amp;partnerID=40&amp;md5=b2ea7833c1ed23c8535bef1208261256</url></web-urls></urls><abstract>Online and hybrid (online plus on-campus) learning has increased significantly in the twenty-first century. One Midwestern university started offering more hybrid courses in 2005 in its Master in Public Administration program. The author conducted student surveys to assess the preferences of adult learners for the different modes of instruction, their perceptions of each process, and their perceptions of each modes learning outcomes. Analysis of survey responses indicates that the majority of adult learners value the flexibility of online learning while still desiring on-campus sessions for interaction with other students and the professor, which students believe improves learning outcomes. Significantly, students believe that the combination of on-campus and online classes adds overall value to aspects of their learning experience.  2017, Copyright  Taylor &amp; Francis Group, LLC.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kempeneer, Shirley</author><author>Heylen, Frederik</author></authors></contributors><titles><title>Virtual state, where are you? A literature review, framework and agenda for failed digital transformation</title><secondary-title>Big Data and Society</secondary-title></titles><periodical><full-title>Big Data and Society</full-title></periodical><volume>10</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1177/20539517231160528</electronic-resource-num><notes>Cited by: 9</notes><research-notes>Cited by: 9</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150257874&amp;doi=10.1177%2F20539517231160528&amp;partnerID=40&amp;md5=f11c1824dc468dfffb38993353bd4774</url></web-urls></urls><abstract>The users, sensors and networks of the Internet of Things generate huge amounts of data. Given the sophisticated (artificially intelligent) algorithms, computing power and software available, we would expect governments to have successfully completed their digital transformation into Jane Fountain's (2001) Virtual State. In practice, despite heavy investments, governments often fail to enact new digital technologies in an efficient, appropriate or fair way. This article provides an overview of techno-rational and socio-political failures and solutions at the macro-, meso- and micro-level to support digital transformation. The reviewed articles suggest a modest approach to digital transformation, with an emphasis on high-quality in-house IT infrastructure and expertise, but also better collaborative networks and strong leadership ensuring human oversight.  The Author(s) 2023.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Wenjing</author></authors></contributors><titles><title>Data analysis of intellectual property policy system based on Internet of Things</title><secondary-title>Enterprise Information Systems</secondary-title></titles><periodical><full-title>Enterprise Information Systems</full-title></periodical><pages>1475 - 1493</pages><volume>14</volume><issue>9-10</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1080/17517575.2020.1712744</electronic-resource-num><notes>Cited by: 9</notes><research-notes>Cited by: 9</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077840756&amp;doi=10.1080%2F17517575.2020.1712744&amp;partnerID=40&amp;md5=3237cbd6c3b68afff981bae2b95412ca</url></web-urls></urls><abstract>The issuance and implementation of intellectual property policies have promoted the rapid development of intellectual property intermediary services in China, bringing new opportunities and challenges for public sectors of the government. With their continuous development, Internet of Things (IoT) technology and big data have become the analytical tools widely applied in many technical fields. Through the analysis of IoT data, the optimal resource configuration could be obtained, which would guide both governments and enterprise managers to make scientific decisions in terms of future development.  2020 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Asadabadi, Mehdi Rajabi</author><author>Chang, Elizabeth</author><author>Sharpe, Keiran</author></authors></contributors><titles><title>Requirement ambiguity and fuzziness in large-scale projects: The problem and potential solutions</title><secondary-title>Applied Soft Computing Journal</secondary-title></titles><periodical><full-title>Applied Soft Computing Journal</full-title></periodical><volume>90</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.asoc.2020.106148</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079098776&amp;doi=10.1016%2Fj.asoc.2020.106148&amp;partnerID=40&amp;md5=355a5f1a267dd669c09921e7515d7aa0</url></web-urls></urls><abstract>In large-scale projects, it often occurs that the product the purchaser ends up receiving  possibly from projects extending over many years  differs from what they expected. The provider usually defends its delivered product and may blame the imprecision and ambiguity of the requirements, defined by the purchaser, as the primary reason for misinterpretation of requirements and resulting deficiencies. This letter relies on game theory to explain this problem including both intentional and unintentional misinterpretation of requirements. The letter also highlights the practical and scientific significance of the problem using two real-world cases and suggests potential tools and techniques from soft computing in order to develop decision support systems to address the problem.  2020 Elsevier B.V.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ballestar, Mara Teresa</author><author>Daz-Chao, ngel</author><author>Sainz, Jorge</author><author>Torrent-Sellens, Joan</author></authors></contributors><titles><title>Impact of robotics on manufacturing: A longitudinal machine learning perspective</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>162</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.techfore.2020.120348</electronic-resource-num><notes>Cited by: 41</notes><research-notes>Cited by: 41</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092165904&amp;doi=10.1016%2Fj.techfore.2020.120348&amp;partnerID=40&amp;md5=1441be0b0779e49505e23ee32333a084</url></web-urls></urls><abstract>The evaluation of the impact of the adoption of industrial robotics on business is increasingly relevant in the current context of digital transformation. Although many companies are eager to adopt these technologies as a means to increase productivity, some concerns have been raised about the cost impact of the transformation, and its effect on the workforce. A growing body of literature is studying these phenomena but according to our review of it, there is no longitudinal perspective over 25 years illustrating the relationship between the attitude of companies to robotics and principal business indicators. This investigation uses an innovative machine learning model comprising an automated nested longitudinal clustering performed in two stages, and it is applied over a large sample of 4,578 companies from the Business Strategy Survey conducted by the Spanish Ministry of Finance and Public Administration. The findings of this research are novel in this field not only because of the longitudinal modelling applied in two stages but also because of the understanding of how companies characteristics and performance evolve over time depending on their degree of adoption of robotics. This knowledge is relevant for companies to understand the impact of their transformation to robotics. It also allows for the development of strategies that boost the efficiency of the companies, provides them with tools to protect them from negative financial events, and leads to an optimal sizing of their workforce.  2020 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cetera, Wiesaw</author><author>Gogoek, Wodzimierz</author><author>onierski, Aleksander</author><author>Jaruga, Dariusz</author></authors></contributors><titles><title>Potential for the use of large unstructured data resources by public innovation support institutions</title><secondary-title>Journal of Big Data</secondary-title></titles><periodical><full-title>Journal of Big Data</full-title></periodical><volume>9</volume><issue>1</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1186/s40537-022-00610-6</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128957082&amp;doi=10.1186%2Fs40537-022-00610-6&amp;partnerID=40&amp;md5=e83541274fd8d5c2c2577ced2015ad4b</url></web-urls></urls><abstract>Effective programming of research and development (R&amp;D) support, adjusted to the actual potential of beneficiaries, requires the use of modern analytical tools. An efficient R&amp;D support system requires up-to-date data on technological trends, ongoing (and planning) research, market needs and developing innovation. The most popular programming methods were based on the analysis of data with a 4 to 5-year time delay until recently. Having described the method of refining information from unstructured data, we explore how to make it possible not only to solve the issue of up-to-date data but to identify of the latest trends in R&amp;D activities. The analytical tools we describe were already fully functional in 2018 and are constantly being improved. The article presents the potential of one tool that can be applied in public support institutions. Methods of identifying and diagnosing technology trends are presented within the case study of the electric car technology trend. The presented case study shows the effectiveness of the method we developed for identifying and diagnosing areas requiring support from public funds. Public institutions, including public institutions supporting R&amp;D and innovation processes, can apply tools that allow an increase in the quality of public support programmes offered, but also beneficial for the quality of strategic resources management within the institution itself. The comparison of the predictions made by the described tools with the classifications made by experts, the former are more accurate and precise. Moreover, the results of the analyses performed by the presented model are not influenced by distorting factorsfads, trends, political pressures, or processes with an unidentified, non-substantive background. It should be emphasized that the accuracy of the whole model is 0.84. The described tools and methods are already directly applicable in many areas related to the support of R&amp;D activity worldwide. The article presents a solution that effectively enables the management of more precise programmes supporting innovative activities used for the first time in Poland. It is also one of the first uses of these methods by public administration in the world. Our approach not only strengthens improved adjustment of the support offered for R&amp;D activity, but also makes it possible to apply and improve management methods in public institutions.  2022, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hartley, Jean</author></authors></contributors><titles><title>Population analysis of organizational innovation and learning</title><secondary-title>Public Administration</secondary-title></titles><periodical><full-title>Public Administration</full-title></periodical><pages>942 - 959</pages><volume>100</volume><issue>4</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1111/padm.12771</electronic-resource-num><notes>Cited by: 6</notes><research-notes>Cited by: 6</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112383054&amp;doi=10.1111%2Fpadm.12771&amp;partnerID=40&amp;md5=7bf9fe4acfa3ffd73da872b64abe7265</url></web-urls></urls><abstract>This article argues for a population level of analysis, addressing a theoretical and empirical gap and enabling the analysis of transition, tempo, and timing at the macro level. The article examines four theories of population-level innovation: population ecology, neo-institutional theory, innovation diffusion, and population-level learning theory. A population-level empirical study of innovation and organizational learning addresses three research questions: the first and second examine patterns of innovation underpinned by learning over space and over time. The third concerns the processes and dynamics of those patterns. The data derive from the local government using mixed methods and multiple respondents over 9 years. The research shows the uneven spread of learning across the population, with the emergence of two subpopulations. Over time, innovation and learning strategies shifted. Learning in the population occurred through both direct interaction and vicarious learning from others in the population. Implications for population-level theory, innovation, and learning are explored.  2021 John Wiley &amp; Sons Ltd.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Espinoza, Maria I</author><author>Aronczyk, Melissa</author></authors></contributors><titles><title>Big data for climate action or climate action for big data?</title><secondary-title>Big Data and Society</secondary-title></titles><periodical><full-title>Big Data and Society</full-title></periodical><volume>8</volume><issue>1</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1177/2053951720982032</electronic-resource-num><notes>Cited by: 23</notes><research-notes>Cited by: 23</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100965281&amp;doi=10.1177%2F2053951720982032&amp;partnerID=40&amp;md5=1a3e4ea443c5dbfd0fe8d757b6068eb0</url></web-urls></urls><abstract>Under the banner of data for good, companies in the technology, finance, and retail sectors supply their proprietary datasets to development agencies, NGOs, and intergovernmental organizations to help solve an array of social problems. We focus on the activities and implications of the Data for Climate Action campaign, a set of publicprivate collaborations that wield user data to design innovative responses to the global climate crisis. Drawing on in-depth interviews, first-hand observations at data for good events, intergovernmental and international organizational reports, and media publicity, we evaluate the logic driving Data for Climate Action initiatives, examining the implications of applying commercial datasets and expertise to environmental problems. Despite the increasing adoption of Data for Climate Action paradigms in government and public sector efforts to address climate change, we argue Data for Climate Action is better seen as a strategy to legitimate extractive, profit-oriented data practices by companies than a means to achieve global goals for environmental sustainability.  The Author(s) 2021.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ortiz, Guadalupe</author><author>Zouai, Meftah</author><author>Kazar, Okba</author><author>Garcia-de-Prado, Alfonso</author><author>Boubeta-Puig, Juan</author></authors></contributors><titles><title>Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing</title><secondary-title>Computer Standards and Interfaces</secondary-title></titles><periodical><full-title>Computer Standards and Interfaces</full-title></periodical><volume>79</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.csi.2021.103550</electronic-resource-num><notes>Cited by: 34</notes><research-notes>Cited by: 34</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109793830&amp;doi=10.1016%2Fj.csi.2021.103550&amp;partnerID=40&amp;md5=ca74fbfbf75ea930971d1ca51b06af7b</url></web-urls></urls><abstract>The Internet of Things (IoT) has grown significantly in popularity, accompanied by increased capacity and lower cost of communications, and overwhelming development of technologies. At the same time, big data and real-time data analysis have taken on great importance and have been accompanied by unprecedented interest in sharing data among citizens, public administrations and other organisms, giving rise to what is known as the Collaborative Internet of Things. This growth in data and infrastructure must be accompanied by a software architecture that allows its exploitation. Although there are various proposals focused on the exploitation of the IoT at edge, fog and/or cloud levels, it is not easy to find a software solution that exploits the three tiers together, taking maximum advantage not only of the analysis of contextual and situational data at each tier, but also of two-way communications between adjacent ones. In this paper, we propose an architecture that solves these deficiencies by proposing novel technologies which are appropriate for managing the resources of each tier: edge, fog and cloud. In addition, the fact that two-way communications along the three tiers of the architecture is allowed considerably enriches the contextual and situational information in each layer, and substantially assists decision making in real time. The paper illustrates the proposed software architecture through a case study of respiratory disease surveillance in hospitals. As a result, the proposed architecture permits efficient communications between the different tiers responding to the needs of these types of IoT scenarios.  2021 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Lee, Gwanhoo</author></authors></contributors><titles><title>What roles should the government play in fostering the advancement of the internet of things?</title><secondary-title>Telecommunications Policy</secondary-title></titles><periodical><full-title>Telecommunications Policy</full-title></periodical><pages>434 - 444</pages><volume>43</volume><issue>5</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.telpol.2018.12.002</electronic-resource-num><notes>Cited by: 24</notes><research-notes>Cited by: 24</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057725886&amp;doi=10.1016%2Fj.telpol.2018.12.002&amp;partnerID=40&amp;md5=2a09962e7f0fb1f3c2689f0639cf9e69</url></web-urls></urls><abstract>The Internet of Things (IoT) has the potential to transform the way we live, work, do business, and meet the needs of the public. While IoT's potential benefits for economic growth and social welfare appear to be indisputable, IoT faces several technological, social, legal, and regulatory policy challenges, ranging from interoperability and spectrum availability to cybersecurity and privacy. These challenges can and should be addressed by the joint efforts of a wide range of stakeholders from the public and private sector. The advancement of IoT depends in part on how policymakers respond to the opportunities and challenges associated with it. This research aims to identify the potential roles for the government in fostering the advancement of IoT innovation and adoption. To this end, we analyze data collected from 177 documents of public comments submitted to the U.S. National Telecommunications and Information Administration and from a focus group discussion with senior managers. Our content data analysis results in a set of recommendations for the government in terms of general policy principles, specific policy prescriptions, and governance and process approach that facilitate policy development.  2018 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Tao</author><author>Guo, Wenshan</author><author>Gao, Xian</author><author>Liang, Zhehao</author></authors></contributors><titles><title>AI-based self-service technology in public service delivery: User experience and influencing factors</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>38</volume><issue>4</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.giq.2020.101520</electronic-resource-num><notes>Cited by: 92</notes><research-notes>Cited by: 92</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089828048&amp;doi=10.1016%2Fj.giq.2020.101520&amp;partnerID=40&amp;md5=28cacbd12928c430ac12983255acca06</url></web-urls></urls><abstract>Public sectors are utilizing AI-based self-service technology (SST) at an accelerating rate, given its potential for improving work efficiency and user experience, reducing service costs, and relieving human workloads. However, there is a limited understanding of the factors influencing citizens' user experience when services supported by AI-based SST are provided. Thus, with insights from the Consumer Value Theory, this paper aims to explore the factors that are important to AI-based SST user experience and the conditional role of trust in government. The on-site survey of 379 citizens in a public service center in China indicates that user experience positively relates to personalization and aesthetics and negatively associates with perceived time spent on the AI-based self-service machines. In addition, the results suggest that citizens with more trust in government are more likely to have a pleasant experience coming from AI-based SST's personalization and aesthetics. Public managers should ensure that the AI-based SST is aesthetically appealing and should be able to personalize the delivery of the right contents to the right person at the right time. Furthermore, they should always prioritize cultivating more trust from citizens to achieve a more positive user experience.  2020 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bogarn, Alejandro</author><author>Cerezo, Rebeca</author><author>Romero, Cristbal</author></authors></contributors><titles><title>A survey on educational process mining</title><secondary-title>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</secondary-title></titles><periodical><full-title>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</full-title></periodical><volume>8</volume><issue>1</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1002/widm.1230</electronic-resource-num><notes>Cited by: 187</notes><research-notes>Cited by: 187</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038557947&amp;doi=10.1002%2Fwidm.1230&amp;partnerID=40&amp;md5=d79624bcefd64800070825fd35b19c4d</url></web-urls></urls><abstract>Educational process mining (EPM) is an emerging field in educational data mining (EDM) aiming to make unexpressed knowledge explicit and to facilitate better understanding of the educational process. EPM uses log data gathered specifically from educational environments in order to discover, analyze, and provide a visual representation of the complete educational process. This paper introduces EPM and elaborates on some of the potential of this technology in the educational domain. It also describes some other relevant, related areas such as intentional mining, sequential pattern mining and graph mining. It highlights the components of an EPM framework and it describes the different challenges when handling event logs and other generic issues. It describes the data, tools, techniques and models used in EPM. In addition, the main work in this area is described and grouped by educational application domains. WIREs Data Mining Knowl Discov 2018, 8:e1230. doi: 10.1002/widm.1230. This article is categorized under: Application Areas &gt; Business and Industry Application Areas &gt; Education and Learning Application Areas &gt; Government and Public Sector.  2017 Wiley Periodicals, Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rachovitsa, Adamantia</author><author>Johann, Niclas</author></authors></contributors><titles><title>The Human Rights Implications of the Use of AI in the Digital Welfare State: Lessons Learned from the Dutch SyRI Case</title><secondary-title>Human Rights Law Review</secondary-title></titles><periodical><full-title>Human Rights Law Review</full-title></periodical><volume>22</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1093/hrlr/ngac010</electronic-resource-num><notes>Cited by: 12</notes><research-notes>Cited by: 12</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128936278&amp;doi=10.1093%2Fhrlr%2Fngac010&amp;partnerID=40&amp;md5=25745b26ef0560ae5f1d0274c2137f70</url></web-urls></urls><abstract>The article discusses the human rights implications of algorithmic decision-making in the social welfare sphere. It does so against the background of the 2020 Hagues District Court judgment in a case challenging the Dutch governments use of System Risk Indicationan algorithm designed to identify potential social welfare fraud. Digital welfare state initiatives are likely to fall short of meeting basic requirements of legality and protecting against arbitrariness. Moreover, the intentional opacity surrounding the implementation of algorithms in the public sector not only hampers the effective exercise of human rights but also undermines proper judicial oversight. The analysis unpacks the relevance and complementarity of three legal/regulatory frameworks governing algorithmic systems: data protection, human rights law and algorithmic accountability. Notwithstanding these frameworks invaluable contribution, the discussion casts doubt on whether they are well-suited to address the legal challenges pertaining to the discriminatory effects of the use of algorithmic systems.  The Author(s) [2022]. Published by Oxford University Press. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Yesmagambetov, Daulet</author><author>Kussainova, Larisa</author><author>Junusbekova, Gulsara</author></authors></contributors><titles><title>DIGITAL TOOLS FOR IMPROVING THE EFFICIENCY OF PUBLIC PROCUREMENT OF WORKS IN THE REPUBLIC OF KAZAKHSTAN; [SKAITMENINES PRIEMONES VIEUJU PIRKIMU EFEKTYVUMUI GERINTI KAZACHSTANO RESPUBLIKOJE]</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>395 - 406</pages><volume>21</volume><issue>4</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.13165/VPA-22-21-4-04</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149005773&amp;doi=10.13165%2FVPA-22-21-4-04&amp;partnerID=40&amp;md5=02e8baaf6bb3bc4c8802d8a5dd21c78f</url></web-urls></urls><abstract>The issue of public procurement effectiveness is becoming increasingly relevant in the context of the observed budget deficit in Kazakhstan. In this article, business processes related to ensuring the best combination of low price and quality in public procurement as the main indicators of procurement efficiency are studied and described in more depth. Considering the problems of public procurement efficiency, many researchers analyze the supplier identification stage. However, in the procurement of works, the execution phase is equally, if not more, important for efficiency. Analysis of the work execution process in Kazakhstan revealed problems related to quality control of the work performed and the construction materials used, as well as limited competition in their procurement. The high degree of the human factor's presence in the quality assurance process and the low availability of information about the demand for goods creates the risk of purchasing poor-quality goods at a high price. While the effectiveness of using big data in the decision-making process is universally proven, information in the public procurement system is not accumulated properly. In this regard, to ensure the best combination of price and quality of work, the authors propose a model of public procurement of works using digital tools.  2022 Uspekhi Khimii, ZIOC RAS, Russian Academy of Sciences.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Xiong, Wenjing</author><author>Zhou, Ping</author></authors></contributors><titles><title>A search strategy for publications in interdisciplinary research</title><secondary-title>Profesional de la Informacion</secondary-title></titles><periodical><full-title>Profesional de la Informacion</full-title></periodical><volume>32</volume><issue>5</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.3145/epi.2023.sep.22</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174628783&amp;doi=10.3145%2Fepi.2023.sep.22&amp;partnerID=40&amp;md5=5edca0c20046ec60ffaa28d518e0542f</url></web-urls></urls><abstract>To retrieve the right collection of publications in interdisciplinary research, we have developed a search strategy with four progressive steps and take the area of public affairs (PA) as a case study. A set of seed publications in PA is first identified, followed by the construction of a pool set of publications with wider coverage for refinement in the next step, which is critical and in which an expanded set of publications is established on the basis of the references and text semantic information, thus generating two respective subsets. One of these subsets is obtained on the basis of the number of references shared between each publication pair between the seed set and the pool set. To optimize the results, we construct two models, viz. a support vector machine (SVM) and a fully connected neural network (FCNN), and find that the FCNN model outperforms the SVM model. The second subset of publications are collected by selecting the publications with high topic similarity to the seed publications collected in the first step. The final step is to integrate the seed publications with the expanded publications collected in steps 1 and 3. The results show that PA research involves an extremely wide range of disciplines (n = 45), among which public administration, environmental sciences, economics, management, and health policy and services, among others, play the most significant roles.  2023, El Profesional de la Informacion. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Misra, Shalini</author><author>Katz, Benjamin</author><author>Roberts, Patrick</author><author>Carney, Mackenzie</author><author>Valdivia, Isabel</author></authors></contributors><titles><title>Toward a person-environment fit framework for artificial intelligence implementation in the public sector</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>41</volume><issue>3</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101962</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199797451&amp;doi=10.1016%2Fj.giq.2024.101962&amp;partnerID=40&amp;md5=19aa9ece174b9508de5bd152088d9a61</url></web-urls></urls><abstract>Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI.  2024 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kulawiak, Marcin</author><author>Dawidowicz, Agnieszka</author><author>Pacholczyk, Marek Emanuel</author></authors></contributors><titles><title>Analysis of server-side and client-side Web-GIS data processing methods on the example of JTS and JSTS using open data from OSM and geoportal</title><secondary-title>Computers and Geosciences</secondary-title></titles><periodical><full-title>Computers and Geosciences</full-title></periodical><pages>26 - 37</pages><volume>129</volume><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.cageo.2019.04.011</electronic-resource-num><notes>Cited by: 38</notes><research-notes>Cited by: 38</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066064473&amp;doi=10.1016%2Fj.cageo.2019.04.011&amp;partnerID=40&amp;md5=689781ec8fc2c88d650f9361768fa1e2</url></web-urls></urls><abstract>The last decade has seen a rapid evolution of processing, analysis and visualization of freely available geographic data using Open Source Web-GIS. In the beginning, Web-based Geographic Information Systems employed a thick-client approach which required installation of platform-specific browser plugins. Later on, research focus shifted to platform-independent thin client solutions in which data processing and analysis was performed by the server machine. More recently, however, the rapid development of computer hardware as well as software technologies such has HTML5 has enabled the creation of platform-independent thick clients which offer advanced GIS functionalities such as geoprocessing. This article aims to analyse the current state of Open Source technologies and publicly available geographic data sources in the context of creating cost-effective Web-GIS applications for integration and processing of spatial data. For this purpose the article discusses the availability and potential of Web-GIS architectures, software libraries and data sources. The analysis of freely available data sources includes a discussion of the quality and accuracy of crowd-sourced as well as public sector data, while the investigation of software libraries and architectures involves a comparison of server-side and client-side data processing performance under a set of real-world scenarios. The article concludes with a discussion of the choice of cost-effective Web-GIS architectures, software libraries and data sources in the context of the institution and environment of system deployment.  2019 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Carbonari, Alessandro</author><author>Corneli, Alessandra</author><author>Di Giuda, Giuseppe Martino</author><author>Ridolfi, Luigi</author><author>Villa, Valentina</author></authors></contributors><titles><title>A decision support system for multi-criteria assessment of large building stocks</title><secondary-title>Journal of Civil Engineering and Management</secondary-title></titles><periodical><full-title>Journal of Civil Engineering and Management</full-title></periodical><pages>477 - 494</pages><volume>25</volume><issue>5</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.3846/jcem.2019.9872</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068085813&amp;doi=10.3846%2Fjcem.2019.9872&amp;partnerID=40&amp;md5=ddc007adb622951feb0c6129633db8f8</url></web-urls></urls><abstract>Both public administrations and private owners of large building stocks need to work out plans for the management of their property, while having to deal with yearly budget limitations. Particularly for the former, this is a rather critical challenge, since public administrations are given the responsibility of sticking to very strict budget distributions over the years. As a consequence, when planning the actions to be taken on their building stocks in order to comply with their current use and the legislation in-force, they need to classify refurbishment priorities. The aim of this paper is to develop a first tool based on Bayesian Networks that offers an effective decision support service for owners even in case some information is incomplete. This tool can be used to evaluate the compliance of existing buildings with the latest standards. The decision support platform proposed includes a multi-criteria evaluation approach combining several performance indicators, each of which related to a specific regulatory area. This tool can be applied to existing buildings, where the building with the lowest score shows the highest priority of intervention. Also, the platform performs an assessment of expected costs for required refurbishment or renovation actions.  2019 The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Corsi, Alana</author><author>de Souza, Fabiane Florencio</author><author>Pagani, Regina Negri</author><author>Kovaleski, Joo Luiz</author></authors></contributors><titles><title>Big data analytics as a tool for fighting pandemics: a systematic review of literature</title><secondary-title>Journal of Ambient Intelligence and Humanized Computing</secondary-title></titles><periodical><full-title>Journal of Ambient Intelligence and Humanized Computing</full-title></periodical><pages>9163 - 9180</pages><volume>12</volume><issue>10</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1007/s12652-020-02617-4</electronic-resource-num><notes>Cited by: 55</notes><research-notes>Cited by: 55</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094658482&amp;doi=10.1007%2Fs12652-020-02617-4&amp;partnerID=40&amp;md5=73e6ca435291ab8cd70018fc712636d9</url></web-urls></urls><abstract>Infectious and contagious diseases represent a major challenge for health systems worldwide, either in private or public sectors. More recently, with the increase in cases related to these problems, combined with the recent global pandemic of COVID-19, the need to study strategies to treat these health disturbs is even more latent. Big Data, as well as Big Data Analytics techniques, have been addressed in this context with the possibility of predicting, mapping, tracking, monitoring, and raising awareness about these epidemics and pandemics. Thus, the purpose of this study is to identify how BDA can help in cases of pandemics and epidemics. To achieve this purpose, a systematic review of literature was carried out using the methodology Methodi Ordinatio. The rigorous search resulted in a portfolio of 45 articles, retrived from scientific databases. For the collection and analysis of data, the softwares NVivo 12 and VOSviewer were used. The content analysis sought to identify how Big Data and Big Data Analytics can help fighting epidemics and pandemics. The types and sources of data used in cases of previous epidemics and pandemics were identified, as well as techniques for treating these data. The results showed that the main sources of data come from social media and Internet search engines. The most common techniques for analyzing these data involve the use of statistics, such as correlation and regression, combined with other techniques. Results shows that there is a fruitiful field of study to be explored by both areas, Big Data and Health.  2020, Springer-Verlag GmbH Germany, part of Springer Nature.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Xia, Yan</author><author>Lv, Gongming</author><author>Wang, Huijuan</author><author>Ding, Lin</author></authors></contributors><titles><title>Evolution of digital economy research: A bibliometric analysis</title><secondary-title>International Review of Economics and Finance</secondary-title></titles><periodical><full-title>International Review of Economics and Finance</full-title></periodical><pages>1151 - 1172</pages><volume>88</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.iref.2023.07.051</electronic-resource-num><notes>Cited by: 15</notes><research-notes>Cited by: 15</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166211542&amp;doi=10.1016%2Fj.iref.2023.07.051&amp;partnerID=40&amp;md5=10cd4bdeb786b2ba7b742842d4c4c78a</url></web-urls></urls><abstract>As a new economic form, the digital economy has become an important manifestation of national comprehensive strength, which is an absolute key force to enhance international competitiveness and reshape the international economic landscape in the digital era. Hundreds of schools of thought contend on the digital economy, and a consensus theory and framework has not yet been formed. In order to clarify the development venation and research status of the digital economy, and highlight the key points of digital economy research field in the future, this paper conducts bibliometric analysis and visualization by using Cite Space on digital economy connotation and extension mainly from four respects: the period characteristics of published articles, the distribution characteristics of articles, the characteristics of keyword changes, and the evolution characteristics of research directions. We take the WOS Core Collection as the database, and sets the subject headings with the digital economy connotation and extension as the retrieval target, and finally obtained 918 and 10,735 articles respectively as of 2022. We find that (a) the research on the connotation of the digital economy has experienced a long incubation and germination period, while the denotation period has maintained a long period of popularity, and both have ushered in a research climax in recent years; (b) the research team on the connotation of the digital economy is relatively scattered, and there is no unified consensus on the connotation of the digital economy, while the connection between the denotation period teams is relatively close; (c) from the perspective of keywords, internet and big data have caused a local upsurge in digital economy research. Otherwise, the denotation period hotspot of the digital economy is about 15 years earlier than the connotation research on average, which provides fertile soil for the formation, development and maturity of the digital economy connotation; (d) judging from the citation frequency of references, the total number of research articles on the connotation of the digital economy published after 2017 is relatively high and relatively concentrated, and a consensus on the understanding of the connotation of the digital economy has begun to form; (e) from the perspective of the evolution of research directions, Information Science Library Science, Computer Science and Government Law are the research hotspots in recent years, and Public Administration and Engineering may be the research growth points in the next few years.  2023 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Banabilah, Syreen</author><author>Aloqaily, Moayad</author><author>Alsayed, Eitaa</author><author>Malik, Nida</author><author>Jararweh, Yaser</author></authors></contributors><titles><title>Federated learning review: Fundamentals, enabling technologies, and future applications</title><secondary-title>Information Processing and Management</secondary-title></titles><periodical><full-title>Information Processing and Management</full-title></periodical><volume>59</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.ipm.2022.103061</electronic-resource-num><notes>Cited by: 195</notes><research-notes>Cited by: 195</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136606514&amp;doi=10.1016%2Fj.ipm.2022.103061&amp;partnerID=40&amp;md5=5244fdba096f23260dda11f14cb60009</url></web-urls></urls><abstract>Federated Learning (FL) has been foundational in improving the performance of a wide range of applications since it was first introduced by Google. Some of the most prominent and commonly used FL-powered applications are Android's Gboard for predictive text and Google Assistant. FL can be defined as a setting that makes on-device, collaborative Machine Learning possible. A wide range of literature has studied FL technical considerations, frameworks, and limitations with several works presenting a survey of the prominent literature on FL. However, prior surveys have focused on technical considerations and challenges of FL, and there has been a limitation in more recent work that presents a comprehensive overview of the status and future trends of FL in applications and markets. In this survey, we introduce the basic fundamentals of FL, describing its underlying technologies, architectures, system challenges, and privacy-preserving methods. More importantly, the contribution of this work is in scoping a wide variety of FL current applications and future trends in technology and markets today. We present a classification and clustering of literature progress in FL in application to technologies including Artificial Intelligence, Internet of Things, blockchain, Natural Language Processing, autonomous vehicles, and resource allocation, as well as in application to market use cases in domains of Data Science, healthcare, education, and industry. We discuss future open directions and challenges in FL within recommendation engines, autonomous vehicles, IoT, battery management, privacy, fairness, personalization, and the role of FL for governments and public sectors. By presenting a comprehensive review of the status and prospects of FL, this work serves as a reference point for researchers and practitioners to explore FL applications under a wide range of domains.  2022 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zeng, Yuan</author><author>Ma, Hui-Min</author><author>Zhang, Qian-Yu</author><author>Tao, Lin</author><author>Wang, Tao</author><author>Wan, Cong</author><author>Chen, She-Jun</author><author>Mai, Bi-Xian</author></authors></contributors><titles><title>Complex polycyclic aromatic compound mixtures in PM2.5 in a Chinese megacity: Spatio-temporal variations, toxicity, and source apportionment</title><secondary-title>Environment International</secondary-title></titles><periodical><full-title>Environment International</full-title></periodical><volume>179</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.envint.2023.108159</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168538622&amp;doi=10.1016%2Fj.envint.2023.108159&amp;partnerID=40&amp;md5=a81dded30341d954528298c4a1ae509b</url></web-urls></urls><abstract>Polycyclic aromatic compounds (PACs) are important toxic organic components in fine particulate matter (PM2.5), whereas the links between PM2.5 toxicity and associated PACs in ambient air are poorly understood. This study investigated the spatialtemporal variations of PACs in PM2.5 collected from 11 sampling sites across a Chinese megacity and characterized the reactive oxygen species (ROS) generation and cytotoxicity induced by organic extracts of PM2.5 based on cellular assays. The extra trees regression model based on machine learning and ridge regression were used to identify the key toxicants among complex PAC mixtures. The total concentrations of these PACs varied from 2.12 to 71.7 ng/m3 across the study city, and polycyclic aromatic hydrocarbons (PAHs) are the main PACs. The spatial variations of the toxicological indicators generally resembled those of the PAC concentrations, and the PM2.5 related to waste treatment facilities exhibited the strongest toxic potencies. The ROS generation was highly correlated with high molecular weight PAHs (MW302 PAHs), followed by PAHs with MW&lt;302 amu and oxygenated PAHs, but not with nitrated PAHs and the plastics additives. The cell mortality showed weak correlations with these organic constituents. The associations between the biological endpoints and these PM2.5-bound contaminants were further confirmed by exposure to authentic chemicals. Four primary sources of PACs were identified, among which coal and biomass combustion sources (30.2% of the total PACs) and industrial sources (31.0%) were predominant. PACs emitted from industrial sources were highly associated with ROS generation in this city. Our findings highlight the potent ROS-generating potential of MW302 PAHs and the importance of industrial sources contributing to PM2.5 toxicity in this megacity, raising public concerns and further administration.  2023 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Giannakos, Michail N</author><author>Mikalef, Patrick</author><author>Pappas, Ilias O</author></authors></contributors><titles><title>Systematic Literature Review of E-Learning Capabilities to Enhance Organizational Learning</title><secondary-title>Information Systems Frontiers</secondary-title></titles><periodical><full-title>Information Systems Frontiers</full-title></periodical><pages>619 - 635</pages><volume>24</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1007/s10796-020-10097-2</electronic-resource-num><notes>Cited by: 33</notes><research-notes>Cited by: 33</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100219106&amp;doi=10.1007%2Fs10796-020-10097-2&amp;partnerID=40&amp;md5=3690fe537b2099573239b9ae7f3a3253</url></web-urls></urls><abstract>E-learning systems are receiving ever increasing attention in academia, business and public administration. Major crises, like the pandemic, highlight the tremendous importance of the appropriate development of e-learning systems and its adoption and processes in organizations. Managers and employees who need efficient forms of training and learning flow within organizations do not have to gather in one place at the same time or to travel far away to attend courses. Contemporary affordances of e-learning systems allow users to perform different jobs or tasks for training courses according to their own scheduling, as well as to collaborate and share knowledge and experiences that result in rich learning flows within organizations. The purpose of this article is to provide a systematic review of empirical studies at the intersection of e-learning and organizational learning in order to summarize the current findings and guide future research. Forty-seven peer-reviewed articles were collected from a systematic literature search and analyzed based on a categorization of their main elements. This survey identifies five major directions of the research on the confluence of e-learning and organizational learning during the last decade. Future research should leverage big data produced from the platforms and investigate how the incorporation of advanced learning technologies (e.g., learning analytics, personalized learning) can help increase organizational value.  2021, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zuiderwijk, Anneke</author><author>Chen, Yu-Che</author><author>Salem, Fadi</author></authors></contributors><titles><title>Implications of the use of artificial intelligence in public governance: A systematic literature review and a research agenda</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>38</volume><issue>3</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.giq.2021.101577</electronic-resource-num><notes>Cited by: 237</notes><research-notes>Cited by: 237</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103086959&amp;doi=10.1016%2Fj.giq.2021.101577&amp;partnerID=40&amp;md5=9d9059392cac8088c36742758978ae30</url></web-urls></urls><abstract>To lay the foundation for the special issue that this research article introduces, we present 1) a systematic review of existing literature on the implications of the use of Artificial Intelligence (AI) in public governance and 2) develop a research agenda. First, an assessment based on 26 articles on this topic reveals much exploratory, conceptual, qualitative, and practice-driven research in studies reflecting the increasing complexities of using AI in government  and the resulting implications, opportunities, and risks thereof for public governance. Second, based on both the literature review and the analysis of articles included in this special issue, we propose a research agenda comprising eight process-related recommendations and seven content-related recommendations. Process-wise, future research on the implications of the use of AI for public governance should move towards more public sector-focused, empirical, multidisciplinary, and explanatory research while focusing more on specific forms of AI rather than AI in general. Content-wise, our research agenda calls for the development of solid, multidisciplinary, theoretical foundations for the use of AI for public governance, as well as investigations of effective implementation, engagement, and communication plans for government strategies on AI use in the public sector. Finally, the research agenda calls for research into managing the risks of AI use in the public sector, governance modes possible for AI use in the public sector, performance and impact measurement of AI use in government, and impact evaluation of scaling-up AI usage in the public sector.  2021 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Wei</author><author>Zhang, Mingyang</author><author>Yuan, Ling</author><author>Fan, Fengchun</author></authors></contributors><titles><title>Social network analysis and public policy: whats new?</title><secondary-title>Journal of Asian Public Policy</secondary-title></titles><periodical><full-title>Journal of Asian Public Policy</full-title></periodical><pages>115 - 145</pages><volume>16</volume><issue>2</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/17516234.2021.1996869</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118342448&amp;doi=10.1080%2F17516234.2021.1996869&amp;partnerID=40&amp;md5=4d43c70f26c41a2f60f79b7d6b59c5d7</url></web-urls></urls><abstract>As a mature paradigm of network analysis, social network analysis (SNA) is suitable for exploring complicated and interactive relationships in policy research and is of great significance to the innovation and development of public policy research. In this paper, 45 typical articles published in high-ranking journals in the field of public administration were analysed using co-word analysis and qualitative analysis. The application of SNA in public policy studies, including research methods, analytic tools, and basic concepts of network analysis, were systematically reviewed. UCINET software was used to visualize the knowledge network of research topics. The main research topics were classified into five categories: agenda setting, policy network, advocacy coalition, policy learning and diffusion, policy implementation. Finally, this article suggests that network analysis in public administration should be thoroughly re-examined; in particular, scholars should consider the benefits of SNA for public policy research. In the application of SNA to public policy research, it is necessary to broaden the study perspective and scope, further strengthen interdisciplinary theoretical interaction and theoretical innovation, and take advantage of big data and other new technological tools that can develop giant network analysis for public policy.  2021 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Uen, Tinn-Shuan</author><author>Chang, Fi-John</author><author>Zhou, Yanlai</author><author>Tsai, Wen-Ping</author></authors></contributors><titles><title>Exploring synergistic benefits of Water-Food-Energy Nexus through multi-objective reservoir optimization schemes</title><secondary-title>Science of the Total Environment</secondary-title></titles><periodical><full-title>Science of the Total Environment</full-title></periodical><pages>341 - 351</pages><volume>633</volume><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1016/j.scitotenv.2018.03.172</electronic-resource-num><notes>Cited by: 89</notes><research-notes>Cited by: 89</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044167012&amp;doi=10.1016%2Fj.scitotenv.2018.03.172&amp;partnerID=40&amp;md5=f57f3619fd7e8917d22cf5aa2af2fadd</url></web-urls></urls><abstract>This study proposed a holistic three-fold scheme that synergistically optimizes the benefits of the Water-Food-Energy (WFE) Nexus by integrating the short/long-term joint operation of a multi-objective reservoir with irrigation ponds in response to urbanization. The three-fold scheme was implemented step by step: (1) optimizing short-term (daily scale) reservoir operation for maximizing hydropower output and final reservoir storage during typhoon seasons; (2) simulating long-term (ten-day scale) water shortage rates in consideration of the availability of irrigation ponds for both agricultural and public sectors during non-typhoon seasons; and (3) promoting the synergistic benefits of the WFE Nexus in a year-round perspective by integrating the short-term optimization and long-term simulation of reservoir operations. The pivotal Shihmen Reservoir and 745 irrigation ponds located in Taoyuan City of Taiwan together with the surrounding urban areas formed the study case. The results indicated that the optimal short-term reservoir operation obtained from the non-dominated sorting genetic algorithm II (NSGA-II) could largely increase hydropower output but just slightly affected water supply. The simulation results of the reservoir coupled with irrigation ponds indicated that such joint operation could significantly reduce agricultural and public water shortage rates by 22.2% and 23.7% in average, respectively, as compared to those of reservoir operation excluding irrigation ponds. The results of year-round short/long-term joint operation showed that water shortage rates could be reduced by 10% at most, the food production rate could be increased by up to 47%, and the hydropower benefit could increase up to 9.33 million USD per year, respectively, in a wet year. Consequently, the proposed methodology could be a viable approach to promoting the synergistic benefits of the WFE Nexus, and the results provided unique insights for stakeholders and policymakers to pursue sustainable urban development plans.  2018</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Uras, Marco</author><author>Cossu, Raimondo</author><author>Ferrara, Enrico</author><author>Liotta, Antonio</author><author>Atzori, Luigi</author></authors></contributors><titles><title>PmA: A real-world system for people mobility monitoring and analysis based on Wi-Fi probes</title><secondary-title>Journal of Cleaner Production</secondary-title></titles><periodical><full-title>Journal of Cleaner Production</full-title></periodical><volume>270</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.jclepro.2020.122084</electronic-resource-num><notes>Cited by: 18</notes><research-notes>Cited by: 18</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088903935&amp;doi=10.1016%2Fj.jclepro.2020.122084&amp;partnerID=40&amp;md5=205a310bce14a5b029ee720d8bf82eb9</url></web-urls></urls><abstract>A UN report states that in 2050, about 70% of the total world population will live in cities. This increases the complexity of the services that the local public administrations have to provide the citizens with to keep an acceptable level of quality of life. For an appropriate design, deployment and management of these services, there is the need for tools to extract data on how the people move, which activities they conduct out and their behaviour (in an anonymous way). This need has justified extensive efforts towards the design of effective solutions for extracting this information. In this work, we present the People Mobility Analytics (PmA) solution, which collects probe requests generated by Wi-Fi devices when scanning the radio channels to detect Access Points. The PmA system processes the collected data to extract key insights on the people mobility, such as: crowd density per area of interest, people flows, time of permanence, time of return, heat maps, origin-destination matrices and estimation of people positions. The major novelty with respect to the state of the art is related to new powerful indicators that are needed for some key city services, such as security management and people transport services, and the experimental activities carried out in real scenarios.  2020 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Huang, Jhong-You</author><author>Wey, Wann-Ming</author></authors></contributors><titles><title>Application of Big Data and Analytic Network Process for the Adaptive Reuse Strategies of School Land</title><secondary-title>Social Indicators Research</secondary-title></titles><periodical><full-title>Social Indicators Research</full-title></periodical><pages>1075 - 1102</pages><volume>142</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s11205-018-1951-y</electronic-resource-num><notes>Cited by: 16</notes><research-notes>Cited by: 16</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049589635&amp;doi=10.1007%2Fs11205-018-1951-y&amp;partnerID=40&amp;md5=d48d40eb7e47aa86b0438cba898dc6b8</url></web-urls></urls><abstract>Most recent discussion of the adaptive reuse of school land has focused almost exclusively on repurposing or redeploying vacant school space rather than comprehensively re-planning and constructing the entire school land for the overall needs of society and urban development. The relevant government agencies for school land reuse in Taiwan, such as the Ministry of Education and municipal governments, mostly provide subjective regulations or revitalization provisions for the sustainable development of school resources; however, no specific scientific assessment or a planning procedure has been proposed to revitalize school land. Therefore, constructing a scientific, quantitative, and objective planning framework and procedure is necessary for the adaptive reuse of school land based on the needs of overall society and urban development in order to replace the existing and outdated planning philosophy and to correct prominent shortcomings of past planning operations that were solely in accordance with the qualitative judgment and decision making of official agencies. In this study, we mainly adopted the analytic network process (ANP) and big data, including demographics, facility usage, and social welfare indicators, to assist the Taipei City government to construct or reform land reuse strategies for junior high and elementary schools facing immediate or future closure, consolidation, or downsizing. To take a more realistic approach to improve final decision making, the investigation of expert questionnaires through the ANP was based on the consideration of future trends that were objectively evaluated by big datasets. The novel planning philosophy and concise decision framework for reuse strategies we designed are expected to improve public decision-making transparency, adaptive reuse effectiveness, and quality of urban life. Ultimately, our proposed strategies and suggestions can not only assist local public sectors to promote the policy of adaptive reuse of surplus school lands but also serve as an appropriate blueprint of urban sustainability for the central government in the near future.  2018, Springer Nature B.V.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mattingly-Jordan, Sara</author></authors></contributors><titles><title>Reasserting the Refounding</title><secondary-title>Administration and Society</secondary-title></titles><periodical><full-title>Administration and Society</full-title></periodical><pages>653 - 678</pages><volume>50</volume><issue>5</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1177/0095399718770392</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046822485&amp;doi=10.1177%2F0095399718770392&amp;partnerID=40&amp;md5=deed32f53b2c8f2f463d8b40436d1a1d</url></web-urls></urls><abstract>What is worth reasserting from the tradition begun by Refounding Public Administration? In this time of reboots and remixes in pop-culture, it may seem trite to suggest reevaluating an established scholarly paradigm. But, in the continued absence of a strong theory of Public Administration and the emergence of new challenges to administrative practice, it is worth revisiting the key concepts of the Refounding tradition to show how this successful normative theory might help solve key problems in contemporary public administration, such as incorporation of algorithmic decision making into public agencies.  2018,  The Author(s) 2018.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Agarwal, P K</author></authors></contributors><titles><title>Public Administration Challenges in the World of AI and Bots</title><secondary-title>Public Administration Review</secondary-title></titles><periodical><full-title>Public Administration Review</full-title></periodical><pages>917 - 921</pages><volume>78</volume><issue>6</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1111/puar.12979</electronic-resource-num><notes>Cited by: 107</notes><research-notes>Cited by: 107</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053198340&amp;doi=10.1111%2Fpuar.12979&amp;partnerID=40&amp;md5=b9e4bea4646dabfc342c7e5654c7f723</url></web-urls></urls><abstract>Technology-driven disruption is taking place at a pace and scale not witnessed before in history. Waves of technology, such as the internet of things, big data, machine learning, and artificial intelligence, are reshaping our personal and professional lives in profound ways. A new world is emerging in which many of the current job classes will disappear, while new ones, requiring entirely different sets of skills, are emerging. Public administrators are unprepared for the challenges they must face in order to cope with this nonincremental and exponential change. Many of the existing government structures and processes that have evolved over the last few centuries will likely become irrelevant in the near future. There is a compelling need to lay the groundwork for governments to rethink how they will be able to best serve their constituents.  2018 by The American Society for Public Administration</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Medhane, Darshan Vishwasrao</author><author>Sangaiah, Arun Kumar</author></authors></contributors><titles><title>PCCA: Position Confidentiality Conserving Algorithm for Content-Protection in e-Governance Services and Applications</title><secondary-title>IEEE Transactions on Emerging Topics in Computational Intelligence</secondary-title></titles><periodical><full-title>IEEE Transactions on Emerging Topics in Computational Intelligence</full-title></periodical><pages>194 - 203</pages><volume>2</volume><issue>3</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1109/TETCI.2017.2769110</electronic-resource-num><notes>Cited by: 15</notes><research-notes>Cited by: 15</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051479273&amp;doi=10.1109%2FTETCI.2017.2769110&amp;partnerID=40&amp;md5=ffac5897e4f6e652e35683c24d5bbd8b</url></web-urls></urls><abstract>E-Governance or electronic governance is a procedure of public sector regulation and is a significant step in the transformation of municipal administration, with the intention of confiding and smoothing collaboration among the population and civic establishments through Information and Communications Technology-based applications. Content Confidentiality has become a serious anxiety for modern Information Societies. The sensitive nature of much of the private personal data that are exchanged or released to untrusted parties necessitates that liable administrations should embark on suitable content confidentiality protection mechanisms. Nowadays, many of these data are texts (e.g., emails, messages posted in social media, healthcare outcomes, etc.) that, because of their unstructured and semantic nature, constitutes a challenge for automatic data protection methods. In this paper, we present a solution for position confidentiality conserving content protection in e-Governance services through computational intelligence. We propose PCCA, a novel position confidentiality conserving algorithm for content protection in e-Governance. The proposed algorithm applies computational intelligence in e-Governance for content protection by means of rule-based approach from computational intelligence and users current position information. A simulation model has been implemented on a desktop PC and evaluation using roaming users real-time position-based information demonstrates that PCCA can efficiently conserve roaming users position confidentiality while accomplishing better performance, guaranteed position confidentiality, and better quality of service in e-Governance.  2017 IEEE.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dai, Ho Kam</author><author>An, Yuting</author><author>Huang, Wenjie</author><author>Chen, Chun</author></authors></contributors><titles><title>Design optimization of floor plan for public housing buildings in Hong Kong with consideration of natural ventilation, noise, and daylighting</title><secondary-title>Building and Environment</secondary-title></titles><periodical><full-title>Building and Environment</full-title></periodical><volume>263</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.buildenv.2024.111865</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199448763&amp;doi=10.1016%2Fj.buildenv.2024.111865&amp;partnerID=40&amp;md5=6b8484273696e6e6a84a14a720b50ba1</url></web-urls></urls><abstract>Indoor environmental quality plays a crucial role in determining the overall quality of life. This study aims to develop a design optimization approach for the floor plan of public housing buildings with modular flat design in Hong Kong, with focus on enhancing natural ventilation, reducing noise levels, and improve daylighting conditions. The evaluation of these environmental factors was conducted using deep neural network models and a mathematically based Calculation of Road Traffic Noise model. A general floor plan representation was developed for three- and four-winged structures of public housing buildings. An optimization approach utilizing Bayesian optimization was applied to three studied cases: Hung Shing House, Hung Hei House, and Cheung Tai House. The optimization process resulted in an average 41.5 % improvement in average natural ventilation rate. The optimized building shapes effectively served as noise barriers, leading to an average reduction of 20 % in average noise levels. The existing window configurations of each unit type under the modular flat design already provided sufficient daylighting, resulting in only a minor improvement from the optimization process.  2024 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Anejionu, Obinna C D</author><author>Thakuriah, Piyushimita (Vonu)</author><author>McHugh, Andrew</author><author>Sun, Yeran</author><author>McArthur, David</author><author>Mason, Phil</author><author>Walpole, Rod</author></authors></contributors><titles><title>Spatial urban data system: A cloud-enabled big data infrastructure for social and economic urban analytics</title><secondary-title>Future Generation Computer Systems</secondary-title></titles><periodical><full-title>Future Generation Computer Systems</full-title></periodical><pages>456 - 473</pages><volume>98</volume><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.future.2019.03.052</electronic-resource-num><notes>Cited by: 42</notes><research-notes>Cited by: 42</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063759990&amp;doi=10.1016%2Fj.future.2019.03.052&amp;partnerID=40&amp;md5=670cf612ee5f79f8d8fb2bf23ecbbf60</url></web-urls></urls><abstract>The Spatial Urban Data System (SUDS) is a spatial big data infrastructure to support UK-wide analytics of the social and economic aspects of cities and city-regions. It utilises data generated from traditional as well as new and emerging sources of urban data. The SUDS deploys geospatial technology, synthetic small area urban metrics, and cloud computing to enable urban analytics, and geovisualization with the goal of deriving actionable knowledge for better urban management and data-driven urban decision making. At the core of the system is a programme of urban indicators generated by using novel forms of data and urban modelling and simulation programme. SUDS differs from other similar systems by its emphasis on the generation and use of regularly updated spatially-activated urban area metrics from real or near-real time data sources, to enhance understanding of intra-city interactions and dynamics. By deploying public transport, labour market accessibility and housing advertisement data in the system, we were able to identify spatial variations of key urban services at intra-city levels as well as social and economically-marginalised output areas in major cities across the UK. This paper discusses the design and implementation of SUDS, the challenges and limitations encountered, and considerations made during its development. The innovative approach adopted in the design of SUDS will enable it to support research and analysis of urban areas, policy and city administration, business decision-making, private sector innovation, and public engagement. Having been tested with housing, transport and employment metrics, efforts are ongoing to integrate information from other sources such as IoT, and User Generated Content into the system to enable urban predictive analytics.  2019</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Aranha, Meera Laetitia B</author><author>Mahapatra, Mrutyunjay</author><author>Jacob, Remya Tressa</author></authors></contributors><titles><title>Mergers of public sector banks: Best partner selection using a data-driven approach</title><secondary-title>Finance Research Letters</secondary-title></titles><periodical><full-title>Finance Research Letters</full-title></periodical><volume>63</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.frl.2024.105297</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189370457&amp;doi=10.1016%2Fj.frl.2024.105297&amp;partnerID=40&amp;md5=c5484a9a08c460af9807f54448747c15</url></web-urls></urls><abstract>This study investigates the selection of the best partners while merging the public sector banks in India. It is set in the context of the announcement of the mega-merger of multiple Indian public sector banks on 30th August 2019. Using the clustering technique (a machine learning approach) and Data Envelopment Analysis (DEA), we identify ideal merger combinations with better efficiency. The findings highlight the possibility of identifying ideal merger combinations using objective techniques.  2024 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ahn, Michael J</author><author>Chen, Yu-Che</author></authors></contributors><titles><title>Digital transformation toward AI-augmented public administration: The perception of government employees and the willingness to use AI in government</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>39</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.giq.2021.101664</electronic-resource-num><notes>Cited by: 73</notes><research-notes>Cited by: 73</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122144137&amp;doi=10.1016%2Fj.giq.2021.101664&amp;partnerID=40&amp;md5=c68caf4d5ae4568a5c61bd0824524bf8</url></web-urls></urls><abstract>Government employees play a critical role in adopting and using new technologies in government, and their attitude and willingness to use them matter in creating a sustainable and meaningful digital transformation. This study explores how the perception of government employees shapes the willingness to support the use of AI technologies in government. Based on a survey data on current government employees in the U.S., our analysis reveals that the willingness to implement and use AI technologies in government was contingent upon a series of positive and negative perceptions about the new technologies, long-term outlook on the role of AI technologies in society, and the familiarity and experience in using some form of AI applications in the past. In particular, the perception of AI enhancing the efficiency and effectiveness of the work and a positive and longer-term outlook on AI's future about human labor (as an assistant or a competitor), the perception of the technology's ultimate harm or benefit (does it harm or benefit humanity), its ability to eventually make ethical and moral judgments influenced the willingness to support AI technologies in government. A substantial proportion of the government employees in the survey sample responded that they had experienced using some form of AI applications in their work and this familiarity had a strong positive influence on their support for AI. Our findings point to the importance of training the government employees in AI technologies to improve their understanding and perception about the new technologies as well as their potentials in government that will foster a culture of innovation toward sustainable and impactful digital transformation.  2021 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Carlsson, Vanja</author><author>Rnnblom, Malin</author></authors></contributors><titles><title>From politics to ethics: Transformations in EU policies on digital technology</title><secondary-title>Technology in Society</secondary-title></titles><periodical><full-title>Technology in Society</full-title></periodical><volume>71</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.techsoc.2022.102145</electronic-resource-num><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140457654&amp;doi=10.1016%2Fj.techsoc.2022.102145&amp;partnerID=40&amp;md5=de529937679ffb0988cce5e4c0983060</url></web-urls></urls><abstract>Artificial intelligence (AI) and digitalisation have become an integral part of public governance. While digital technology is expected to enhance neutrality and accuracy in decision-making, it raises concerns about the status of public values and democratic principles. Guided by the theoretical concepts of input, throughput and output democracy, this article analyses how democratic principles have been interpreted and defended in EU policy formulations relating to digital technology over the last decade. The emergence of AI policy has changed the conditions for democratic input and throughput legitimacy, which is an expression of a shift in power and influence between public and private sectors. Democratic input values in AI production are promoted by ethical guidelines directed towards the industry, while democratic throughput, e.g., accountability and transparency, receive less attention in EU AI policy. This indicates future political implications for the ability of citizens to influence technological change and pass judgement on accountable actors.  2022 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kragh-Furbo, Mette</author><author>Walker, Gordon</author></authors></contributors><titles><title>Electricity as (Big) Data: Metering, spatiotemporal granularity and value</title><secondary-title>Big Data and Society</secondary-title></titles><periodical><full-title>Big Data and Society</full-title></periodical><volume>5</volume><issue>1</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1177/2053951718757254</electronic-resource-num><notes>Cited by: 17</notes><research-notes>Cited by: 17</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050499722&amp;doi=10.1177%2F2053951718757254&amp;partnerID=40&amp;md5=6c45fd7957be1f5ea6870f8a624bbe4e</url></web-urls></urls><abstract>Electricity is hidden within wires and networks only revealing its quantity and flow when metered. The making of its properties into data is therefore particularly important to the relations that are formed around electricity as a produced and managed phenomenon. We propose approaching all metering as a situated activity, a form of quantification work in which data is made and becomes mobile in particular spatial and temporal terms, enabling its entry into data infrastructures and schemes of evaluation and value production. We interrogate the transition from the pre-digital into the making of bigger, more spatiotemporally granular electricity data, through focusing on those actors selling and materialising new metering technologies, data infrastructures and services for larger businesses and public sector organisations in the UK. We examine the claims of truth and visibility that accompany these shifts and their enrolment into management techniques that serve to more precisely apportion responsibility for, and evaluate the status of, particular patterns and instances of electricity use. We argue that whilst through becoming Big Data electricity flow is now able to be known and given identity in significantly new terms, enabling new relations to be formed with the many heterogeneous entities implicated in making and managing energy demand, it is necessary to sustain some ambivalence as to the performative consequences that follow for energy governance. We consider the wider application of our conceptualisation of metering, reflecting on comparisons with the introduction of new metering systems in domestic settings and as part of other infrastructural networks.  The Author(s) 2018.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jato-Espino, Daniel</author><author>Mayor-Vitoria, Fernando</author></authors></contributors><titles><title>A statistical and machine learning methodology to model rural depopulation risk and explore its attenuation through agricultural land use management</title><secondary-title>Applied Geography</secondary-title></titles><periodical><full-title>Applied Geography</full-title></periodical><volume>152</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.apgeog.2023.102870</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146319426&amp;doi=10.1016%2Fj.apgeog.2023.102870&amp;partnerID=40&amp;md5=03fde80be25cd4b61a23d036c4c7694f</url></web-urls></urls><abstract>The abandonment of rural areas has become a major demographical challenge in recent years, especially in Spain and, more specifically, in the Valencian Community. A classification released by the government of this region revealed that almost a third of its municipalities are at depopulation risk. This classification is based on demographic variables, which are valid for identifying the phenomenon but insufficient to provide insight into how to counteract it. Instead, this study developed a methodology to model rural depopulation risk from land use and socioeconomic variables. Correlation analysis and principal component analysis enabled identifying which variables were meaningful for rural depopulation. Then, support vector classification was used to fit the demography-based depopulation classification used by the regional government. The mean accuracy reached was above 80%, which validated the proposed model and variables. Since crop areas was found to be one of the most influential variables in such model, the potential of agroeconomic measures to counter depopulation was examined. The results achieved suggested that depopulation might be reduced by 25% if exploiting 25% of the areas suitable for agriculture. In view of these outputs, public administrations may promote the implementation of land use spatial strategies based on sustainable agriculture.  2023 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Desouza, Kevin C</author><author>Dawson, Gregory S</author><author>Chenok, Daniel</author></authors></contributors><titles><title>Designing, developing, and deploying artificial intelligence systems: Lessons from and for the public sector</title><secondary-title>Business Horizons</secondary-title></titles><periodical><full-title>Business Horizons</full-title></periodical><pages>205 - 213</pages><volume>63</volume><issue>2</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.bushor.2019.11.004</electronic-resource-num><notes>Cited by: 143</notes><research-notes>Cited by: 143</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076865373&amp;doi=10.1016%2Fj.bushor.2019.11.004&amp;partnerID=40&amp;md5=fc35479cd1a61daae78aa0c13e609810</url></web-urls></urls><abstract>Artificial intelligence applications in cognitive computing systems can be found in organizations across every market, including chatbots that help customers navigate websites, predictive analytics systems used for fraud detection, and augmented decision-support systems for knowledge workers. In this article, we share reflections and insights from our experience with AI projects in the public sector that can add value to any organization. We organized our findings into four thematic domains(1) data, (2) technology, (3) organizational, and (4) environmentaland examine them relative to the phases of AI. We conclude with best practices for capturing value with cognitive computing systems.  2019 Kelley School of Business, Indiana University</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chien, Herlin</author><author>Hori, Keiko</author><author>Saito, Osamu</author></authors></contributors><titles><title>Urban commons in the techno-economic paradigm shift: An information and communication technology-enabled climate-resilient solutions review</title><secondary-title>Environment and Planning B: Urban Analytics and City Science</secondary-title></titles><periodical><full-title>Environment and Planning B: Urban Analytics and City Science</full-title></periodical><pages>1389 - 1405</pages><volume>49</volume><issue>5</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1177/23998083211066324</electronic-resource-num><notes>Cited by: 7</notes><research-notes>Cited by: 7</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124579307&amp;doi=10.1177%2F23998083211066324&amp;partnerID=40&amp;md5=47b013d9c479ee22a17e4891fa46feeb</url></web-urls></urls><abstract>The commons concept has evolved in multiple ways after the publication of Ostroms seminal work in 1990, which emphasized the evolution of resource management institutions and the usefulness of self-governance. As we move into the 21st century, one of the institutional transformations is catalyzed by the emergence of Information and Communication Technology (ICT) as a techno-economic paradigm shift and the epochal creation of a new online social structure. However, there is a lack of understanding about the impact of ICT on common resource management, particularly in urban settings, that is urban commons. This study presents a systematic literature review of ICT-enabled urban commons with particular attention to its application to climate-related issues such as climate mitigation/adaptation in order to improve our collective ability to leverage ICT for building a more sustainable and resilient city. A total of 66 pieces of literature were included in our qualitative synthesis. We analyzed the geographical, categorical, and climate relevance. Subsequently, we used the coupled infrastructure system framework as a system thinking approach to dissect distinct usefulness of ICT-enabled commons in the building of relationships between resource system, resource user, infrastructure, and infrastructure provider to tackle climate-related issues. Our findings identified three key contributions of ICT to innovate climate-resilient solutions: 1) to redefine role of resource user as co-producer, co-designer, and co-monitor; 2) to enable real-time data-driven urban planning; 3) to improve resource efficiency and effectiveness. In other words, in a time of insufficient and limited public resources, the public sector can leverage the power of technology to harness public support and engage non-traditional stakeholders to make cities more sustainable and resilient while allowing policy-making to be big data-driven to tackle new urban problems that cannot be otherwise uncovered without the aid of ICT. The results provide directions to rethink the city based on collective action to diversity modes to govern common resources.  The Author(s) 2022.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rnnblom, Malin</author><author>Carlsson, Vanja</author><author>jehag-Pettersson, Andreas</author></authors></contributors><titles><title>Gender equality in Swedish AI policies. What's the problem represented to be?</title><secondary-title>Review of Policy Research</secondary-title></titles><periodical><full-title>Review of Policy Research</full-title></periodical><pages>688 - 704</pages><volume>40</volume><issue>5</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1111/ropr.12547</electronic-resource-num><notes>Cited by: 9</notes><research-notes>Cited by: 9</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150754418&amp;doi=10.1111%2Fropr.12547&amp;partnerID=40&amp;md5=4bcda433d37402970e19e3b8ee52b0f6</url></web-urls></urls><abstract>Over the past few decades, Sweden has established itself as a world leader in gender equality. Alongside this development, Swedish politicians have also initiated ambitious plans that aim to establish the country as world class in terms of digitalization. International research shows that women and racialized groups are in a minority in the design processes, that AI facial recognition systems are built with white male faces as the norm, and that digital tools replicate racial injustices. In this paper, we are interested in if, and if so how, gender equality is articulated and thus filled with meaning in national policies on AI and digitalization. The overall aim is to discuss the potential of gender (equality) mainstreaming to challenge systems of privilege in the implementation of AI systems in the public sector. The paper analyses how gender equality is filled with meaning in national policy documents on AI and gender equality. The main findings show that gender equality is turned into a question of lack of knowledge and information, which in turn blocks out an understanding of gender equality as something that is related to gendered power relations.  2023 The Authors. Review of Policy Research published by Wiley Periodicals LLC on behalf of Policy Studies Organization.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Giest, Sarah</author></authors></contributors><titles><title>Big data for policymaking: fad or fasttrack?</title><secondary-title>Policy Sciences</secondary-title></titles><periodical><full-title>Policy Sciences</full-title></periodical><pages>367 - 382</pages><volume>50</volume><issue>3</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1007/s11077-017-9293-1</electronic-resource-num><notes>Cited by: 132</notes><research-notes>Cited by: 132</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027009690&amp;doi=10.1007%2Fs11077-017-9293-1&amp;partnerID=40&amp;md5=95d8382918059aad38fe07b4e430fa08</url></web-urls></urls><abstract>The buzz surrounding big data has taken shape in various theoretical and practical forms when it comes to policymaking. The paper combines current research streams with long-standing discussions on government and technology in public policy and public administration, such as e-government and evidence-based policymaking. The goal is to answer the question whether big data is a fleeting trend or has long-lasting effects on policymaking. Three larger themes in the literature are identified: First, the role that institutional capacity has within government to utilize big data analytics; second, government use of big data analytics in the context of digital public services; and finally, the way that big data information enters the policy cycle, focusing on substantive and procedural policy instruments. Examples from the education, crisis management, environmental and healthcare domain highlight the opportunities and challenges for each of these themes. Exploring the various aspects of big data and policymaking shows that big data is here to stay, but that its utilization by government will take time due to institutional barriers and capacity bottlenecks.  2017, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bellucci, Marco</author><author>Marzi, Giacomo</author><author>Orlando, Beatrice</author><author>Ciampi, Francesco</author></authors></contributors><titles><title>Journal of Intellectual Capital: a review of emerging themes and future trends</title><secondary-title>Journal of Intellectual Capital</secondary-title></titles><periodical><full-title>Journal of Intellectual Capital</full-title></periodical><pages>744 - 767</pages><volume>22</volume><issue>4</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1108/JIC-10-2019-0239</electronic-resource-num><notes>Cited by: 67</notes><research-notes>Cited by: 67</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088134731&amp;doi=10.1108%2FJIC-10-2019-0239&amp;partnerID=40&amp;md5=479f9ab1f895168bf15a250aca0a1eca</url></web-urls></urls><abstract>Purpose: This article aims to provide a bibliometric and systematic literature analysis of studies published in the Journal of Intellectual Capital (JIC) from 2014 to 2018 in order to highlight emerging themes and future trends. Design/methodology/approach: The analysis focused on 187 papers published on JIC over a period of five years. A scientometric approach to data mining enabled the detection of patterns in the dataset. Precisely, the investigation was conducted by integrating a bibliometric analysis on VOSviewer with a systematic literature review. Findings: Four main streams of research on JIC emerged in the years of the analysis: reporting and disclosure of intellectual capital; intellectual capital research in universities, education and public sector; knowledge management; intellectual capital, financial performance, and market value. Research limitations/implications: The study offers valid insights to the topics covered by the Journal of Intellectual Capital by identifying the main research gaps and trends, along with future research avenues. Originality/value: Prior scholars mostly focused on systematic literature reviews, whilst the use of bibliometric methods generally seems to be a missing tile in the research domain. Also, none of the extant studies has focused on the Journal of Intellectual Capital with reference to the 20142018 period. The use of both bibliometric and systematic approaches to literature review delivered extremely fine-tuned results in terms of factors such as citations, contents and evolution of clusters over time.  2020, Emerald Publishing Limited.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ekimova, Ksenia V</author></authors></contributors><titles><title>Development of the potential of the digital economy of Russian regions through artificial intelligence humanisation</title><secondary-title>Humanities and Social Sciences Communications</secondary-title></titles><periodical><full-title>Humanities and Social Sciences Communications</full-title></periodical><volume>10</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1057/s41599-023-02444-w</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179709244&amp;doi=10.1057%2Fs41599-023-02444-w&amp;partnerID=40&amp;md5=03335b28e497c1416848e28cebf96913</url></web-urls></urls><abstract>This paper is aimed at balancing the interests of business and society in the digital economy, to reduce the social risks of the Fourth Industrial Revolution. The goal of this paper is to study the experience and prospects of the humanisation of AI through the improvement of the practice of corporate social responsibility in Russia. By the example of the experience of Russian regions in 2021, we use econometric modelling to prove that the digital regional economy has a large potential in the sphere of humanisation of AI. The potential for the humanisation of AI in the digital economy of Russian regions is determined by responsible innovations, responsible production and logistics, as well as responsible marketing and sales, which contribute to the implementation of SDGs 912. The theoretical significance of the paper lies in its presenting smart region as a socio-economic environment for the humanisation of AI. The scientific novelty of the paper lies in its offering a newmeso-levelview of the humanisation of AI. The advantages of the new view include, first, consideration of socio-economic conditions for the humanisation of AI in a region; second, the most precise identification and correct measuring of the consequences of humanisation of AI for the quality of life in a region. The practical significance of the research results consists in the fact that the new proposed approach to the humanisation of AI, which implies public administration of this process at the level of a region, allows accelerating the considered process.  2023, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Deng, Jianwei</author><author>Guo, Yilun</author><author>Ma, Tengyang</author><author>Yang, Tianan</author><author>Tian, Xu</author></authors></contributors><titles><title>How job stress influences job performance among Chinese healthcare workers: A cross-sectional study</title><secondary-title>Environmental Health and Preventive Medicine</secondary-title></titles><periodical><full-title>Environmental Health and Preventive Medicine</full-title></periodical><volume>24</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1186/s12199-018-0758-4</electronic-resource-num><notes>Cited by: 48</notes><research-notes>Cited by: 48</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059493349&amp;doi=10.1186%2Fs12199-018-0758-4&amp;partnerID=40&amp;md5=41b1973d8999b808ccd37663c1548184</url></web-urls></urls><abstract>Objectives: Public service motivation refers to the idea of commitment to the public service, pursuit of the public interest, and the desire to perform work that is worthwhile to society. This study investigates how challenge stress and hindrance stress influence job performance among healthcare workers in Chinese public hospitals. It has also examined the mediating effect of public service motivation. Methods: Data of 1594 healthcare workers were obtained from typical public hospitals in eastern, central, and western China. To test our hypotheses, we used descriptive statistical analysis, correlation analysis, structural equation modeling, and subgroup analysis to investigate the sample. Results: Challenge stress and hindrance stress were strongly correlated among healthcare workers in Chinese public hospitals ( = 0.59; p &lt; 0.001). Challenge stress was significantly positively associated with public service motivation ( = 0.14; p &lt; 0.001) and job performance ( = 0.13; p &lt; 0.001). Hindrance stress was significantly negatively associated with public service motivation ( = - 0.27; p &lt; 0.001) and job performance ( = - 0.08; p &lt; 0.05). Public service motivation was directly positively associated with job performance ( = 0.58; p &lt; 0.001), and it indirectly mediated the association between job stress and job performance. Conclusions: This study provides important empirical evidence on the effects of job stress and public service motivation on job performance among healthcare workers in Chinese public hospitals. Job performance may be raised by limiting hindrance stress, which provides moderate challenge stress and increases public service motivation.  2019 The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gao, Ling</author><author>Zhang, Han</author><author>Yang, Fukun</author><author>Tan, Wangshu</author><author>Wu, Ronghua</author><author>Song, Yi</author></authors></contributors><titles><title>First estimation of hourly full-coverage ground-level ozone from Fengyun-4A satellite using machine learning</title><secondary-title>Environmental Research Letters</secondary-title></titles><periodical><full-title>Environmental Research Letters</full-title></periodical><volume>19</volume><issue>2</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1088/1748-9326/ad2022</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184852014&amp;doi=10.1088%2F1748-9326%2Fad2022&amp;partnerID=40&amp;md5=583b4d7ef43adc5d3b5ec6c3fac06f76</url></web-urls></urls><abstract>Ground-level ozone (O3), renowned for its adverse impacts on human health and crop production, has garnered significant attention from governmental and public sectors. To address the limitations posed by sparse and uneven ground-level O3 observations, this study proposes an innovative method for hourly full-coverage ground-level O3 estimation using machine learning. Meteorological data from National Centers for Environmental Prediction global forecasting system, satellite data from Fengyun-4 A(FY-4 A) and Ozone Monitoring Instrument, emission inventory from Multi-resolution Emission Inventory for China, and other auxiliary data are utilized as input variables, while ground-based O3 observations serve as the response variable. The method is applied on a monthly basis across China for the year 2022, resulting in the generation of an hourly full-coverage high-resolution (4 km) ground-level O3 estimation, termed ML-derived-O3. Cross-validation results demonstrate the robustness of ML-derived-O3 yielding a coefficient of determination (R 2) of 0.96 (0.91) for sample-based (site-based) evaluations and a root-mean-square error (RMSE) of 9.22 (13.65) g m3. However, the date-based evaluation is less satisfactory due to the imbalanced training data, resulting from the pronounced daily variations in ground-level O3 concentrations. Nevertheless, the seasonal and hourly ML-derived-O3 exhibits high prediction accuracy, with R 2 values surpassing 0.95 and RMSE remaining below 7.5 g m3. This study marks a significant milestone as the first successful attempt to obtain hourly full-coverage ground-level O3 data across China. The diurnal variation of ML-derived-O3 demonstrates high consistency with ground-based observations, irrespective of clear or cloudy days, effectively capturing ground-level O3 pollution exposure events. This novel estimation method will be employed to establish a long-term high spatial-temporal resolution ground-level O3 dataset, which holds valuable applications for air pollution monitoring and environmental health research in future endeavors.  2024 The Author(s). Published by IOP Publishing Ltd.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wong, Wilson</author><author>C. Hinnant, Charles</author></authors></contributors><titles><title>Competing perspectives on the Big Data revolution: a typology of applications in public policy</title><secondary-title>Journal of Economic Policy Reform</secondary-title></titles><periodical><full-title>Journal of Economic Policy Reform</full-title></periodical><pages>268 - 282</pages><volume>26</volume><issue>3</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1080/17487870.2022.2103701</electronic-resource-num><notes>Cited by: 8</notes><research-notes>Cited by: 8</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135491304&amp;doi=10.1080%2F17487870.2022.2103701&amp;partnerID=40&amp;md5=3677f3fc10384b4e67d26849b76562a0</url></web-urls></urls><abstract>While the Big Data revolution is transforming public policy, some debates and competing perspectives on the impact of the disruptive technology of Big Data analytics remain. Although trade-offs among objectives are inevitable in Big Data applications, its ultimate impact would depend on the moderating factors, which vary across contexts such as policy areas and national systems. Integrating the literature from multiple disciplines, this article identifies some of the critical moderating factors accounting for the differentials of Big Data impacts and develops a typology of its applications in public policy as a heuristic to understand and reconcile competing perspectives.  2022 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pistore, Lorenza</author><author>Pernigotto, Giovanni</author><author>Cappelletti, Francesca</author><author>Gasparella, Andrea</author><author>Romagnoni, Piercarlo</author></authors></contributors><titles><title>A stepwise approach integrating feature selection, regression techniques and cluster analysis to identify primary retrofit interventions on large stocks of buildings</title><secondary-title>Sustainable Cities and Society</secondary-title></titles><periodical><full-title>Sustainable Cities and Society</full-title></periodical><volume>47</volume><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.scs.2019.101438</electronic-resource-num><notes>Cited by: 33</notes><research-notes>Cited by: 33</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067957986&amp;doi=10.1016%2Fj.scs.2019.101438&amp;partnerID=40&amp;md5=653b90c4dd7c97a9d1075e5ef5a93af6</url></web-urls></urls><abstract>In the recent years, existing public buildings have been put under the spotlight for the application of retrofit strategies prescribed by the European Energy Efficiency Directives. Among them, schools have a pivotal role since, besides energy performance, they have to cope also with high indoor environmental quality requirements. However, the definition of a refurbishment policy for the stock of school buildings presents some criticalities: limited data are often available, comprehensive energy audits are too onerous to apply to each school building, and the findings of many case-studies discussed in the literature can be too specific for a robust generalization. In this context, this work proposes a new integrated method for energy audit on large stocks of existing buildings, avoiding case-by-case analyses and focusing on identifying the most significant retrofit areas and priorities of intervention. This approach, based on the combination of different data mining techniques (i.e., Wrapper Feature Selection, Random Forests, Hierarchical and k-medoids Clustering), is meant to deliver a useful tool for the existing buildings stock to professionals and Public Administrations. The method is described and discussed, and then applied for validation purpose on a case study of 41 educational buildings in the Province of Treviso, Italy.  2019 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pizza, Mariagrazia</author><author>Pecetta, Simone</author><author>Rappuoli, Rino</author></authors></contributors><titles><title>Vaccines 2020: The era of the digital vaccine is here</title><secondary-title>Science Translational Medicine</secondary-title></titles><periodical><full-title>Science Translational Medicine</full-title></periodical><volume>13</volume><issue>624</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1126/scitranslmed.abm3249</electronic-resource-num><notes>Cited by: 13</notes><research-notes>Cited by: 13</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122011851&amp;doi=10.1126%2Fscitranslmed.abm3249&amp;partnerID=40&amp;md5=80049d7e6a499b268616a36927b6adc3</url></web-urls></urls></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schmid, Andreas</author></authors></contributors><titles><title>BigData-PublicControlling Fundamental changes in Public Management</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>325 - 334</pages><volume>16</volume><issue>2</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.13165/VPA-17-16-2-11</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028679650&amp;doi=10.13165%2FVPA-17-16-2-11&amp;partnerID=40&amp;md5=b7dced8ec6f98b5dfa3d94de9c0b1bd4</url></web-urls></urls><abstract>The @ is the link between the name of the recipient and its address. The e-mail has revolutionized the communication behavior. It represents a new era of information and data exchange. The speed of information exchange and the possibility of non-physical data transport have fundamentally changed human communication. Big Data has become the synonym for a new technological age. Generally Big Data collects data and delivers valuable and useful information (Baron, 2013, 1). A general definition of the term has not yet taken place in science and practice. The work of the public sector is based on the collection, identification and use of data in many areas. Public organizations are often data monopolists and the only provider of public goods. The acquisition of new information in the sense of Big Data requires a connection between existing data and the use of new information. This gives the public administration a whole new potential. The organizational function &quot;Controlling&quot; supports decision-makers in the context of management and control (Horvth, 2011, 16). The proximity of Big Data and Controlling is obvious. This article describes the potentials resulting from the use of Big Data and its effects on Public Controlling. Big Data will revolutionize Public Controlling and thus the public administration as a whole.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Shah, Syed Iftikhar Hussain</author><author>Peristeras, Vassilios</author><author>Magnisalis, Ioannis</author></authors></contributors><titles><title>DaLiF: a data lifecycle framework for data-driven governments</title><secondary-title>Journal of Big Data</secondary-title></titles><periodical><full-title>Journal of Big Data</full-title></periodical><volume>8</volume><issue>1</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1186/s40537-021-00481-3</electronic-resource-num><notes>Cited by: 21</notes><research-notes>Cited by: 21</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107949250&amp;doi=10.1186%2Fs40537-021-00481-3&amp;partnerID=40&amp;md5=7e2b6c38f966b0ec182fc8db046b6f01</url></web-urls></urls><abstract>The public sector, private firms, business community, and civil society are generating data that is high in volume, veracity, velocity and comes from a diversity of sources. This kind of data is known as big data. Public Administrations (PAs) pursue big data as new oil and implement data-centric policies to transform data into knowledge, to promote good governance, transparency, innovative digital services, and citizens engagement in public policy. From the above, the Government Big Data Ecosystem (GBDE) emerges. Managing big data throughout its lifecycle becomes a challenging task for governmental organizations. Despite the vast interest in this ecosystem, appropriate big data management is still a challenge. This study intends to fill the above-mentioned gap by proposing a data lifecycle framework for data-driven governments. Through a Systematic Literature Review, we identified and analysed 76 data lifecycles models to propose a data lifecycle framework for data-driven governments (DaliF). In this way, we contribute to the ongoing discussion around big data management, which attracts researchers and practitioners interest.  2021, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Meissner, Fran</author><author>Taylor, Linnet</author></authors></contributors><titles><title>Migration information infrastructures: power, control and responsibility at a new frontier of migration research</title><secondary-title>Journal of Ethnic and Migration Studies</secondary-title></titles><periodical><full-title>Journal of Ethnic and Migration Studies</full-title></periodical><pages>2227 - 2246</pages><volume>50</volume><issue>9</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1080/1369183X.2024.2307772</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186417922&amp;doi=10.1080%2F1369183X.2024.2307772&amp;partnerID=40&amp;md5=9a52ee6192aec1132c6ec8cb849db3ed</url></web-urls></urls><abstract>The nature and production of migration statistics are in flux. State bureaucracies are no longer the primary source of migration data. Instead, there are a myriad unofficial data sources and processing collaborations which produce migration and mobility data as a by-product of both commercial and governmental processes. This has implications both for international processes of migration assessment and control, and for states domestic policies with respect to migrants. This paper brings together migration studies with Science and Technology Studies (STS) literature to take stock of these new data sources theoretical and empirical implications for both migrants and the links between migration and broader social processes. We identify migration information infrastructures: configurations of data assemblages which involve private and public sector actors, where data originally collected for one purpose (billing customers, sharing social information, sensing environmental change) become repurposed as migration statistics. We explore the implications of such migration information infrastructures for migration researchers: what are the entanglements that such infrastructures bring with them, and what do they mean for the ethics and practicalities of doing migration research?.  2024 The Author(s). Published by Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Enriquez-Sarano, Louis</author></authors></contributors><titles><title>Data-rich and knowledge-poor: How privacy law privatized medical data and what to do about it</title><secondary-title>Columbia Law Review</secondary-title></titles><periodical><full-title>Columbia Law Review</full-title></periodical><pages>2319 - 2358</pages><volume>120</volume><issue>8</issue><keywords/><dates><year>2020</year></dates><notes>Cited by: 5</notes><research-notes>Cited by: 5</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101926971&amp;partnerID=40&amp;md5=315651c768b632e3d71d95806cb283a9</url></web-urls></urls><abstract>The Health Information Technology for Economic and Clinical Health Act (HITECH) successfully encouraged widespread adoption of electronic health records (EHR). Their suitability for big data analysis make EHR data immensely valuable for secondary research, which could help scientists develop new drugs, medical devices, and public-health knowledge. Thus far, EHR data have not been widely available to academic medical scientists in quantities sufficient to support big data analysis. Instead, the data are aggregated, analyzed, and sold by insurance companies, EHR vendors, and other medical informatics firms. This Note argues that the advent of the EHR data market is a direct result of HITECHs interaction with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) (together, the Privacy Regime). The Privacy Regime (1) establishes the necessary preconditions for the EHR data market; (2) funnels EHR data towards a few large firms; and (3) prevents others, including academic scientists, from acquiring data in similarly large quantities. The Privacy Regime has radically changed medical research regulation. Traditional clinical trials and retrospective studies are governed by the familiar safeguards of medical ethics including IRB review, peer review, and publication. But under the Privacy Regime, private-sector EHR-based studies are not subject to any ethical review. This result subverts the fundamental principles of medical ethics and inhibits socially valuable public-sector research. This Note proposes reforming the Privacy Regime to subject all medical research to ethical review and to incentivize private firms to share EHR data with academic researchers.  2020, Columbia Law Review Association. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mohabeer, Preethivirajsingh</author><author>Santally, Mohammad Issack</author><author>Sungkur, Roopesh Kevin</author></authors></contributors><titles><title>An Investigation of the Potential Benefits of Big Data in the Public Sector of Mauritius</title><secondary-title>Journal of the Knowledge Economy</secondary-title></titles><periodical><full-title>Journal of the Knowledge Economy</full-title></periodical><pages>1230 - 1247</pages><volume>10</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s13132-018-0524-2</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070240786&amp;doi=10.1007%2Fs13132-018-0524-2&amp;partnerID=40&amp;md5=5ff3be2b36f511901b7eb908f1a94330</url></web-urls></urls><abstract>This study examines how big data analytics could optimize the use of public funds while ensuring delivery of quality service by public organizations to the citizens of Mauritius. Political Economic Social Technological (PEST) analysis has been carried out to scan the environment to identify at least two major policies and initiatives corresponding to big data that will be impacting the Mauritian Economy in the next 10years. Subsequently, causal layered analysis (CLA) has been applied for the two signals to create transformative spaces for the creation of alternative futures. Indeed, the findings have demonstrated that open data initiative and the implementation of e-health project in Mauritius would certainly contribute positively to the government of Mauritius. However, this study has revealed through a matrix diagram for probable futures that the Mauritian government should bring amendments to existing conventional laws through reforms and regulations to fully take advantage of big data analytics applications. This is also one of the recommendations of the Mauritius e-Government 20132017Formulation and Implementation of Data Sharing Policy. Considering only the recent emergence of big data analytics in governments, still there is certain aspect of it that needs careful consideration before the full potential of big data could be realized. This research also highlights the factors that need to be addressed for the successful use of Big Data in this particular context.  2018, Springer Science+Business Media, LLC, part of Springer Nature.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schug, Donald M</author><author>Taylor, Peter H</author><author>Iudicello, Suzanne</author><author>Swasey, Jill H</author></authors></contributors><titles><title>Using online data visualization and analysis to facilitate public involvement in management of catch share programs</title><secondary-title>Marine Policy</secondary-title></titles><periodical><full-title>Marine Policy</full-title></periodical><volume>122</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.marpol.2020.104272</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093701142&amp;doi=10.1016%2Fj.marpol.2020.104272&amp;partnerID=40&amp;md5=8b22b3ecaa58ecfdc45bf0ab74440b40</url></web-urls></urls><abstract>This case study examines the experience of the interdisciplinary Measuring the Effects of Catch Shares (MECS) project, a five-year demonstration project designed to explore the opportunities and constraints for third-party acquisition, organization, and communication of government fisheries statistics in order to track the ecological, economic, social, and governance outcomes of catch share programs. Catch share programs, whereby fishery managers allocate to private entities percentages of the total amount of fish that can be caught in a year, have been used to manage some US fisheries since the 1990s. Given the high financial stakes of commercial fisheries and the wide-ranging impacts ascribed to these programs, they are among the most controversial and contentious tools of contemporary fisheries management. The goal of the MECS project was to create an interactive, web-based platform for conveying a set of neutral, scientific indicators based on the best available fisheries data that could be used by fishing industry participants, fishery managers, and other interested parties to supplement and inform their own understanding of catch share program effects. The MECS project focused on the effects of two US catch share programs: the Northeast Multispecies Sector Program implemented in 2010 in the Northeast groundfish fishery and the Shorebased IFQ Program implemented in 2011 in the West Coast groundfish trawl fishery. The MECS project encountered data access challenges but ultimately succeeded in developing a website that has been received by members of the private and public sector alike as a useful tool that brings together and communicates disparate information that is not otherwise readily accessible.  2020 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mattei, Paola</author></authors></contributors><titles><title>Digital governance in tax-funded European healthcare systems: From the Back office to patient empowerment</title><secondary-title>Israel Journal of Health Policy Research</secondary-title></titles><periodical><full-title>Israel Journal of Health Policy Research</full-title></periodical><volume>9</volume><issue>1</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1186/s13584-020-0361-1</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078000204&amp;doi=10.1186%2Fs13584-020-0361-1&amp;partnerID=40&amp;md5=9b3f60175ef8fd242ecebc3b8934cad4</url></web-urls></urls><abstract>Digital healthcare promises to achieve cost-efficiency gains, improve clinical effectiveness, support better public sector governance by enhancing transparency and accountability, and increase confidence in medical diagnoses, especially in the field of oncology. This article aims to discuss the benefits offered by digital technologies in tax-based European healthcare systems against the backdrop of structural bureaucratic rigidities and a slow pace of implementation. Artificial intelligence (AI) will transform the existing delivery of healthcare services, inducing a redesign of public accountability systems and the traditional relationships between professionals and patients. Despite legitimate ethical and accountability concerns, which call for clearer guidance and regulation, digital governance of healthcare is a powerful means of empowering patients and improving their medical treatment in terms of quality and effectiveness. On the path to better health, the use of digital technologies has moved beyond the back office of administrative processes and procedures, and is now being applied to clinical activities and direct patient engagement.  2020 The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zang, Tongguang</author><author>Zhou, Tiancheng</author><author>He, Xiangting</author><author>Yang, Xiaoqi</author><author>Ikebe, Konomi</author></authors></contributors><titles><title>Rethinking Japanese public libraries from the perspective of time</title><secondary-title>Sustainable Cities and Society</secondary-title></titles><periodical><full-title>Sustainable Cities and Society</full-title></periodical><volume>87</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.scs.2022.104222</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139077499&amp;doi=10.1016%2Fj.scs.2022.104222&amp;partnerID=40&amp;md5=becfcfcff1d70f06bc95a620c74f2491</url></web-urls></urls><abstract>This study discusses sustainable design strategies for Japanese public libraries by introducing the time concept. Currently, public libraries in Japan are facing declining utilization and decaying facilities, and many require renovation or reconstruction. We explore how design can help libraries avoid their current dilemmas and cope with the increasing e-books and pandemic-born boom in online learning and communication. Only by addressing these issues and planning for similar situations in the future will libraries manage to achieve their sustainability goals. This requires a systematic rethinking of traditional library design approaches by introducing the time element. We review the development of Japanese public libraries to identify the short- and long-term roles of libraries in cities from an international perspective, based on which we reevaluate the functions of public libraries. As different regions and conceptions of time and space influence people's needs for space and services, we also explore the view of time in architecture and the unique Japanese time perception. We then discuss possible solutions for libraries in Japan and the feasibility for other countries. We have three main suggestions. 1. A central + local development model.2. A three-stage design process from stable to resilient.3. An operating plan considering the economy.  2022 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gupta, Agrayan K</author><author>Grannis, Shaun J</author><author>Kasthurirathne, Suranga N</author></authors></contributors><titles><title>Evaluation of a parsimonious COVID-19 outbreak prediction model: Heuristic modeling approach using publicly available data sets</title><secondary-title>Journal of Medical Internet Research</secondary-title></titles><periodical><full-title>Journal of Medical Internet Research</full-title></periodical><volume>23</volume><issue>7</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.2196/28812</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111662029&amp;doi=10.2196%2F28812&amp;partnerID=40&amp;md5=91e9b6c0330c87a0a41079b625b4537c</url></web-urls></urls><abstract>Background: The COVID-19 pandemic has changed public health policies and human and community behaviors through lockdowns and mandates. Governments are rapidly evolving policies to increase hospital capacity and supply personal protective equipment and other equipment to mitigate disease spread in affected regions. Current models that predict COVID-19 case counts and spread are complex by nature and offer limited explainability and generalizability. This has highlighted the need for accurate and robust outbreak prediction models that balance model parsimony and performance. Objective: We sought to leverage readily accessible data sets extracted from multiple states to train and evaluate a parsimonious predictive model capable of identifying county-level risk of COVID-19 outbreaks on a day-to-day basis. Methods: Our modeling approach leveraged the following data inputs: COVID-19 case counts per county per day and county populations. We developed an outbreak gold standard across California, Indiana, and Iowa. The model utilized a per capita running 7-day sum of the case counts per county per day and the mean cumulative case count to develop baseline values. The model was trained with data recorded between March 1 and August 31, 2020, and tested on data recorded between September 1 and October 31, 2020. Results: The model reported sensitivities of 81%, 92%, and 90% for California, Indiana, and Iowa, respectively. The precision in each state was above 85% while specificity and accuracy scores were generally &gt;95%. Conclusions: Our parsimonious model provides a generalizable and simple alternative approach to outbreak prediction. This methodology can be applied to diverse regions to help state officials and hospitals with resource allocation and to guide risk management, community education, and mitigation strategies.  Agrayan K Gupta, Shaun J Grannis, Suranga N Kasthurirathne. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 26.07.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Baur, Aaron W</author></authors></contributors><titles><title>Harnessing the social web to enhance insights into peoples opinions in business, government and public administration</title><secondary-title>Information Systems Frontiers</secondary-title></titles><periodical><full-title>Information Systems Frontiers</full-title></periodical><pages>231 - 251</pages><volume>19</volume><issue>2</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1007/s10796-016-9681-7</electronic-resource-num><notes>Cited by: 42</notes><research-notes>Cited by: 42</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979692073&amp;doi=10.1007%2Fs10796-016-9681-7&amp;partnerID=40&amp;md5=2828e55730f793b2b6e35bef8411253a</url></web-urls></urls><abstract>Transparency, participation, and collaboration are the core pillars of open government. For the systematic integration of citizens and other stakeholders into the policy and public value creation process, their opinions, wishes, and complaints first need to be received. In the future, including user-generated content from social media will become a main channel for the enrichment of this information base for public administrative bodies and commercial firms. However, the sheer speed of growth of this constantly updated data pool makes manual work infeasible. The automated gathering, combination, analysis, and visualization of user-generated content from various sources and multiple languages is therefore imperative. In this study, we present a design science research approach to develop a general framework (MarketMiner) to handle large amounts of foreign-language user-generated content. As a first empirical application, we implement the framework in the automotive industry by analyzing Chinese automotive forums for the benefit of English-speaking users. At the same time, the ideas, methods, and insights are transferred to the public sector context, especially in light of the current challenges of a high number of political refugees from Arabic countries entering into the European Union. The results are promising in that MarketMiner can dramatically improve the utilization of multi-language, multi-source social media content. The modular set-up of the artifact allows an easy transfer to additional areas of application.  2016, Springer Science+Business Media New York.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Henriksen, Anne</author><author>Blond, Lasse</author></authors></contributors><titles><title>Executive-centered AI? Designing predictive systems for the public sector</title><secondary-title>Social Studies of Science</secondary-title></titles><periodical><full-title>Social Studies of Science</full-title></periodical><pages>738 - 760</pages><volume>53</volume><issue>5</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1177/03063127231163756</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159071461&amp;doi=10.1177%2F03063127231163756&amp;partnerID=40&amp;md5=b6aef03032ac59ee1e771b681f33769d</url></web-urls></urls><abstract>Recent policies and research articles call for turning AI into a form of IA (intelligence augmentation), by envisioning systems that center on and enhance humans. Based on a field study at an AI company, this article studies how AI is performed as developers enact two predictive systems along with stakeholders in public sector accounting and public sector healthcare. Inspired by STS theories about values in design, we analyze our empirical data focusing especially on how objectives, structured performances, and divisions of labor are built into the two systems and at whose expense. Our findings reveal that the development of the two AI systems is informed by politically motivated managerial interests in cost-efficiency. This results in AI systems that are (1) designed as managerial tools meant to enable efficiency improvements and cost reductions, and (2) enforced on professionals on the shop floor in a top-down manner. Based on our findings and a discussion drawing on literature on the original visions of human-centered systems design from the 1960s, we argue that turning AI into IA seems dubious, and ask what human-centered AI really means and whether it remains an ideal not easily realizable in practice. More work should be done to rethink human-machine relationships in the age of big data and AI, in this way making the call for ethical and responsible AI more genuine and trustworthy.  The Author(s) 2023.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Yi</author><author>Hu, Ailing</author><author>Wang, Jiahua</author><author>Zhang, Yaojie</author></authors></contributors><titles><title>Detection of fraud statement based on word vector: Evidence from financial companies in China</title><secondary-title>Finance Research Letters</secondary-title></titles><periodical><full-title>Finance Research Letters</full-title></periodical><volume>46</volume><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1016/j.frl.2021.102477</electronic-resource-num><notes>Cited by: 12</notes><research-notes>Cited by: 12</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115922488&amp;doi=10.1016%2Fj.frl.2021.102477&amp;partnerID=40&amp;md5=cda2a9cb0ada2b5b6be1f61d8c91d0e4</url></web-urls></urls><abstract>This paper aims to detect plausible frauds of financial companies via text analysis of annual and quarterly reports of China's listed companies. The Management Discussion and Analysis (MD&amp;A) is digitized as vectors. The empirical results indicate that compared with various vector indexes, the bag-of-words (BoW) model and machine learning algorithm have a prediction effect and the ability to recognize frauds where the BoW model can correctly recognize 77% of the fraud reports. This would be helpful for audit authorities to identify fraud reports.  2021 Elsevier Inc.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ballestar, Mara Teresa</author><author>Mir, Miguel Cuerdo</author><author>Pedrera, Luis Miguel Doncel</author><author>Sainz, Jorge</author></authors></contributors><titles><title>Effectiveness of tutoring at school: A machine learning evaluation</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>199</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techfore.2023.123043</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178346572&amp;doi=10.1016%2Fj.techfore.2023.123043&amp;partnerID=40&amp;md5=cf855fa8b9d87d804828ebb9893b3df6</url></web-urls></urls><abstract>Tutoring programs are effective in reducing school failures among at-risk students. However, there is still room for improvement in maximising the social returns they provide on investments. Many factors and components can affect student engagement in a program and academic success. This complexity presents a challenge for Public Administrations to use their budgets as efficiently as possible. Our research focuses on providing public administration with advanced decision-making tools. First, we analyse a database with information on 2066 students of the Programa para la Mejora de xito Educativo (Programme for the Improvement of Academic Success) of the Junta de Comunidades de Castilla y Lon in Spain, in 20182019, the academic year previous to the pandemic. This program is designed to help schools with students at risk of failure in Spanish, literature, mathematics, and English. We developed a machine learning model (ML) based on Kohonen self-organising maps (SOMs), which are a type of unsupervised (ANN), to group students based on their characteristics, the type of tutoring program in which they were enrolled, and their results in both the completion of the program and the 4th year of Compulsory Secondary Education (ESO). Second, we evaluated the results of tutoring programs and identified and explained how different factors and components affect student engagement and academic success. Our findings provide Public Administrations with better decision-making tools to evaluate and measure the results of tutoring programs in terms of social return on investment, improve the design of these programs, and choose the students to enrol.  2023 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kim, Joo-Chang</author><author>Chung, Kyungyong</author></authors></contributors><titles><title>Sequential-index pattern mining for lifecare telecommunication platform</title><secondary-title>Cluster Computing</secondary-title></titles><periodical><full-title>Cluster Computing</full-title></periodical><pages>1039 - 1048</pages><volume>22</volume><issue>4</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s10586-018-2852-1</electronic-resource-num><notes>Cited by: 5</notes><research-notes>Cited by: 5</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055945429&amp;doi=10.1007%2Fs10586-018-2852-1&amp;partnerID=40&amp;md5=0a5eafa7e09d53d8addcfd7e4499752e</url></web-urls></urls><abstract>Lifecare for quality-of-life improvement includes not only the prevention and treatment of diseases and health management anywhere and at any-time, but also the improvement of lifestyle, the psychological environment, and the emergency response. The construction of a sustainable model on the telecommunications platform as a solution has been constantly studied using intelligence information technology. In this study, sequential-index pattern mining on the lifecare telecommunications platform is proposed. The method is as follows. Various temporal and regional indices that are provided by the Meteorological Administration, Meteorological Data Open Portal, Public Data Portal, Healthcare Big Data Hub, and Korea Environment Corporation are collected as lifecare index data. The collected index data are transmitted to the NAS file server of the lifecare telecommunications platform using peer-to-peer (P2P)-based interconnection technology and high-performance computing. The sequential relationships among the indices are discovered to consider the semantic relationships. Using the AprioriAll mining algorithm, the maximum sequence is determined to find sequential relationships in the frequent sequence set. To process the pattern extraction and computation efficiently, recomposed transactions are stored in the high-performance NAS file server. Also, a mining-index prediction model is developed in consideration of the sequential relationships to complement the weakness of the statistical time-series analysis. Since the regional meteorological conditions are similar, the index sequential pattern can solve the problem of the generation of omissions or errors regarding the real-time monitoring data that are due to the monitoring equipment or communication failures. Therefore, the proposed sequential-index pattern mining can be utilized as a lifecare tool for risk-factor detection, risk prediction, and trend analysis.  2018, Springer Science+Business Media, LLC, part of Springer Nature.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cooke, Philip</author></authors></contributors><titles><title>Digital tech and the public sector: what new role after public funding?</title><secondary-title>European Planning Studies</secondary-title></titles><periodical><full-title>European Planning Studies</full-title></periodical><pages>739 - 754</pages><volume>25</volume><issue>5</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1080/09654313.2017.1282067</electronic-resource-num><notes>Cited by: 16</notes><research-notes>Cited by: 16</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010976248&amp;doi=10.1080%2F09654313.2017.1282067&amp;partnerID=40&amp;md5=ebeffa6562e616f2f6f864359782b4e2</url></web-urls></urls><abstract>Innovation scholars have long recognized entrepreneurship is imitative, whereas the commercialization of novelty is innovative. Thus they are highly distinctive skill-sets. Entrepreneurship, first, involves optimizing market sentiment for pure profit sometimes to the point of catastrophe and even fraudulence in many markets. These include: payment protection insurance (PPI) to flash crashes, automotive emission defeat devices, corporate bribery settlements, social media hacking, fake news and a litany of other infractions and catastrophes. Innovation, by contrast, is more explorative and team-reliant. Even if patenting betrays the hope for commercialization on markets, patented innovation frequently fails. Some academic innovators even profess a preference for prizes over profits. Second, this means that collective bonding among entrepreneurs, in the form of claimed entrepreneurial ecosystems, is often based on a single customer platform or as a supplier of a highly specialist type of imitative service from identikit pizza chains to me-too smartphone apps. Through the latter, fused with artificial intelligence some interactive machine-learning services have long-existed as postsocial algorithms serving customers of, for example, investment banks in stock and currency markets. Finally, entrepreneurship is fundamentally competitive, individualistic and non-solidaristic, whereas open innovation was born from the practices of open science and the collegiate tradition of research. Accordingly, entrepreneurial ecosystems can display more closure than RIS set-ups. This special issue explores aspects of these ecosystem platforms and their implications for emergent forms of urban and regional evolution in the near and nearly present future.  2017 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kouziokas, Georgios N</author><author>Chatzigeorgiou, Alexander</author><author>Perakis, Konstantinos</author></authors></contributors><titles><title>Multilayer Feed Forward Models in Groundwater Level Forecasting Using Meteorological Data in Public Management</title><secondary-title>Water Resources Management</secondary-title></titles><periodical><full-title>Water Resources Management</full-title></periodical><pages>5041 - 5052</pages><volume>32</volume><issue>15</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1007/s11269-018-2126-y</electronic-resource-num><notes>Cited by: 44</notes><research-notes>Cited by: 44</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056627269&amp;doi=10.1007%2Fs11269-018-2126-y&amp;partnerID=40&amp;md5=d5df90ba2336da500c6a63891fbb82ff</url></web-urls></urls><abstract>Managing the groundwater resources is very vital for human life. This research proposes a methodology for predicting the groundwater levels which can be very valuable in water resources management. This study investigates the application of multilayer feed forward network models for forecasting the groundwater values in the region of Montgomery country in Pennsylvania. Multiple training algorithms and network structures were investigated to develop the best model in order to forecast the groundwater levels. Several multilayer feed forward models were created in order to be tested for their performance by changing the network topology parameters so as to find the optimal prediction model. The forecasting models were developed by applying different structures regarding the number of the neurons in every hidden layer and the number of the hidden network layers. The final results have shown a very good forecasting accuracy of the predicted groundwater levels. This research can be very valuable in water resources and environmental management.  2018, Springer Nature B.V.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Madsen, Anders Koed</author></authors></contributors><titles><title>Data in the smart city: How incongruent frames challenge the transition from ideal to practice</title><secondary-title>Big Data and Society</secondary-title></titles><periodical><full-title>Big Data and Society</full-title></periodical><volume>5</volume><issue>2</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1177/2053951718802321</electronic-resource-num><notes>Cited by: 25</notes><research-notes>Cited by: 25</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069871184&amp;doi=10.1177%2F2053951718802321&amp;partnerID=40&amp;md5=216c8dc841b816a6805201705d644638</url></web-urls></urls><abstract>This paper presents an analysis of interviews, focus groups and workshops with employees in the technical administration in the municipality of Copenhagen in the year after it won a prestigious Smart City award. The administration is interpreted as a most likely to succeed in translating the idealised version of the smart city into a workable bureaucratic practice. Drawing on the work of Orlikowski and Gash, the empirical analysis identifies and describes two incongruent technological frames that illustrates different ways of making sense of data and the smart city within this single organisational unit. One is called the experimentalists credo and it is characterised by inspiration from the development of an Internet of Things as well as a readiness to learn from the open source community in software development. The other is called the data-owners vocation and it is characterised by a more situated approach that interprets data as strategic and political. It is argued that the existence of these frames provides two insights relevant for the literature on smart cities. First, they illustrate that one should be careful not to reify the smart city as a phenomenon that can be criticised in generic terms. Second, they suggest that even if there exists a transition toward the implementation of a technocratic smart city paradigm across public administrations, this paradigm is not unique in its focus on markets and evidence in governance.  The Author(s) 2018.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Campazas-Vega, Adrin</author><author>Crespo-Martnez, Ignacio Samuel</author><author>Guerrero-Higueras, ngel Manuel</author><author>lvarez-Aparicio, Claudia</author><author>Matelln, Vicente</author><author>Fernndez-Llamas, Camino</author></authors></contributors><titles><title>Analyzing the influence of the sampling rate in the detection of malicious traffic on flow data</title><secondary-title>Computer Networks</secondary-title></titles><periodical><full-title>Computer Networks</full-title></periodical><volume>235</volume><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1016/j.comnet.2023.109951</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167424563&amp;doi=10.1016%2Fj.comnet.2023.109951&amp;partnerID=40&amp;md5=a042b371d061f0b6f821d54063cb145a</url></web-urls></urls><abstract>Cyberattacks are a growing concern for companies and public administrations. The literature shows that analyzing network-layer traffic can detect intrusion attempts. However, such detection usually implies studying every datagram in a computer network. Therefore, routers routing a significant volume of network traffic do not perform an in-depth analysis of every packet. Instead, they analyze traffic patterns based on network flows. However, even gathering and analyzing flow data has a high-computational cost, and therefore routers usually apply a sampling rate to generate flow data. Adjusting the sampling rate is a tricky problem. If the sampling rate is low, much information is lost and some cyberattacks may be neglected, but if the sampling rate is high, routers cannot deal with it. This paper tries to characterize the influence of this parameter in different detection methods based on machine learning. To do so, we trained and tested malicious-traffic detection models using synthetic flow data gathered with several sampling rates. Then, we double-check the above models with flow data from the public BoT-IoT dataset and with actual flow data collected on RedCAYLE, the Castilla y Len regional academic network.  2023 The Author(s)</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhu, Nan</author><author>Zhu, Chuanjin</author><author>Emrouznejad, Ali</author></authors></contributors><titles><title>A combined machine learning algorithms and DEA method for measuring and predicting the efficiency of Chinese manufacturing listed companies</title><secondary-title>Journal of Management Science and Engineering</secondary-title></titles><periodical><full-title>Journal of Management Science and Engineering</full-title></periodical><pages>435 - 448</pages><volume>6</volume><issue>4</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.jmse.2020.10.001</electronic-resource-num><notes>Cited by: 51</notes><research-notes>Cited by: 51</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100680656&amp;doi=10.1016%2Fj.jmse.2020.10.001&amp;partnerID=40&amp;md5=4cbc6ffa4a84aa0d20e18344a0c38914</url></web-urls></urls><abstract>Data Envelopment Analysis (DEA) is a linear programming methodology for measuring the efficiency of Decision Making Units (DMUs) to improve organizational performance in the private and public sectors. However, if a new DMU needs to be known its efficiency score, the DEA analysis would have to be re-conducted, especially nowadays, datasets from many fields have been growing rapidly in the real world, which will need a huge amount of computation. Following the previous studies, this paper aims to establish a linkage between the DEA method and machine learning (ML) algorithms, and proposes an alternative way that combines DEA with ML (ML-DEA) algorithms to measure and predict the DEA efficiency of DMUs. Four ML-DEA algorithms are discussed, namely DEA-CCR model combined with back-propagation neural network (BPNN-DEA), with genetic algorithm (GA) integrated with back-propagation neural network (GANN-DEA), with support vector machines (SVM-DEA), and with improved support vector machines (ISVM-DEA), respectively. To illustrate the applicability of above models, the performance of Chinese manufacturing listed companies in 2016 is measured, predicted and compared with the DEA efficiency scores obtained by the DEA-CCR model. The empirical results show that the average accuracy of the predicted efficiency of DMUs is about 94%, and the comprehensive performance order of four ML-DEA algorithms ranked from good to poor is GANN-DEA, BPNN-DEA, ISVM-DEA, and SVM-DEA.  2020 China Science Publishing &amp; Media Ltd.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Li, Sihong</author><author>Chen, Jinglong</author></authors></contributors><titles><title>Virtual human on social media: Text mining and sentiment analysis</title><secondary-title>Technology in Society</secondary-title></titles><periodical><full-title>Technology in Society</full-title></periodical><volume>78</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techsoc.2024.102666</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199480062&amp;doi=10.1016%2Fj.techsoc.2024.102666&amp;partnerID=40&amp;md5=f59276ee2da71aeae562c59e122145d7</url></web-urls></urls><abstract>Virtual humans are embodied agents with a human-like appearance. Despite the recent booming development that has sparked widespread academic interest, how people perceive these seemingly human but entirely fictional creations remains unclear. To explore the status, trends, emotional tendencies, and focus of attention of the Chinese public towards virtual humans, this paper utilizes text mining techniques to collect and analyze popular posts related to virtual humans on Chinese social media. The results indicate that public discussions primarily focus on the technological and industrial development of virtual humans, applications in the fields of virtual idols and virtual streamers, and the corporate investment and policy development of virtual humans. Despite positive emotions dominating, there is an increasing trend in negative emotions. Concerns are related to service failures, the uncanny valley effect, ethical crises, and technological unemployment. The research findings contribute to policymakers, industry stakeholders, and the public in understanding the general attitudes toward virtual human technology, enabling informed decision-making.  2024 Elsevier Ltd</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cong, Wanshu</author></authors></contributors><titles><title>From Pandemic Control to Data-Driven Governance: The Case of Chinas Health Code</title><secondary-title>Frontiers in Political Science</secondary-title></titles><periodical><full-title>Frontiers in Political Science</full-title></periodical><volume>3</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.3389/fpos.2021.627959</electronic-resource-num><notes>Cited by: 29</notes><research-notes>Cited by: 29</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118887215&amp;doi=10.3389%2Ffpos.2021.627959&amp;partnerID=40&amp;md5=7f33ab4bc6e1a8f866c51a9640ce3ce4</url></web-urls></urls><abstract>Current debates over digital contact tracing mainly focus on the tools and experiences in the West. Chinas health code, while often seen as one of the earliest and most widely adopted apps since the outbreak of COVID-19, has not been studied specifically. This article provides a detailed analysis of the health code, draws comparison with the contact tracing apps developed by Google and Apple, and seeks to understand the specifications and contradictions internal to the health codes development and deployment in China. Looking at both technical features and the mode and process of its adoption, the article argues that the health code is strictly speaking not a contact tracing tool, but a technology of population control which is integrated in traditional forms of control and facilitates the enhancement of such control. As a technology of ruling the population, rather than the virus as such, the health code also reveals crucial problems in the modernization and informatization of the state governance and public administration. A critique on the health code solely informed by privacy and personal data protection runs the risk of being co-opted by the government and technology companies deploying such tools to expand their surveillance and regulatory power. Copyright  2021 Cong.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhong, Wei</author><author>Hu, Qian</author><author>Kapucu, Naim</author></authors></contributors><titles><title>Robust crisis communication in turbulent times: Conceptualization and empirical evidence from the United States</title><secondary-title>Public Administration</secondary-title></titles><periodical><full-title>Public Administration</full-title></periodical><pages>158 - 181</pages><volume>101</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1111/padm.12855</electronic-resource-num><notes>Cited by: 16</notes><research-notes>Cited by: 16</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130283265&amp;doi=10.1111%2Fpadm.12855&amp;partnerID=40&amp;md5=1ff2e23318fdf999af030f8e27c9cb51</url></web-urls></urls><abstract>Drawing on recent research on robust governance, we conceptualize robust crisis communication as a dynamic process centered on evolving public communication demands. We propose a three-dimensional measurement for empirically examining the robustness of government crisis communication in the context of the COVID-19 pandemic. We collected 43,642 Twitter messages posted by 50 state governors in the United States from January 1 to June 30, 2020. We applied machine learning algorithms to code the voluminous Twitter data based on messaging topics, sentiments, and interactions. This study found an overall low level of robustness in the governors' crisis communication. Governors most frequently posted reputation management tweets, followed by tweets about the government's handling of the pandemic. This research presents empirical evidence for the heavy influence of politics on governors' crisis communication strategies and highlights the need to understand and build robust crisis communication. . 50202011202063043,642.  2022 John Wiley &amp; Sons Ltd.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Contiero, Barbara</author><author>Cozzi, Giulio</author><author>Karpf, Lee</author><author>Gottardo, Flaviana</author></authors></contributors><titles><title>Pain in Pig Production: Text Mining Analysis of the Scientific Literature</title><secondary-title>Journal of Agricultural and Environmental Ethics</secondary-title></titles><periodical><full-title>Journal of Agricultural and Environmental Ethics</full-title></periodical><pages>401 - 412</pages><volume>32</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s10806-019-09781-4</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067279001&amp;doi=10.1007%2Fs10806-019-09781-4&amp;partnerID=40&amp;md5=c8a12dd89fe5a8461aaceb036010c20d</url></web-urls></urls><abstract>Publics concern about poor animal welfare provided by intensive farming systems has increased over the last decades. This study reviewed the interest of the scientific research on the pain issue in pig production to assess if the societal instances may be a driving force for the research activity. A literature search protocol was set up to identify the peer-reviewed papers published between 1970 and 2017 that covered the topic of pain in pigs using Scopus, database of Elsevier. One hundred and thirty papers were selected and they were mainly focused on the practice of castration (64%) followed by tail docking (24%). The scientific community first focused on these painful practices as a way to improve production efficiency and quality issues while more recently, due to the increased pressure by the public opinion, turned its interest towards the search of alternative solutions. A text mining analysis on the abstract of the selected papers clearly indicated the effort of the research to explore solutions to alleviate pain. Evocative words of this target were the selected terms pharmacological analgesic and anaesthetic treatments. The text mining highlighted vocalizations as the main pain indicators in pigs as this term was frequently associated to acute stress. Ethical issues were a minor research topic in the scientific literature on pig breeding but in the short run, they are supposed to become a major subject to justify the acceptance of the modern production systems at the eyes of the consumers.  2019, The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Manegre, Marni</author><author>Sabiri, Kashif Ali</author></authors></contributors><titles><title>Online language learning using virtual classrooms: an analysis of teacher perceptions</title><secondary-title>Computer Assisted Language Learning</secondary-title></titles><periodical><full-title>Computer Assisted Language Learning</full-title></periodical><pages>973 - 988</pages><volume>35</volume><issue>5-6</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1080/09588221.2020.1770290</electronic-resource-num><notes>Cited by: 33</notes><research-notes>Cited by: 33</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086258056&amp;doi=10.1080%2F09588221.2020.1770290&amp;partnerID=40&amp;md5=12a42d4c3d900a0c3dd01e28ad585dfc</url></web-urls></urls><abstract>This study explains the emergence of virtual classrooms as an online language learning (OLL) instruction method. There is clarification of how virtual classroom systems operate, followed by a discussion of the benefits of learning in these environments. Private corporations are capitalizing on OLL and generating an estimated global gross income of 86 billion USD. While these corporations likely create quality educational materials that are of interest to the student, the materials presented in these platforms are currently not regulated, and, while some companies follow CEFR guidelines, there is no guarantee whether they meet the standards of education boards in the public sector. We surveyed 35 OLL teachers who teach English in virtual classrooms for their perceptions and opinions in working in this environment. Not only did we discover that over 50 percent of the online teachers who participated have also been students, which is of interest because they have both teaching and learning experience in virtual classrooms, but also that these teachers generally believe that teaching English online in virtual classrooms creates a positive teaching environment for both the teacher and the student. The participants generally feel they get to know the students better in virtual classrooms than in other teaching environments. The teachers also perceive that students in virtual classrooms learn at the same rate or faster than in traditional classrooms and that, not only would they like to see more subjects offered online, but they also generally believe that online learning in virtual classrooms may be an alternative learning method to replace traditional classroom learning and home-schooling in most subjects. Continued attention should be paid to the educational opportunities in virtual classrooms, not just for OLL, but for the emergence of other curricula as well.  2020 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hlter, Svenja M</author><author>Ertel, Christian</author><author>Heidemann, Ansgar</author></authors></contributors><titles><title>Exploring the individual adoption of human resource analytics: Behavioural beliefs and the role of machine learning characteristics</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>208</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.techfore.2024.123709</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202345905&amp;doi=10.1016%2Fj.techfore.2024.123709&amp;partnerID=40&amp;md5=6f310f5c943d1a055f4977dcd0d0815e</url></web-urls></urls><abstract>The technological capabilities of Human Resource Analytics (HRA), enhanced by recent innovations in Machine Learning (ML), offer exciting opportunities. However, organisations often fail to realise these potentials because of a limited understanding of why individuals choose to adopt or disregard respective tools. Prior research on innovation adoption offers preliminary insights but fails to aggregate the determinants of individual adoption into actionable suggestions for decisions in the ML adoption process. Our study applies focused interviews to examine non-ML experts' reasoning for using a specific tool tailored to a public sector organisation, which corresponds to the usual end-user perspective of ML-based HRA adoption. By drawing from the HRA adoption framework, provided by Vargas et al. (2018), we contribute to the literature by identifying relevant beliefs and experiences influencing one's intention to adopt ML-based HRA and by qualitatively linking these beliefs to ML characteristics such as transparency, automation and fairness. For practitioners, we provide actionable guidance emphasising the need to ensure fairness proactively, as interviewees do not consider this aspect when deciding to adopt ML-based HRA.  2024 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fertier, Audrey</author><author>Montarnal, Aurlie</author><author>Barthe-Delano, Anne-Marie</author><author>Truptil, Sbastien</author><author>Bnaben, Frdrick</author></authors></contributors><titles><title>Real-time data exploitation supported by model- and event-driven architecture to enhance situation awareness, application to crisis management</title><secondary-title>Enterprise Information Systems</secondary-title></titles><periodical><full-title>Enterprise Information Systems</full-title></periodical><pages>769 - 796</pages><volume>14</volume><issue>6</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1080/17517575.2019.1691268</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075751430&amp;doi=10.1080%2F17517575.2019.1691268&amp;partnerID=40&amp;md5=e228c8ac55142603a797ddbe5d73d375</url></web-urls></urls><abstract>An effective crisis response requires up-to-date information. The crisis cell must reach for new, external, data sources. However, new data lead to new issues: their volume, veracity, variety or velocity cannot be managed by humans only, especially under high stress and time pressure. This paper proposes (i) a framework to enhance situation awareness while managing the 5Vs of Big Data, (ii) general principles to be followed and (iii) a new architecture implementing the proposed framework. The latter merges event-driven and model-driven architectures. It has been tested on a realistic flood scenario set up by official French services.  2019,  2019 Informa UK Limited, trading as Taylor &amp; Francis Group.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Sowmya, Damodharan Varadarajan</author><author>Chandrasekaran, Anil</author><author>Patterson, Louise</author></authors></contributors><titles><title>An empirical study of leadership styles in the uae human resource strategy</title><secondary-title>Academy of Strategic Management Journal</secondary-title></titles><periodical><full-title>Academy of Strategic Management Journal</full-title></periodical><volume>17</volume><issue>6</issue><keywords/><dates><year>2018</year></dates><notes>Cited by: 6</notes><research-notes>Cited by: 6</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059887182&amp;partnerID=40&amp;md5=ebb5a91a5121d07c25cc6d3db6beda11</url></web-urls></urls><abstract>Introduction: This study focuses on eliciting the leadership styles used in the decisionmaking process against various organizational levels across different organizational types and the influence of the position, age, experience, department, education under differing situations among the employed people of UAE. Initially, the authors believed that participant's traits such as age, education would have the major impact rather than position-based experience, industry, and different situations on the leadership styles expressed. However, a deeper analysis and study of the data gathered from various organizations, the results were surprisingly different. Aim: The analysis of the study revealed how the participant's position, qualifications, experienced and industry affected the leadership styles. Some very interesting questions and situations have been attempted to understand the leadership style in this report based on a standard leadership style survey. This paper aims to report the findings of an empirical study exploring the relationship between three prominent models of leadership styles using the independent variables. Further, a Neural Network analysis methods and identify the most prominent influencer of the choice probability of leadership style. The independent variable which relates to the demographic and work-related includes factor such as age, gender, level of education, industry type, levels of management, total work experience, experience in the organization. Methodology: The study is an empirical study based on leadership questionnaire survey using multivariate analysis followed by neural network estimation on the data collected from employees across various levels of management in the UAE. Multifactor Leadership Questionnaire developed and administered as a means of objective assessment of the leadership style of various managers across the UAE followed by the categorizing of scores to identify prominent/explicit styles and dormant styles that were then analyzed based on modeling. Findings: The results reveal that the spectrum of three leadership styles containing basic characteristics, such as the type of branches, the age, and educational level are inter-related with communication, commitment, satisfaction, and effectiveness. The authors conclude that the unique setting and context found in the public sector-very much defined by the UAE Constitution-leads to subtle, but very real and noteworthy differences. The current literature around the world show that the private sector is more efficient than the public sector based on the various analyses. However, our research analyses gives a different picture for the UAE. The results shows that in the UAE the public sector is more effective and efficient than the private sector because of the leadership styles followed in this sector. Research Limitations/Implications: Limitations include the self-report methodology that measures perceptual data with a series of questionnaire items. The survey responses that were complete for analysis were more skewed towards the public sector as the other sectors did not respond well. Originality/Value: The paper is original research that identifies the characteristics of an organization linked to selected demographic (personal and professional) variables of all level of managers on their managerial style in the UAE.  2002-2019 Allied Business Academies.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Oswald, Marion</author><author>Grace, Jamie</author><author>Urwin, Sheena</author><author>Barnes, Geoffrey C</author></authors></contributors><titles><title>Algorithmic risk assessment policing models: Lessons from the Durham HART model and experimental proportionality</title><secondary-title>Information and Communications Technology Law</secondary-title></titles><periodical><full-title>Information and Communications Technology Law</full-title></periodical><pages>223 - 250</pages><volume>27</volume><issue>2</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1080/13600834.2018.1458455</electronic-resource-num><notes>Cited by: 105</notes><research-notes>Cited by: 105</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044749514&amp;doi=10.1080%2F13600834.2018.1458455&amp;partnerID=40&amp;md5=c6df75361f92320c53dd43d9b6e0bafe</url></web-urls></urls><abstract>As is common across the public sector, the UK police service is under pressure to do more with less, to target resources more efficiently and take steps to identify threats proactively; for example under riskassessment schemes such as Clares Law and Sarahs Law. Algorithmic tools promise to improve a police forces decisionmaking and prediction abilities by making better use of data (including intelligence), both from inside and outside the force. This article uses Durham Constabularys Harm Assessment Risk Tool (HART) as a case-study. HART is one of the first algorithmic models to be deployed by a UK police force in an operational capacity. Our article comments upon the potential benefits of such tools, explains the concept and method of HART and considers the results of the first validation of the models use and accuracy. The article then critiques the use of algorithmic tools within policing from a societal and legal perspective, focusing in particular upon substantive common law grounds for judicial review. It considers a concept of experimental proportionality to permit the use of unproven algorithms in the public sector in a controlled and time-limited way, and as part of a combination of approaches to combat algorithmic opacity, proposes ALGO-CARE, a guidance framework of some of the key legal and practical concerns that should be considered in relation to the use of algorithmic risk assessment tools by the police. The article concludes that for the use of algorithmic tools in a policing context to result in a better outcome, that is to say, a more efficient use of police resources in a landscape of more consistent, evidence-based decision-making, then an experimental proportionality approach should be developed to ensure that new solutions from big data can be found for criminal justice problems traditionally arising from clouded, non-augmented decision-making. Finally, this article notes that there is a sub-set of decisions around which there is too great an impact upon society and upon the welfare of individuals for them to be influenced by an emerging technology; to an extent, in fact, that they should be removed from the influence of algorithmic decision-making altogether.  2018 The Author(s).</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jonek-Kowalska, Izabela</author><author>Musio-Urbaczyk, Anna</author><author>Podgrska, Marzena</author><author>Wolny, Maciej</author></authors></contributors><titles><title>Does motivation matter in evaluation of research institutions? Evidence from Polish public universities</title><secondary-title>Technology in Society</secondary-title></titles><periodical><full-title>Technology in Society</full-title></periodical><volume>67</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.techsoc.2021.101782</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117132275&amp;doi=10.1016%2Fj.techsoc.2021.101782&amp;partnerID=40&amp;md5=f477260f83735d3df77afacff1b40f65</url></web-urls></urls><abstract>The ongoing internationalisation of economies more and more intensely influences the activity of the education and science sectorconsequently, the pressure to achieve the institutional and individual goals increases. Given these circumstances, the authors of this article decided to identify the relations between the type and scope of motivation used at universities and the evaluation results of their study and scientific activity. The study was carried out on Polish universities among a representative study sample of 1303 academics. For the analysis of the results, correlation analysis, regression models and data mining techniques were used. The research results indicated connections between the level of the study being carried out with such motivators as working in conditions of high innovativeness, wide access to publications and infrastructure, allowing for commercialisation of the study results. The increase in the quality level of the study is also fostered by the support and help of direct supervisors. What is demotivating is the periodic qualitative assessment and unproductive relations with the environment. The study results filled the gaps in the knowledge on the relations between the motivation and the evaluation of the university and between the range and type of motivators used in higher education.  2021 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Delfos, J</author><author>Zuiderwijk, A M G</author><author>van Cranenburgh, S</author><author>Chorus, C G</author><author>Dobbe, R I J</author></authors></contributors><titles><title>Integral system safety for machine learning in the public sector: An empirical account</title><secondary-title>Government Information Quarterly</secondary-title></titles><periodical><full-title>Government Information Quarterly</full-title></periodical><volume>41</volume><issue>3</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.giq.2024.101963</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201764597&amp;doi=10.1016%2Fj.giq.2024.101963&amp;partnerID=40&amp;md5=f307761584c81878e8fe6049c7717033</url></web-urls></urls><abstract>This paper introduces systems theory and system safety concepts to ongoing academic debates about the safety of Machine Learning (ML) systems in the public sector. In particular, we analyze the risk factors of ML systems and their respective institutional context, which impact the ability to control such systems. We use interview data to abductively show what risk factors of such systems are present in public professionals' perceptions and what factors are expected based on systems theory but are missing. Based on the hypothesis that ML systems are best addressed with a systems theory lens, we argue that the missing factors deserve greater attention in ongoing efforts to address ML systems safety. These factors include the explication of safety goals and constraints, the inclusion of systemic factors in system design, the development of safety control structures, and the tendency of ML systems to migrate towards higher risk. Our observations support the hypothesis that ML systems can be best regarded through a systems theory lens. Therefore, we conclude that system safety concepts can be useful aids for policymakers who aim to improve ML system safety.  2024</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hu, Yi-Chung</author></authors></contributors><titles><title>Combination forecasting using multiple attribute decision making in tourism demand</title><secondary-title>Tourism Review</secondary-title></titles><periodical><full-title>Tourism Review</full-title></periodical><pages>731 - 750</pages><volume>77</volume><issue>3</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1108/TR-09-2021-0451</electronic-resource-num><notes>Cited by: 10</notes><research-notes>Cited by: 10</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125150157&amp;doi=10.1108%2FTR-09-2021-0451&amp;partnerID=40&amp;md5=b0fde0cbf55084d13b18a8d437d3b677</url></web-urls></urls><abstract>Purpose: This study aims to address three important issues of combination forecasting in the tourism context: reducing the restrictions arising from requirements related to the statistical properties of the available data, assessing the weights of single models and considering nonlinear relationships among combinations of single-model forecasts. Design Methodology Approach: A three-stage multiple-attribute decision-making (MADM)-based methodological framework was proposed. Single-model forecasts were generated by grey prediction models for the first stage. Vlsekriterijumska Optimizacija I Kompromisno Resenje was adopted to develop a weighting scheme in the second stage, and the Choquet integral was used to combine forecasts nonlinearly in the third stage. Findings: The empirical results for inbound tourism in Taiwan showed that the proposed method can significantly improve accuracy to a greater extent than other combination methods. Along with scenario forecasting, a good forecasting practice can be further provided by estimating ex-ante forecasts post-COVID-19. Practical Implications: The private and public sectors in economies with high tourism dependency can benefit from the proposed method by using the forecasts to help them formulate tourism strategies. Originality Value: This study contributed to presenting a MADM-based framework that advances the development of a more accurate combination method for tourism forecasting.  2022, Emerald Publishing Limited.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kussl, Sebastian</author><author>Omberg, Kristian S</author><author>Lekang, Odd-Ivar</author></authors></contributors><titles><title>Advancing Vehicle Classification: A Novel Framework for Type, Model, and Fuel Identification Using Nonvisual Sensor Systems for Seamless Data Sharing</title><secondary-title>IEEE Sensors Journal</secondary-title></titles><periodical><full-title>IEEE Sensors Journal</full-title></periodical><pages>19390 - 19397</pages><volume>23</volume><issue>17</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1109/JSEN.2023.3289230</electronic-resource-num><notes>Cited by: 3</notes><research-notes>Cited by: 3</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163722393&amp;doi=10.1109%2FJSEN.2023.3289230&amp;partnerID=40&amp;md5=c5372e5070e661275457f168be3891a3</url></web-urls></urls><abstract>Vehicle classification (VC) down to type and model is exclusively visual-/image-based and struggles with restricted data availability and latency in data-sharing toward an increasing market of public and private mobility service providers. This article presents a framework architecture for VC down to type and model using a microelectromechanical systems (MEMS) intrusive magnetic sensor system combined with advanced machine learning (ML). The framework follows the principles of 'privacy-by-design' (PbD) and adds fuel identification as a new attribute. The framework was validated in an experiment on nine predefined passenger car models, confirming the capability of nonvisual sensors to classify vehicle type, model, and fuel. This innovative approach has the potential to significantly impact how transport and infrastructure agencies collect, process, and share intelligent traffic monitoring systems (ITMS) data in the future, providing more accurate and detailed information for improving roadway utilization efficiency, predicting transportation needs, enhancing transportation safety, and reducing environmental impact. The work proposes a system framework, experimental design, and evaluation against automatic number plate recognition. The evaluation involved collaboration among various partners, including academia, public road administration, and private companies, with diverse interests that need to be preserved due to significant development progress.   2001-2012 IEEE.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Merhi, Mohammad I</author></authors></contributors><titles><title>Evaluating the critical success factors of data intelligence implementation in the public sector using analytical hierarchy process</title><secondary-title>Technological Forecasting and Social Change</secondary-title></titles><periodical><full-title>Technological Forecasting and Social Change</full-title></periodical><volume>173</volume><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.techfore.2021.121180</electronic-resource-num><notes>Cited by: 21</notes><research-notes>Cited by: 21</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114125763&amp;doi=10.1016%2Fj.techfore.2021.121180&amp;partnerID=40&amp;md5=0789d492ad5068a120a6a2b024e925df</url></web-urls></urls><abstract>This study aims to fill a gap in the literature by identifying, defining, and evaluating the critical success factors that impact the implementation of data intelligence in the public sector. Fourteen factors were identified, and then divided into three categories: organization, process, and technology. We used the analytical hierarchy process, a quantitative method of decision-making, to evaluate the importance of the factors presented in the study using data collected from nine experts. The results showed that technology, as a category, is the most important. The analysis also indicated that project management, information systems &amp; data, and data quality are the most important factors among all fourteen critical success factors. We discuss the implications of the analysis for practitioners and researchers in the paper.  2021</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Coglianese, Cary</author><author>Lai, Alicia</author></authors></contributors><titles><title>ALGORITHM VS. ALGORITHM</title><secondary-title>Duke Law Journal</secondary-title></titles><periodical><full-title>Duke Law Journal</full-title></periodical><pages>1281 - 1340</pages><volume>71</volume><issue>6</issue><keywords/><dates><year>2022</year></dates><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125709723&amp;partnerID=40&amp;md5=e955527b82192394f71fa9d54132b2aa</url></web-urls></urls><abstract>Critics raise alarm bells about governmental use of digital algorithms, charging that they are too complex, inscrutable, and prone to bias. A realistic assessment of digital algorithms, though, must acknowledge that government is already driven by algorithms of arguably greater complexity and potential for abuse: the algorithms implicit in human decision-making. The human brain operates algorithmically through complex neural networks. And when humans make collective decisions, they operate via algorithms toothose reflected in legislative, judicial, and administrative processes. Yet these human algorithms undeniably fail and are far from transparent. On an individual level, human decision-making suffers from memory limitations, fatigue, cognitive biases, and racial prejudices, among other problems. On an organizational level, humans succumb to groupthink and free riding, along with other collective dysfunctionalities. As a result, human decisions will in some cases prove far more problematic than their digital counterparts. Digital algorithms, such as machine learning, can improve governmental performance by facilitating outcomes that are more accurate, timely, and consistent. Still, when deciding whether to deploy digital algorithms to perform tasks currently completed by humans, public officials should proceed with care on a case-by-case basis. They should consider both whether a particular use would satisfy the basic preconditions for successful machine learning and whether it would in fact lead to demonstrable improvements over the status quo. The question about the future of public administration is not whether digital algorithms are perfect. Rather, it is a question about what will work better: human algorithms or digital ones.  2022,Duke Law Journal. All Rights Reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rangone, Nicoletta</author></authors></contributors><titles><title>Intelligenza artificiale e pubbliche amministrazioni: affrontare i numerosi rischi per trarne tutti i vantaggi; [ARTIFICIAL INTELLIGENCE AND PUBLIC ADMINISTRATIONS: ADDRESSING THE MANY RISKS TO GAIN ALL THE BENEFITS]</title><secondary-title>BioLaw Journal</secondary-title></titles><periodical><full-title>BioLaw Journal</full-title></periodical><pages>473 - 488</pages><volume>2022</volume><issue>2</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.15168/2284-4503-2350</electronic-resource-num><notes>Cited by: 1</notes><research-notes>Cited by: 1</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135095978&amp;doi=10.15168%2F2284-4503-2350&amp;partnerID=40&amp;md5=988e1d8b7dd9556a92ac114aaf7a94f1</url></web-urls></urls><abstract>The paper aims at analysing the most relevant examples of the use of artificial intelligence within the Italian public administrations, in order to highlight related benefits and risks. It focuses on the internal organization, rulemaking and enforcement decisions. There appears to be a need for a general regulatory framework, as well as for specific procedural disciplines in each administration in order to allow real accessibility, comprehensibility and non-discrimination for the stakeholders. At the same time, these disciplines should introduce mechanisms and evaluation adequate to verify the appropriateness of the use of artificial intelligence instead of human intelligence, with a view to the effectiveness of organization and administrative action.  2022. All Rights Reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chaudhary, Megha</author><author>Bansal, Divya</author></authors></contributors><titles><title>Open source intelligence extraction for terrorism-related information: A review</title><secondary-title>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</secondary-title></titles><periodical><full-title>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</full-title></periodical><volume>12</volume><issue>5</issue><keywords/><dates><year>2022</year></dates><electronic-resource-num>10.1002/widm.1473</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133547962&amp;doi=10.1002%2Fwidm.1473&amp;partnerID=40&amp;md5=56381c931174ffdc73145c4045cbb53e</url></web-urls></urls><abstract>In this contemporary era, where a large part of the world population is deluged by extensive use of the internet and social media, terrorists have found it a potential opportunity to execute their vicious plans. They have got a befitting medium to reach out to their targets to spread propaganda, disseminate training content, operate virtually, and further their goals. To restrain such activities, information over the internet in context of terrorism needs to be analyzed to channel it to appropriate measures in combating terrorism. Open Source Intelligence (OSINT) accounts for a felicitous solution to this problem, which is an emerging discipline of leveraging publicly accessible sources of information over the internet by effectively utilizing it to extract intelligence. The process of OSINT extraction is broadly observed to be in three phases (i) Data Acquisition, (ii) Data Enrichment, and (iii) Knowledge Inference. In the context of terrorism, researchers have given noticeable contributions in compliance with these three phases. However, a comprehensive review that delineates these research contributions into an integrated workflow of intelligence extraction has not been found. The paper presents the most current review in OSINT, reflecting how the various state-of-the-art tools and techniques can be applied in extracting terrorism-related textual information from publicly accessible sources. Various data mining and text analysis-based techniques, that is, natural language processing, machine learning, and deep learning have been reviewed to extract and evaluate textual data. Additionally, towards the end of the paper, we discuss challenges and gaps observed in different phases of OSINT extraction. This article is categorized under: Application Areas &gt; Government and Public Sector Commercial, Legal, and Ethical Issues &gt; Social Considerations Fundamental Concepts of Data and Knowledge &gt; Motivation and Emergence of Data Mining.  2022 Wiley Periodicals LLC.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Mengji</author><author>Xu, Shan</author><author>Husain, Lewis</author><author>Galea, Gauden</author></authors></contributors><titles><title>Digital health interventions for COVID-19 in China: a retrospective analysis</title><secondary-title>Intelligent Medicine</secondary-title></titles><periodical><full-title>Intelligent Medicine</full-title></periodical><pages>29 - 36</pages><volume>1</volume><issue>1</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.imed.2021.03.001</electronic-resource-num><notes>Cited by: 14</notes><research-notes>Cited by: 14</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127092627&amp;doi=10.1016%2Fj.imed.2021.03.001&amp;partnerID=40&amp;md5=a7cb429f52fba17270bfed2276b4e656</url></web-urls></urls><abstract>Background: The use of digital health technologies was an integral part to China's early response to coronavirus disease 2019 (COVID-19). Existing literatures have analyzed and discussed implemented digital health innovations from the perspective of technologies, whereas how policy mechanisms contributed to the formulation of the digital health landscape for COVID-19 was overlooked. This study aimed to examine the contexts and key mechanisms in China's rapid mobilization of digital health interventions in response to COVID-19, and to document and share lessons learned. Methods: Policy documents were identified and retrieved from government portals and recognized media outlets. Data on digital health interventions were collected through three consecutive surveys administered between 23 January 2020 and 31 March 2020 by China Academy of Information and Communication Technology (CAICT) affiliated to the Ministry of Industry and Information Technology (MIIT). Participants were member companies of the Internet Health alliance established by MIIT and the National Health Commission (NHC) in June 2016. Self-report digital interventions focusing on social and economic recovery were excluded. Two hundred and sixty-six unique digital health interventions meeting our criteria were extracted from 175 narratives on digital health interventions submitted by 116 participating companies. Thematic analysis was conducted to describe the scope and priority of policies advocating for the use of digital health technologies and the implementation pattern of digital health interventions. Data limitations precluded an evaluation of the impact of digital health interventions over a longer time frame. Results: Between January and March 2020, national policy directives promoting the use of digital technologies for the containment of COVID-19 collectively advocated for use cases in emergency planning and preparedness, public health response, and clinical services. Interventions to strengthen clinical services were mentioned more than the other two themes (n = 15, 62.5% (15/24)). Using digital technologies for public health response was mentioned much less than clinical services (n = 5, 20.8% (5/24)). Emergency planning and preparedness was least mentioned (n = 4, 16.7% (4/24)). Interventions in support of clinical services disproportionately favored healthcare facilities in less resource-constraint settings. Digital health interventions shared the same pattern of distribution. More digital health technologies were implemented in clinical services (n = 103, 38.7% (103/266)) than that in public health response (n = 91, 34.2% (91/266)). Emergency planning and preparedness had the least self-reported digital health interventions (n = 72, 27.1% (72/266)). We further identified case studies under each theme in which the wide use of digital health technologies highlighted contextual factors and key enabling mechanisms. Conclusions: The contextual factors and key enabling mechanisms through the use of policy instruments to promote digital health interventions for COVID-19 in China include pathway of policy directives influencing the private sector using a decentralized system, the booming digital health landscape before COVID-19, agility of the public sector in introducing regulatory flexibilities and incentives to mobilize the private sector.  2021</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jiang, Peng</author><author>Hu, Yi-Chung</author></authors></contributors><titles><title>Constructing interval models using neural networks with non-additive combinations of grey prediction models in tourism demand</title><secondary-title>Grey Systems</secondary-title></titles><periodical><full-title>Grey Systems</full-title></periodical><pages>58 - 77</pages><volume>13</volume><issue>1</issue><keywords/><dates><year>2023</year></dates><electronic-resource-num>10.1108/GS-11-2021-0180</electronic-resource-num><notes>Cited by: 11</notes><research-notes>Cited by: 11</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133543602&amp;doi=10.1108%2FGS-11-2021-0180&amp;partnerID=40&amp;md5=f94f22c6216064a849aa1c87bf8ac126</url></web-urls></urls><abstract>Purpose: In contrast to point forecasts, interval forecasts provide information on future variability. This research thus aimed to develop interval prediction models by addressing two significant issues: (1) a simple average with an additive property is commonly used to derive combined forecasts, but this unreasonably ignores the interaction among sequences used as sources of information, and (2) the time series often does not conform to any statistical assumptions. Design/methodology/approach: To develop an interval prediction model, the fuzzy integral was applied to nonlinearly combine forecasts generated by a set of grey prediction models, and a sequence including the combined forecasts was then used to construct a neural network. All required parameters relevant to the construction of an interval model were optimally determined by the genetic algorithm. Findings: The empirical results for tourism demand showed that the proposed non-additive interval model outperformed the other interval prediction models considered. Practical implications: The private and public sectors in economies with high tourism dependency can benefit from the proposed model by using the forecasts to help them formulate tourism strategies. Originality/value: In light of the usefulness of combined point forecasts and interval model forecasting, this research contributed to the development of non-additive interval prediction models on the basis of combined forecasts generated by grey prediction models.  2022, Emerald Publishing Limited.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bradonjic, Philip</author><author>Franke, Nikolaus</author><author>Lthje, Christian</author></authors></contributors><titles><title>Decision-makers underestimation of user innovation</title><secondary-title>Research Policy</secondary-title></titles><periodical><full-title>Research Policy</full-title></periodical><pages>1354 - 1361</pages><volume>48</volume><issue>6</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1016/j.respol.2019.01.020</electronic-resource-num><notes>Cited by: 49</notes><research-notes>Cited by: 49</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062231312&amp;doi=10.1016%2Fj.respol.2019.01.020&amp;partnerID=40&amp;md5=3f2624a50bae40c9de5c23b9164b7799</url></web-urls></urls><abstract>In the past few decades, much research has documented the importance of users as sources of innovations. Over the last 10 years, Research Policy alone has published 56 research articles investigating this phenomenon. We ask to what degree the findings of users as innovators have been absorbed by decision-makers responsible for new product development (managers) and by those who shape the contextual conditions for innovation (policy makers and public administration). A realistic perception of the sources of innovation is important as it constitutes the basis for a rational allocation of resources and thus indirectly impacts the innovation performance of companies and societies at large. In a large-scale survey of n = 1500 decision-makers, we found support for a substantial underestimation of users as a source of innovation: While the true proportion of user innovation among the most valuable 1678 innovations in nine industries is 54.4% (as established in existing research articles), decision-makers estimate it to be 21.7%. A content analysis of transfer media (450 academic textbooks, popular innovation books, and business articles) underscores this theory-practice gap: Of 3469 text paragraphs dealing with the sources of innovation, only 2.7% mention users as innovators. We develop six propositions on the reasons for and consequences of this underestimation that may serve as a starting point for future research and practical consequences.  2019 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hashim, Hasan</author></authors></contributors><titles><title>E-government impact on developing smart cities initiative in Saudi Arabia: Opportunities &amp; challenges</title><secondary-title>Alexandria Engineering Journal</secondary-title></titles><periodical><full-title>Alexandria Engineering Journal</full-title></periodical><pages>124 - 131</pages><volume>96</volume><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.1016/j.aej.2024.04.008</electronic-resource-num><notes>Cited by: 2</notes><research-notes>Cited by: 2</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189864367&amp;doi=10.1016%2Fj.aej.2024.04.008&amp;partnerID=40&amp;md5=4036c8fdcbc9a2df07dc18026332daa8</url></web-urls></urls><abstract>Information and communication technologies (ICT) have a recent impact on governance and public administration. Electronic government (e-government) services were created to streamline administrative processes and enhance citizen engagement on the one hand, and to build new governance models that would empower individuals, involve them in the decision-making process, and increase transparency on the other. Many individuals are doubtful about smart city projects because of the security issues that arise in such environments. In essence, internet of things gadgets are security flaws. Concerns about the proliferation of IoT sensors and the tighter coupling of infrastructure silos in cities are well-founded. The major objective of the study is to identify the influencing factors of smart cities on e-government in Saudi Arabia. Additionally, this research explores the definition of e-government, and its supporting technologies like smart cities, IoT, big data, cloud computing and other digital government platforms. After exploring the detailed definitions, the study identifies the challenging scenarios of e-government in Saudi Arabia, and discusses the different opportunities. This study also concentrates on the good practices to be followed to overcome the challenges. Furthermore, this study can be used in future research for solving real time challenges of e-government.  2024 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fatima, Samar</author><author>Desouza, Kevin C</author><author>Dawson, Gregory S</author></authors></contributors><titles><title>National strategic artificial intelligence plans: A multi-dimensional analysis</title><secondary-title>Economic Analysis and Policy</secondary-title></titles><periodical><full-title>Economic Analysis and Policy</full-title></periodical><pages>178 - 194</pages><volume>67</volume><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.1016/j.eap.2020.07.008</electronic-resource-num><notes>Cited by: 77</notes><research-notes>Cited by: 77</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088951674&amp;doi=10.1016%2Fj.eap.2020.07.008&amp;partnerID=40&amp;md5=ac89bbeb30219b35234f7a809685c74b</url></web-urls></urls><abstract>Nations have recognized the transformational potential of artificial intelligence (AI). Advances in AI will impact all facets of society. A spate of recently released national strategic AI plans provides valuable insights into how nations are considering their future trajectories. These strategic plans offer a rich source of evidence to understand national-level strategic actions, both proactive and reactive, in the face of rapid technological innovation. Based on a comprehensive content analysis of thirty-four national strategic plans, this article reports on (1) opportunities for AI to modernize the public sector and enhance industry competitiveness, (2) the role of the public sector in ensuring that the two most critical elements of AI systems, data and algorithms, are managed responsibly, (3) the role of the public sector in the governance of AI systems, and (4) how nations plan to invest in capacity development initiatives to strengthen their AI capabilities.  2020 Economic Society of Australia, Queensland</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Scannapieco, Monica</author><author>Virgillito, Antonino</author></authors></contributors><titles><title>How to be responsible in all the steps of a data science pipeline: The case of the Italian public sector</title><secondary-title>Patterns</secondary-title></titles><periodical><full-title>Patterns</full-title></periodical><volume>2</volume><issue>12</issue><keywords/><dates><year>2021</year></dates><electronic-resource-num>10.1016/j.patter.2021.100393</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123699030&amp;doi=10.1016%2Fj.patter.2021.100393&amp;partnerID=40&amp;md5=59508b82ca85b4bd4c7c7900835c15bc</url></web-urls></urls><abstract>The paper highlights how each step of a data science pipeline can be performed in a responsible way, taking into account privacy, ethics, and quality issues. Several examples from the Italian public sector contribute to clarifying how data collections and data analyses can be carried out under a responsible view.  2021 The Authors</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kurmangali, Medeu</author><author>Yeraliyeva, Yana</author><author>Beimisheva, Aigul</author></authors></contributors><titles><title>DIGITALIZATION AND ARTIFICIAL INTELLIGENCE IN CENTRAL ASIA: GOVERNMENTAL RESPONSES AND FURTHER IMPLICATIONS; [SKAITMENINIMAS IR DIRBTINIS INTELEKTAS VIDURINJE AZIJOJE: IKIAI IR POVEIKIS VYRIAUSYBMS]</title><secondary-title>Public Policy and Administration</secondary-title></titles><periodical><full-title>Public Policy and Administration</full-title></periodical><pages>146 - 159</pages><volume>23</volume><issue>2</issue><keywords/><dates><year>2024</year></dates><electronic-resource-num>10.13165/VPA-24-23-2-03</electronic-resource-num><notes>Cited by: 0</notes><research-notes>Cited by: 0</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197797777&amp;doi=10.13165%2FVPA-24-23-2-03&amp;partnerID=40&amp;md5=2b06d077e517bf0d2fc22746ab3ea89e</url></web-urls></urls><abstract>Digitalization and new technologies are now firmly on the agendas of governments worldwide. New technological trends have not only become catalysts for economic development, but are also reshaping how the public sector works and implements its policies. Amid technological transformations, the countries of Central Asia are searching for new ways to adapt to these changes. This paper aims to assess these attempts by exploring the digitalization policies of the five Central Asian countries. By using qualitative methods and expert interviews, the article identifies key limitations and potential areas of development for the Central Asian states regarding digitalization and artificial intelligence. By providing valuable insights, the article contributes to a deeper understanding of the digitalization challenges faced by developing countries. Through the analysis of local expert opinions, the article seeks to contribute valuable insights to the distinct approaches adopted by these countries, thus enriching the understanding of the regions trajectory in the digital era.  2024 Mykolo Romerio Universitetas. All rights reserved.</abstract></record><record><database name="JIF-Q1-Article-database-262.enl" path="JIF-Q1-Article-database-262.enl">JIF-Q1-Article-database-262.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cha, Heewon</author><author>Rhee, Yunna</author><author>Chung, Chung Joo</author></authors></contributors><titles><title>Comparative nation-branding analysis of Big Data: Focusing on Korea and Japan</title><secondary-title>Journal of Global Information Technology Management</secondary-title></titles><periodical><full-title>Journal of Global Information Technology Management</full-title></periodical><pages>276 - 295</pages><volume>20</volume><issue>4</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.1080/1097198X.2017.1388697</electronic-resource-num><notes>Cited by: 8</notes><research-notes>Cited by: 8</research-notes><language>English</language><urls><web-urls><url>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042855729&amp;doi=10.1080%2F1097198X.2017.1388697&amp;partnerID=40&amp;md5=d32dfd2fef5624d1438b3b6e7d4bb7ff</url></web-urls></urls><abstract>This exploratory research used Google to collect atypical data concerning Korea and Japans nation branding and used these to provide a structural description of the international perspectives of the countries cultures. Japan differs from Korea by focusing on developing various media, content, and geographical factors through fostering and supporting private-run local brands; also, variations relating to history, strategy, and system have resulted in different online nation-branding practices between the two countries. This study proposes several methods of enhancing nation branding and suggests further analysis of both private and public sector discussions, traditional and up-to-date channels, and various media content.  2017 Heewon Cha, Yunna Rhee and Chung Joo Chung  2017 Heewon Cha, Yunna Rhee and Chung Joo Chung.</abstract></record></records></xml>
