{"title": "Accountable Artificial Intelligence: Holding Algorithms to Account",
"doi_number": "10.1111/puar.13293",
"research_approach": "Qualitative",
"research_method": "Conceptual analysis",
"analysis_techniques": "descriptive analysis",
"research_topics": "Theoretical studies",
"research_context": "control and governance",
"analysis_level": "Macro",
"geographical_context": "not specified",
"government_level": "Others (not specified)",
"theoretical_background": "Unspecified",
"technology_discussed": "Artificial Intelligence/General",
"research_description": "This paper discusses the accountability challenges posed by the increasing use of AI algorithms in the public sector. It examines the implications of opaque, complex AI models for public accountability and provides policy recommendations for improving algorithmic transparency and interpretability.",
"research_results": "The study highlights that AI algorithms, particularly deep learning models, pose significant accountability challenges due to their opacity and complexity. Public sector bodies face difficulties in ensuring oversight and holding AI systems accountable, necessitating the adoption of transparent, interpretable models.",
"future_research": "Future research should explore practical ways to improve AI transparency in the public sector and develop frameworks for holding AI systems accountable, particularly in high-stakes decision-making scenarios."}