{"title": "Human\u2013AI Interactions in Public Sector Decision Making: Automation Bias and Selective Adherence to Algorithmic Advice", "doi_number": "10.1093/jopart/muac007", "research_approach": "Quantitative", "research_method": "Survey", "analysis_techniques": "Logistic regression analysis; Descriptive statistics; Simulation/experiment", "research_topics": "Determinants, risks and impacts", "research_context": "Public services/decision making", "analysis_level": "Micro", "geographical_context": "Netherlands", "government_level": "National", "theoretical_background": "Unspecified", "technology_discussed": "Artificial Intelligence; Algorithmic decision making", "research_description": "The study investigates how automation bias and selective adherence to algorithmic advice affect public sector decision making. Through three experimental studies, it examines whether participants, including Dutch civil servants, are more likely to trust AI-generated decisions or human-expert advice and whether they selectively adhere to advice based on stereotypes.", "research_results": "The results show no significant automation bias, with decision-makers not favoring AI over human-expert advice. However, selective adherence to advice based on group stereotypes was evident, particularly in cases where the advice aligned with negative preconceptions about minority groups.", "future_research": "Future research could explore how heightened awareness of algorithmic bias, especially following public scandals like the Dutch childcare benefits scandal, impacts decision-making behavior in bureaucratic contexts."}